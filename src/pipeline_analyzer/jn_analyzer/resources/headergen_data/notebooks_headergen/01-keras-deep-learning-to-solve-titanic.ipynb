{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregularizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m l1\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[0;32m~/miniconda3/envs/notebooks/lib/python3.11/site-packages/keras/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/miniconda3/envs/notebooks/lib/python3.11/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/miniconda3/envs/notebooks/lib/python3.11/site-packages/keras/engine/functional.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.regularizers import l1\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# ignore Deprecation Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import os\n",
    "\n",
    "train_orj = pd.read_csv(\"../input/train.csv\", header=0)\n",
    "test_orj = pd.read_csv(\"../input/test.csv\", header=0)\n",
    "train_orj.head()\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_orj.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "facfa03728a1b6f9022048d24900fb877419c784"
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \n",
    "    #Kabin\n",
    "    data.Cabin.fillna('9', inplace=True)\n",
    "    #data['Cabin'].replace('0', 9, inplace=True)\n",
    "    data.loc[data.Cabin.str[0] == 'A', 'Cabin'] = 1\n",
    "    data.loc[data.Cabin.str[0] == 'B', 'Cabin'] = 2\n",
    "    data.loc[data.Cabin.str[0] == 'C', 'Cabin'] = 3\n",
    "    data.loc[data.Cabin.str[0] == 'D', 'Cabin'] = 4\n",
    "    data.loc[data.Cabin.str[0] == 'E', 'Cabin'] = 5\n",
    "    data.loc[data.Cabin.str[0] == 'F', 'Cabin'] = 6\n",
    "    data.loc[data.Cabin.str[0] == 'G', 'Cabin'] = 7\n",
    "    data.loc[data.Cabin.str[0] == 'T', 'Cabin'] = 8\n",
    "    data = data.drop([\"Cabin\"],axis=1)\n",
    "\n",
    "    # Cinsiyeti tam sayıya çevirelim\n",
    "    data['Sex'].replace('female', 1, inplace=True)\n",
    "    data['Sex'].replace('male', 2, inplace=True)\n",
    "    \n",
    "    # Gemiye biniş limanlarını tam sayıya çevirelim\n",
    "    data['Embarked'].replace('S', 1, inplace=True)\n",
    "    data['Embarked'].replace('C', 2, inplace=True)\n",
    "    data['Embarked'].replace('Q', 3, inplace=True)\n",
    "    \n",
    "    # Olmayan (NA) yaş değerlerini medyan ile dolduralım\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    #data['Age'] = [0 if each >= 60 else 1 if each >= 35 else 2 if each >= 18 else 3 if each >= 12 else 4 if each >= 5 else 5 for each in data['Age']]\n",
    "   \n",
    "    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "    data['Embarked'].fillna(data['Embarked'].median(), inplace=True)\n",
    "    \n",
    "    data = data.drop([\"Ticket\"],axis=1)\n",
    "    data = data.drop([\"Fare\"],axis=1)\n",
    "    data['SibSp'].replace(0, 9, inplace=True)\n",
    "    data['Parch'].replace(0, 9, inplace=True)\n",
    "    return data\n",
    "\n",
    "def group_titles(data):\n",
    "    #data['Names'] = data['Name'].map(lambda x: len(re.split(' ', x)))\n",
    "    data['Title'] = data['Name'].map(lambda x: re.search(', (.+?) ', x).group(1))\n",
    "    data['Title'].replace('Master.', 1, inplace=True)\n",
    "    data['Title'].replace('Mr.', 2, inplace=True)\n",
    "    data['Title'].replace(['Ms.','Mlle.', 'Miss.'], 3, inplace=True)\n",
    "    data['Title'].replace(['Mme.', 'Mrs.'], 4, inplace=True)\n",
    "    data['Title'].replace(['Dona.', 'Lady.', 'the Countess.', 'Capt.', 'Col.', 'Don.', 'Dr.', 'Major.', 'Rev.', 'Sir.', 'Jonkheer.', 'the'], 5, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d05c1efea8ba5e4e3008d395df3a3abed3ad572a"
   },
   "outputs": [],
   "source": [
    "train = train_orj.copy().drop([\"PassengerId\"],axis=1)\n",
    "train=preprocess(train)\n",
    "train=group_titles(train)\n",
    "train = train.drop([\"Name\"],axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a29acfbda9afd7569858a496b42b841f73f2510"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "499a867e84b4afc5b6e7f94d238ef3193d5bdc24"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(train.Age, palette=\"icefire\")\n",
    "#train.Age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "299a4f206b1dba1e38edd31e9f67d87cd2a1bd5b"
   },
   "outputs": [],
   "source": [
    "x = train.iloc[:,1:train.shape[1]].values #bağımsız değişkenler\n",
    "y = train.Survived.values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x, y, test_size = 0.1, random_state=2)\n",
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_test shape\",X_val.shape)\n",
    "print(\"y_train shape\",Y_train.shape)\n",
    "print(\"y_test shape\",Y_val.shape)\n",
    "\n",
    "\n",
    "#Y_train=np.array(Y_train).astype(int)\n",
    "#X_train=np.array(X_train).astype(float)\n",
    "#Y_val = np.array(Y_val).astype(int)\n",
    "#X_val = np.array(X_val).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8981e7fcb315c6aece7948257d5d804ed9a42995"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(Y_train, palette=\"icefire\")\n",
    "plt.title(\"Number of Survived classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "760749aad03ad34562ba669eab9f2c8c961ef50e"
   },
   "outputs": [],
   "source": [
    "#model 1\n",
    "'''\n",
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_length-1, activation='softplus'))\n",
    "model.add(Dense(32, activation='softplus'))\n",
    "model.add(Dense(16, activation='softplus'))  \n",
    "model.add(Dense(8, activation='softplus')) \n",
    "model.add(Dense(1, activation='softplus'))\n",
    "\n",
    "lr = .001\n",
    "adam0 = Adam(lr = lr)\n",
    "\n",
    "# Modeli derleyip ve daha iyi bir sonuç elde edildiğinde ağırlıkları kaydedelim\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam0, metrics=['accuracy'])\n",
    "filepath = 'weights.best.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history_model = model.fit(X_train, Y_train, callbacks=callbacks_list, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e943c35d044c8e76eb83baad9b7b420f383a1333",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model 2\n",
    "model = Sequential()\n",
    "\n",
    "# layers\n",
    "model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "history = model.fit(X_train, Y_train, batch_size = 32, epochs = 300, validation_data = (X_val,Y_val))\n",
    "\n",
    "scores = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"%s: %.3f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "487c5432ed4a6ef8f5e2583e1a93423716e6350f"
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "plt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6be620cee72b5b9f411c0daa3ab4dadbe58f223"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Predict the values from the validation dataset\n",
    "y_pred = model.predict(X_val)\n",
    "y_final = (y_pred > 0.5).astype(int).reshape(X_val.shape[0])\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_val, y_final) \n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eced493bb8226d199354caefee1bb69e15e8bc28"
   },
   "outputs": [],
   "source": [
    "# model 3\n",
    "'''\n",
    "from keras.layers import Input\n",
    "import keras\n",
    "from keras.models import Model\n",
    "\n",
    "def DenseNet(X_train):\n",
    "    ip = Input(shape=(X_train.shape[1],))\n",
    "    x_list = [ip]\n",
    "    \n",
    "    x = Dense(128, use_bias=False)(ip)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x_list.append(x)\n",
    "    x = keras.layers.concatenate(x_list)    \n",
    "    x = Dense(128, use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x_list.append(x)\n",
    "    x = keras.layers.concatenate(x_list)    \n",
    "    x = Dense(64, use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x_list.append(x)\n",
    "    x = keras.layers.concatenate(x_list)    \n",
    "    x = Dense(64, use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x_list.append(x)\n",
    "    x = keras.layers.concatenate(x_list)    \n",
    "    x = Dense(32, use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x_list.append(x)\n",
    "    x = keras.layers.concatenate(x_list)    \n",
    "    x = Dense(32, use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x_list.append(x)\n",
    "    x = keras.layers.concatenate(x_list)    \n",
    "    x = Dense(16, use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x_list.append(x)\n",
    "    x = keras.layers.concatenate(x_list)    \n",
    "    x = Dense(16, use_bias=False)(ip)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)    \n",
    "    \n",
    "    op = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=ip, outputs=op)\n",
    "    adam = Adam(lr=0.05,)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = DenseNet(X_train)\n",
    "history_model=model.fit(X_train, Y_train, epochs=32, batch_size=200, verbose=0,\n",
    "          validation_split=0.1)\n",
    "scores = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"%s: %.3f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "417caaedebc5cd53925d6b69a0639a2db2c91364"
   },
   "outputs": [],
   "source": [
    "test = test_orj.copy()\n",
    "test=preprocess(test)\n",
    "test=group_titles(test)\n",
    "test = test.drop([\"Name\"],axis=1)\n",
    "test.head()\n",
    "#print(test.Title.value_counts())\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "959d59cae62b742c04c82b04530de86acc96ea67"
   },
   "outputs": [],
   "source": [
    "sns.countplot(test.Age, palette=\"icefire\")\n",
    "#train.Age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "816ff32b1086e438cd245d46c927bd81346eadfc"
   },
   "outputs": [],
   "source": [
    "test_ids = test.iloc[:,0].values #test_orj['PassengerId'].copy()\n",
    "testdata = test.iloc[:,1:test.shape[1]].values #bağımsız değişkenler\n",
    "X_test =testdata # np.array(testdata).astype(float)\n",
    "\n",
    "#print(len(X_test))\n",
    "#print(X_test[0])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_final = (y_pred > 0.5).astype(int).reshape(X_test.shape[0])\n",
    "#print(len(y_final))\n",
    "output = pd.DataFrame({'PassengerId': test_orj['PassengerId'], 'Survived': y_final})\n",
    "output.to_csv('prediction-ann_0150.csv', index=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(y_final, palette=\"icefire\")\n",
    "plt.title(\"(Test data) Number of Survived classes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebooks]",
   "language": "python",
   "name": "conda-env-notebooks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
