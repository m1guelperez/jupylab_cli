{
    "cells": [
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "import os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, log_loss\nimport pandas as pd\nimport numpy as np\nimport time\nimport random\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\n\nMODEL_PATH = ''\n\n\ntrain_df = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv',index_col='ID_code')\ntest_df = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv',index_col='ID_code')\n\nsynthetic_indices = np.load('../input/synthetissantandersamples/synthetic_samples_indexes.npy')\nmask=np.full(len(test_df),True,dtype=bool)\nmask[synthetic_indices]=False\ntest_df_nonsynthetic = test_df.iloc[mask].reset_index(drop=True).copy()\n\n\ny = train_df.pop('target')\ntarget = y\n\ntr_te = pd.concat([train_df,test_df])\n\nnum_cols = [c for c in train_df.columns]\n\nfor f in tqdm(num_cols):\n    tr_te[f+'_counts'] = tr_te[f].map(pd.concat([train_df[f], test_df_nonsynthetic[f]], axis=0).value_counts().to_dict(), na_action='ignore')\n    tr_te[f+'_counts'] = tr_te[f+'_counts'].fillna(1)\n\n\ncount_cols = [f+'_counts' for f in num_cols]\n\n\nfrom scipy.special import erfinv\nfrom scipy.stats import rankdata\n\ndef rankgauss(x):\n    r = (rankdata(x) - 1) / len(x)  # to [0,1]\n    r = 2 * r - 1  # to [-1,1]\n    r = np.clip(r, -0.99, 0.99)\n    r2 = erfinv(r)\n    return r2\n\n\n\n\nprint('scaling num_cols')\nfor col in num_cols + count_cols:\n    print('scaling {}'.format(col))\n    col_mean = tr_te[col].mean()\n    col_std = tr_te[col].std()\n    tr_te[col].fillna(col_mean, inplace=True)\n    tr_te[col] = rankgauss(tr_te[col].values)\n\n\ntrain_df = tr_te[0:train_df.shape[0]]\ntest_df = tr_te[train_df.shape[0]:]\n\n\n\n\n\nX = np.stack([train_df[num_cols].values,train_df[count_cols].values],axis = -1)\nX_test = np.stack([test_df[num_cols].values,test_df[count_cols].values],axis = -1)\n#X = train_df[num_cols].values\n\ndef augment_counts(x, y, t_pos, t_neg):\n    xs,xn = [],[]\n    for i in range(t_pos):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(200):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n            #x1[:,c+200] = x1[ids][:,c+200]\n        xs.append(x1)\n\n    for i in range(t_neg):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(200):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n            #x1[:,c+200] = x1[ids][:,c+200]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y\n\nfrom keras import layers as L\nimport keras.backend as K\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import ModelCheckpoint\ndef build_model():\n    inp = L.Input((200,2))\n    x = L.Dense(64)(inp)\n    x = L.PReLU()(x)\n    x = L.BatchNormalization()(x)\n    x = L.Dropout(0.2)(x)\n    x = L.Dense(8)(x)\n    x = L.PReLU()(x)\n    x = L.Flatten()(x)\n    out = L.Dense(1,activation='sigmoid')(x)\n\n    m = Model(inp,out)\n    print(m.summary())\n    return m\n\nnum_folds = 5\nfolds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\nsplits = list(folds.split(train_df.values, target.values))\n\noof_preds = np.zeros(y.shape)\ntest_preds = np.zeros(X_test.shape[0])\n\nfrom keras.callbacks import ReduceLROnPlateau\n\nfor fold_ in [0, 1, 2, 3, 4]:\n    trn_idx, val_idx = splits[fold_]\n\n    X_train, y_train = X[trn_idx], y[trn_idx]\n    X_valid, y_valid = X[val_idx], y[val_idx]\n    \n    X_train, y_train = augment_counts(X_train, y_train, 2, 1)\n\n    m = build_model()\n    ckpt = ModelCheckpoint(MODEL_PATH + 'nn{}.hdf5'.format(fold_), save_best_only=True, verbose=True)\n    pl = ReduceLROnPlateau(factor=0.5,patience=5)\n    m.compile(optimizer=Adam(), loss=binary_crossentropy)\n    m.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20, verbose=1, callbacks=[ckpt,pl], batch_size = 256)\n    m.load_weights(MODEL_PATH + 'nn{}.hdf5'.format(fold_))\n    oof_preds[val_idx] = m.predict(X_valid)[:, 0]\n    test_preds += m.predict(X_test)[:,0]\ntest_preds/= 5\n\n\n\nnp.save(MODEL_PATH + 'oof_NN13b_aug.npy',oof_preds)\nnp.save(MODEL_PATH + 'sub_NN13b_aug.npy',test_preds)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "submission = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv')\nsubmission['target'] = test_preds\nsubmission.to_csv(MODEL_PATH + 'submission.csv',index=False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.4",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}