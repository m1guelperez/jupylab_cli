{
    "cells": [
        {
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "trusted": true
            },
            "cell_type": "code",
            "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
                "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
                "trusted": true
            },
            "cell_type": "code",
            "source": "import numpy as np\nimport pandas as pd ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "sales_data = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\nitem_cat = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\nsample_submission = pd.read_csv('../input/competitive-data-science-predict-future-sales/sample_submission.csv')\ntest_data = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "def basic_eda(df):\n\n    print(\"----------TOP 5 RECORDS--------\")\n    print(df.head(5))\n    print(\"----------INFO-----------------\")\n    print(df.info())\n    print(\"----------Describe-------------\")\n    print(df.describe())\n    print(\"----------Columns--------------\")\n    print(df.columns)\n    print(\"----------Data Types-----------\")\n    print(df.dtypes)\n    print(\"-------Missing Values----------\")\n    print(df.isnull().sum())\n    print(\"-------NULL values-------------\")\n    print(df.isna().sum())\n    print(\"-----Shape Of Data-------------\")\n    print(df.shape)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "sales_data['date'] = pd.to_datetime(sales_data['date'],format = '%d.%m.%Y')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "dataset = sales_data.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],fill_value = 0,aggfunc='sum')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "dataset",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "dataset.reset_index(inplace = True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "dataset",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "# predict\ndataset = pd.merge(test_data,dataset,on = ['item_id','shop_id'],how = 'left')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "dataset",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "# lets fill all NaN values with 0\ndataset.fillna(0,inplace = True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "dataset.drop(['shop_id','item_id','ID'],inplace = True, axis = 1)\ndataset.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "# X we will keep all columns execpt the last one \nX_train = np.expand_dims(dataset.values[:,:-1],axis = 2)\n# the last column is our label\ny_train = dataset.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(dataset.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "from keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "# our defining our model \nmy_model = Sequential()\nmy_model.add(LSTM(units = 64,input_shape = (33,1)))\n\nmy_model.add(Dropout(0.4))\nmy_model.add(Dense(1))\n\nmy_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nmy_model.summary()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "# my_model.fit(X_train,y_train,batch_size = 4096,epochs = 10)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "# our defining our model \nmy_model2 = Sequential()\nmy_model2.add(LSTM(units = 32,input_shape = (33,1), return_sequences=True))\nmy_model2.add(LSTM(units = 64, return_sequences=True))\nmy_model2.add(LSTM(units = 128, return_sequences=True))\nmy_model2.add(Dropout(0.4))\n\nmy_model2.add(LSTM(units = 128, return_sequences=True))\nmy_model2.add(LSTM(units = 64, return_sequences=True))\nmy_model2.add(LSTM(units = 32))\nmy_model2.add(Dropout(0.4))\n\nmy_model2.add(Dense(1))\n\nmy_model2.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nmy_model2.summary()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "my_model2.fit(X_train,y_train,batch_size = 4096,epochs = 10)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "# creating submission file \nsubmission_pfs = my_model2.predict(X_test)\n# we will keep every value between 0 and 20\nsubmission_pfs = submission_pfs.clip(0,20)\n# creating dataframe with required columns \nsubmission = pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfs.ravel()})\n# creating csv file from dataframe\nsubmission.to_csv('sub_pfs2.csv',index = False)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "\n# regressor = Sequential()\n\n# regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (33, 1)))\n# regressor.add(Dropout(0.2))\n\n# regressor.add(LSTM(units = 50, return_sequences = True))\n# regressor.add(Dropout(0.2))\n\n# regressor.add(LSTM(units = 50, return_sequences = True))\n# regressor.add(Dropout(0.2))\n\n# regressor.add(LSTM(units = 50))\n# regressor.add(Dropout(0.2))\n\n# regressor.add(Dense(units = 1))\n\n# regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# regressor.fit(X_train, y_train, epochs = 10, batch_size = 4096)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "# submission_pfss = regressor.predict(X_test)\n# # we will keep every value between 0 and 20\n# submission_pfss = submission_pfss.clip(0,20)\n# # creating dataframe with required columns \n# submission12 = pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfss.ravel()})\n# # creating csv file from dataframe\n# submission12.to_csv('sub_pfs12.csv',index = False)",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "version": "3.6.4",
            "file_extension": ".py",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "name": "python",
            "mimetype": "text/x-python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}