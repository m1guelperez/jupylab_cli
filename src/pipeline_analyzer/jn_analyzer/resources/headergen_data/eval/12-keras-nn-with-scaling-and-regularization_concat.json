{
    "source": [
        {
            "content": [
                "import tensorflow as tf",
                "import pandas as pd",
                "import os",
                "from sklearn.metrics import roc_auc_score",
                "from sklearn.model_selection import train_test_split",
                "from sklearn.preprocessing import StandardScaler",
                "from keras import Sequential",
                "from keras import layers",
                "from keras import backend as K",
                "from keras.layers.core import Dense",
                "from keras import regularizers",
                "from keras.layers import Dropout",
                "from keras.constraints import max_norm"
            ],
            "content_processed": [
                "SETUP"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Library Loading"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "# Import data",
                "train = pd.read_csv('../input/train.csv')",
                "test = pd.read_csv('../input/test.csv')"
            ],
            "content_processed": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "train.shape"
            ],
            "content_processed": [
                "CHECKPOINT",
                "train.shape"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "test.shape"
            ],
            "content_processed": [
                "CHECKPOINT",
                "test.shape"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "#Check num of cases in label ",
                "print(train.target.value_counts())",
                "print(train.target.value_counts()[1]/train.target.value_counts()[0])"
            ],
            "content_processed": [
                "CHECKPOINT",
                "print(print)",
                "print(print)"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "train_features = train.drop(['target', 'ID_code'], axis=1)",
                "train_targets = train['target']",
                "test_features = test.drop(['ID_code'], axis=1)"
            ],
            "content_processed": [
                "ASSIGN = train.drop(['target', 'ID_code'], axis=1)",
                "ASSIGN = train['target']",
                "ASSIGN = test.drop(['ID_code'], axis=1)"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "X_train, X_test, y_train, y_test = train_test_split(train_features, train_targets, test_size = 0.25, random_state = 50)"
            ],
            "content_processed": [
                "X_train, X_test, y_train, y_test = train_test_split(train_features, train_targets, test_size = 0.25, random_state = 50)"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "# Feature Scaling",
                "from sklearn.preprocessing import StandardScaler",
                "sc = StandardScaler()",
                "X_train = sc.fit_transform(X_train)",
                "X_test = sc.transform(X_test)",
                "test_features = sc.transform(test_features)"
            ],
            "content_processed": [
                "SETUP",
                "ASSIGN = StandardScaler()",
                "ASSIGN = sc.fit_transform(ASSIGN)",
                "ASSIGN = sc.transform(ASSIGN)",
                "ASSIGN = sc.transform(ASSIGN)"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Library Loading",
                "Feature Engineering"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "# Add RUC metric to monitor NN",
                "def auc(y_true, y_pred):",
                "    auc = tf.metrics.auc(y_true, y_pred)[1]",
                "    K.get_session().run(tf.local_variables_initializer())",
                "    return auc"
            ],
            "content_processed": [
                "def auc(y_true, y_pred):",
                "ASSIGN = tf.metrics.ASSIGN(y_true, y_pred)[1]",
                "K.get_session().run(tf.local_variables_initializer())",
                "return auc"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "input_dim = X_train.shape[1]",
                "input_dim"
            ],
            "content_processed": [
                "CHECKPOINT",
                "ASSIGN = X_train.shape[1]",
                "input_dim"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "# Try early stopping",
                "#from keras.callbacks import EarlyStopping",
                "#callback = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=0, mode='auto', baseline=None, restore_best_weights=True)"
            ],
            "content_processed": [],
            "tag_pred": [],
            "headergen_tag": [
                ""
            ],
            "correct_tag": []
        },
        {
            "content": [
                "model = Sequential()",
                "# Input layer",
                "model.add(Dense(units = 200, activation = \"relu\", input_dim = input_dim, kernel_initializer = \"normal\", kernel_regularizer=regularizers.l2(0.005), ",
                "                kernel_constraint = max_norm(5.)))",
                "# Add dropout regularization",
                "model.add(Dropout(rate=0.2))",
                "",
                "# First hidden layer",
                "model.add(Dense(units = 200, activation='relu', kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))",
                "# Add dropout regularization",
                "model.add(Dropout(rate=0.1))",
                "",
                "# Second hidden layer",
                "model.add(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))",
                "# Add dropout regularization",
                "model.add(Dropout(rate=0.1))",
                "",
                "# Third hidden layer",
                "model.add(Dense(50, activation='tanh', kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))",
                "# Add dropout regularization",
                "model.add(Dropout(rate=0.1))",
                "",
                "# Output layer",
                "model.add(layers.Dense(units = 1, activation='sigmoid'))",
                "",
                "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])",
                "model.summary()"
            ],
            "content_processed": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Dense(units = 200, activation = \"relu\", input_dim = input_dim, kernel_initializer = \"normal\", kernel_regularizer=regularizers.l2(0.005),",
                "ASSIGN = max_norm(5.)))",
                "ASSIGN.add(Dropout(rate=0.2))",
                "ASSIGN.add(Dense(units = 200, activation='relu', kernel_regularizer=regularizers.l2(0.005), ASSIGN=max_norm(5)))",
                "ASSIGN.add(Dropout(rate=0.1))",
                "ASSIGN.add(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.005), ASSIGN=max_norm(5)))",
                "ASSIGN.add(Dropout(rate=0.1))",
                "ASSIGN.add(Dense(50, activation='tanh', kernel_regularizer=regularizers.l2(0.005), ASSIGN=max_norm(5)))",
                "ASSIGN.add(Dropout(rate=0.1))",
                "ASSIGN.add(layers.Dense(units = 1, activation='sigmoid'))",
                "ASSIGN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])",
                "ASSIGN.summary()"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "model.fit(X_train, y_train, batch_size = 16384, epochs = 125, validation_data = (X_test, y_test))#, callbacks = [callback])"
            ],
            "content_processed": [
                "model.fit(X_train, y_train, batch_size = 16384, epochs = 125, validation_data = (X_test, y_test))"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "y_pred = model.predict_proba(X_test)",
                "roc_auc_score(y_test, y_pred)"
            ],
            "content_processed": [
                "ASSIGN = model.predict_proba(X_test)",
                "roc_auc_score(y_test, ASSIGN)"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "id_code_test = test['ID_code']",
                "# Make predicitions",
                "pred = model.predict(test_features)",
                "pred_ = pred[:,0]"
            ],
            "content_processed": [
                "ASSIGN = test['ID_code']",
                "ASSIGN = model.predict(test_features)",
                "ASSIGN = pred[:,0]"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "pred_"
            ],
            "content_processed": [
                "pred_"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "# To CSV",
                "my_submission = pd.DataFrame({\"ID_code\" : id_code_test, \"target\" : pred_})"
            ],
            "content_processed": [
                "ASSIGN = pd.DataFrame({\"ID_code\" : id_code_test, \"target\" : pred_})"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "my_submission"
            ],
            "content_processed": [
                "CHECKPOINT",
                "my_submission"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                "my_submission.to_csv('submission.csv', index = False, header = True)"
            ],
            "content_processed": [
                "my_submission.to_csv('submission.csv', index = False, header = True)"
            ],
            "tag_pred": [],
            "headergen_tag": [
                "Data Preparation"
            ],
            "correct_tag": []
        },
        {
            "content": [
                ""
            ],
            "content_processed": [],
            "tag_pred": [],
            "headergen_tag": [
                ""
            ],
            "correct_tag": []
        }
    ]
}