{
    "source": [
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# This Python 3 environment comes with many helpful analytics libraries installed",
                "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python",
                "# For example, here's several helpful packages to load in ",
                "",
                "import numpy as np # linear algebra",
                "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)",
                "from tqdm import tqdm, tqdm_notebook",
                "",
                "# Input data files are available in the \"../input/\" directory.",
                "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory",
                "",
                "import os",
                "print(os.listdir(\"../input\"))",
                "import gc",
                "",
                "",
                "# Any results you write to the current directory are saved as output.",
                "import tensorflow as tf",
                "from sklearn.model_selection import train_test_split, StratifiedKFold",
                "from sklearn.preprocessing import StandardScaler",
                "from keras import layers",
                "from keras import backend as K",
                "from keras import regularizers",
                "from keras.constraints import max_norm",
                "from keras.models import Sequential",
                "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau",
                "from keras.models import load_model",
                "from keras.models import Model",
                "from keras.initializers import glorot_uniform",
                "from keras.layers import Input,Dense,Activation,ZeroPadding2D,BatchNormalization,Flatten,Conv2D,AveragePooling2D,MaxPooling2D,Dropout,concatenate",
                "from sklearn import preprocessing",
                "",
                "import matplotlib.pyplot as plt",
                "from sklearn.metrics import roc_curve",
                "#from sklearn.metrics import auc",
                "from sklearn.metrics import roc_auc_score",
                "",
                "import warnings",
                "warnings.filterwarnings(\"ignore\")"
            ],
            "content_processed": [
                "SETUP",
                "VALIDATION",
                "print(os.listdir())",
                "warnings.filterwarnings(\"ignore\")"
            ],
            "tag_pred": [
                "setup_notebook",
                "validate_data"
            ],
            "correct_tag_ours": [
                "setup_notebook",
                "validate_data"
            ],
            "headergen_tag": [
                "Library Loading"
            ],
            "headergen_sot": [
                "Library Loading"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# define helper functions. auc, plot_history",
                "def auc(y_true, y_pred):",
                "    #auc = tf.metrics.auc(y_true, y_pred)[1]",
                "    y_pred = y_pred.ravel()",
                "    y_true = y_true.ravel()",
                "    return roc_auc_score(y_true, y_pred)",
                "",
                "def auc_2(y_true, y_pred):",
                "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)",
                "",
                "def plot_history(histories, key='binary_crossentropy'):",
                "    plt.figure(figsize=(16,10))",
                "    #plt.plot([0, 1], [0, 1], 'k--')",
                "    for name, history in histories:",
                "        val = plt.plot(history.epoch, history.history['val_'+key], '--', label=name.title()+' Val')",
                "",
                "    plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=name.title()+' Train')",
                "",
                "    plt.xlabel('Epochs')",
                "    plt.ylabel(key.replace('_',' ').title())",
                "    plt.legend()",
                "",
                "    plt.xlim([0,max(history.epoch)])",
                "    plt.ylim([0, 0.4])",
                "    plt.show()"
            ],
            "content_processed": [
                "def auc(y_true, y_pred):",
                "ASSIGN = ASSIGN.ravel()",
                "ASSIGN = ASSIGN.ravel()",
                "return roc_auc_score(ASSIGN, ASSIGN)",
                "def auc_2(ASSIGN, ASSIGN):",
                "return tf.py_func(roc_auc_score, (ASSIGN, ASSIGN), tf.double)",
                "def plot_history(histories, key='binary_crossentropy'):",
                "plt.figure(figsize=(16,10))",
                "for name, history in histories:",
                "ASSIGN = plt.plot(history.epoch, history.history['val_'+key], '--', label=name.title()+' Val')",
                "plt.plot(history.epoch, history.history[key], color=ASSIGN[0].get_color(), label=name.title()+' Train')",
                "plt.xlabel('Epochs')",
                "plt.ylabel(key.replace('_',' ').title())",
                "plt.legend()",
                "plt.xlim([0,max(history.epoch)])",
                "plt.ylim([0, 0.4])",
                "plt.show()"
            ],
            "tag_pred": [
                "visualize_data",
                "evaluate_model"
            ],
            "correct_tag_ours": [
                "evaluate_model",
                "visualize_data"
            ],
            "headergen_tag": [
                "Model Building and Training",
                "Visualization"
            ],
            "headergen_sot": [
                "Model Building and Training",
                "Visualization"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# load data ",
                "train_df = pd.read_csv('../input/train.csv')",
                "test_df =  pd.read_csv(\"../input/test.csv\")",
                "base_features = [x for x in train_df.columns.values.tolist() if x.startswith('var_')]"
            ],
            "content_processed": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = [x for x in train_df.columns.values.tolist() if x.startswith('var_')]"
            ],
            "tag_pred": [
                "ingest_data",
                "process_data"
            ],
            "correct_tag_ours": [
                "ingest_data",
                "process_data"
            ],
            "headergen_tag": [
                "Data Preparation"
            ],
            "headergen_sot": [
                "Data Preparation"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# mark real vs fake",
                "train_df['real'] = 1",
                "",
                "for col in base_features:",
                "    test_df[col] = test_df[col].map(test_df[col].value_counts())",
                "a = test_df[base_features].min(axis=1)",
                "",
                "test_df = pd.read_csv('../input/test.csv')",
                "test_df['real'] = (a == 1).astype('int')",
                "",
                "train = train_df.append(test_df).reset_index(drop=True)",
                "del test_df, train_df; gc.collect()"
            ],
            "content_processed": [
                "train_df['real'] = 1",
                "for col in base_features:",
                "test_df[col] = test_df[col].map(test_df[col].value_counts())",
                "ASSIGN = test_df[base_features].min(axis=1)",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN['real'] = (ASSIGN == 1).astype('int')",
                "ASSIGN = train_df.append(test_df).reset_index(drop=True)",
                "del ASSIGN, train_df; gc.collect()"
            ],
            "tag_pred": [
                "ingest_data",
                "process_data"
            ],
            "correct_tag_ours": [
                "ingest_data",
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering",
                "Data Preparation"
            ],
            "headergen_sot": [
                "Feature Engineering",
                "Data Preparation"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# count features",
                "for col in tqdm(base_features):",
                "    train[col + 'size'] = train[col].map(train.loc[train.real==1, col].value_counts())",
                "cnt_features = [col + 'size' for col in base_features]"
            ],
            "content_processed": [
                "for col in tqdm(base_features):",
                "train[col + 'size'] = train[col].map(train.loc[train.real==1, col].value_counts())",
                "ASSIGN = [col + 'size' for col in base_features]"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering"
            ],
            "headergen_sot": [
                "Feature Engineering"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# magice features 1",
                "for col in tqdm(base_features):",
                "#        train[col+'size'] = train.groupby(col)['target'].transform('size')",
                "    train.loc[train[col+'size']>1,col+'no_noise'] = train.loc[train[col+'size']>1,col]",
                "noise1_features = [col + 'no_noise' for col in base_features]"
            ],
            "content_processed": [
                "for col in tqdm(base_features):",
                "train.loc[train[col+'size']>1,col+'no_noise'] = train.loc[train[col+'size']>1,col]",
                "ASSIGN = [col + 'no_noise' for col in base_features]"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering"
            ],
            "headergen_sot": [
                "Feature Engineering"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# fill NA as 0, inspired by lightgbm",
                "train[noise1_features] = train[noise1_features].fillna(train[noise1_features].mean())"
            ],
            "content_processed": [
                "train[noise1_features] = train[noise1_features].fillna(train[noise1_features].mean())"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering"
            ],
            "headergen_sot": [
                "Feature Engineering"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# magice features 2",
                "for col in tqdm(base_features):",
                "#        train[col+'size'] = train.groupby(col)['target'].transform('size')",
                "    train.loc[train[col+'size']>2,col+'no_noise2'] = train.loc[train[col+'size']>2,col]",
                "noise2_features = [col + 'no_noise2' for col in base_features]"
            ],
            "content_processed": [
                "for col in tqdm(base_features):",
                "train.loc[train[col+'size']>2,col+'no_noise2'] = train.loc[train[col+'size']>2,col]",
                "ASSIGN = [col + 'no_noise2' for col in base_features]"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering"
            ],
            "headergen_sot": [
                "Feature Engineering"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# fill NA as 0, inspired by lightgbm",
                "train[noise2_features] = train[noise2_features].fillna(train[noise2_features].mean())"
            ],
            "content_processed": [
                "train[noise2_features] = train[noise2_features].fillna(train[noise2_features].mean())"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering"
            ],
            "headergen_sot": [
                "Feature Engineering"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "train_df = train[train['target'].notnull()]",
                "test_df = train[train['target'].isnull()]",
                "all_features = base_features + noise1_features + noise2_features"
            ],
            "content_processed": [
                "ASSIGN = train[train['target'].notnull()]",
                "ASSIGN = train[train['target'].isnull()]",
                "ASSIGN = base_features + noise1_features + noise2_features"
            ],
            "tag_pred": [
                "validate_data",
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering",
                "Data Preparation"
            ],
            "headergen_sot": [
                "Feature Engineering",
                "Data Preparation"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "scaler = preprocessing.StandardScaler().fit(train_df[all_features].values)",
                "df_trn = pd.DataFrame(scaler.transform(train_df[all_features].values), columns=all_features)",
                "df_tst = pd.DataFrame(scaler.transform(test_df[all_features].values), columns=all_features)",
                "y = train_df['target'].values"
            ],
            "content_processed": [
                "ASSIGN = preprocessing.StandardScaler().fit(train_df[all_features].values)",
                "ASSIGN = pd.DataFrame(scaler.transform(train_df[all_features].values), columns=all_features)",
                "ASSIGN = pd.DataFrame(scaler.transform(test_df[all_features].values), columns=all_features)",
                "ASSIGN = train_df['target'].values"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering"
            ],
            "headergen_sot": [
                "Feature Engineering"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "def get_keras_data(dataset, cols_info):",
                "    X = {}",
                "    base_feats, noise_feats, noise2_feats = cols_info",
                "    X['base'] = np.reshape(np.array(dataset[base_feats].values), (-1, len(base_feats), 1))",
                "    X['noise1'] = np.reshape(np.array(dataset[noise_feats].values), (-1, len(noise_feats), 1))",
                "    X['noise2'] = np.reshape(np.array(dataset[noise2_feats].values), (-1, len(noise2_feats), 1))",
                "    return X"
            ],
            "content_processed": [
                "def get_keras_data(dataset, cols_info):",
                "ASSIGN = {}",
                "base_feats, noise_feats, noise2_feats = cols_info",
                "ASSIGN = np.reshape(np.array(ASSIGN.values), (-1, len(base_feats), 1))",
                "ASSIGN['noise1'] = np.reshape(np.array(dataset[noise_feats].values), (-1, len(noise_feats), 1))",
                "ASSIGN['noise2'] = np.reshape(np.array(dataset[noise2_feats].values), (-1, len(noise2_feats), 1))",
                "return X"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering"
            ],
            "headergen_sot": [
                "Feature Engineering"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "cols_info = [base_features, noise1_features, noise2_features]",
                "#X = get_keras_data(df_trn[all_features], cols_info)",
                "X_test = get_keras_data(df_tst[all_features], cols_info)"
            ],
            "content_processed": [
                "ASSIGN = [base_features, noise1_features, noise2_features]",
                "ASSIGN = get_keras_data(df_tst[all_features], cols_info)"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering"
            ],
            "headergen_sot": [
                "Feature Engineering"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# define network structure -> 2D CNN",
                "def Convnet(cols_info, classes=1):",
                "    base_feats, noise1_feats, noise2_feats = cols_info",
                "    ",
                "    # base_feats",
                "    X_base_input = Input(shape=(len(base_feats), 1), name='base')",
                "    X_base = Dense(16)(X_base_input)",
                "    X_base = Activation('relu')(X_base)",
                "    X_base = Flatten(name='base_last')(X_base)",
                "    ",
                "    # noise1",
                "    X_noise1_input = Input(shape=(len(noise1_feats), 1), name='noise1')",
                "    X_noise1 = Dense(16)(X_noise1_input)",
                "    X_noise1 = Activation('relu')(X_noise1)",
                "    X_noise1 = Flatten(name='nose1_last')(X_noise1)",
                "    ",
                "    # noise2",
                "    X_noise2_input = Input(shape=(len(noise2_feats), 1), name='noise2')",
                "    X_noise2 = Dense(16)(X_noise2_input)",
                "    X_noise2 = Activation('relu')(X_noise2)",
                "    X_noise2 = Flatten(name='nose2_last')(X_noise2)",
                "    ",
                "    ",
                "    X = concatenate([X_base, X_noise1, X_noise2])",
                "    X = Dense(classes, activation='sigmoid')(X)",
                "    ",
                "    model = Model(inputs=[X_base_input, X_noise1_input, X_noise2_input],outputs=X)",
                "    ",
                "    return model",
                "model = Convnet(cols_info)",
                "model.summary()"
            ],
            "content_processed": [
                "def Convnet(cols_info, classes=1):",
                "base_feats, noise1_feats, noise2_feats = cols_info",
                "ASSIGN = Input(shape=(len(base_feats), 1), name='base')",
                "ASSIGN = Dense(16)(X_base_input)",
                "ASSIGN = Activation('relu')(ASSIGN)",
                "ASSIGN = Flatten(name='base_last')(ASSIGN)",
                "X_noise1_input = Input(shape=(len(noise1_feats), 1), name='noise1')",
                "X_noise1 = Dense(16)(X_noise1_input)",
                "X_noise1 = Activation('relu')(X_noise1)",
                "X_noise1 = Flatten(name='nose1_last')(X_noise1)",
                "X_noise2_input = Input(shape=(len(noise2_feats), 1), name='noise2')",
                "X_noise2 = Dense(16)(X_noise2_input)",
                "X_noise2 = Activation('relu')(X_noise2)",
                "X_noise2 = Flatten(name='nose2_last')(X_noise2)",
                "ASSIGN = concatenate([X_base, X_noise1, X_noise2])",
                "ASSIGN = Dense(classes, activation='sigmoid')(ASSIGN)",
                "ASSIGN = Model(inputs=[X_base_input, X_noise1_input, X_noise2_input],outputs=X)",
                "return model",
                "ASSIGN = Convnet(cols_info)",
                "ASSIGN.summary()"
            ],
            "tag_pred": [
                "validate_data",
                "train_model"
            ],
            "correct_tag_ours": [
                "train_model",
                "validate_data"
            ],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "headergen_sot": [
                "Model Building and Training"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "try:",
                "    del df_tst",
                "except:",
                "    pass",
                "gc.collect()"
            ],
            "content_processed": [
                "try:",
                "del df_tst",
                "except:",
                "pass",
                "gc.collect()"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "None"
            ],
            "headergen_tag": [
                ""
            ],
            "headergen_sot": [
                ""
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# parameters",
                "SEED = 2019",
                "n_folds = 5",
                "debug_flag = True",
                "folds = 5",
                "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)"
            ],
            "content_processed": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = True",
                "ASSIGN = 5",
                "ASSIGN = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)"
            ],
            "tag_pred": [
                "setup_notebook"
            ],
            "correct_tag_ours": [
                "setup_notebook",
                "evaluate_model"
            ],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "headergen_sot": [
                "Model Building and Training"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "#transformed_shape = tuple([-1] + list(shape))",
                "#X_test = np.reshape(X_test, transformed_shape)",
                "",
                "i = 0",
                "result = pd.DataFrame({\"ID_code\": test_df.ID_code.values})",
                "val_aucs = []",
                "valid_X = train_df[['target']]",
                "valid_X['predict'] = 0",
                "for train_idx, val_idx in skf.split(df_trn, y):",
                "    if i == folds:",
                "        break",
                "    i += 1    ",
                "    X_train, y_train = df_trn.iloc[train_idx], y[train_idx]",
                "    X_valid, y_valid = df_trn.iloc[val_idx], y[val_idx]",
                "    ",
                "    X_train = get_keras_data(X_train, cols_info)",
                "    X_valid = get_keras_data(X_valid, cols_info)",
                "    #X_train = np.reshape(X_train, transformed_shape)",
                "    #X_valid = np.reshape(X_valid, transformed_shape)",
                "    ",
                "    model_name = 'NN_fold{}.h5'.format(str(i))",
                "    ",
                "    model = Convnet(cols_info)",
                "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'binary_crossentropy', auc_2])",
                "    checkpoint = ModelCheckpoint(model_name, monitor='val_auc_2', verbose=1, ",
                "                                 save_best_only=True, mode='max', save_weights_only = True)",
                "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, ",
                "                                       verbose=1, mode='min', epsilon=0.0001)",
                "    earlystop = EarlyStopping(monitor='val_auc_2', mode='max', patience=10, verbose=1)",
                "    history = model.fit(X_train, y_train, ",
                "                        epochs=300, ",
                "                        batch_size=1024 * 2, ",
                "                        validation_data=(X_valid, y_valid), ",
                "                        callbacks=[checkpoint, reduceLROnPlat, earlystop])",
                "    train_history = pd.DataFrame(history.history)",
                "    train_history.to_csv('train_profile_fold{}.csv'.format(str(i)), index=None)",
                "    ",
                "    # load and predict",
                "    model.load_weights(model_name)",
                "    ",
                "    #predict",
                "    y_pred_keras = model.predict(X_valid).ravel()",
                "    ",
                "    # AUC",
                "    valid_X['predict'].iloc[val_idx] = y_pred_keras",
                "    ",
                "    fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_valid, y_pred_keras)",
                "    auc_valid = roc_auc_score(y_valid, y_pred_keras)",
                "    val_aucs.append(auc_valid)",
                "    ",
                "    prediction = model.predict(X_test)",
                "    result[\"fold{}\".format(str(i))] = prediction"
            ],
            "content_processed": [
                "ASSIGN = 0",
                "ASSIGN = pd.DataFrame({\"ID_code\": test_df.ID_code.values})",
                "ASSIGN = []",
                "ASSIGN = train_df[['target']]",
                "ASSIGN['predict'] = 0",
                "for train_idx, val_idx in skf.split(df_trn, y):",
                "ASSIGN == folds:",
                "break",
                "ASSIGN += 1",
                "ASSIGN = df_trn.iloc[train_idx], y[train_idx]",
                "ASSIGN = df_trn.iloc[val_idx], y[val_idx]",
                "ASSIGN = get_keras_data(ASSIGN, cols_info)",
                "ASSIGN = get_keras_data(ASSIGN, cols_info)",
                "ASSIGN = 'NN_fold{}.h5'.format(str(i))",
                "ASSIGN = Convnet(cols_info)",
                "ASSIGN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'binary_crossentropy', auc_2])",
                "ASSIGN = ModelCheckpoint(model_name, monitor='val_auc_2', verbose=1,",
                "ASSIGN=True, mode='max', save_weights_only = True)",
                "ASSIGN = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4,",
                "ASSIGN=1, mode='min', epsilon=0.0001)",
                "ASSIGN = EarlyStopping(monitor='val_auc_2', mode='max', patience=10, verbose=1)",
                "ASSIGN = model.fit(X_train, y_train,",
                "ASSIGN=300,",
                "ASSIGN=1024 * 2,",
                "ASSIGN=(X_valid, y_valid),",
                "ASSIGN=[checkpoint, reduceLROnPlat, earlystop])",
                "ASSIGN = pd.DataFrame(history.history)",
                "ASSIGN.to_csv('train_profile_fold{}.csv'.format(str(ASSIGN)), index=None)",
                "ASSIGN.load_weights(ASSIGN)",
                "ASSIGN = model.predict(X_valid).ravel()",
                "ASSIGN['predict'].iloc[val_idx] = ASSIGN",
                "ASSIGN = roc_curve(y_valid, y_pred_keras)",
                "ASSIGN = roc_auc_score(y_valid, y_pred_keras)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = model.predict(X_test)",
                "ASSIGN[\"fold{}\".format(str(ASSIGN))] = ASSIGN"
            ],
            "tag_pred": [
                "ingest_data",
                "train_model",
                "evaluate_model",
                "transfer_results"
            ],
            "correct_tag_ours": [
                "ingest_data",
                "train_model",
                "evaluate_model",
                "transfer_results"
            ],
            "headergen_tag": [
                "Model Building and Training",
                "Data Preparation"
            ],
            "headergen_sot": [
                "Model Building and Training",
                "Data Preparation"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "for i in range(len(val_aucs)):",
                "    print('Fold_%d AUC: %.6f' % (i+1, val_aucs[i]))"
            ],
            "content_processed": [
                "VALIDATION",
                "for i in range(len(val_aucs)):",
                "print('Fold_%d AUC: %.6f' % (i+1, val_aucs[i]))"
            ],
            "tag_pred": [
                "validate_data"
            ],
            "correct_tag_ours": [
                "validate_data",
                "evaluate_model"
            ],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "headergen_sot": [
                "Model Building and Training"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "# summary on results",
                "auc_mean = np.mean(val_aucs)",
                "auc_std = np.std(val_aucs)",
                "auc_all = roc_auc_score(valid_X.target, valid_X.predict)",
                "print('%d-fold auc mean: %.9f, std: %.9f. All auc: %6f.' % (n_folds, auc_mean, auc_std, auc_all))"
            ],
            "content_processed": [
                "VALIDATION",
                "ASSIGN = np.mean(val_aucs)",
                "ASSIGN = np.std(val_aucs)",
                "ASSIGN = roc_auc_score(valid_X.target, valid_X.predict)",
                "print('%d-fold auc mean: %.9f, std: %.9f. All auc: %6f.' % (n_folds, ASSIGN, ASSIGN, ASSIGN))"
            ],
            "tag_pred": [
                "validate_data",
                "evaluate_model"
            ],
            "correct_tag_ours": [
                "evaluate_model",
                "validate_data"
            ],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "headergen_sot": [
                "Model Building and Training"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                "y_all = result.values[:, 1:]",
                "result['target'] = np.mean(y_all, axis = 1)",
                "to_submit = result[['ID_code', 'target']]",
                "to_submit.to_csv('NN_submission.csv', index=None)",
                "result.to_csv('NN_all_prediction.csv', index=None)",
                "valid_X['ID_code'] = train_df['ID_code']",
                "valid_X = valid_X[['ID_code', 'target', 'predict']].to_csv('NN_oof.csv', index=None)"
            ],
            "content_processed": [
                "ASSIGN = result.values[:, 1:]",
                "ASSIGN = np.mean(y_all, axis = 1)",
                "ASSIGN = result[['ID_code', 'target']]",
                "ASSIGN.to_csv('NN_submission.csv', index=None)",
                "result.to_csv('NN_all_prediction.csv', index=None)",
                "valid_X['ID_code'] = train_df['ID_code']",
                "ASSIGN = ASSIGN[['ID_code', 'target', 'predict']].to_csv('NN_oof.csv', index=None)"
            ],
            "tag_pred": [
                "process_data",
                "evaluate_model"
            ],
            "correct_tag_ours": [
                "process_data",
                "transfer_results"
            ],
            "headergen_tag": [
                "Data Preparation"
            ],
            "headergen_sot": [
                "Data Preparation"
            ]
        },
        {
            "notebook_name": "14-multibranch-nn-baseline-magic",
            "content": [
                ""
            ],
            "content_processed": [],
            "tag_pred": [
                "None"
            ],
            "correct_tag_ours": [
                "None"
            ],
            "headergen_tag": [
                ""
            ],
            "headergen_sot": [
                ""
            ]
        }
    ]
}