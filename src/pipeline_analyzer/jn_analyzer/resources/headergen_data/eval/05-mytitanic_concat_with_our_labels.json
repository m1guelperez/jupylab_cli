{
    "source": [
        {
            "notebook_name": "05-mytitanic",
            "content": [
                "import numpy as np",
                "import pandas as pd",
                "import keras",
                "",
                "import keras",
                "from keras.models import Model",
                "from keras.layers import Input,Dense",
                "from keras import Sequential",
                "",
                "train = pd.read_csv(\"../input/titanic/train.csv\")",
                "test = pd.read_csv(\"../input/titanic/test.csv\")",
                "",
                "train.Pclass = train.Pclass.values.astype('str')",
                "test.Pclass = test.Pclass.values.astype('str')",
                "",
                "train.SibSp = train.SibSp.values.astype('str')",
                "test.SibSp = test.SibSp.values.astype('str')",
                "",
                "train.Parch = train.Parch.values.astype('str')",
                "test.Parch = test.Parch.values.astype('str')",
                "",
                "use_col =  ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp','Parch','Fare', 'Embarked']",
                "",
                "train[\"Age\"] = train.Age.fillna(30.).values",
                "test[\"Age\"] = test.Age.fillna(30.).values",
                "",
                "test.Fare[152]=np.mean(test.Fare)",
                "",
                "train = train[use_col]",
                "test_x = test[use_col[1:]]",
                "",
                "train = train.dropna()",
                "",
                "train_y = train[use_col[0]].values",
                "train_x = train[use_col[1:]].copy()"
            ],
            "content_processed": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN.Pclass = ASSIGN.Pclass.values.astype('str')",
                "ASSIGN.Pclass = ASSIGN.Pclass.values.astype('str')",
                "ASSIGN.SibSp = ASSIGN.SibSp.values.astype('str')",
                "ASSIGN.SibSp = ASSIGN.SibSp.values.astype('str')",
                "ASSIGN.Parch = ASSIGN.Parch.values.astype('str')",
                "ASSIGN.Parch = ASSIGN.Parch.values.astype('str')",
                "ASSIGN = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp','Parch','Fare', 'Embarked']",
                "ASSIGN = train.Age.fillna(30.).values",
                "ASSIGN = test.Age.fillna(30.).values",
                "ASSIGN.Fare[152]=np.mean(ASSIGN.Fare)",
                "ASSIGN = ASSIGN[use_col]",
                "ASSIGN = test[use_col[1:]]",
                "ASSIGN = ASSIGN.dropna()",
                "ASSIGN = train[use_col[0]].values",
                "ASSIGN = train[use_col[1:]].copy()"
            ],
            "tag_pred": [
                "setup_notebook",
                "ingest_data",
                "process_data"
            ],
            "correct_tag_ours": [
                "setup_notebook",
                "ingest_data",
                "process_data"
            ],
            "headergen_tag": [
                "Library Loading",
                "Feature Engineering",
                "Data Preparation"
            ],
            "headergen_sot": [
                "Library Loading",
                "Feature Engineering",
                "Data Preparation"
            ]
        },
        {
            "notebook_name": "05-mytitanic",
            "content": [
                "import numpy as np",
                "import pandas as pd",
                "",
                "def pandas_type(inp):",
                "    if str(type(inp)) != \"<class 'pandas.core.frame.DataFrame'>\":",
                "        print(\"Use pandas DataFrame\")",
                "        return False",
                "    else:",
                "        if np.any(inp.isnull()==True)==True:",
                "            print(\"Your data is a mess\")",
                "            return False",
                "        else:",
                "            pass",
                "    ",
                "def pandas_enc_str(inp,m_co_var=True):",
                "    out = pd.DataFrame()",
                "    zw = inp.astype",
                "    try:",
                "        zzw = zw.unique()",
                "    except:",
                "        zw = pd.Series(inp)",
                "        zzw = zw.unique()",
                "",
                "    if m_co_var == True:",
                "        for i in zzw[1:]:",
                "            try:",
                "                bin_ = eval('zw=='+str(i)).replace({True : 1 , False : 0})",
                "            except:",
                "                bin_ = eval('zw==\"'+str(i)+'\"').replace({True : 1 , False : 0})",
                "            out[i]=bin_",
                "        return out",
                "    else:",
                "        for i in zzw:",
                "            try:",
                "                bin_ = eval('zw=='+str(i)).replace({True : 1 , False : 0})",
                "            except:",
                "                bin_ = eval('zw==\"'+str(i)+'\"').replace({True : 1 , False : 0})",
                "            out[i]=bin_",
                "        return out",
                "    ",
                "def get_split_len(inp):",
                "    nn1 = str(np.float32(np.mean(inp))-min(inp)).split(\".\")[0]",
                "    nn2 = str(np.float32(min(inp))).split(\".\")[1]",
                "    if nn1 != \"0\":",
                "        return -len(nn1)+3",
                "    else:",
                "        return len(nn2)",
                "",
                "def categorize_cat(inp,bins):",
                "    nn = get_split_len(inp)",
                "    leng = (max(inp)-min(inp))/bins",
                "    cats = []",
                "    for i in range(bins):",
                "        cats.append(min(inp)+leng*(i+1))",
                "    return np.around(cats,nn)",
                "",
                "def categorize_(inp,bins):",
                "    out = inp.values",
                "    bins_ = categorize_cat(inp,bins)",
                "    zw = np.ones(len(out))*bins_[0]",
                "    for i in range(len(bins_[:-1])):",
                "        for j in range(len(zw)):",
                "            if out[j] > bins_[i]:",
                "                zw[j]=bins_[i+1]",
                "    return zw",
                "",
                "def cat_str(inp):",
                "    zw = pd.Series(inp)",
                "    zzw = np.sort(zw.unique())",
                "    cat_dic={}",
                "    for i in range(1,len(zzw)-1):",
                "        cat_dic.update({zzw[i] : str(zzw[i])+\"-\"+str(zzw[i+1])})",
                "    cat_dic.update({zzw[-1] : \"> \"+str(zzw[-1])})",
                "    cat_dic.update({zzw[0] : \" <\"+str(zzw[0])})",
                "    return pd.Series(zw),cat_dic",
                "",
                "def pandas_enc(inp,col,bins=5,m_co_var=True):",
                "    out1 = inp[inp.columns[inp.columns!=col]]",
                "    zw = inp[col]",
                "    if pandas_type(inp)!=False:",
                "        pass",
                "    else:",
                "        return None",
                "    if zw.dtype==float:",
                "        zw = categorize_(zw,bins)",
                "        zw,cat_dic = cat_str(zw)",
                "        out2 = pandas_enc_str(zw,m_co_var)",
                "        out2 = out2[np.sort(out2.columns)]",
                "        out2 = out2.rename(columns=cat_dic)",
                "    elif zw.dtype==int:",
                "        print(\"Specify: str or float\")",
                "    elif zw.dtype==\"O\":",
                "        zw=str(col)+\"_\"+zw",
                "        out2 = pandas_enc_str(zw,m_co_var)",
                "    else:",
                "        print(\"Strange dtype\")",
                "    return pd.concat([out1,out2], axis=1)",
                "",
                "def pandas_multi_enc(inp,col,bins=5,m_co_var=True):",
                "    out = inp",
                "    for i in col:",
                "        out = pandas_enc(out,str(i))",
                "    return out"
            ],
            "content_processed": [
                "SETUP",
                "VALIDATION",
                "def pandas_type(inp):",
                "if str(type(inp)) != \"<class 'pandas.core.frame.DataFrame'>\":",
                "print()",
                "return False",
                "else:",
                "if np.any(inp.isnull()==True)==True:",
                "print()",
                "return False",
                "else:",
                "pass",
                "def pandas_enc_str(inp,m_co_var=True):",
                "ASSIGN = pd.DataFrame()",
                "ASSIGN = inp.astype",
                "try:",
                "ASSIGN = zw.unique()",
                "except:",
                "ASSIGN = pd.Series(inp)",
                "ASSIGN = zw.unique()",
                "ASSIGN == True:",
                "for i in ASSIGN[1:]:",
                "try:",
                "ASSIGN = eval('zw=='+str(i)).replace({True : 1 , False : 0})",
                "except:",
                "ASSIGN = eval('zw==\"'+str(i)+'\"').replace({True : 1 , False : 0})",
                "SLICE=ASSIGN",
                "return out",
                "else:",
                "for i in ASSIGN:",
                "try:",
                "ASSIGN = eval('zw=='+str(i)).replace({True : 1 , False : 0})",
                "except:",
                "ASSIGN = eval('zw==\"'+str(i)+'\"').replace({True : 1 , False : 0})",
                "SLICE=ASSIGN",
                "return out",
                "def get_split_len(inp):",
                "ASSIGN = str(np.float32(np.mean(inp))-min(inp)).split(\".\")[0]",
                "ASSIGN = str(np.float32(min(inp))).split(\".\")[1]",
                "if ASSIGN != \"0\":",
                "return -len(nn1)+3",
                "else:",
                "return len(ASSIGN)",
                "def categorize_cat(inp,bins):",
                "ASSIGN = get_split_len(inp)",
                "ASSIGN = (max(inp)-min(inp))path",
                "ASSIGN = []",
                "for i in range(bins):",
                "ASSIGN.append(min(inp)+ASSIGN*(i+1))",
                "return np.around(ASSIGN,ASSIGN)",
                "def categorize_(inp,bins):",
                "ASSIGN = inp.values",
                "ASSIGN = categorize_cat(inp,bins)",
                "ASSIGN = np.ones(len(out))*bins_[0]",
                "for i in range(len(ASSIGN[:-1])):",
                "for j in range(len(ASSIGN)):",
                "if ASSIGN[j] > ASSIGN[i]:",
                "SLICE=ASSIGN[i+1]",
                "return zw",
                "def cat_str(inp):",
                "ASSIGN = pd.Series(inp)",
                "ASSIGN = np.sort(zw.unique())",
                "ASSIGN={}",
                "for i in range(1,len(ASSIGN)-1):",
                "ASSIGN.update({ASSIGN[i] : str(ASSIGN[i])+\"-\"+str(ASSIGN[i+1])})",
                "ASSIGN.update({ASSIGN[-1] : \"> \"+str(ASSIGN[-1])})",
                "ASSIGN.update({ASSIGN[0] : \" <\"+str(ASSIGN[0])})",
                "return pd.Series(zw),cat_dic",
                "def pandas_enc(inp,col,bins=5,m_co_var=True):",
                "ASSIGN = inp[inp.columns[inp.columns!=col]]",
                "ASSIGN = inp[col]",
                "if pandas_type(inp)!=False:",
                "pass",
                "else:",
                "return None",
                "if ASSIGN.dtype==float:",
                "ASSIGN = categorize_(ASSIGN,bins)",
                "ASSIGN = cat_str(zw)",
                "ASSIGN = pandas_enc_str(zw,m_co_var)",
                "ASSIGN = ASSIGN[np.sort(ASSIGN.columns)]",
                "ASSIGN = ASSIGN.rename(columns=cat_dic)",
                "elif ASSIGN.dtype==int:",
                "print()",
                "elif ASSIGN.dtype==\"O\":",
                "ASSIGN=str(col)+\"_\"+ASSIGN",
                "ASSIGN = pandas_enc_str(zw,m_co_var)",
                "else:",
                "print()",
                "return pd.concat([ASSIGN,ASSIGN], axis=1)",
                "def pandas_multi_enc(inp,col,bins=5,m_co_var=True):",
                "ASSIGN = inp",
                "for i in col:",
                "ASSIGN = pandas_enc(ASSIGN,str(i))",
                "return out"
            ],
            "tag_pred": [
                "setup_notebook",
                "process_data"
            ],
            "correct_tag_ours": [
                "setup_notebook",
                "process_data",
                "validate_data"
            ],
            "headergen_tag": [
                "Library Loading",
                "Feature Engineering",
                "Data Preparation"
            ],
            "headergen_sot": [
                "Library Loading",
                "Feature Engineering",
                "Data Preparation"
            ]
        },
        {
            "notebook_name": "05-mytitanic",
            "content": [
                "zw = train_x.append(test_x)",
                "zzw = pandas_multi_enc(zw,['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'])",
                "",
                "train_x = zzw.iloc[:len(train_x)].values",
                "test_x = zzw.iloc[len(train_x):].values"
            ],
            "content_processed": [
                "ASSIGN = train_x.append(test_x)",
                "ASSIGN = pandas_multi_enc(zw,['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'])",
                "ASSIGN = zzw.iloc[:len(ASSIGN)].values",
                "ASSIGN = zzw.iloc[len(train_x):].values"
            ],
            "tag_pred": [
                "process_data"
            ],
            "correct_tag_ours": [
                "process_data"
            ],
            "headergen_tag": [
                "Feature Engineering",
                "Data Preparation"
            ],
            "headergen_sot": [
                "Feature Engineering",
                "Data Preparation"
            ]
        },
        {
            "notebook_name": "05-mytitanic",
            "content": [
                "model=Sequential()",
                "model.add(Dense(512,input_dim=zzw.shape[1],activation='linear'))",
                "model.add(Dense(2048,activation='sigmoid'))",
                "model.add(Dense(512,activation='sigmoid'))",
                "model.add(Dense(16,activation='linear'))",
                "model.add(Dense(1,activation='linear'))",
                "",
                "",
                "sgd=keras.optimizers.SGD(lr=.0001)",
                "model.compile(optimizer=sgd,loss='mse')",
                "",
                "res_model = model.fit(train_x,train_y, batch_size=32, epochs=100)"
            ],
            "content_processed": [
                "ASSIGN=Sequential()",
                "ASSIGN.add(Dense(512,input_dim=zzw.shape[1],activation='linear'))",
                "ASSIGN.add(Dense(2048,activation='sigmoid'))",
                "ASSIGN.add(Dense(512,activation='sigmoid'))",
                "ASSIGN.add(Dense(16,activation='linear'))",
                "ASSIGN.add(Dense(1,activation='linear'))",
                "ASSIGN=keras.optimizers.SGD(lr=.0001)",
                "ASSIGN.compile(optimizer=ASSIGN,loss='mse')",
                "ASSIGN = model.fit(train_x,train_y, batch_size=32, epochs=100)"
            ],
            "tag_pred": [
                "train_model"
            ],
            "correct_tag_ours": [
                "train_model"
            ],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "headergen_sot": [
                "Model Building and Training"
            ]
        },
        {
            "notebook_name": "05-mytitanic",
            "content": [
                "zw = model.predict(test_x)",
                "",
                "result_csv=pd.DataFrame()",
                "",
                "result_csv[\"PassengerId\"]=test.PassengerId",
                "result_csv[\"Survived\"]=np.rint(zw).astype(int)"
            ],
            "content_processed": [
                "ASSIGN = model.predict(test_x)",
                "ASSIGN=pd.DataFrame()",
                "ASSIGN[\"PassengerId\"]=test.PassengerId",
                "ASSIGN[\"Survived\"]=np.rint(ASSIGN).astype(int)"
            ],
            "tag_pred": [
                "evaluate_model"
            ],
            "correct_tag_ours": [
                "evaluate_model"
            ],
            "headergen_tag": [
                "Model Building and Training"
            ],
            "headergen_sot": [
                "Model Building and Training"
            ]
        },
        {
            "notebook_name": "05-mytitanic",
            "content": [
                "result_csv.to_csv(\"my_titanic_res.csv\",index=False)"
            ],
            "content_processed": [
                "result_csv.to_csv(\"my_titanic_res.csv\",index=False)"
            ],
            "tag_pred": [
                "transfer_results"
            ],
            "correct_tag_ours": [
                "transfer_results"
            ],
            "headergen_tag": [
                "Data Preparation"
            ],
            "headergen_sot": [
                "Data Preparation"
            ]
        }
    ]
}