content,tag,output_type,original_content,y_pred
"VALIDATION ASSIGN = 0.0 ASSIGN = list(0. for i in range(10)) ASSIGN = list(0. for i in range(10)) model.eval() for data, target in test_loader: ASSIGN = model(data) ASSIGN = criterion(output, target) ASSIGN += ASSIGN.item()*data.size(0) ASSIGN = torch.max(output, 1) ASSIGN = np.squeeze(pred.eq(target.data.view_as(pred))) for i in range(len(target)): ASSIGN = target.data[i] ASSIGN[ASSIGN] += ASSIGN[i].item() ASSIGN[ASSIGN] += 1 ASSIGN = test_losspath(test_loader.sampler) print('Test Loss: {:.6f}\n'.format(ASSIGN)) for i in range(10): if ASSIGN[i] > 0: print('Test Accuracy of %5s: %2d%% (%2dpath%2d)' % ( str(i), 100 * ASSIGN[i] path[i], np.sum(ASSIGN[i]), np.sum(ASSIGN[i]))) else: print('Test Accuracy of %5s: Npath(no training examples)' % (classes[i])) print('\nTest Accuracy (Overall): %2d%% (%2dpath%2d)' % ( 100. * np.sum(ASSIGN) path(ASSIGN), np.sum(ASSIGN), np.sum(ASSIGN)))",1,not_existent,"# initialize lists to monitor test loss and accuracy test_loss = 0.0 class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10))  model.eval() # prep model for evaluation  for data, target in test_loader:     # forward pass: compute predicted outputs by passing inputs to the model     output = model(data)     # calculate the loss     loss = criterion(output, target)     # update test loss      test_loss += loss.item()*data.size(0)     # convert output probabilities to predicted class     _, pred = torch.max(output, 1)     # compare predictions to true label     correct = np.squeeze(pred.eq(target.data.view_as(pred)))     # calculate test accuracy for each object class     for i in range(len(target)):         label = target.data[i]         class_correct[label] += correct[i].item()         class_total[label] += 1  # calculate and print avg test loss test_loss = test_loss/len(test_loader.sampler) print('Test Loss: {:.6f}\n'.format(test_loss))  for i in range(10):     if class_total[i] > 0:         print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (             str(i), 100 * class_correct[i] / class_total[i],             np.sum(class_correct[i]), np.sum(class_total[i])))     else:         print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))  print('\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (     100. * np.sum(class_correct) / np.sum(class_total),     np.sum(class_correct), np.sum(class_total)))",0
"SETUP VALIDATION sys.path.append('..path') binder.bind(globals()) print() ASSIGN = pd.read_csv('..path', nrows=50000) ASSIGN = ASSIGN.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' + 'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' + 'pickup_longitude > -74 and pickup_longitude < -73.9 and ' + 'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' + 'fare_amount > 0' ) ASSIGN = data.fare_amount ASSIGN = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'] ASSIGN = data[base_features] train_X, val_X, train_y, val_y = train_test_split(ASSIGN, ASSIGN, random_state=1) ASSIGN = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y) print() ASSIGN.head()",0,not_existent,"import pandas as pd from sklearn.ensemble import RandomForestRegressor from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split  # Environment Set-Up for feedback system. import sys sys.path.append('../input/ml-insights-tools') from learntools.core import binder binder.bind(globals()) from ex3 import * print(""Setup Complete"")  # Data manipulation code below here data = pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv', nrows=50000)  # Remove data with extreme outlier coordinates or negative fares data = data.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +                   'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +                   'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +                   'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +                   'fare_amount > 0'                   )  y = data.fare_amount  base_features = ['pickup_longitude',                  'pickup_latitude',                  'dropoff_longitude',                  'dropoff_latitude']  X = data[base_features]   train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1) first_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y) print(""Data sample:"") data.head()",1
evaluate_model(estimator=tuned_br_age),1,not_existent,evaluate_model(estimator=tuned_br_age),0
"VALIDATION ASSIGN = pd.Series(df_train_v3.columns) ASSIGN = var[~var.isin(['country','suicides_no','suicidespath'])] ASSIGN = 'suicidespath' ASSIGN = df_train_v3[x] ASSIGN = df_train_v3[y] ASSIGN = len(X3) ASSIGN = len(Y3) ASSIGN.loc[ASSIGN+1] = [2016, 'male', '25-34 years', 21845000, 57588, 'Millenials', 'North America'] ASSIGN.loc[ASSIGN+2] = [2016, 'female', '25-34 years', 21917000, 57588, 'Millenials', 'North America'] ASSIGN.loc[ASSIGN+3] = [2016, 'male', '35-54 years', 40539000, 57588, 'Generation X', 'North America'] ASSIGN.loc[ASSIGN+4] = [2016, 'female', '35-54 years', 42031000, 57588, 'Generation X', 'North America'] ASSIGN.loc[ASSIGN+5] = [2016, 'male', '15-24 years', 21719000, 57588, 'Millenials', 'North America'] ASSIGN.loc[ASSIGN+6] = [2016, 'female', '15-24 years', 21169000, 57588, 'Millenials', 'North America'] ASSIGN.loc[ASSIGN+1] = 26.95 ASSIGN.loc[ASSIGN+2] = 6.75 ASSIGN.loc[ASSIGN+3] = 28.35 ASSIGN.loc[ASSIGN+4] = 9.46 ASSIGN.loc[ASSIGN+5] = 21.06 ASSIGN.loc[ASSIGN+6] = 5.42 ASSIGN,ASSIGN = dataset_ready(ASSIGN, ASSIGN) ASSIGN = ASSIGN.loc[nx+1:nx+6] ASSIGN = ASSIGN.loc[ny+1:nx+6] ASSIGN = GLM_result.ASSIGN(X3[best_var]) for i in range(len(ASSIGN)) : print('Option',i+1) print('Predicted suicide rates :',round(ASSIGN.iloc[i],2)) print('Actual suicide rates :',ASSIGN.iloc[i]) print('')",1,not_existent,"# Preparing prediction var = pd.Series(df_train_v3.columns) x = var[~var.isin(['country','suicides_no','suicides/100k pop'])] y = 'suicides/100k pop'  X3 = df_train_v3[x] Y3 = df_train_v3[y]  # Input data for prediction nx = len(X3) ny = len(Y3) X3.loc[nx+1] = [2016, 'male', '25-34 years', 21845000, 57588, 'Millenials', 'North America'] X3.loc[nx+2] = [2016, 'female', '25-34 years', 21917000, 57588, 'Millenials', 'North America'] X3.loc[nx+3] = [2016, 'male', '35-54 years', 40539000, 57588, 'Generation X', 'North America'] X3.loc[nx+4] = [2016, 'female', '35-54 years', 42031000, 57588, 'Generation X', 'North America'] X3.loc[nx+5] = [2016, 'male', '15-24 years', 21719000, 57588, 'Millenials', 'North America'] X3.loc[nx+6] = [2016, 'female', '15-24 years', 21169000, 57588, 'Millenials', 'North America'] Y3.loc[ny+1] = 26.95 Y3.loc[ny+2] = 6.75 Y3.loc[ny+3] = 28.35 Y3.loc[ny+4] = 9.46 Y3.loc[ny+5] = 21.06 Y3.loc[ny+6] = 5.42  # Tranform the data to be ready for precition X3,Y3 = dataset_ready(X3, Y3) X3 = X3.loc[nx+1:nx+6] Y3 = Y3.loc[ny+1:nx+6]  # Predict predict = GLM_result.predict(X3[best_var]) for i in range(len(predict)) :     print('Option',i+1)     print('Predicted suicide rates :',round(predict.iloc[i],2))     print('Actual suicide rates :',Y3.iloc[i])     print('')",0
"SETUP ASSIGN = Sequential() ASSIGN.add(Dense(units=1, input_shape=[1])) ASSIGN.compile(optimizer='sgd', loss='mean_squared_error') ASSIGN = np.array([0,1,2,3,4,5,6], dtype=float) ASSIGN = np.array([0.5,1,1.5,2,2.5,3,3.5], dtype=float) ASSIGN.fit(ASSIGN, ASSIGN, epochs=500) ASSIGN.predict([7])",1,not_existent,"### House price from keras import Sequential from keras.layers import Dense  # Define model model = Sequential() model.add(Dense(units=1, input_shape=[1]))  # Compile model model.compile(optimizer='sgd', loss='mean_squared_error')  # Define data xs = np.array([0,1,2,3,4,5,6], dtype=float) ys = np.array([0.5,1,1.5,2,2.5,3,3.5], dtype=float)  # Train model model.fit(xs, ys, epochs=500)  # Predict model.predict([7])",0
"model.evaluate(test_img, test_lab)",1,not_existent,"### Evaluate model model.evaluate(test_img, test_lab)",0
"model.evaluate(val_img, val_label)",1,not_existent,"### Evaluate model model.evaluate(val_img, val_label)",0
"ASSIGN = cross_val_score(knn, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')",1,not_existent,"knn_score = cross_val_score(knn, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')",0
knn_score.mean(),0,not_existent,knn_score.mean(),1
"ASSIGN = cross_val_score(lasso, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')",1,not_existent,"lasso_score = cross_val_score(lasso, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')",0
"ASSIGN = cross_val_score(ridge, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')",1,not_existent,"ridge_score = cross_val_score(ridge, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')",0
"VALIDATION ASSIGN = cross_val_score(NB, Xtrain,Ytrain, cv=10) scores",1,not_existent,"scores = cross_val_score(NB, Xtrain,Ytrain, cv=10) scores",0
"ASSIGN = cross_val_score(knn, Xtrain_h, Ytrain_h, cv=10)",1,not_existent,"scores = cross_val_score(knn, Xtrain_h, Ytrain_h, cv=10)",0
"plt.plot(score_array, 'ro')",0,not_existent,"plt.plot(score_array, 'ro')",1
"ASSIGN = pd.read_csv('path', index_col=""ID"") ASSIGN = ASSIGN[[x for x in column_list if x != 'TARGET']] for col in squared_cols: ASSIGN = np.power(ASSIGN,2) ASSIGN = pipe.ASSIGN(test)",1,error,"test = pd.read_csv('/kaggle/input/cs-challenge/test_set.csv', index_col=""ID"")  #test = test[[x for x in non_redundant_cols if x != 'TARGET']]  test = test[[x for x in column_list if x != 'TARGET']]    for col in squared_cols:      test[col] = np.power(test[col],2)    predict = pipe.predict(test)",0
"ASSIGN = predict test['TARGET'].to_csv(""squared_ridge.csv"")",0,error,"test['TARGET'] = predict  test['TARGET'].to_csv(""squared_ridge.csv"")",1
"SETUP VALIDATION ASSIGN = linear_model.LassoCV(cv=5, random_state=0, max_iter=10000).fit(train.drop(""TARGET"",axis=1), train[""TARGET""]) print(ASSIGN.score(train.drop(,axis=1), train[]))",1,stream,"from sklearn import linear_model    lasso_reg = linear_model.LassoCV(cv=5, random_state=0, max_iter=10000).fit(train.drop(""TARGET"",axis=1), train[""TARGET""])  print(lasso_reg.score(train.drop(""TARGET"",axis=1), train[""TARGET""]))",0
"SETUP VALIDATION ASSIGN = linear_model.LassoCV(cv=5, random_state=0, max_iter=20000, fit_intercept=True,normalize = True).fit(train_base.drop(""TARGET"",axis=1), train_base[""TARGET""]) print(ASSIGN.score(train_base.drop(,axis=1), train_base[]))",1,stream,"from sklearn import linear_model    lasso_reg_base = linear_model.LassoCV(cv=5, random_state=0, max_iter=20000, fit_intercept=True,normalize = True).fit(train_base.drop(""TARGET"",axis=1), train_base[""TARGET""])  print(lasso_reg_base.score(train_base.drop(""TARGET"",axis=1), train_base[""TARGET""]))",0
"VALIDATION ASSIGN = KNeighborsClassifier(n_neighbors = 13) ASSIGN = 'accuracy' ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(ASSIGN) round(np.mean(ASSIGN)*100, 2)",1,stream,"clf = KNeighborsClassifier(n_neighbors = 13) scoring = 'accuracy' score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(score) round(np.mean(score)*100, 2)",0
"VALIDATION ASSIGN = DecisionTreeClassifier() ASSIGN = 'accuracy' ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(ASSIGN) round(np.mean(ASSIGN)*100, 2)",1,stream,"clf = DecisionTreeClassifier() scoring = 'accuracy' score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(score) round(np.mean(score)*100, 2)",0
"VALIDATION ASSIGN = RandomForestClassifier(n_estimators=13) ASSIGN = 'accuracy' ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(ASSIGN) round(np.mean(ASSIGN)*100, 2)",1,stream,"clf = RandomForestClassifier(n_estimators=13) scoring = 'accuracy' score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(score) round(np.mean(score)*100, 2)",0
"VALIDATION ASSIGN = GaussianNB() ASSIGN = 'accuracy' ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(ASSIGN) round(np.mean(ASSIGN)*100, 2)",1,stream,"clf = GaussianNB() scoring = 'accuracy' score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(score) round(np.mean(score)*100, 2)",0
"VALIDATION ASSIGN = SVC() ASSIGN = 'accuracy' ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(ASSIGN) round(np.mean(ASSIGN)*100,2)",1,stream,"clf = SVC() scoring = 'accuracy' score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(score) round(np.mean(score)*100,2)",0
"VALIDATION ASSIGN = QuadraticDiscriminantAnalysis() ASSIGN = 'accuracy' ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(ASSIGN) round(np.mean(ASSIGN)*100,2)",1,stream,"clf = QuadraticDiscriminantAnalysis() scoring = 'accuracy' score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) print(score) round(np.mean(score)*100,2)",0
"VALIDATION ASSIGN = linear_model.LinearRegression() ASSIGN = 'accuracy' ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1) print(ASSIGN) round(np.mean(ASSIGN)*100,2)",1,stream,"clf = linear_model.LinearRegression() scoring = 'accuracy' score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1) print(score) round(np.mean(score)*100,2)",0
"VALIDATION print(classification_report(y1_test, NB_pred))",0,stream,"print(classification_report(y1_test, NB_pred))",1
"VALIDATION print(classification_report(y2_test, NB_func_pred))",0,stream,"print(classification_report(y2_test, NB_func_pred))",1
"VALIDATION print(classification_report(y3_test, NB_tfidf_pred))",0,stream,"print(classification_report(y3_test, NB_tfidf_pred))",1
"VALIDATION print(classification_report(y4_test, NB_func_tfidf_pred))",0,stream,"print(classification_report(y4_test, NB_func_tfidf_pred))",1
"VALIDATION ASSIGN = {} ASSIGN = 0.0 for k in range(30, 35): ASSIGN = KNeighborsClassifier(k, metric = 'manhattan') ASSIGN = np.mean(cross_val_score(knn, numX_train, Yadult, cv = 10)) if ASSIGN > ASSIGN: ASSIGN = k ASSIGN = score ASSIGN = knn ASSIGN['KNN'].fit(numX_train, Yadult) print(.format(ASSIGN, ASSIGN))",1,stream,"classifiers = {}  scores = 0.0      for k in range(30, 35):      knn = KNeighborsClassifier(k, metric = 'manhattan')      score = np.mean(cross_val_score(knn, numX_train, Yadult, cv = 10))            if score > scores:          bestK = k          scores = score          classifiers['KNN'] = knn              classifiers['KNN'].fit(numX_train, Yadult)            print(""Best acc: {}, K = {}"".format(scores, bestK))",0
"VALIDATION ASSIGN = df['SalePrice'] ASSIGN = df.drop('SalePrice',axis=1) X_train, X_test, y_train, y_test = train_test_split( ASSIGN, ASSIGN, test_size=0.10, random_state=0) ASSIGN = Filterdataset(ASSIGN) ASSIGN = Filterdataset(ASSIGN) ASSIGN = Filterdataset(ASSIGN) ASSIGN = [] for c in ASSIGN.ASSIGN: if c in ASSIGN.ASSIGN: if c in ASSIGN.ASSIGN: ASSIGN.append(c) ASSIGN = ASSIGN[columns] ASSIGN = ASSIGN[columns] ASSIGN = ASSIGN[columns] ASSIGN = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=100) ASSIGN.fit(ASSIGN, np.log(y_train)) print(len(ASSIGN.ASSIGN), len(ASSIGN.ASSIGN), len(ASSIGN.ASSIGN))",0,not_existent,"y = df['SalePrice'] X = df.drop('SalePrice',axis=1)  X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.10, random_state=0)  X_train = Filterdataset(X_train) X_test = Filterdataset(X_test) test_final = Filterdataset(test_final) columns = [] for c in X_train.columns:     if c in X_test.columns:         if c in test_final.columns:             columns.append(c) X_train = X_train[columns] test_final = test_final[columns] X_test = X_test[columns] regr = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=100) regr.fit(X_train, np.log(y_train)) print(len(X_train.columns), len(X_test.columns), len(test_final.columns))",1
"def Mrmse(y_true,y_pred): ASSIGN = np.log(ASSIGN) ASSIGN = math.sqrt(mean_squared_error(y_true, y_pred)) return rmse",1,not_existent,"def Mrmse(y_true,y_pred):     y_true = np.log(y_true)     #y_pred = np.log(y_pred)     rmse = math.sqrt(mean_squared_error(y_true, y_pred))     return rmse",0
"VALIDATION print(metrics.r2_score(y_true=y_test, y_pred=y_test_lasso_predict)) print(metrics.r2_score(y_true=y_train, y_pred=y_train_lasso_predict))",0,stream,"print(metrics.r2_score(y_true=y_test, y_pred=y_test_lasso_predict))  print(metrics.r2_score(y_true=y_train, y_pred=y_train_lasso_predict))",1
"VALIDATION print(metrics.r2_score(y_true=y_test, y_pred=y_test_ridge_predict)) print(metrics.r2_score(y_true=y_train, y_pred=y_train_ridge_predict))",0,stream,"print(metrics.r2_score(y_true=y_test, y_pred=y_test_ridge_predict))  print(metrics.r2_score(y_true=y_train, y_pred=y_train_ridge_predict))",1
"VALIDATION print(metrics.r2_score(y_true=y_test, y_pred=y_test_elasticnet_predict)) print(metrics.r2_score(y_true=y_train, y_pred=y_train_elasticnet_predict))",0,stream,"print(metrics.r2_score(y_true=y_test, y_pred=y_test_elasticnet_predict))  print(metrics.r2_score(y_true=y_train, y_pred=y_train_elasticnet_predict))",1
"SETUP ASSIGN = make_scorer(mean_squared_error, greater_is_better = False) def rmse_cv_train(model): ASSIGN= np.sqrt(-cross_val_score(model, X_trainData, Y, scoring = scorer, cv = 5)) return(ASSIGN)",1,not_existent,"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV from sklearn.model_selection import cross_val_score, train_test_split  # Define error measure for official scoring : RMSE scorer = make_scorer(mean_squared_error, greater_is_better = False)  def rmse_cv_train(model):     rmse= np.sqrt(-cross_val_score(model, X_trainData, Y, scoring = scorer, cv = 5))     return(rmse)",0
"VALIDATION ASSIGN = LassoCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1], ASSIGN = 50000, cv = 10) ASSIGN.fit(X_trainData, Y) ASSIGN = lasso.alpha_ print(, ASSIGN) print( + str(ASSIGN)) ASSIGN = LassoCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, ASSIGN * .85, ASSIGN * .9, ASSIGN * .95, ASSIGN, ASSIGN * 1.05, ASSIGN * 1.1, ASSIGN * 1.15, ASSIGN * 1.25, ASSIGN * 1.3, ASSIGN * 1.35, ASSIGN * 1.4], ASSIGN = 50000, cv = 10) ASSIGN.fit(X_trainData, Y) ASSIGN = lasso.alpha_ print(, ASSIGN) print(, rmse_cv_train(ASSIGN).mean()) ASSIGN = lasso.predict(X_trainData) ASSIGN = lasso.predict(X_testData) plt.scatter(ASSIGN, ASSIGN - Y, c = ""blue"", marker = ""s"", label = ""Training data"", ASSIGN=0.7) plt.scatter(ASSIGN, ASSIGN - pr_testData['SalePrice'], c = ""green"", marker = ""s"", label = ""Validation data"", ASSIGN=0.7) plt.title(""Linear regression with Lasso regularization"") plt.xlabel(""Predicted values"") plt.ylabel(""Residuals"") plt.legend(loc = ""upper left"") plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = ""red"") plt.show() plt.scatter(ASSIGN, Y, c = ""blue"", marker = ""s"", label = ""Training data"", ASSIGN=0.7) plt.scatter(ASSIGN, pr_testData['SalePrice'], c = ""green"", marker = ""s"", label = ""Validation data"", ASSIGN=0.7) plt.title(""Linear regression with Lasso regularization"") plt.xlabel(""Predicted values"") plt.ylabel(""Real values"") plt.legend(loc = ""upper left"") plt.plot([10.5, 13.5], [10.5, 13.5], c = ""red"") plt.show() ASSIGN = pd.Series(lasso.coef_, index = X_trainData.columns) print( + str(sum(ASSIGN != 0)) + + \ str(sum(ASSIGN == 0)) + "" features"") ASSIGN = pd.concat([coefs.sort_values().head(10), ASSIGN.sort_values().tail(10)]) ASSIGN.plot(kind = ""barh"") plt.title(""Coefficients in the Lasso Model"") plt.show()",0,not_existent,"lasso = LassoCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1],                  max_iter = 50000, cv = 10) lasso.fit(X_trainData, Y) alpha = lasso.alpha_ print(""Best alpha :"", alpha)  print(""Try again for more precision with alphas centered around "" + str(alpha)) lasso = LassoCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8,                            alpha * .85, alpha * .9, alpha * .95, alpha, alpha * 1.05,                            alpha * 1.1, alpha * 1.15, alpha * 1.25, alpha * 1.3, alpha * 1.35,                            alpha * 1.4],                  max_iter = 50000, cv = 10) lasso.fit(X_trainData, Y) alpha = lasso.alpha_ print(""Best alpha :"", alpha)  print(""Lasso RMSE on Training set :"", rmse_cv_train(lasso).mean()) y_train_las = lasso.predict(X_trainData) y_test_las = lasso.predict(X_testData)  # Plot residuals plt.scatter(y_train_las, y_train_las - Y, c = ""blue"", marker = ""s"", label = ""Training data"", alpha=0.7) plt.scatter(y_test_las, y_test_las - pr_testData['SalePrice'], c = ""green"", marker = ""s"", label = ""Validation data"", alpha=0.7) plt.title(""Linear regression with Lasso regularization"") plt.xlabel(""Predicted values"") plt.ylabel(""Residuals"") plt.legend(loc = ""upper left"") plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = ""red"") plt.show()  # Plot predictions plt.scatter(y_train_las, Y, c = ""blue"", marker = ""s"", label = ""Training data"", alpha=0.7) plt.scatter(y_test_las, pr_testData['SalePrice'], c = ""green"", marker = ""s"", label = ""Validation data"", alpha=0.7) plt.title(""Linear regression with Lasso regularization"") plt.xlabel(""Predicted values"") plt.ylabel(""Real values"") plt.legend(loc = ""upper left"") plt.plot([10.5, 13.5], [10.5, 13.5], c = ""red"") plt.show()  # Plot important coefficients coefs = pd.Series(lasso.coef_, index = X_trainData.columns) print(""Lasso picked "" + str(sum(coefs != 0)) + "" features and eliminated the other "" +  \       str(sum(coefs == 0)) + "" features"") imp_coefs = pd.concat([coefs.sort_values().head(10),                      coefs.sort_values().tail(10)]) imp_coefs.plot(kind = ""barh"") plt.title(""Coefficients in the Lasso Model"") plt.show()",1
"VALIDATION ASSIGN = ['elefante_train', 'farfalla_train', 'mucca_train','pecora_train','scoiattolo_train'] print(classification_report(validation_generator.labels, y_pred, ASSIGN=ASSIGN))",0,stream,"  target_names = ['elefante_train', 'farfalla_train', 'mucca_train','pecora_train','scoiattolo_train']  print(classification_report(validation_generator.labels, y_pred, target_names=target_names))",1
"VALIDATION print( % (accuracy_score(y_test, pred1) * 100)) print( % (accuracy_score(y_test, pred2) * 100))",0,not_existent,"print(""Accuracy for model 1: %.2f"" % (accuracy_score(y_test, pred1) * 100)) print(""Accuracy for model 2: %.2f"" % (accuracy_score(y_test, pred2) * 100))",1
"VALIDATION print('Model 3 XGboost Report %r' % (classification_report(y_test, pred3)))",0,not_existent,"print('Model 3 XGboost Report %r' % (classification_report(y_test, pred3)))",1
"VALIDATION print('Model 5 XGboost Report %r' % (classification_report(y_test, pred5)))",0,not_existent,"print('Model 5 XGboost Report %r' % (classification_report(y_test, pred5)))",1
"VALIDATION print('Model 4 XGboost Report %r' % (classification_report(y_test, pred4)))",0,not_existent,"print('Model 4 XGboost Report %r' % (classification_report(y_test, pred4)))",1
"VALIDATION ASSIGN = [evaluate(model, valid_dl)] history",1,error,"history = [evaluate(model, valid_dl)] history",0
"SETUP VALIDATION print(classification_report(y_test, y_pred_test))",0,stream,"#Classification report from sklearn.metrics import classification_report  print(classification_report(y_test, y_pred_test))",1
"VALIDATION ASSIGN = accuracy_score(y_train,y_pred_train) print(.format(ASSIGN))",1,stream,"#Check accuracy of our model with train set  predict_train = accuracy_score(y_train,y_pred_train) print(""Accuracy of our model on train set :: {}"".format(predict_train))",0
"VALIDATION print(.format(logreg.score(X_test,y_test)))",0,stream,"#Overall Accuracy  print(""Accuracy of our model :: {}"".format(logreg.score(X_test,y_test)))",1
"VALIDATION print(.format(logreg100.score(X_test,y_test)))",0,stream,"#Overall Accuracy  print(""Accuracy of our model :: {}"".format(logreg100.score(X_test,y_test)))",1
"VALIDATION print(classification_report(y_test, y_pred_test))",0,stream,"#Classification report print(classification_report(y_test, y_pred_test))",1
"VALIDATION print(.format(logreg001.score(X_test,y_test)))",0,stream,"#Overall Accuracy  print(""Accuracy of our model :: {}"".format(logreg001.score(X_test,y_test)))",1
"ASSIGN = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0) model.compile(ASSIGN = ASSIGN , loss='sparse_categorical_crossentropy', ASSIGN=['sparse_categorical_accuracy']) ASSIGN = 37 ASSIGN = 20 ASSIGN = ImageDataGenerator( ASSIGN=False, ASSIGN=False, ASSIGN=False, ASSIGN=False, ASSIGN=False, ASSIGN=5, ASSIGN = 0.05, ASSIGN=0, ASSIGN=0, ASSIGN=False, ASSIGN=False) ASSIGN.fit(X_train) ASSIGN = model.fit_generator( ASSIGN.flow(X_train,y_train, ASSIGN=ASSIGN), ASSIGN = epoch, ASSIGN = (X_test,y_test), ASSIGN = 2, ASSIGN=X_train.shape[0] path, ASSIGN=[learning_rate_reduction] )",0,stream,"optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0) model.compile(optimizer = optimizer , loss='sparse_categorical_crossentropy',             metrics=['sparse_categorical_accuracy']) epoch = 37 batch_size = 20  datagen = ImageDataGenerator(         featurewise_center=False,  # set input mean to 0 over the dataset         samplewise_center=False,  # set each sample mean to 0         featurewise_std_normalization=False,  # divide inputs by std of the dataset         samplewise_std_normalization=False,  # divide each input by its std         zca_whitening=False,  # apply ZCA whitening         rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)         zoom_range = 0.05, # Randomly zoom image          width_shift_range=0,  # randomly shift images horizontally (fraction of total width)         height_shift_range=0,  # randomly shift images vertically (fraction of total height)         horizontal_flip=False,  # randomly flip images         vertical_flip=False)  # randomly flip images datagen.fit(X_train)  history = model.fit_generator(                               datagen.flow(X_train,y_train, batch_size=batch_size),                               epochs = epoch,                                validation_data = (X_test,y_test),                               verbose = 2,                                steps_per_epoch=X_train.shape[0] // batch_size,                               callbacks=[learning_rate_reduction]                              )",1
"VALIDATION print(history.history.keys()) plt.plot(history.history['sparse_categorical_accuracy']) plt.plot(history.history['val_sparse_categorical_accuracy']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['train', 'test'], loc='upper left') plt.show() plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss') plt.ylabel('loss') plt.xlabel('epoch') plt.legend(['train', 'test'], loc='upper left') plt.show()",0,stream,"print(history.history.keys()) # summarize history for accuracy plt.plot(history.history['sparse_categorical_accuracy']) plt.plot(history.history['val_sparse_categorical_accuracy']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['train', 'test'], loc='upper left') plt.show() # summarize history for loss plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss') plt.ylabel('loss') plt.xlabel('epoch') plt.legend(['train', 'test'], loc='upper left') plt.show()",1
evaluate_model(lr),1,display_data,evaluate_model(lr),0
"VALIDATION ASSIGN = np.nonzero(lr_pred[""Label""].values==y_test)[0] ASSIGN = np.nonzero(lr_pred[""Label""].values!=y_test)[0] print(len(ASSIGN),) print(len(ASSIGN),)",0,stream,"correct_predictions = np.nonzero(lr_pred[""Label""].values==y_test)[0] incorrect_predictions = np.nonzero(lr_pred[""Label""].values!=y_test)[0] print(len(correct_predictions),"" classified correctly"") print(len(incorrect_predictions),"" classified incorrectly"")",1
"SETUP classification_report(y_test, prediction)",1,error,"from sklearn.metrics import classification_report,accuracy_score  classification_report(y_test, prediction)",0
"VALIDATION print(+str(accuracy_score(y_test, prediction)))",0,error,"print(""Accuracy: ""+str(accuracy_score(y_test, prediction)))  # model1.score(X_test,y_test)",1
"testCNNModel('path',model)",1,execute_result,"testCNNModel('/kaggle/input/testdata2/fist1.jpg',model)",0
"testCNNModel('path',model)",1,error,"testCNNModel('/kaggle/input/testdata2/two14.jpg',model)",0
"testCNNModel('path',model)",1,execute_result,"testCNNModel('/kaggle/input/testdata2/fist5.jpg',model)",0
"testCNNModel('path',model)",1,execute_result,"testCNNModel('/kaggle/input/testdata2/two4.jpg',model)",0
"def MSE(y,y_predicted): return ((y- y_predicted)**2).mean()",1,not_existent,"def MSE(y,y_predicted):     return ((y- y_predicted)**2).mean() ",0
"SETUP def cross_entropy(y, y_hat): ASSIGN = np.clip(ASSIGN, EPS, 1-EPS) return -np.sum(y * np.log(ASSIGN)path)",1,not_existent,"EPS = 1e-9 #same as in softmax,the first line in this function just gives numerical stability for cross entropy  def cross_entropy(y, y_hat):     y_hat = np.clip(y_hat, EPS, 1-EPS) # for numerical stability     return -np.sum(y * np.log(y_hat)/n) ",0
"def predictDis(x): ASSIGN = np.array(x, dtype='float') ASSIGN = x[0:64].reshape((8, 8)) plt.imshow(ASSIGN, cmap='gray') ASSIGN = np.dot(x,w) print (""the class of this Image is: "",giveMeValueFromOneHot(softmax(ASSIGN)))",1,not_existent,"def predictDis(x):     img = np.array(x, dtype='float')     pixels = x[0:64].reshape((8, 8))     plt.imshow(pixels, cmap='gray')     z = np.dot(x,w)     print (""the class of this Image is: "",giveMeValueFromOneHot(softmax(z)))",0
ASSIGN = X[0] predictDis(ASSIGN),1,not_existent,x = X[0] predictDis(x),0
ASSIGN = X[1] predictDis(ASSIGN),1,not_existent,x = X[1] predictDis(x),0
ASSIGN = X[3] predictDis(ASSIGN),1,not_existent,x = X[3] predictDis(x),0
"SETUP ASSIGN = KMeans(n_clusters=9) ASSIGN = kmeans.fit_predict(X_5d) ASSIGN = go.Scatter(x=X_5d[:, 0], y= X_5d[:, 1], mode=""markers"", ASSIGN=False, ASSIGN=dict( ASSIGN=8, ASSIGN = X_clustered, ASSIGN = 'Portland', ASSIGN=False, ASSIGN = dict( ASSIGN = 2, ASSIGN = 'rgb(255, 255, 255)' ) )) ASSIGN = go.Layout( ASSIGN= 'KMeans Clustering', ASSIGN= 'closest', ASSIGN= dict( ASSIGN= 'First Principal Component', ASSIGN= 5, ASSIGN= False, ASSIGN= 2, ), ASSIGN=dict( ASSIGN= 'Second Principal Component', ASSIGN= 5, ASSIGN= 2, ), ASSIGN= True ) ASSIGN = [trace_Kmeans] ASSIGN = dict(data=data, layout= layout) py.iplot(ASSIGN, filename=""svm"")",1,display_data,"from sklearn.cluster import KMeans # KMeans clustering   # Set a KMeans clustering with 9 components ( 9 chosen sneakily ;) as hopefully we get back our 9 class labels)  kmeans = KMeans(n_clusters=9)  # Compute cluster centers and predict cluster indices  X_clustered = kmeans.fit_predict(X_5d)    trace_Kmeans = go.Scatter(x=X_5d[:, 0], y= X_5d[:, 1], mode=""markers"",                      showlegend=False,                      marker=dict(                              size=8,                              color = X_clustered,                              colorscale = 'Portland',                              showscale=False,                               line = dict(              width = 2,              color = 'rgb(255, 255, 255)'          )                     ))    layout = go.Layout(      title= 'KMeans Clustering',      hovermode= 'closest',      xaxis= dict(           title= 'First Principal Component',          ticklen= 5,          zeroline= False,          gridwidth= 2,      ),      yaxis=dict(          title= 'Second Principal Component',          ticklen= 5,          gridwidth= 2,      ),      showlegend= True  )    data = [trace_Kmeans]  fig1 = dict(data=data, layout= layout)  # fig1.append_trace(contour_list)  py.iplot(fig1, filename=""svm"")",0
VALIDATION for col in test_data.columns: if test_data[col].isnull().any(): ASSIGN=test_data[col].isnull().sum() if ASSIGN>50: print(col++str(ASSIGN)),0,stream,"for col in test_data.columns:      if test_data[col].isnull().any():          x=test_data[col].isnull().sum()          if x>50:              print(col+""\t""+str(x))",1
"ASSIGN = {'undamaged': 0, 'repair': 1, 'replace': 2} data['operation_rank'] = data['operation'].apply(lambda x: ASSIGN[x]) def mae_single_point(urr_score, operation_rank, repair_threshold, replace_threshold): ASSIGN = int(urr_score > repair_threshold) + int(urr_score > replace_threshold) return abs(ASSIGN - operation_rank) assert(mae_single_point(0.9, 0, 0.4, 0.7) == 2) assert(mae_single_point(0.5, 1, 0.4, 0.7) == 0) assert(mae_single_point(0.5, 2, 0.4, 0.7) == 1)",1,not_existent,"operation_ranks = {'undamaged': 0,                     'repair': 1,                     'replace': 2}    data['operation_rank'] = data['operation'].apply(lambda x: operation_ranks[x])    def mae_single_point(urr_score, operation_rank, repair_threshold, replace_threshold):      classified_outcome_rank = int(urr_score > repair_threshold) + int(urr_score > replace_threshold)        return abs(classified_outcome_rank - operation_rank)    assert(mae_single_point(0.9, 0, 0.4, 0.7) == 2)  assert(mae_single_point(0.5, 1, 0.4, 0.7) == 0)  assert(mae_single_point(0.5, 2, 0.4, 0.7) == 1)      ",0
"VALIDATION ASSIGN=range(1,15) ASSIGN='accuracy' ASSIGN = [] ASSIGN = [] ASSIGN = [] ASSIGN = [] for depth in ASSIGN: DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth) DecisionTree.fit(X, y_equidistant) ASSIGN = cross_val_score(DecisionTree, X, y_equidistant, cv=cv_strategy, scoring=scoring) ASSIGN.append(ASSIGN) ASSIGN.append(ASSIGN.mean()) ASSIGN.append(ASSIGN.std()) ASSIGN.append(DecisionTree.score(X, y_equidistant)) ASSIGN=""depth %d, cv_val_scores_mean %f score %f""%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_equidistant)) print(ASSIGN) ASSIGN = np.array(ASSIGN) ASSIGN = np.array(ASSIGN) ASSIGN = np.array(ASSIGN)",1,stream,"depths=range(1,15)  scoring='accuracy'  cv_val_scores_list = []  cv_val_scores_std = []  cv_val_scores_mean = []  accuracy_scores = []  for depth in depths:      DecisionTree = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=depth)      DecisionTree.fit(X, y_equidistant)      cv_val_scores = cross_val_score(DecisionTree, X, y_equidistant, cv=cv_strategy, scoring=scoring)      cv_val_scores_list.append(cv_val_scores)      cv_val_scores_mean.append(cv_val_scores.mean())      cv_val_scores_std.append(cv_val_scores.std())      accuracy_scores.append(DecisionTree.score(X, y_equidistant))      Text=""depth %d, cv_val_scores_mean %f  score %f""%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_equidistant))      print(Text)  cv_val_scores_mean = np.array(cv_val_scores_mean)  cv_val_scores_std = np.array(cv_val_scores_std)  accuracy_scores = np.array(accuracy_scores)",0
"VALIDATION ASSIGN=range(1,15) ASSIGN='accuracy' ASSIGN = [] ASSIGN = [] ASSIGN = [] ASSIGN = [] for depth in ASSIGN: DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth) DecisionTree.fit(X, y_balanced) ASSIGN = cross_val_score(DecisionTree, X, y_balanced, cv=cv_strategy, scoring=scoring) ASSIGN.append(ASSIGN) ASSIGN.append(ASSIGN.mean()) ASSIGN.append(ASSIGN.std()) ASSIGN.append(DecisionTree.score(X, y_balanced)) ASSIGN=""depth %d, cv_val_scores_mean %f score %f""%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_balanced)) print(ASSIGN) ASSIGN = np.array(ASSIGN) ASSIGN = np.array(ASSIGN) ASSIGN = np.array(ASSIGN)",1,stream,"depths=range(1,15)  scoring='accuracy'  cv_val_scores_list = []  cv_val_scores_std = []  cv_val_scores_mean = []  accuracy_scores = []  for depth in depths:      DecisionTree = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=depth)      DecisionTree.fit(X, y_balanced)      cv_val_scores = cross_val_score(DecisionTree, X, y_balanced, cv=cv_strategy, scoring=scoring)      cv_val_scores_list.append(cv_val_scores)      cv_val_scores_mean.append(cv_val_scores.mean())      cv_val_scores_std.append(cv_val_scores.std())      accuracy_scores.append(DecisionTree.score(X, y_balanced))      Text=""depth %d, cv_val_scores_mean %f  score %f""%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_balanced))      print(Text)  cv_val_scores_mean = np.array(cv_val_scores_mean)  cv_val_scores_std = np.array(cv_val_scores_std)  accuracy_scores = np.array(accuracy_scores)",0
"SETUP ASSIGN = ListedColormap([' ASSIGN = ListedColormap([' ASSIGN=pd.DataFrame(feature_2).loc[:][0] ASSIGN=pd.DataFrame(feature_2).loc[:][1] ASSIGN='distance' ASSIGN = .02 ASSIGN = Pipeline([ ('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors=k_Optimal)) ]) ASSIGN.fit(feature_2, y_equidistant) feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1 feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1 ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h)) ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()]) ASSIGN = Z.reshape(xx.shape)",1,not_existent,"from matplotlib.colors import ListedColormap  from sklearn import neighbors, datasets  from sklearn.metrics import accuracy_score    # Create color maps  cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF', '#EFFF00', '#B4FCFF', '#FFB4F5'])  cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF', '#FF00F7', '#00FFE6', '#FFA200'])    feature1=pd.DataFrame(feature_2).loc[:][0]  feature2=pd.DataFrame(feature_2).loc[:][1]    weights='distance'  h = .02  # step size in the mesh  # we create an instance of Neighbours Classifier and fit the data.  # Create a k-NN pipeline  knn_pipe = Pipeline([      ('scaler', StandardScaler()),      ('knn', KNeighborsClassifier(n_neighbors=k_Optimal))      #, weights=weights))  ])  # Fit estimator  knn_pipe.fit(feature_2, y_equidistant)  # Plot the decision boundary. For that, we will assign a color to each  # point in the mesh [x_min, x_max]x[y_min, y_max].  feature1_min, feature1_max = feature1.min() - 1, feature1.max() + 1  feature2_min, feature2_max = feature2.min() - 1, feature2.max() + 1  xx, yy = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))  Z = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])  Zo = Z.reshape(xx.shape)",0
"SETUP VALIDATION print(classification_report(y_true=y_fea_2_te_equid, y_pred=knn_predict))",0,stream,"from sklearn.metrics import classification_report  print(classification_report(y_true=y_fea_2_te_equid, y_pred=knn_predict))",1
"ASSIGN = ListedColormap([' ASSIGN = ListedColormap([' ASSIGN=pd.DataFrame(feature_2).loc[:][0] ASSIGN=pd.DataFrame(feature_2).loc[:][1] ASSIGN='distance' ASSIGN = .02 ASSIGN = Pipeline([ ('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN)) ]) ASSIGN.fit(feature_2, y_balanced) feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1 feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1 ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h)) ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()]) ASSIGN = Z.reshape(xx.shape)",1,not_existent,"# Create color maps  cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF', '#EFFF00', '#B4FCFF', '#FFB4F5'])  cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF', '#FF00F7', '#00FFE6', '#FFA200'])  #  feature1=pd.DataFrame(feature_2).loc[:][0]  feature2=pd.DataFrame(feature_2).loc[:][1]  #  weights='distance'  h = .02  # step size in the mesh  # Create a k-NN pipeline  knn_pipe = Pipeline([      ('scaler', StandardScaler()),      ('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))  ])  # Fit estimator  knn_pipe.fit(feature_2, y_balanced)  # Plot the decision boundary. For that, we will assign a color to each  # point in the mesh [x_min, x_max]x[y_min, y_max].  feature1_min, feature1_max = feature1.min() - 1, feature1.max() + 1  feature2_min, feature2_max = feature2.min() - 1, feature2.max() + 1  xx, yy = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))  Z = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])  Zo = Z.reshape(xx.shape)",0
"VALIDATION ASSIGN=range(1,15) ASSIGN='accuracy' ASSIGN = [] ASSIGN = [] ASSIGN = [] ASSIGN = [] for depth in ASSIGN: DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth) DecisionTree.fit(X, y_equidistant) ASSIGN = cross_val_score(DecisionTree, X, y_equidistant, cv=cv_strategy, scoring=scoring) ASSIGN.append(ASSIGN) ASSIGN.append(ASSIGN.mean()) ASSIGN.append(ASSIGN.std()) ASSIGN.append(DecisionTree.score(X, y_equidistant)) ASSIGN=""depth %d, cv_val_scores_mean %f std %f score %f""%(depth,cv_val_scores.mean(),cv_val_scores.std(),DecisionTree.score(X, y_equidistant)) print(ASSIGN) ASSIGN = np.array(ASSIGN) ASSIGN = np.array(ASSIGN) ASSIGN = np.array(ASSIGN)",1,stream,"depths=range(1,15)  scoring='accuracy'  cv_val_scores_list = []  cv_val_scores_std = []  cv_val_scores_mean = []  accuracy_scores = []  for depth in depths:      DecisionTree = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=depth)      DecisionTree.fit(X, y_equidistant)      cv_val_scores = cross_val_score(DecisionTree, X, y_equidistant, cv=cv_strategy, scoring=scoring)      cv_val_scores_list.append(cv_val_scores)      cv_val_scores_mean.append(cv_val_scores.mean())      cv_val_scores_std.append(cv_val_scores.std())      accuracy_scores.append(DecisionTree.score(X, y_equidistant))      Text=""depth %d, cv_val_scores_mean %f std %f score %f""%(depth,cv_val_scores.mean(),cv_val_scores.std(),DecisionTree.score(X, y_equidistant))      print(Text)  cv_val_scores_mean = np.array(cv_val_scores_mean)  cv_val_scores_std = np.array(cv_val_scores_std)  accuracy_scores = np.array(accuracy_scores)",0
"ASSIGN = ListedColormap([' ASSIGN = ListedColormap([' ASSIGN=pd.DataFrame(feature_2).loc[:][0] ASSIGN=pd.DataFrame(feature_2).loc[:][1] ASSIGN='distance' ASSIGN = .02 ASSIGN = Pipeline([ ('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN)) ]) ASSIGN.fit(feature_2, y_equidistant) feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1 feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1 ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h)) ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()]) ASSIGN = Z.reshape(xx.shape)",1,not_existent,"# Create color maps  cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF', '#EFFF00', '#B4FCFF', '#FFB4F5'])  cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF', '#FF00F7', '#00FFE6', '#FFA200'])    feature1=pd.DataFrame(feature_2).loc[:][0]  feature2=pd.DataFrame(feature_2).loc[:][1]    weights='distance'  h = .02  # step size in the mesh  # we create an instance of Neighbours Classifier and fit the data.  # Create a k-NN pipeline  knn_pipe = Pipeline([      ('scaler', StandardScaler()),      ('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))  ])  # Fit estimator  knn_pipe.fit(feature_2, y_equidistant)  # Plot the decision boundary. For that, we will assign a color to each  # point in the mesh [x_min, x_max]x[y_min, y_max].  feature1_min, feature1_max = feature1.min() - 1, feature1.max() + 1  feature2_min, feature2_max = feature2.min() - 1, feature2.max() + 1  xx, yy = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))  Z = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])  Zo = Z.reshape(xx.shape)",0
"ASSIGN = ListedColormap([' ASSIGN = ListedColormap([' ASSIGN=pd.DataFrame(feature_2).loc[:][0] ASSIGN=pd.DataFrame(feature_2).loc[:][1] ASSIGN='distance' ASSIGN = .02 ASSIGN = Pipeline([ ('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN)) ]) ASSIGN.fit(feature_2, y_balanced) feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1 feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1 ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h)) ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()]) ASSIGN = Z.reshape(xx.shape)",1,not_existent,"# Create color maps  cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF', '#EFFF00', '#B4FCFF', '#FFB4F5'])  cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF', '#FF00F7', '#00FFE6', '#FFA200'])    feature1=pd.DataFrame(feature_2).loc[:][0]  feature2=pd.DataFrame(feature_2).loc[:][1]    weights='distance'  h = .02  # step size in the mesh  # we create an instance of Neighbours Classifier and fit the data.  # Create a k-NN pipeline  knn_pipe = Pipeline([      ('scaler', StandardScaler()),      ('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))  ])  # Fit estimator  knn_pipe.fit(feature_2, y_balanced)  # Plot the decision boundary. For that, we will assign a color to each  # point in the mesh [x_min, x_max]x[y_min, y_max].  feature1_min, feature1_max = feature1.min() - 1, feature1.max() + 1  feature2_min, feature2_max = feature2.min() - 1, feature2.max() + 1  xx, yy = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))  Z = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])  Zo = Z.reshape(xx.shape)",0
"SETUP VALIDATION ASSIGN = LinearRegression() ASSIGN.fit(x_train.reshape(-1,1), y_train.reshape(-1,1)) print(ASSIGN.coef_) print(ASSIGN.intercept_)",0,not_existent,"from sklearn.linear_model import LinearRegression lr = LinearRegression() lr.fit(x_train.reshape(-1,1), y_train.reshape(-1,1)) print(lr.coef_) print(lr.intercept_)",1
"VALIDATION ASSIGN = model.score_samples(X) ASSIGN = np.percentile(density,4) cc1['cluster']=clusters cc1['Anamoly'] = ASSIGN<ASSIGN cc1",1,execute_result,"density = model.score_samples(X)  density_threshold = np.percentile(density,4)  cc1['cluster']=clusters  cc1['Anamoly'] = density<density_threshold  cc1",0
"plt.scatter(shyness_score, friendship_len)",0,execute_result,"plt.scatter(shyness_score, friendship_len)",1
