{
    "source": [
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=['timestamp'])",
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=['timestamp'])",
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=['timestamp'])",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=['timestamp'])",
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=['timestamp'])",
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=['timestamp'])",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df_train['price_doc'].hist(bins=50)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_train['price_doc'].hist(bins=50)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df_train['price_doc'].values",
                "ASSIGN = df_test['id']",
                "df_train.drop(['id', 'price_doc'], axis=1, inplace=True)",
                "df_test.drop(['id'], axis=1, inplace=True)",
                "ASSIGN = len(df_train)",
                "ASSIGN = pd.concat([df_train, df_test])",
                "ASSIGN = pd.merge_ordered(ASSIGN, df_macro, on='timestamp', how='left')",
                "print(ASSIGN.shape)",
                "ASSIGN = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)",
                "ASSIGN = month_year.value_counts().to_dict()",
                "ASSIGN['month_year_cnt'] = ASSIGN.map(ASSIGN)",
                "ASSIGN = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)",
                "ASSIGN = week_year.value_counts().to_dict()",
                "ASSIGN['week_year_cnt'] = ASSIGN.map(ASSIGN)",
                "ASSIGN['month'] = ASSIGN.timestamp.dt.month",
                "ASSIGN['dow'] = ASSIGN.timestamp.dt.dayofweek",
                "ASSIGN['rel_floor'] = ASSIGN['floor'] path['max_floor'].astype(float)",
                "ASSIGN['rel_kitch_sq'] = ASSIGN['kitch_sq'] path['full_sq'].astype(float)",
                "ASSIGN.drop(['timestamp'], axis=1, inplace=True)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df_train['price_doc'].values",
                "ASSIGN = df_test['id']",
                "df_train.drop(['id', 'price_doc'], axis=1, inplace=True)",
                "df_test.drop(['id'], axis=1, inplace=True)",
                "ASSIGN = len(df_train)",
                "ASSIGN = pd.concat([df_train, df_test])",
                "ASSIGN = pd.merge_ordered(ASSIGN, df_macro, on='timestamp', how='left')",
                "print(ASSIGN.shape)",
                "ASSIGN = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)",
                "ASSIGN = month_year.value_counts().to_dict()",
                "ASSIGN['month_year_cnt'] = ASSIGN.map(ASSIGN)",
                "ASSIGN = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)",
                "ASSIGN = week_year.value_counts().to_dict()",
                "ASSIGN['week_year_cnt'] = ASSIGN.map(ASSIGN)",
                "ASSIGN['month'] = ASSIGN.timestamp.dt.month",
                "ASSIGN['dow'] = ASSIGN.timestamp.dt.dayofweek",
                "ASSIGN['rel_floor'] = ASSIGN['floor'] path['max_floor'].astype(float)",
                "ASSIGN['rel_kitch_sq'] = ASSIGN['kitch_sq'] path['full_sq'].astype(float)",
                "ASSIGN.drop(['timestamp'], axis=1, inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df_all.select_dtypes(exclude=['object'])",
                "ASSIGN = df_all.select_dtypes(include=['object']).copy()",
                "for c in ASSIGN:",
                "ASSIGN[c] = pd.factorize(ASSIGN[c])[0]",
                "ASSIGN = pd.concat([df_numeric, df_obj], axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df_all.select_dtypes(exclude=['object'])",
                "ASSIGN = df_all.select_dtypes(include=['object']).copy()",
                "for c in ASSIGN:",
                "ASSIGN[c] = pd.factorize(ASSIGN[c])[0]",
                "ASSIGN = pd.concat([df_numeric, df_obj], axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df_values.values",
                "print(ASSIGN.shape)",
                "ASSIGN = X_all[:num_train]",
                "ASSIGN = X_all[num_train:]",
                "ASSIGN = df_values.columns"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df_values.values",
                "print(ASSIGN.shape)",
                "ASSIGN = X_all[:num_train]",
                "ASSIGN = X_all[num_train:]",
                "ASSIGN = df_values.columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {",
                "'eta': 0.05,",
                "'max_depth': 5,",
                "'subsample': 0.7,",
                "'colsample_bytree': 0.7,",
                "'objective': 'reg:linear',",
                "'eval_metric': 'rmse',",
                "'silent': 1",
                "}",
                "ASSIGN = xgb.DMatrix(X_train, y_train, feature_names=df_columns)",
                "ASSIGN = xgb.DMatrix(X_test, feature_names=df_columns)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {",
                "'eta': 0.05,",
                "'max_depth': 5,",
                "'subsample': 0.7,",
                "'colsample_bytree': 0.7,",
                "'objective': 'reg:linear',",
                "'eval_metric': 'rmse',",
                "'silent': 1",
                "}",
                "ASSIGN = xgb.DMatrix(X_train, y_train, feature_names=df_columns)",
                "ASSIGN = xgb.DMatrix(X_test, feature_names=df_columns)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 383"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 383"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_round)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_round)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1, 1, figsize=(8, 16))",
                "xgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1, 1, figsize=(8, 16))",
                "xgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = model.predict(dtest)",
                "ASSIGN = pd.DataFrame({'id': id_test, 'price_doc': y_pred})",
                "ASSIGN.to_csv('sub.csv', index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = model.predict(dtest)",
                "ASSIGN = pd.DataFrame({'id': id_test, 'price_doc': y_pred})",
                "ASSIGN.to_csv('sub.csv', index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN=test_data"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN=test_data"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train_data.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train_data.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test_data.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test_data.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [col for col in train_data.columns if train_data[col].isnull().any()]",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [col for col in train_data.columns if train_data[col].isnull().any()]",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [col for col in test_data.columns if test_data[col].isnull().any()]",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [col for col in test_data.columns if test_data[col].isnull().any()]",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "ASSIGN=[]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=[]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for col in train_data.columns:",
                "if train_data[col].isnull().any():",
                "ASSIGN=train_data[col].isnull().sum()",
                "if ASSIGN>50:",
                "print(col++str(ASSIGN))",
                "drop_column.append(col)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for col in train_data.columns:",
                "if train_data[col].isnull().any():",
                "ASSIGN=train_data[col].isnull().sum()",
                "if ASSIGN>50:",
                "print(col++str(ASSIGN))",
                "drop_column.append(col)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for col in test_data.columns:",
                "if test_data[col].isnull().any():",
                "ASSIGN=test_data[col].isnull().sum()",
                "if ASSIGN>50:",
                "print(col++str(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for col in test_data.columns:",
                "if test_data[col].isnull().any():",
                "ASSIGN=test_data[col].isnull().sum()",
                "if ASSIGN>50:",
                "print(col++str(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(drop_column)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(drop_column)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN.drop(drop_column,axis=1)",
                "ASSIGN=ASSIGN.drop(drop_column,axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=ASSIGN.drop(drop_column,axis=1)",
                "ASSIGN=ASSIGN.drop(drop_column,axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=train_data.drop([\"SalePrice\"],axis=1)",
                "ASSIGN=train_data[\"SalePrice\"]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=train_data.drop([\"SalePrice\"],axis=1)",
                "ASSIGN=train_data[\"SalePrice\"]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "X_train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "X_train.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "Y_train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Y_train.head()"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "ASSIGN=[]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=[]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for col in X_train.columns:",
                "if X_train[col].dtype=='object':",
                "cat_column.append(col)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for col in X_train.columns:",
                "if X_train[col].dtype=='object':",
                "cat_column.append(col)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(cat_column)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(cat_column)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for col in cat_column:",
                "print(col)",
                "print(X_train[col].value_counts())",
                "print(*50)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for col in cat_column:",
                "print(col)",
                "print(X_train[col].value_counts())",
                "print(*50)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "def score_dataset(X_train, X_valid, y_train, y_valid):",
                "ASSIGN = XGBRegressor(n_estimators=1000, learning_rate=0.01)",
                "ASSIGN.fit(X_train, y_train, early_stopping_rounds=50,",
                "ASSIGN=[(X_valid, y_valid)], verbose=False)",
                "ASSIGN.fit(X_train, y_train)",
                "ASSIGN = my_model.predict(X_valid)",
                "return mean_absolute_error(y_valid, ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "def score_dataset(X_train, X_valid, y_train, y_valid):",
                "ASSIGN = XGBRegressor(n_estimators=1000, learning_rate=0.01)",
                "ASSIGN.fit(X_train, y_train, early_stopping_rounds=50,",
                "ASSIGN=[(X_valid, y_valid)], verbose=False)",
                "ASSIGN.fit(X_train, y_train)",
                "ASSIGN = my_model.predict(X_valid)",
                "return mean_absolute_error(y_valid, ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = train_test_split(X_train, Y_train,",
                "ASSIGN=0.8, test_size=0.2,",
                "ASSIGN=0)",
                "ASSIGN=test_data"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = train_test_split(X_train, Y_train,",
                "ASSIGN=0.8, test_size=0.2,",
                "ASSIGN=0)",
                "ASSIGN=test_data"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=SimpleImputer(strategy=\"most_frequent\")",
                "ASSIGN= pd.DataFrame(my_imputer.fit_transform(x_train))",
                "ASSIGN=pd.DataFrame(my_imputer.transform(x_test))",
                "ASSIGN=pd.DataFrame(my_imputer.transform(x_valid))",
                "ASSIGN.index = x_train.index",
                "ASSIGN.index = x_valid.index",
                "ASSIGN.index = x_test.index",
                "ASSIGN.columns=x_train.columns",
                "ASSIGN.columns=x_valid.columns",
                "ASSIGN.columns=x_test.columns"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN=SimpleImputer(strategy=\"most_frequent\")",
                "ASSIGN= pd.DataFrame(my_imputer.fit_transform(x_train))",
                "ASSIGN=pd.DataFrame(my_imputer.transform(x_test))",
                "ASSIGN=pd.DataFrame(my_imputer.transform(x_valid))",
                "ASSIGN.index = x_train.index",
                "ASSIGN.index = x_valid.index",
                "ASSIGN.index = x_test.index",
                "ASSIGN.columns=x_train.columns",
                "ASSIGN.columns=x_valid.columns",
                "ASSIGN.columns=x_test.columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "Col_with_missing_2 = [col for col in imputed_X_valid.columns if imputed_X_valid[col].isnull().any()]",
                "print(Col_with_missing_2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "Col_with_missing_2 = [col for col in imputed_X_valid.columns if imputed_X_valid[col].isnull().any()]",
                "print(Col_with_missing_2)"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "ASSIGN=[]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=[]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for col in x_train.columns:",
                "if(x_train[col].dtype!=\"object\"):",
                "print(col++str(x_train[col].dtype))",
                "if col!=\"Id\":",
                "Num_col.append(col)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for col in x_train.columns:",
                "if(x_train[col].dtype!=\"object\"):",
                "print(col++str(x_train[col].dtype))",
                "if col!=\"Id\":",
                "Num_col.append(col)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(Num_col)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(Num_col)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "\"\"\"",
                "ASSIGN=[]",
                "for col in Num_col:",
                "ASSIGN.append(col)",
                "\"\"\"",
                "ASSIGN=['TotalBsmtSF', 'WoodDeckSF', 'BsmtUnfSF', 'YearRemodAdd', '3SsnPorch', 'KitchenAbvGr', '2ndFlrSF', 'ScreenPorch', 'PoolArea', 'TotRmsAbvGrd', 'MoSold', 'BedroomAbvGr', 'MiscVal', 'BsmtHalfBath', '1stFlrSF', 'GarageCars', 'OverallQual', 'YrSold', 'HalfBath', 'OpenPorchSF', 'BsmtFullBath', 'LowQualFinSF', 'LotArea', 'OverallCond', 'YearBuilt', 'EnclosedPorch', 'FullBath', 'Fireplaces', 'BsmtFinSF2', 'BsmtFinSF1', 'MSSubClass', 'GrLivArea', 'GarageArea']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "\"\"\"",
                "ASSIGN=[]",
                "for col in Num_col:",
                "ASSIGN.append(col)",
                "\"\"\"",
                "ASSIGN=['TotalBsmtSF', 'WoodDeckSF', 'BsmtUnfSF', 'YearRemodAdd', '3SsnPorch', 'KitchenAbvGr', '2ndFlrSF', 'ScreenPorch', 'PoolArea', 'TotRmsAbvGrd', 'MoSold', 'BedroomAbvGr', 'MiscVal', 'BsmtHalfBath', '1stFlrSF', 'GarageCars', 'OverallQual', 'YrSold', 'HalfBath', 'OpenPorchSF', 'BsmtFullBath', 'LowQualFinSF', 'LotArea', 'OverallCond', 'YearBuilt', 'EnclosedPorch', 'FullBath', 'Fireplaces', 'BsmtFinSF2', 'BsmtFinSF1', 'MSSubClass', 'GrLivArea', 'GarageArea']"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(feature)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(feature)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for col in cat_column:",
                "print(col)",
                "print(X_train[col].value_counts())",
                "print(*50)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for col in cat_column:",
                "print(col)",
                "print(X_train[col].value_counts())",
                "print(*50)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for col in cat_enc_col:",
                "feature.append(col)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for col in cat_enc_col:",
                "feature.append(col)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN[feature]",
                "ASSIGN=ASSIGN[feature]",
                "ASSIGN=ASSIGN[feature]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=ASSIGN[feature]",
                "ASSIGN=ASSIGN[feature]",
                "ASSIGN=ASSIGN[feature]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "imputed_X_train.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "imputed_X_train.head(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=cat_enc_col"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=cat_enc_col"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = OneHotEncoder(handle_unknown='ignore', sparse=False)",
                "ASSIGN = pd.DataFrame(OH_encoder.fit_transform(imputed_X_train[Cat_cols]))",
                "ASSIGN = pd.DataFrame(OH_encoder.transform(imputed_X_valid[Cat_cols]))",
                "ASSIGN = pd.DataFrame(OH_encoder.transform(imputed_X_test[Cat_cols]))",
                "ASSIGN.index = imputed_X_train.index",
                "ASSIGN.index = imputed_X_valid.index",
                "ASSIGN.index = imputed_X_test.index",
                "ASSIGN = imputed_X_train.drop(Cat_cols, axis =1)",
                "ASSIGN = imputed_X_valid.drop(Cat_cols, axis =1)",
                "ASSIGN = imputed_X_test.drop(Cat_cols, axis =1)",
                "ASSIGN = pd.concat([num_X_train, OH_cols_train], axis=1)",
                "ASSIGN = pd.concat([num_X_valid, OH_cols_valid], axis=1)",
                "ASSIGN = pd.concat([num_X_test, OH_cols_test], axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = OneHotEncoder(handle_unknown='ignore', sparse=False)",
                "ASSIGN = pd.DataFrame(OH_encoder.fit_transform(imputed_X_train[Cat_cols]))",
                "ASSIGN = pd.DataFrame(OH_encoder.transform(imputed_X_valid[Cat_cols]))",
                "ASSIGN = pd.DataFrame(OH_encoder.transform(imputed_X_test[Cat_cols]))",
                "ASSIGN.index = imputed_X_train.index",
                "ASSIGN.index = imputed_X_valid.index",
                "ASSIGN.index = imputed_X_test.index",
                "ASSIGN = imputed_X_train.drop(Cat_cols, axis =1)",
                "ASSIGN = imputed_X_valid.drop(Cat_cols, axis =1)",
                "ASSIGN = imputed_X_test.drop(Cat_cols, axis =1)",
                "ASSIGN = pd.concat([num_X_train, OH_cols_train], axis=1)",
                "ASSIGN = pd.concat([num_X_valid, OH_cols_valid], axis=1)",
                "ASSIGN = pd.concat([num_X_test, OH_cols_test], axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN = ASSIGN.apply(pd.to_numeric)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN = ASSIGN.apply(pd.to_numeric)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "OH_X_test.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "OH_X_test.head(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,end=)",
                "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,end=)",
                "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = GradientBoostingRegressor(loss=\"ls\",learning_rate=0.01,n_estimators=1000,max_depth=4,alpha=0.08)",
                "ASSIGN.fit(OH_X_train, y_train)",
                "ASSIGN = my_model.predict(OH_X_valid)",
                "print(,mean_absolute_error(y_valid, ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = GradientBoostingRegressor(loss=\"ls\",learning_rate=0.01,n_estimators=1000,max_depth=4,alpha=0.08)",
                "ASSIGN.fit(OH_X_train, y_train)",
                "ASSIGN = my_model.predict(OH_X_valid)",
                "print(,mean_absolute_error(y_valid, ASSIGN))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = XGBRegressor(n_estimators=2000, learning_rate=0.008)",
                "ASSIGN.fit(OH_X_train, y_train, early_stopping_rounds=50,",
                "ASSIGN=[(OH_X_valid, y_valid)], verbose=False)",
                "ASSIGN = my_model_1.predict(OH_X_valid)",
                "print(,mean_absolute_error(y_valid, ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = XGBRegressor(n_estimators=2000, learning_rate=0.008)",
                "ASSIGN.fit(OH_X_train, y_train, early_stopping_rounds=50,",
                "ASSIGN=[(OH_X_valid, y_valid)], verbose=False)",
                "ASSIGN = my_model_1.predict(OH_X_valid)",
                "print(,mean_absolute_error(y_valid, ASSIGN))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = GradientBoostingRegressor(loss=\"ls\",learning_rate=0.01,n_estimators=2000,max_depth=4,alpha=0.08)",
                "ASSIGN.fit(OH_X_train, y_train)",
                "ASSIGN = my_model_2.predict(OH_X_valid)",
                "print(,mean_absolute_error(y_valid, ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = GradientBoostingRegressor(loss=\"ls\",learning_rate=0.01,n_estimators=2000,max_depth=4,alpha=0.08)",
                "ASSIGN.fit(OH_X_train, y_train)",
                "ASSIGN = my_model_2.predict(OH_X_valid)",
                "print(,mean_absolute_error(y_valid, ASSIGN))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=(preds_1+preds_2)path",
                "print(,mean_absolute_error(y_valid, ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=(preds_1+preds_2)path",
                "print(,mean_absolute_error(y_valid, ASSIGN))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = my_model_1.predict(OH_X_test)",
                "ASSIGN = my_model_2.predict(OH_X_test)",
                "ASSIGN=(predictions1+predictions2)path"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = my_model_1.predict(OH_X_test)",
                "ASSIGN = my_model_2.predict(OH_X_test)",
                "ASSIGN=(predictions1+predictions2)path"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "Preds_last"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "Preds_last"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({'Id': test.Id,'SalePrice': Preds_last})",
                "ASSIGN.to_csv('submission1.csv', index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame({'Id': test.Id,'SalePrice': Preds_last})",
                "ASSIGN.to_csv('submission1.csv', index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",",
                "ASSIGN=\"github_repos\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",",
                "ASSIGN=\"github_repos\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = (\"\"\"",
                "-- Select all the columns we want in our joined table",
                "SELECT L.license, COUNT(sf.path) AS number_of_files",
                "FROM `bigquery-public-data.github_repos.sample_files` as sf",
                "-- Table to merge into sample_files",
                "INNER JOIN `bigquery-public-data.github_repos.licenses` as L",
                "ON sf.repo_name = L.repo_name -- what columns should we join on?",
                "GROUP BY L.license",
                "ORDER BY number_of_files DESC",
                "\"\"\")",
                "ASSIGN = github.query_to_pandas_safe(query, max_gb_scanned=6)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = (\"\"\"",
                "-- Select all the columns we want in our joined table",
                "SELECT L.license, COUNT(sf.path) AS number_of_files",
                "FROM `bigquery-public-data.github_repos.sample_files` as sf",
                "-- Table to merge into sample_files",
                "INNER JOIN `bigquery-public-data.github_repos.licenses` as L",
                "ON sf.repo_name = L.repo_name -- what columns should we join on?",
                "GROUP BY L.license",
                "ORDER BY number_of_files DESC",
                "\"\"\")",
                "ASSIGN = github.query_to_pandas_safe(query, max_gb_scanned=6)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(file_count_by_license)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(file_count_by_license)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "github.list_tables()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "github.list_tables()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "github.head(\"sample_commits\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "github.head(\"sample_commits\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "github.head(\"sample_files\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "github.head(\"sample_files\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = (\"\"\"",
                "-- Select all the columns we want in our joined table",
                "SELECT sf.repo_name, count(sc.commit) number_of_commits_in_python",
                "FROM `bigquery-public-data.github_repos.sample_commits` as sc",
                "-- Table to merge into sample_files",
                "INNER JOIN `bigquery-public-data.github_repos.sample_files` as sf",
                "ON sc.repo_name = sf.repo_name -- what columns should we join on?",
                "WHERE sf.path LIKE '%.py'",
                "GROUP BY sf.repo_name",
                "ORDER BY number_of_commits_in_python DESC",
                "\"\"\")",
                "print(github.estimate_query_size(ASSIGN))",
                "ASSIGN = github.query_to_pandas_safe(query, max_gb_scanned=6)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = (\"\"\"",
                "-- Select all the columns we want in our joined table",
                "SELECT sf.repo_name, count(sc.commit) number_of_commits_in_python",
                "FROM `bigquery-public-data.github_repos.sample_commits` as sc",
                "-- Table to merge into sample_files",
                "INNER JOIN `bigquery-public-data.github_repos.sample_files` as sf",
                "ON sc.repo_name = sf.repo_name -- what columns should we join on?",
                "WHERE sf.path LIKE '%.py'",
                "GROUP BY sf.repo_name",
                "ORDER BY number_of_commits_in_python DESC",
                "\"\"\")",
                "print(github.estimate_query_size(ASSIGN))",
                "ASSIGN = github.query_to_pandas_safe(query, max_gb_scanned=6)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "file_count_by_python_files"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "file_count_by_python_files"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "SETUP",
                "ASSIGN = multiprocessing.cpu_count()",
                "n_jobs"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "SETUP",
                "ASSIGN = multiprocessing.cpu_count()",
                "n_jobs"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = len(list(df.columns))",
                "num_of_cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = len(list(df.columns))",
                "num_of_cols"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "pd.options.display.max_columns = num_of_cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "pd.options.display.max_columns = num_of_cols"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(df)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(df.isnull().sum())",
                "ASSIGN.loc[(ASSIGN.loc[:, ASSIGN.dtypes != object] != 0).any(1)]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(df.isnull().sum())",
                "ASSIGN.loc[(ASSIGN.loc[:, ASSIGN.dtypes != object] != 0).any(1)]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = list(df_isna.loc[(df_isna.loc[:, df_isna.dtypes != object] != 0).any(1)].T.columns)",
                "nan_cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = list(df_isna.loc[(df_isna.loc[:, df_isna.dtypes != object] != 0).any(1)].T.columns)",
                "nan_cols"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[nan_cols].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[nan_cols].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.describe(include='all')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.describe(include='all')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[nan_cols].sample(3000).describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[nan_cols].sample(3000).describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['parentesco1'].loc[df.parentesco1 == 1].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['parentesco1'].loc[df.parentesco1 == 1].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "(df['parentesco1'].loc[df.parentesco1 == 1].describe()['count']path(df))*100"
            ],
            "output_type": "not_existent",
            "content_old": [
                "(df['parentesco1'].loc[df.parentesco1 == 1].describe()['count']path(df))*100"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['idhogar'].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['idhogar'].describe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = list(df['idhogar'].unique())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = list(df['idhogar'].unique())"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['parentesco1','idhogar']].loc[df.parentesco1 == 1].head(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['parentesco1','idhogar']].loc[df.parentesco1 == 1].head(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = df.groupby(['idhogar'])['parentesco1'].apply(lambda x: pd.unique(x.values.ravel()).tolist()).reset_index()",
                "len(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df.groupby(['idhogar'])['parentesco1'].apply(lambda x: pd.unique(x.values.ravel()).tolist()).reset_index()",
                "len(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(hid_heads, index=None, columns=['idhogar','parentesco1'])",
                "ASSIGN.sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(hid_heads, index=None, columns=['idhogar','parentesco1'])",
                "ASSIGN.sample(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_hid['parentesco1'] = df_hid['parentesco1'].apply(lambda x: ''.join(map(str, x)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_hid['parentesco1'] = df_hid['parentesco1'].apply(lambda x: ''.join(map(str, x)))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_hid.sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_hid.sample(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_hid.loc[df_hid.parentesco1 == '0']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_hid.loc[df_hid.parentesco1 == '0']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = list(df_hid['idhogar'].loc[df_hid.parentesco1 == '0'])",
                "len(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = list(df_hid['idhogar'].loc[df_hid.parentesco1 == '0'])",
                "len(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df[df['idhogar'].isin(hid_wo_heads)]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df[df['idhogar'].isin(hid_wo_heads)]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_hwoh[['idhogar', 'parentesco1','v2a1']]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_hwoh[['idhogar', 'parentesco1','v2a1']]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['v2a1'].hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].hist()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['v2a1'].loc[-df['idhogar'].isin(hid_wo_heads)].hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].loc[-df['idhogar'].isin(hid_wo_heads)].hist()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df_hwoh['v2a1'].hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_hwoh['v2a1'].hist()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(df_hwoh)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df_hwoh)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_hwoh['idhogar'].unique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_hwoh['idhogar'].unique()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(df[['Id','v2a1','idhogar','parentesco1','Target']].loc[df.idhogar == '09b195e7a'])",
                "print(df[['Id','v2a1','idhogar','parentesco1','Target']].loc[df.idhogar == 'f2bfa75c4'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(df[['Id','v2a1','idhogar','parentesco1','Target']].loc[df.idhogar == '09b195e7a'])",
                "print(df[['Id','v2a1','idhogar','parentesco1','Target']].loc[df.idhogar == 'f2bfa75c4'])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(, len(df))",
                "ASSIGN = ASSIGN.loc[-ASSIGN['idhogar'].isin(hid_wo_heads)]",
                "print(, len(ASSIGN))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(, len(df))",
                "ASSIGN = ASSIGN.loc[-ASSIGN['idhogar'].isin(hid_wo_heads)]",
                "print(, len(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['v2a1'].describe().plot()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].describe().plot()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df[['v18q1', 'rez_esc', 'meaneduc', 'SQBmeaned']].describe().plot()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v18q1', 'rez_esc', 'meaneduc', 'SQBmeaned']].describe().plot()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "gc.collect()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "gc.collect()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(df['v2a1'].unique())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df['v2a1'].unique())"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['v2a1'].unique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].unique()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['v2a1'].max()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].max()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1','Target']].loc[df.v2a1 > 1000000]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1','Target']].loc[df.v2a1 > 1000000]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1','Target']].loc[df.v2a1 >= 1000000]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1','Target']].loc[df.v2a1 >= 1000000]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1','Target']].loc[df.idhogar == '563cc81b7']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1','Target']].loc[df.idhogar == '563cc81b7']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(, len(df))",
                "df.drop(df[df.idhogar == '563cc81b7'].index, inplace=True)",
                "print(, len(df))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(, len(df))",
                "df.drop(df[df.idhogar == '563cc81b7'].index, inplace=True)",
                "print(, len(df))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['v2a1'].hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].hist()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['v2a1'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['v2a1'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['v18q1'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['v18q1'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['rez_esc'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['rez_esc'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['meaneduc'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['meaneduc'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['SQBmeaned'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['SQBmeaned'])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = list(df.columns)",
                "cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = list(df.columns)",
                "cols"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.sample(10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.sample(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "set(df.dtypes)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "set(df.dtypes)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {}",
                "for col in cols:",
                "ASSIGN[col] = df[col].dtype"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {}",
                "for col in cols:",
                "ASSIGN[col] = df[col].dtype"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(len(col_types))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(len(col_types))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for key in sorted(col_types):",
                "print(key, col_types[key])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "for key in sorted(col_types):",
                "print(key, col_types[key])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = []",
                "for col in cols:",
                "if df[col].dtype == 'O':",
                "ASSIGN.append(col)",
                "print(col, df[col].dtype)",
                "else:",
                "ASSIGN.append(col)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = []",
                "for col in cols:",
                "if df[col].dtype == 'O':",
                "ASSIGN.append(col)",
                "print(col, df[col].dtype)",
                "else:",
                "ASSIGN.append(col)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "cat_cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "cat_cols"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[cat_cols].sample(10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[cat_cols].sample(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(num_cols)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(num_cols)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "sorted(num_cols)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sorted(num_cols)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = sns.PairGrid(df[nan_cols])",
                "ASSIGN = ASSIGN.map_offdiag(plt.scatter)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = sns.PairGrid(df[nan_cols])",
                "ASSIGN = ASSIGN.map_offdiag(plt.scatter)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = ['refrig','mobilephone','television','qmobilephone','computer', 'v18q', 'v18q1', ]",
                "ASSIGN = ['v2a1', 'area1', 'area2', 'bedrooms','rooms', 'cielorazo', 'v14a',",
                "'tamhog', 'hacdor', 'hacapo', 'r4t3', ]",
                "ASSIGN = ['age', 'agesq', 'female', 'male',]",
                "ASSIGN = ['SQBage', 'SQBdependency', 'SQBedjefe', 'SQBescolari', 'SQBhogar_nin',",
                "'SQBhogar_total', 'SQBmeaned', 'SQBovercrowding',]",
                "ASSIGN = ['abastaguadentro', 'abastaguafuera', 'abastaguano',]",
                "ASSIGN = [ 'hhsize', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total',]",
                "ASSIGN = ['r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3',]",
                "ASSIGN = ['tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5',]",
                "ASSIGN = ['techocane', 'techoentrepiso', 'techootro', 'techozinc',]",
                "ASSIGN = ['pisocemento', 'pisomadera', 'pisomoscer', 'pisonatur', 'pisonotiene', 'pisoother',]",
                "ASSIGN = [ 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6',]",
                "ASSIGN = [ 'parentesco1', 'parentesco10', 'parentesco11', 'parentesco12', 'parentesco2', 'parentesco3',",
                "'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9',]",
                "ASSIGN = [ 'paredblolad', 'pareddes', 'paredfibras', 'paredmad', 'paredother',",
                "'paredpreb', 'paredzinc', 'paredzocalo',]",
                "ASSIGN = [ 'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6',",
                "'instlevel7', 'instlevel8', 'instlevel9',]",
                "ASSIGN = [ 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6',]",
                "ASSIGN = [ 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4',",
                "'estadocivil5', 'estadocivil6', 'estadocivil7',]",
                "ASSIGN = ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6',]",
                "ASSIGN = ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4',]",
                "ASSIGN = [ 'eviv1', 'eviv2', 'eviv3',]",
                "ASSIGN = [ 'etecho1', 'etecho2', 'etecho3',]",
                "ASSIGN = [ 'epared1', 'epared2', 'epared3',]",
                "ASSIGN = [ 'dis', 'escolari', 'meaneduc',",
                "'overcrowding', 'rez_esc', 'tamhog', 'tamviv', ]",
                "ASSIGN = ['coopele', 'noelec', 'planpri', 'public',]",
                "ASSIGN = cols_electronics+cols_house_details+cols_person_details+\\",
                "ASSIGN+ASSIGN+ASSIGN+ASSIGN+ASSIGN+ASSIGN+\\",
                "ASSIGN+ASSIGN+ASSIGN+ASSIGN+\\",
                "ASSIGN+ASSIGN+ASSIGN+ASSIGN+ASSIGN+\\",
                "cols_eviv+cols_etech+cols_pared+cols_unknown+cols_elec",
                "len(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['refrig','mobilephone','television','qmobilephone','computer', 'v18q', 'v18q1', ]",
                "ASSIGN = ['v2a1', 'area1', 'area2', 'bedrooms','rooms', 'cielorazo', 'v14a',",
                "'tamhog', 'hacdor', 'hacapo', 'r4t3', ]",
                "ASSIGN = ['age', 'agesq', 'female', 'male',]",
                "ASSIGN = ['SQBage', 'SQBdependency', 'SQBedjefe', 'SQBescolari', 'SQBhogar_nin',",
                "'SQBhogar_total', 'SQBmeaned', 'SQBovercrowding',]",
                "ASSIGN = ['abastaguadentro', 'abastaguafuera', 'abastaguano',]",
                "ASSIGN = [ 'hhsize', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total',]",
                "ASSIGN = ['r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3',]",
                "ASSIGN = ['tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5',]",
                "ASSIGN = ['techocane', 'techoentrepiso', 'techootro', 'techozinc',]",
                "ASSIGN = ['pisocemento', 'pisomadera', 'pisomoscer', 'pisonatur', 'pisonotiene', 'pisoother',]",
                "ASSIGN = [ 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6',]",
                "ASSIGN = [ 'parentesco1', 'parentesco10', 'parentesco11', 'parentesco12', 'parentesco2', 'parentesco3',",
                "'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9',]",
                "ASSIGN = [ 'paredblolad', 'pareddes', 'paredfibras', 'paredmad', 'paredother',",
                "'paredpreb', 'paredzinc', 'paredzocalo',]",
                "ASSIGN = [ 'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6',",
                "'instlevel7', 'instlevel8', 'instlevel9',]",
                "ASSIGN = [ 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6',]",
                "ASSIGN = [ 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4',",
                "'estadocivil5', 'estadocivil6', 'estadocivil7',]",
                "ASSIGN = ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6',]",
                "ASSIGN = ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4',]",
                "ASSIGN = [ 'eviv1', 'eviv2', 'eviv3',]",
                "ASSIGN = [ 'etecho1', 'etecho2', 'etecho3',]",
                "ASSIGN = [ 'epared1', 'epared2', 'epared3',]",
                "ASSIGN = [ 'dis', 'escolari', 'meaneduc',",
                "'overcrowding', 'rez_esc', 'tamhog', 'tamviv', ]",
                "ASSIGN = ['coopele', 'noelec', 'planpri', 'public',]",
                "ASSIGN = cols_electronics+cols_house_details+cols_person_details+\\",
                "ASSIGN+ASSIGN+ASSIGN+ASSIGN+ASSIGN+ASSIGN+\\",
                "ASSIGN+ASSIGN+ASSIGN+ASSIGN+\\",
                "ASSIGN+ASSIGN+ASSIGN+ASSIGN+ASSIGN+\\",
                "cols_eviv+cols_etech+cols_pared+cols_unknown+cols_elec",
                "len(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df[cols_electronics].plot.area()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[cols_electronics].plot.area()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['Target'].unique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['Target'].unique()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = cols_electronics.append('Target')",
                "df[cols_electronics].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = cols_electronics.append('Target')",
                "df[cols_electronics].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "CHECKPOINT",
                "cols_electronics.remove('Target')",
                "cols_electronics"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "cols_electronics.remove('Target')",
                "cols_electronics"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.groupby('Target')[cols_electronics].sum()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.groupby('Target')[cols_electronics].sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['tamhog'].unique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['tamhog'].unique()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['tamhog','r4t3', 'tamviv']].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['tamhog','r4t3', 'tamviv']].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['r4t3','tamviv']].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['r4t3','tamviv']].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "total_features.remove('r4t3')",
                "total_features.remove('tamhog')",
                "total_features.remove('tamviv')",
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "total_features.remove('r4t3')",
                "total_features.remove('tamhog')",
                "total_features.remove('tamviv')",
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['escolari'].unique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['escolari'].unique()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['escolari'].hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['escolari'].hist()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['escolari'].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['escolari'].describe()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['escolari'].plot.line()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['escolari'].plot.line()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df.escolari)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df.escolari)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df[num_cols].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df[num_cols].corr()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.zeros_like(correlations, dtype=np.bool)",
                "ASSIGN[np.triu_indices_from(ASSIGN)] = True",
                "ASSIGN = plt.subplots(figsize=(17, 13))",
                "ASSIGN = sns.diverging_palette(220, 10, as_cmap=True)",
                "sns.heatmap(correlations, ASSIGN=ASSIGN, ASSIGN=ASSIGN, vmax=.3, center=0,",
                "ASSIGN=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.zeros_like(correlations, dtype=np.bool)",
                "ASSIGN[np.triu_indices_from(ASSIGN)] = True",
                "ASSIGN = plt.subplots(figsize=(17, 13))",
                "ASSIGN = sns.diverging_palette(220, 10, as_cmap=True)",
                "sns.heatmap(correlations, ASSIGN=ASSIGN, ASSIGN=ASSIGN, vmax=.3, center=0,",
                "ASSIGN=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df[num_cols].corrwith(df.escolari, axis=0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df[num_cols].corrwith(df.escolari, axis=0)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for x,y in zip(num_cols, list(es_corr)):",
                "if (y >= 0.75) or (y < -0.6):",
                "print(x,y)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "for x,y in zip(num_cols, list(es_corr)):",
                "if (y >= 0.75) or (y < -0.6):",
                "print(x,y)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df[num_cols].corrwith(df.SQBescolari, axis=0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df[num_cols].corrwith(df.SQBescolari, axis=0)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for x,y in zip(num_cols, list(sqbes_corr)):",
                "if (y >= 0.5) or (y < -0.6):",
                "print(x,y)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "for x,y in zip(num_cols, list(sqbes_corr)):",
                "if (y >= 0.5) or (y < -0.6):",
                "print(x,y)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "total_features.remove('escolari')",
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "total_features.remove('escolari')",
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df.loc[df.Target == 1].groupby('overcrowding').SQBescolari.value_counts().unstack().plot.bar()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.loc[df.Target == 1].groupby('overcrowding').SQBescolari.value_counts().unstack().plot.bar()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['overcrowding'].hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['overcrowding'].hist()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['overcrowding'].unique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['overcrowding'].unique()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df.plot.scatter(x='Target', y='overcrowding')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.plot.scatter(x='Target', y='overcrowding')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df.groupby('Target').overcrowding.value_counts().unstack().plot.bar()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.groupby('Target').overcrowding.value_counts().unstack().plot.bar()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['Target'].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['Target'].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['Target'].unique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['Target'].unique()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['Target'].hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['Target'].hist()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "nan_cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "nan_cols"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[nan_cols].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[nan_cols].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for col in nan_cols:",
                "if col != 'v2a1':",
                "print(col, df[col].unique())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "for col in nan_cols:",
                "if col != 'v2a1':",
                "print(col, df[col].unique())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.regplot(df['meaneduc'],df['SQBmeaned'], order=2)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.regplot(df['meaneduc'],df['SQBmeaned'], order=2)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df['meaneduc'].fillna(0, inplace=True)",
                "df['SQBmeaned'].fillna(0, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['meaneduc'].fillna(0, inplace=True)",
                "df['SQBmeaned'].fillna(0, inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "total_features.remove('meaneduc')",
                "total_features"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "total_features.remove('meaneduc')",
                "total_features"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v18q','v18q1','idhogar']].loc[df.v18q1.isna()].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v18q','v18q1','idhogar']].loc[df.v18q1.isna()].describe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df['v18q1'] = df['v18q'].groupby(df['idhogar']).transform('sum')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v18q1'] = df['v18q'].groupby(df['idhogar']).transform('sum')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.sample(7)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.sample(7)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(df.isnull().sum())",
                "ASSIGN.loc[(ASSIGN.loc[:, ASSIGN.dtypes != object] != 0).any(1)]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(df.isnull().sum())",
                "ASSIGN.loc[(ASSIGN.loc[:, ASSIGN.dtypes != object] != 0).any(1)]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['rez_esc'].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['rez_esc'].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['rez_esc'].isnull().sum()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['rez_esc'].isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(df) - df['rez_esc'].isnull().sum()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df) - df['rez_esc'].isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['v2a1'].isnull().sum()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(df) - df['v2a1'].isnull().sum()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df) - df['v2a1'].isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(df.loc[(df.v2a1 >= 0)]), len(df.loc[(df.rez_esc >= 0)])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df.loc[(df.v2a1 >= 0)]), len(df.loc[(df.rez_esc >= 0)])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "len(df.loc[(df.v2a1 >= 0) & (df.rez_esc >= 0)])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df.loc[(df.v2a1 >= 0) & (df.rez_esc >= 0)])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "len(df.loc[(df.v2a1 >= 0) | (df.rez_esc >= 0)])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df.loc[(df.v2a1 >= 0) | (df.rez_esc >= 0)])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['rez_esc'].hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['rez_esc'].hist()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['rez_esc','v2a1']].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['rez_esc','v2a1']].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['Target','rez_esc']].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['Target','rez_esc']].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['Target','rez_esc']].fillna(0).corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['Target','rez_esc']].fillna(0).corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','Target']].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','Target']].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','Target']].fillna(0).corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','Target']].fillna(0).corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['rez_esc'].unique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['rez_esc'].unique()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(13,7))",
                "sns.kdeplot(df['rez_esc'])",
                "sns.kdeplot(df['rez_esc'].fillna(0))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.figure(figsize=(13,7))",
                "sns.kdeplot(df['rez_esc'])",
                "sns.kdeplot(df['rez_esc'].fillna(0))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(13,7))",
                "sns.kdeplot(df['v2a1'])",
                "sns.kdeplot(df['v2a1'].fillna(0))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.figure(figsize=(13,7))",
                "sns.kdeplot(df['v2a1'])",
                "sns.kdeplot(df['v2a1'].fillna(0))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df['rez_esc'], df['v2a1']",
                "plt.figure(figsize=(23,17))",
                "ASSIGN = sns.jointplot(x, y, data=df, kind=\"kde\", color=\"m\")",
                "ASSIGN.plot_joint(plt.scatter, c=\"w\", s=30, linewidth=1, marker=\"+\")",
                "ASSIGN.ax_joint.collections[0].set_alpha(0)",
                "ASSIGN.set_axis_labels(\"$X$\", \"$Y$\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df['rez_esc'], df['v2a1']",
                "plt.figure(figsize=(23,17))",
                "ASSIGN = sns.jointplot(x, y, data=df, kind=\"kde\", color=\"m\")",
                "ASSIGN.plot_joint(plt.scatter, c=\"w\", s=30, linewidth=1, marker=\"+\")",
                "ASSIGN.ax_joint.collections[0].set_alpha(0)",
                "ASSIGN.set_axis_labels(\"$X$\", \"$Y$\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df['rez_esc'].fillna(0), df['v2a1'].fillna(0)",
                "sns.jointplot(ASSIGN, data=df, kind=\"kde\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df['rez_esc'].fillna(0), df['v2a1'].fillna(0)",
                "sns.jointplot(ASSIGN, data=df, kind=\"kde\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df['rez_esc'].fillna(0, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['rez_esc'].fillna(0, inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(df.isnull().sum())",
                "ASSIGN.loc[(ASSIGN.loc[:, ASSIGN.dtypes != object] != 0).any(1)]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(df.isnull().sum())",
                "ASSIGN.loc[(ASSIGN.loc[:, ASSIGN.dtypes != object] != 0).any(1)]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df['Target'], df['v2a1']",
                "plt.figure(figsize=(23,17))",
                "ASSIGN = sns.jointplot(x, y, data=df, kind=\"kde\", color=\"m\")",
                "ASSIGN.plot_joint(plt.scatter, c=\"w\", s=30, linewidth=1, marker=\"+\")",
                "ASSIGN.ax_joint.collections[0].set_alpha(0)",
                "ASSIGN.set_axis_labels(\"$X$\", \"$Y$\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df['Target'], df['v2a1']",
                "plt.figure(figsize=(23,17))",
                "ASSIGN = sns.jointplot(x, y, data=df, kind=\"kde\", color=\"m\")",
                "ASSIGN.plot_joint(plt.scatter, c=\"w\", s=30, linewidth=1, marker=\"+\")",
                "ASSIGN.ax_joint.collections[0].set_alpha(0)",
                "ASSIGN.set_axis_labels(\"$X$\", \"$Y$\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df['Target'], df['v2a1'].fillna(0)",
                "plt.figure(figsize=(23,17))",
                "ASSIGN = sns.jointplot(x, y, data=df, kind=\"kde\", color=\"m\")",
                "ASSIGN.plot_joint(plt.scatter, c=\"w\", s=30, linewidth=1, marker=\"+\")",
                "ASSIGN.ax_joint.collections[0].set_alpha(0)",
                "ASSIGN.set_axis_labels(\"$X$\", \"$Y$\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df['Target'], df['v2a1'].fillna(0)",
                "plt.figure(figsize=(23,17))",
                "ASSIGN = sns.jointplot(x, y, data=df, kind=\"kde\", color=\"m\")",
                "ASSIGN.plot_joint(plt.scatter, c=\"w\", s=30, linewidth=1, marker=\"+\")",
                "ASSIGN.ax_joint.collections[0].set_alpha(0)",
                "ASSIGN.set_axis_labels(\"$X$\", \"$Y$\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['Target'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['Target'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.groupby('Target').count()['v2a1']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.groupby('Target').count()['v2a1']"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(figsize=(15,7))",
                "df.groupby('Target').count()['v2a1'].plot(ax=ax)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(figsize=(15,7))",
                "df.groupby('Target').count()['v2a1'].plot(ax=ax)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(figsize=(15,7))",
                "df.fillna(0).groupby('Target').count()['v2a1'].plot(ax=ax)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(figsize=(15,7))",
                "df.fillna(0).groupby('Target').count()['v2a1'].plot(ax=ax)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(figsize=(15,7))",
                "df.groupby(['Target','hhsize']).count()['v2a1'].unstack().plot(ax=ax)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(figsize=(15,7))",
                "df.groupby(['Target','hhsize']).count()['v2a1'].unstack().plot(ax=ax)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(figsize=(15,7))",
                "df.fillna(0).groupby(['Target','hhsize']).count()['v2a1'].unstack().plot(ax=ax)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(figsize=(15,7))",
                "df.fillna(0).groupby(['Target','hhsize']).count()['v2a1'].unstack().plot(ax=ax)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['hhsize'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['hhsize'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['hogar_total'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['hogar_total'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "total_features.remove('hogar_total')",
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "total_features.remove('hogar_total')",
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['hhsize','hogar_adul']].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['hhsize','hogar_adul']].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['hhsize','Target']].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['hhsize','Target']].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['Target','hogar_adul']].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['Target','hogar_adul']].corr()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['hogar_adul'])",
                "sns.kdeplot(df['hhsize'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['hogar_adul'])",
                "sns.kdeplot(df['hhsize'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['hogar_total'])",
                "sns.kdeplot(df['hogar_adul'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['hogar_total'])",
                "sns.kdeplot(df['hogar_adul'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "max(df['hogar_adul']), max(df['hogar_total'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "max(df['hogar_adul']), max(df['hogar_total'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df.groupby('idhogar').sum()[['hogar_adul','hogar_total']].sample(10).plot.bar()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.groupby('idhogar').sum()[['hogar_adul','hogar_total']].sample(10).plot.bar()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['hogar_total'])",
                "sns.kdeplot(df['hogar_nin'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['hogar_total'])",
                "sns.kdeplot(df['hogar_nin'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['male'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['male'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['female'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['female'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "total_features.remove('female')",
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "total_features.remove('female')",
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['r4t3'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['r4t3'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['tamhog'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['tamhog'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['tamviv'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['tamviv'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(17,13))",
                "sns.kdeplot(df['tamviv'])",
                "sns.kdeplot(df['tamhog'])",
                "sns.kdeplot(df['r4t3'])",
                "sns.kdeplot(df['hhsize'])",
                "sns.kdeplot(df['hogar_total'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.figure(figsize=(17,13))",
                "sns.kdeplot(df['tamviv'])",
                "sns.kdeplot(df['tamhog'])",
                "sns.kdeplot(df['r4t3'])",
                "sns.kdeplot(df['hhsize'])",
                "sns.kdeplot(df['hogar_total'])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "total_features.remove('r4t3')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "total_features.remove('r4t3')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['dependency'].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['dependency'].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['dependency'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['dependency'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['SQBdependency'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['SQBdependency'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['SQBdependency'].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['SQBdependency'].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "cat_cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "cat_cols"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['edjefe'].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['edjefe'].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['edjefa'].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['edjefa'].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['edjefe'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['edjefe'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['edjefa'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['edjefa'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df.loc[df.edjefa == 'yes', 'edjefa'] = 1",
                "df.loc[df.edjefa == 'no', 'edjefa'] = 0"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.loc[df.edjefa == 'yes', 'edjefa'] = 1",
                "df.loc[df.edjefa == 'no', 'edjefa'] = 0"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df.loc[df.edjefe == 'yes', 'edjefe'] = 1",
                "df.loc[df.edjefe == 'no', 'edjefe'] = 0"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.loc[df.edjefe == 'yes', 'edjefe'] = 1",
                "df.loc[df.edjefe == 'no', 'edjefe'] = 0"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['edjefa','edjefe']].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['edjefa','edjefe']].describe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df[['edjefa','edjefe']] = df[['edjefa','edjefe']].apply(pd.to_numeric)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['edjefa','edjefe']] = df[['edjefa','edjefe']].apply(pd.to_numeric)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df[['edjefa','edjefe']].dtypes"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "df[['edjefa','edjefe']].dtypes"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "total_features.append('edjefa')",
                "total_features.append('edjefe')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "total_features.append('edjefa')",
                "total_features.append('edjefe')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "cols_water"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "cols_water"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[cols_water].describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[cols_water].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[cols_water].corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[cols_water].corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['abastaguadentro'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['abastaguadentro'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['abastaguafuera'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['abastaguafuera'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['abastaguano'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['abastaguano'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_water].sum().reset_index()",
                "df_water_target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_water].sum().reset_index()",
                "df_water_target"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "722+1496+1133+5844"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "722+1496+1133+5844"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_water_target.corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_water_target.corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "total_features.remove('abastaguano')",
                "total_features.remove('abastaguafuera')",
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "total_features.remove('abastaguano')",
                "total_features.remove('abastaguafuera')",
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['pisocemento'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['pisocemento'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_floor].sum().reset_index()",
                "df_floor_target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_floor].sum().reset_index()",
                "df_floor_target"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "total_features.remove('pisonatur')",
                "total_features.remove('pisonotiene')",
                "total_features.remove('pisoother')",
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "total_features.remove('pisonatur')",
                "total_features.remove('pisonotiene')",
                "total_features.remove('pisoother')",
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_outside_wall].sum().reset_index()",
                "df_wall_target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_outside_wall].sum().reset_index()",
                "df_wall_target"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['paredblolad'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['paredblolad'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['paredpreb'])",
                "sns.kdeplot(df['paredmad'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['paredpreb'])",
                "sns.kdeplot(df['paredmad'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['paredmad'])",
                "sns.kdeplot(df['paredzocalo'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['paredmad'])",
                "sns.kdeplot(df['paredzocalo'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['paredpreb'])",
                "sns.kdeplot(df['paredmad'])",
                "sns.kdeplot(df['paredzocalo'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['paredpreb'])",
                "sns.kdeplot(df['paredmad'])",
                "sns.kdeplot(df['paredzocalo'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_roof].sum().reset_index()",
                "df_roof_target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_roof].sum().reset_index()",
                "df_roof_target"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['techozinc'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['techozinc'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['techozinc'])",
                "sns.kdeplot(df['techoentrepiso'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['techozinc'])",
                "sns.kdeplot(df['techoentrepiso'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['techoentrepiso'])",
                "sns.kdeplot(df['techocane'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['techoentrepiso'])",
                "sns.kdeplot(df['techocane'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_sanitary].sum().reset_index()",
                "df_sani_target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_sanitary].sum().reset_index()",
                "df_sani_target"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['sanitario1'])",
                "sns.kdeplot(df['sanitario6'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['sanitario1'])",
                "sns.kdeplot(df['sanitario6'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['sanitario3'])",
                "sns.kdeplot(df['sanitario2'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['sanitario3'])",
                "sns.kdeplot(df['sanitario2'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_tip].sum().reset_index()",
                "df_tipo_target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df.groupby('Target')[cols_tip].sum().reset_index()",
                "df_tipo_target"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['tipovivi2'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['tipovivi2'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['tipovivi1'])",
                "sns.kdeplot(df['tipovivi3'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['tipovivi1'])",
                "sns.kdeplot(df['tipovivi3'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.kdeplot(df['tipovivi5'])",
                "sns.kdeplot(df['tipovivi4'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.kdeplot(df['tipovivi5'])",
                "sns.kdeplot(df['tipovivi4'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['v2a1'].isna().sum()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].isna().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['tipovivi3'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['tipovivi3'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.loc[(df['v2a1'].isna()) & (df.tipovivi3 == 1)]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.loc[(df['v2a1'].isna()) & (df.tipovivi3 == 1)]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['v2a1'].loc[df.parentesco1 == 1].plot.line()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].loc[df.parentesco1 == 1].plot.line()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "df['v2a1'].loc[df.parentesco1 == 1].plot.hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].loc[df.parentesco1 == 1].plot.hist()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['v2a1'].loc[df.parentesco1 == 1].mean(), df['v2a1'].loc[df.parentesco1 == 1].max(), df['v2a1'].loc[df.parentesco1 == 1].min()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].loc[df.parentesco1 == 1].mean(), df['v2a1'].loc[df.parentesco1 == 1].max(), df['v2a1'].loc[df.parentesco1 == 1].min()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 == 1) & (df.v2a1.isna())].describe(include='all')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 == 1) & (df.v2a1.isna())].describe(include='all')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 == 1) & (-df.v2a1.isna()) & (df.tipovivi3==1) & (df.tipovivi1==0)].describe(include='all')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 == 1) & (-df.v2a1.isna()) & (df.tipovivi3==1) & (df.tipovivi1==0)].describe(include='all')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 == 1) & (-df.v2a1.isna()) & (df.tipovivi3==1) & (df.tipovivi1==0)].mean()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 == 1) & (-df.v2a1.isna()) & (df.tipovivi3==1) & (df.tipovivi1==0)].mean()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 != 1) & (-df.v2a1.isna()) & (df.tipovivi3==1) & (df.tipovivi1==0)].mean()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 != 1) & (-df.v2a1.isna()) & (df.tipovivi3==1) & (df.tipovivi1==0)].mean()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 != 1) & (-df.v2a1.isna()) & (df.tipovivi3==1) & (df.tipovivi1==0)].describe(include='all')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1']].loc[(df.parentesco1 != 1) & (-df.v2a1.isna()) & (df.tipovivi3==1) & (df.tipovivi1==0)].describe(include='all')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1']].loc[df.parentesco1 != 1].describe(include='all')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1']].loc[df.parentesco1 != 1].describe(include='all')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[['v2a1','idhogar','parentesco1']].loc[df.parentesco1 == 1].describe(include='all')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df[['v2a1','idhogar','parentesco1']].loc[df.parentesco1 == 1].describe(include='all')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df['v2a1'].fillna(120000, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].fillna(120000, inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['v2a1'].isna().sum()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df['v2a1'].isna().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "'Target' in total_features"
            ],
            "output_type": "not_existent",
            "content_old": [
                "'Target' in total_features"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df[total_features], df['Target']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df[total_features], df['Target']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 42",
                "ASSIGN = 0.3",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, ASSIGN=ASSIGN, random_state=ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 42",
                "ASSIGN = 0.3",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, ASSIGN=ASSIGN, random_state=ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = xgb.XGBClassifier(n_jobs=n_jobs)",
                "model1"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = xgb.XGBClassifier(n_jobs=n_jobs)",
                "model1"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = model1.fit(X_train, y_train)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = model1.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5, n_jobs=n_jobs)",
                "model2"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5, n_jobs=n_jobs)",
                "model2"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = model2.fit(X_train, y_train)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = model2.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = train_model1.predict(X_test)",
                "ASSIGN = train_model2.predict(X_test)",
                "print('Model 1 XGboost Report %r' % (classification_report(y_test, ASSIGN)))",
                "print('Model 2 XGboost Report %r' % (classification_report(y_test, ASSIGN)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = train_model1.predict(X_test)",
                "ASSIGN = train_model2.predict(X_test)",
                "print('Model 1 XGboost Report %r' % (classification_report(y_test, ASSIGN)))",
                "print('Model 2 XGboost Report %r' % (classification_report(y_test, ASSIGN)))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print( % (accuracy_score(y_test, pred1) * 100))",
                "print( % (accuracy_score(y_test, pred2) * 100))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print( % (accuracy_score(y_test, pred1) * 100))",
                "print( % (accuracy_score(y_test, pred2) * 100))"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = xgb.XGBClassifier(",
                "ASSIGN =0.1,",
                "ASSIGN=1000,",
                "ASSIGN=5,",
                "ASSIGN=1,",
                "ASSIGN=0,",
                "ASSIGN=0.8,",
                "ASSIGN=0.8,",
                "ASSIGN= 'binary:logistic',",
                "ASSIGN=ASSIGN,",
                "ASSIGN=1,",
                "ASSIGN=27)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = xgb.XGBClassifier(",
                "ASSIGN =0.1,",
                "ASSIGN=1000,",
                "ASSIGN=5,",
                "ASSIGN=1,",
                "ASSIGN=0,",
                "ASSIGN=0.8,",
                "ASSIGN=0.8,",
                "ASSIGN= 'binary:logistic',",
                "ASSIGN=ASSIGN,",
                "ASSIGN=1,",
                "ASSIGN=27)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = model3.fit(X_train, y_train)",
                "ASSIGN = train_model3.predict(X_test)",
                "print( % (accuracy_score(y_test, ASSIGN) * 100))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = model3.fit(X_train, y_train)",
                "ASSIGN = train_model3.predict(X_test)",
                "print( % (accuracy_score(y_test, ASSIGN) * 100))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print('Model 3 XGboost Report %r' % (classification_report(y_test, pred3)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print('Model 3 XGboost Report %r' % (classification_report(y_test, pred3)))"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "gc.collect()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "gc.collect()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {",
                "'n_estimators': [100],",
                "'max_depth': [6, 9],",
                "'subsample': [0.9, 1.0],",
                "'colsample_bytree': [0.9, 1.0],",
                "}"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {",
                "'n_estimators': [100],",
                "'max_depth': [6, 9],",
                "'subsample': [0.9, 1.0],",
                "'colsample_bytree': [0.9, 1.0],",
                "}"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = GridSearchCV(model3,",
                "ASSIGN=n_jobs,",
                "ASSIGN=\"neg_log_loss\",",
                "ASSIGN=3)",
                "grid"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = GridSearchCV(model3,",
                "ASSIGN=n_jobs,",
                "ASSIGN=\"neg_log_loss\",",
                "ASSIGN=3)",
                "grid"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "gc.collect()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "gc.collect()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(figsize=(23, 17))",
                "plot_importance(model3, ax=ax)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(figsize=(23, 17))",
                "plot_importance(model3, ax=ax)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['estadocivil1','instlevel9','techocane','parentesco10','v14a',",
                "'parentesco11','parentesco5','paredother','parentesco7','noelec',",
                "'elimbasu4','elimbasu6']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['estadocivil1','instlevel9','techocane','parentesco10','v14a',",
                "'parentesco11','parentesco5','paredother','parentesco7','noelec',",
                "'elimbasu4','elimbasu6']"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for f in less_imp_features:",
                "if f in total_features:",
                "total_features.remove(f)",
                "len(total_features)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for f in less_imp_features:",
                "if f in total_features:",
                "total_features.remove(f)",
                "len(total_features)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df[total_features], df['Target']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df[total_features], df['Target']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 43",
                "ASSIGN = 0.3",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, ASSIGN=ASSIGN, random_state=ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 43",
                "ASSIGN = 0.3",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, ASSIGN=ASSIGN, random_state=ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = model3.fit(X_train, y_train)",
                "ASSIGN = train_model5.predict(X_test)",
                "print( % (accuracy_score(y_test, ASSIGN) * 100))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = model3.fit(X_train, y_train)",
                "ASSIGN = train_model5.predict(X_test)",
                "print( % (accuracy_score(y_test, ASSIGN) * 100))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print('Model 5 XGboost Report %r' % (classification_report(y_test, pred5)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print('Model 5 XGboost Report %r' % (classification_report(y_test, pred5)))"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = train_model5.fit(X, y)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train_model5.fit(X, y)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train_model6"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "train_model6"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = sort(model3.feature_importances_)",
                "thresholds"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = sort(model3.feature_importances_)",
                "thresholds"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "thresholds.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "thresholds.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "np.unique(thresholds).shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "np.unique(thresholds).shape"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = RandomForestClassifier(n_jobs=n_jobs)",
                "model4"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = RandomForestClassifier(n_jobs=n_jobs)",
                "model4"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "gc.collect()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "gc.collect()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = model4.fit(X_train, y_train)",
                "ASSIGN = train_model4.predict(X_test)",
                "print( % (accuracy_score(y_test, ASSIGN) * 100))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = model4.fit(X_train, y_train)",
                "ASSIGN = train_model4.predict(X_test)",
                "print( % (accuracy_score(y_test, ASSIGN) * 100))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print('Model 4 XGboost Report %r' % (classification_report(y_test, pred4)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print('Model 4 XGboost Report %r' % (classification_report(y_test, pred4)))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "confusion_matrix(y_test, pred4)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "confusion_matrix(y_test, pred4)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(df_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df_test)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_test.sample(10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_test.sample(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(df_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "len(df_test)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_test.loc[df_test.edjefa == 'yes', 'edjefa'] = 1",
                "df_test.loc[df_test.edjefa == 'no', 'edjefa'] = 0",
                "df_test.loc[df_test.edjefe == 'yes', 'edjefe'] = 1",
                "df_test.loc[df_test.edjefe == 'no', 'edjefe'] = 0",
                "df_test[['edjefa','edjefe']] = df_test[['edjefa','edjefe']].apply(pd.to_numeric)",
                "df_test[['edjefa','edjefe']].dtypes"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "df_test.loc[df_test.edjefa == 'yes', 'edjefa'] = 1",
                "df_test.loc[df_test.edjefa == 'no', 'edjefa'] = 0",
                "df_test.loc[df_test.edjefe == 'yes', 'edjefe'] = 1",
                "df_test.loc[df_test.edjefe == 'no', 'edjefe'] = 0",
                "df_test[['edjefa','edjefe']] = df_test[['edjefa','edjefe']].apply(pd.to_numeric)",
                "df_test[['edjefa','edjefe']].dtypes"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df_test[total_features]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df_test[total_features]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_actual_test.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "X_actual_test.shape"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = train_model6.predict(X_actual_test)",
                "pred_actual"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = train_model6.predict(X_actual_test)",
                "pred_actual"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "pred_actual.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "pred_actual.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(df['Id'], pred_actual).reset_index()",
                "ASSIGN.columns = ['Target','Id']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(df['Id'], pred_actual).reset_index()",
                "ASSIGN.columns = ['Target','Id']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df_final.columns.tolist()",
                "cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df_final.columns.tolist()",
                "cols"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN[-1:] + ASSIGN[:-1]",
                "cols"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN[-1:] + ASSIGN[:-1]",
                "cols"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN[cols]",
                "ASSIGN.head(7)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN[cols]",
                "ASSIGN.head(7)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_final.index.name = None",
                "df_final.head(7)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_final.index.name = None",
                "df_final.head(7)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_final['Target'].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_final['Target'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_final[cols].sample(4)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_final[cols].sample(4)"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "df_final[cols].to_csv('sample_submission.csv', index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_final[cols].to_csv('sample_submission.csv', index=False)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "os.listdir('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "os.listdir('..path')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = train_data.columns[2:]",
                "ASSIGN = []",
                "ASSIGN = []",
                "for dtype, feature in zip(train_data.dtypes[2:], train_data.columns[2:]):",
                "ASSIGN == object:",
                "ASSIGN.append(feature)",
                "else:",
                "ASSIGN.append(feature)",
                "categorical_features"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = train_data.columns[2:]",
                "ASSIGN = []",
                "ASSIGN = []",
                "for dtype, feature in zip(train_data.dtypes[2:], train_data.columns[2:]):",
                "ASSIGN == object:",
                "ASSIGN.append(feature)",
                "else:",
                "ASSIGN.append(feature)",
                "categorical_features"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "np.random.seed(13)",
                "def impact_coding(data, feature, target='y'):",
                "'''",
                "In this implementation we get the values and the dictionary as two different steps.",
                "This is just because initially we were ignoring the dictionary as a result variable.",
                "In this implementation the KFolds use shuffling. If you want reproducibility the cv",
                "could be moved to a parameter.",
                "'''",
                "ASSIGN = 20",
                "ASSIGN = 10",
                "ASSIGN = pd.Series()",
                "ASSIGN = data[target].mean()",
                "ASSIGN = KFold(n_splits=n_folds, shuffle=True)",
                "ASSIGN = pd.DataFrame()",
                "ASSIGN = 0",
                "for infold, oof in ASSIGN.ASSIGN(data[feature]):",
                "ASSIGN = pd.Series()",
                "ASSIGN = KFold(n_splits=n_inner_folds, shuffle=True)",
                "ASSIGN = 0",
                "ASSIGN = pd.DataFrame()",
                "ASSIGN = data.iloc[infold][target].mean()",
                "for infold_inner, oof_inner in ASSIGN.ASSIGN(data.iloc[infold]):",
                "ASSIGN = data.iloc[infold_inner].groupby(by=feature)[target].mean()",
                "ASSIGN = ASSIGN.append(data.iloc[infold].apply(",
                "lambda x: ASSIGN[x[feature]]",
                "if x[feature] in oof_mean.index",
                "else oof_default_inner_mean",
                ", axis=1))",
                "ASSIGN = ASSIGN.join(pd.DataFrame(oof_mean), rsuffix=inner_split, how='outer')",
                "ASSIGN.fillna(value=ASSIGN, inplace=True)",
                "ASSIGN += 1",
                "ASSIGN = ASSIGN.join(pd.DataFrame(inner_oof_mean_cv), rsuffix=split, how='outer')",
                "ASSIGN.fillna(value=ASSIGN, inplace=True)",
                "ASSIGN += 1",
                "ASSIGN = ASSIGN.append(data.iloc[oof].apply(",
                "lambda x: ASSIGN.loc[x[feature]].mean()",
                "if x[feature] in inner_oof_mean_cv.index",
                "else oof_default_mean",
                ", axis=1))",
                "return ASSIGN, ASSIGN.mean(axis=1), ASSIGN",
                "ASSIGN = {}",
                "for f in categorical_features:",
                "print(.format(f))",
                "train_data[\"impact_encoded_{}\".format(f)], impact_coding_mapping, default_coding = impact_coding(train_data, f)",
                "ASSIGN[f] = (impact_coding_mapping, default_coding)",
                "ASSIGN = impact_coding_map[f]",
                "test_data[\"impact_encoded_{}\".format(f)] = test_data.apply(lambda x: mapping[x[f]]",
                "if x[f] in mapping",
                "else default_mean",
                ", axis=1)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "np.random.seed(13)",
                "def impact_coding(data, feature, target='y'):",
                "'''",
                "In this implementation we get the values and the dictionary as two different steps.",
                "This is just because initially we were ignoring the dictionary as a result variable.",
                "In this implementation the KFolds use shuffling. If you want reproducibility the cv",
                "could be moved to a parameter.",
                "'''",
                "ASSIGN = 20",
                "ASSIGN = 10",
                "ASSIGN = pd.Series()",
                "ASSIGN = data[target].mean()",
                "ASSIGN = KFold(n_splits=n_folds, shuffle=True)",
                "ASSIGN = pd.DataFrame()",
                "ASSIGN = 0",
                "for infold, oof in ASSIGN.ASSIGN(data[feature]):",
                "ASSIGN = pd.Series()",
                "ASSIGN = KFold(n_splits=n_inner_folds, shuffle=True)",
                "ASSIGN = 0",
                "ASSIGN = pd.DataFrame()",
                "ASSIGN = data.iloc[infold][target].mean()",
                "for infold_inner, oof_inner in ASSIGN.ASSIGN(data.iloc[infold]):",
                "ASSIGN = data.iloc[infold_inner].groupby(by=feature)[target].mean()",
                "ASSIGN = ASSIGN.append(data.iloc[infold].apply(",
                "lambda x: ASSIGN[x[feature]]",
                "if x[feature] in oof_mean.index",
                "else oof_default_inner_mean",
                ", axis=1))",
                "ASSIGN = ASSIGN.join(pd.DataFrame(oof_mean), rsuffix=inner_split, how='outer')",
                "ASSIGN.fillna(value=ASSIGN, inplace=True)",
                "ASSIGN += 1",
                "ASSIGN = ASSIGN.join(pd.DataFrame(inner_oof_mean_cv), rsuffix=split, how='outer')",
                "ASSIGN.fillna(value=ASSIGN, inplace=True)",
                "ASSIGN += 1",
                "ASSIGN = ASSIGN.append(data.iloc[oof].apply(",
                "lambda x: ASSIGN.loc[x[feature]].mean()",
                "if x[feature] in inner_oof_mean_cv.index",
                "else oof_default_mean",
                ", axis=1))",
                "return ASSIGN, ASSIGN.mean(axis=1), ASSIGN",
                "ASSIGN = {}",
                "for f in categorical_features:",
                "print(.format(f))",
                "train_data[\"impact_encoded_{}\".format(f)], impact_coding_mapping, default_coding = impact_coding(train_data, f)",
                "ASSIGN[f] = (impact_coding_mapping, default_coding)",
                "ASSIGN = impact_coding_map[f]",
                "test_data[\"impact_encoded_{}\".format(f)] = test_data.apply(lambda x: mapping[x[f]]",
                "if x[f] in mapping",
                "else default_mean",
                ", axis=1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train_data[['y', 'X0'] + list(train_data.columns[-8:])]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train_data[['y', 'X0'] + list(train_data.columns[-8:])]"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "rcParams['figure.figsize'] = [10,5]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "warnings.filterwarnings('ignore')",
                "pd.set_option('display.max_rows', 50)",
                "pd.set_option('display.max_columns', 50)",
                "pd.options.display.float_format = '{:.5f}'.format",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "rcParams['figure.figsize'] = [10,5]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "warnings.filterwarnings('ignore')",
                "pd.set_option('display.max_rows', 50)",
                "pd.set_option('display.max_columns', 50)",
                "pd.options.display.float_format = '{:.5f}'.format",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Sequential([Dense(units=1, input_shape=[1])])",
                "ASSIGN.compile(optimizer='sgd', loss='mean_squared_error')",
                "ASSIGN = np.array([-1, 0, 1, 2, 3, 4], dtype=float)",
                "ASSIGN = np.array([-3, -1, 1, 3, 5, 7], dtype=float)",
                "ASSIGN.fit(ASSIGN, ASSIGN, epochs=500)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Sequential([Dense(units=1, input_shape=[1])])",
                "ASSIGN.compile(optimizer='sgd', loss='mean_squared_error')",
                "ASSIGN = np.array([-1, 0, 1, 2, 3, 4], dtype=float)",
                "ASSIGN = np.array([-3, -1, 1, 3, 5, 7], dtype=float)",
                "ASSIGN.fit(ASSIGN, ASSIGN, epochs=500)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "model.predict([6])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.predict([6])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Dense(units=1, input_shape=[1]))",
                "ASSIGN.compile(optimizer='sgd', loss='mean_squared_error')",
                "ASSIGN = np.array([0,1,2,3,4,5,6], dtype=float)",
                "ASSIGN = np.array([0.5,1,1.5,2,2.5,3,3.5], dtype=float)",
                "ASSIGN.fit(ASSIGN, ASSIGN, epochs=500)",
                "ASSIGN.predict([7])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Dense(units=1, input_shape=[1]))",
                "ASSIGN.compile(optimizer='sgd', loss='mean_squared_error')",
                "ASSIGN = np.array([0,1,2,3,4,5,6], dtype=float)",
                "ASSIGN = np.array([0.5,1,1.5,2,2.5,3,3.5], dtype=float)",
                "ASSIGN.fit(ASSIGN, ASSIGN, epochs=500)",
                "ASSIGN.predict([7])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "(train_img, train_lab), (test_img, test_lab) = fashion_mnist.load_data()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "(train_img, train_lab), (test_img, test_lab) = fashion_mnist.load_data()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.imshow(train_img[11]) ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.imshow(train_img[11]) ;"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN path",
                "ASSIGN = ASSIGN path"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN path",
                "ASSIGN = ASSIGN path"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,'Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.9)",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Flatten(input_shape=(28,28)))",
                "ASSIGN.add(Dense(512, activation=tf.nn.relu))",
                "ASSIGN.add(Dense(512, activation=tf.nn.relu))",
                "ASSIGN.add(Dense(10, activation=tf.nn.softmax))",
                "ASSIGN.compile(optimizer=tf.optimizers.Adam(),",
                "ASSIGN='sparse_categorical_crossentropy',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(train_img, train_lab, epochs=10, ASSIGN=[ASSIGN])",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,'Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.9)",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Flatten(input_shape=(28,28)))",
                "ASSIGN.add(Dense(512, activation=tf.nn.relu))",
                "ASSIGN.add(Dense(512, activation=tf.nn.relu))",
                "ASSIGN.add(Dense(10, activation=tf.nn.softmax))",
                "ASSIGN.compile(optimizer=tf.optimizers.Adam(),",
                "ASSIGN='sparse_categorical_crossentropy',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(train_img, train_lab, epochs=10, ASSIGN=[ASSIGN])",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "model.evaluate(test_img, test_lab)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.evaluate(test_img, test_lab)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = model.predict(test_img)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = model.predict(test_img)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "np.argmax(pred[0])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "np.argmax(pred[0])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "(train_img, train_lab), (test_img, test_lab) = mnist.load_data()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "(train_img, train_lab), (test_img, test_lab) = mnist.load_data()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN path",
                "ASSIGN = ASSIGN path"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN path",
                "ASSIGN = ASSIGN path"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(train_img.shape)",
                "print(len(set(train_lab)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(train_img.shape)",
                "print(len(set(train_lab)))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,'Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.99)",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Flatten(input_shape=(28,28)))",
                "ASSIGN.add(Dense(512, activation=tf.nn.relu))",
                "ASSIGN.add(Dense(512, activation=tf.nn.relu))",
                "ASSIGN.add(Dense(10, activation=tf.nn.softmax))",
                "ASSIGN.compile(optimizer=tf.optimizers.Adam(),",
                "ASSIGN='sparse_categorical_crossentropy',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(train_img, train_lab, epochs=10, ASSIGN=[ASSIGN])",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,'Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.99)",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Flatten(input_shape=(28,28)))",
                "ASSIGN.add(Dense(512, activation=tf.nn.relu))",
                "ASSIGN.add(Dense(512, activation=tf.nn.relu))",
                "ASSIGN.add(Dense(10, activation=tf.nn.softmax))",
                "ASSIGN.compile(optimizer=tf.optimizers.Adam(),",
                "ASSIGN='sparse_categorical_crossentropy',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(train_img, train_lab, epochs=10, ASSIGN=[ASSIGN])",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "https:path\\",
                "-O path"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "https:path\\",
                "-O path"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(data_zip, 'r')",
                "ASSIGN.extractall()",
                "ASSIGN.close()",
                "print('Unzip Data Completed')",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(data_zip, 'r')",
                "ASSIGN.extractall()",
                "ASSIGN.close()",
                "print('Unzip Data Completed')",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 'path'",
                "ASSIGN = os.path.join(base_dir, 'train')",
                "ASSIGN = os.path.join(base_dir, 'validation')",
                "ASSIGN = os.path.join(train_dir, 'cats')",
                "ASSIGN = os.path.join(train_dir, 'dogs')",
                "ASSIGN = os.path.join(val_dir, 'cats')",
                "ASSIGN = os.path.join(val_dir, 'dogs')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 'path'",
                "ASSIGN = os.path.join(base_dir, 'train')",
                "ASSIGN = os.path.join(base_dir, 'validation')",
                "ASSIGN = os.path.join(train_dir, 'cats')",
                "ASSIGN = os.path.join(train_dir, 'dogs')",
                "ASSIGN = os.path.join(val_dir, 'cats')",
                "ASSIGN = os.path.join(val_dir, 'dogs')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = os.listdir(train_cats_dir)",
                "ASSIGN = os.listdir(train_dogs_dir)",
                "ASSIGN = os.listdir(val_cats_dir)",
                "ASSIGN = os.listdir(val_dogs_dir)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = os.listdir(train_cats_dir)",
                "ASSIGN = os.listdir(train_dogs_dir)",
                "ASSIGN = os.listdir(val_cats_dir)",
                "ASSIGN = os.listdir(val_dogs_dir)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "rcParams['figure.figsize'] = [10,5]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(1,2)",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN = mpimg.imread(os.path.join(train_cats_dir, train_cat_fn[0]))",
                "ASSIGN.imshow(ASSIGN)",
                "ASSIGN.axis('off') ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN = mpimg.imread(os.path.join(train_dogs_dir, train_dog_fn[0]))",
                "ASSIGN.imshow(ASSIGN)",
                "ASSIGN.axis('off') ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "rcParams['figure.figsize'] = [10,5]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(1,2)",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN = mpimg.imread(os.path.join(train_cats_dir, train_cat_fn[0]))",
                "ASSIGN.imshow(ASSIGN)",
                "ASSIGN.axis('off') ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN = mpimg.imread(os.path.join(train_dogs_dir, train_dog_fn[0]))",
                "ASSIGN.imshow(ASSIGN)",
                "ASSIGN.axis('off') ;"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = ImageDataGenerator(rescale=1path)",
                "ASSIGN = ImageDataGenerator(rescale=1path)",
                "ASSIGN = train_datagen.flow_from_directory(train_dir,",
                "ASSIGN=20,",
                "ASSIGN='binary',",
                "ASSIGN=(150,150))",
                "ASSIGN = val_datagen.flow_from_directory(val_dir,",
                "ASSIGN=20,",
                "ASSIGN='binary',",
                "ASSIGN=(150,150))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = ImageDataGenerator(rescale=1path)",
                "ASSIGN = ImageDataGenerator(rescale=1path)",
                "ASSIGN = train_datagen.flow_from_directory(train_dir,",
                "ASSIGN=20,",
                "ASSIGN='binary',",
                "ASSIGN=(150,150))",
                "ASSIGN = val_datagen.flow_from_directory(val_dir,",
                "ASSIGN=20,",
                "ASSIGN='binary',",
                "ASSIGN=(150,150))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('val_accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,' Validation Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.72)",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Conv2D(64, (3,3), activation='relu', input_shape=(150,150,3)))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(512, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),",
                "ASSIGN='binary_crossentropy',",
                "ASSIGN=['accuracy'])",
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=val_gen,",
                "ASSIGN=100,",
                "ASSIGN=20,",
                "ASSIGN=50,",
                "ASSIGN=1,",
                "ASSIGN=[ASSIGN])",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('val_accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,' Validation Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.72)",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Conv2D(64, (3,3), activation='relu', input_shape=(150,150,3)))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(512, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),",
                "ASSIGN='binary_crossentropy',",
                "ASSIGN=['accuracy'])",
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=val_gen,",
                "ASSIGN=100,",
                "ASSIGN=20,",
                "ASSIGN=50,",
                "ASSIGN=1,",
                "ASSIGN=[ASSIGN])",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = [os.path.join(val_cats_dir, fn) for fn in sample(val_cat_fn, 5)]",
                "ASSIGN = [os.path.join(val_dogs_dir, fn) for fn in sample(val_dog_fn, 5)]",
                "ASSIGN = list_cat_fn + list_dog_fn",
                "for fn in ASSIGN :",
                "ASSIGN = load_img(fn, target_size=(150,150))",
                "ASSIGN = img_to_array(img)",
                "ASSIGN = np.expand_dims(ASSIGN, axis=0)",
                "ASSIGN = np.vstack([vect_img])",
                "ASSIGN = model.predict(ready_img, batch_size=10)",
                "ASSIGN == 0 :",
                "print(fn,'is a cat')",
                "else :",
                "print(fn,'is a dog')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = [os.path.join(val_cats_dir, fn) for fn in sample(val_cat_fn, 5)]",
                "ASSIGN = [os.path.join(val_dogs_dir, fn) for fn in sample(val_dog_fn, 5)]",
                "ASSIGN = list_cat_fn + list_dog_fn",
                "for fn in ASSIGN :",
                "ASSIGN = load_img(fn, target_size=(150,150))",
                "ASSIGN = img_to_array(img)",
                "ASSIGN = np.expand_dims(ASSIGN, axis=0)",
                "ASSIGN = np.vstack([vect_img])",
                "ASSIGN = model.predict(ready_img, batch_size=10)",
                "ASSIGN == 0 :",
                "print(fn,'is a cat')",
                "else :",
                "print(fn,'is a dog')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = [os.path.join(val_cats_dir, fn) for fn in sample(val_cat_fn, 5)]",
                "ASSIGN = [os.path.join(val_dogs_dir, fn) for fn in sample(val_dog_fn, 5)]",
                "ASSIGN = list_cat_fn + list_dog_fn",
                "ASSIGN = [layer.output for layer in model.layers[1:]]",
                "ASSIGN = keras.models.Model(inputs=model.input, outputs=succ_out)",
                "ASSIGN = load_img(choice(list_fn), target_size=(150,150))",
                "ASSIGN = img_to_array(img)",
                "ASSIGN  = ASSIGN.reshape((1,) + ASSIGN.shape)",
                "ASSIGN = ASSIGN path",
                "ASSIGN = viz_model.predict(x)",
                "ASSIGN = [layer.name for layer in model.layers]",
                "for layer_name, feature_map in zip(ASSIGN, ASSIGN):",
                "if len(feature_map.shape) == 4:",
                "ASSIGN = feature_map.shape[-1]",
                "ASSIGN    = feature_map.shape[ 1]",
                "ASSIGN = np.zeros((size, size * n_features))",
                "for i in range(ASSIGN):",
                "ASSIGN = feature_map[0, :, :, i]",
                "ASSIGN -= ASSIGN.mean()",
                "ASSIGN= x.std ()",
                "ASSIGN *= 64",
                "ASSIGN += 128",
                "ASSIGN = np.clip(ASSIGN, 0, 255).astype('uint8')",
                "ASSIGN[:, i * ASSIGN : (i + 1) * ASSIGN] = ASSIGN",
                "ASSIGN = 20. path",
                "plt.figure( figsize=(ASSIGN * ASSIGN, ASSIGN) )",
                "plt.title ( layer_name )",
                "plt.grid ( False )",
                "plt.imshow( ASSIGN, aspect='auto', cmap='viridis' )"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = [os.path.join(val_cats_dir, fn) for fn in sample(val_cat_fn, 5)]",
                "ASSIGN = [os.path.join(val_dogs_dir, fn) for fn in sample(val_dog_fn, 5)]",
                "ASSIGN = list_cat_fn + list_dog_fn",
                "ASSIGN = [layer.output for layer in model.layers[1:]]",
                "ASSIGN = keras.models.Model(inputs=model.input, outputs=succ_out)",
                "ASSIGN = load_img(choice(list_fn), target_size=(150,150))",
                "ASSIGN = img_to_array(img)",
                "ASSIGN  = ASSIGN.reshape((1,) + ASSIGN.shape)",
                "ASSIGN = ASSIGN path",
                "ASSIGN = viz_model.predict(x)",
                "ASSIGN = [layer.name for layer in model.layers]",
                "for layer_name, feature_map in zip(ASSIGN, ASSIGN):",
                "if len(feature_map.shape) == 4:",
                "ASSIGN = feature_map.shape[-1]",
                "ASSIGN    = feature_map.shape[ 1]",
                "ASSIGN = np.zeros((size, size * n_features))",
                "for i in range(ASSIGN):",
                "ASSIGN = feature_map[0, :, :, i]",
                "ASSIGN -= ASSIGN.mean()",
                "ASSIGN= x.std ()",
                "ASSIGN *= 64",
                "ASSIGN += 128",
                "ASSIGN = np.clip(ASSIGN, 0, 255).astype('uint8')",
                "ASSIGN[:, i * ASSIGN : (i + 1) * ASSIGN] = ASSIGN",
                "ASSIGN = 20. path",
                "plt.figure( figsize=(ASSIGN * ASSIGN, ASSIGN) )",
                "plt.title ( layer_name )",
                "plt.grid ( False )",
                "plt.imshow( ASSIGN, aspect='auto', cmap='viridis' )"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN   = list(range(len(acc)))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Loss')",
                "ASSIGN.set_title('Training and Validation Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Acc')",
                "ASSIGN.set_title('Training and Validation Accuracy')",
                "ASSIGN.legend() ;",
                "plt.tight_layout()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN   = list(range(len(acc)))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Loss')",
                "ASSIGN.set_title('Training and Validation Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Acc')",
                "ASSIGN.set_title('Training and Validation Accuracy')",
                "ASSIGN.legend() ;",
                "plt.tight_layout()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "plt.plot ( ASSIGN, ASSIGN )",
                "plt.plot ( ASSIGN, ASSIGN )",
                "plt.title ('Training and validation accuracy')",
                "plt.figure()",
                "plt.plot ( ASSIGN, ASSIGN )",
                "plt.plot ( ASSIGN, ASSIGN )",
                "plt.title ('Training and validation ASSIGN' )"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "plt.plot ( ASSIGN, ASSIGN )",
                "plt.plot ( ASSIGN, ASSIGN )",
                "plt.title ('Training and validation accuracy')",
                "plt.figure()",
                "plt.plot ( ASSIGN, ASSIGN )",
                "plt.plot ( ASSIGN, ASSIGN )",
                "plt.title ('Training and validation ASSIGN' )"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(train_zip, 'r')",
                "ASSIGN.extractall()",
                "ASSIGN.close()",
                "print('Unzip Train Completed')",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)",
                "ASSIGN = time.time()",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(test_zip, 'r')",
                "ASSIGN.extractall()",
                "ASSIGN.close()",
                "print('Unzip Test Completed')",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = time.time()",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(train_zip, 'r')",
                "ASSIGN.extractall()",
                "ASSIGN.close()",
                "print('Unzip Train Completed')",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)",
                "ASSIGN = time.time()",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(test_zip, 'r')",
                "ASSIGN.extractall()",
                "ASSIGN.close()",
                "print('Unzip Test Completed')",
                "ASSIGN = time.time()",
                "print('Time Used :',(ASSIGN-ASSIGN)path)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Post Development Phase"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "os.mkdir(TRAINING_DIR)",
                "os.mkdir(TRAINING_CAT_DIR)",
                "os.mkdir(TRAINING_DOG_DIR)",
                "os.mkdir(VALIDATION_DIR)",
                "os.mkdir(VALIDATION_CAT_DIR)",
                "os.mkdir(VALIDATION_DOG_DIR)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "SETUP",
                "os.mkdir(TRAINING_DIR)",
                "os.mkdir(TRAINING_CAT_DIR)",
                "os.mkdir(TRAINING_DOG_DIR)",
                "os.mkdir(VALIDATION_DIR)",
                "os.mkdir(VALIDATION_CAT_DIR)",
                "os.mkdir(VALIDATION_DOG_DIR)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = os.listdir(SOURCE_DIR)",
                "ASSIGN = [fn for fn in list_fn if 'cat' in fn]",
                "ASSIGN = [fn for fn in list_fn if 'dog' in fn]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = os.listdir(SOURCE_DIR)",
                "ASSIGN = [fn for fn in list_fn if 'cat' in fn]",
                "ASSIGN = [fn for fn in list_fn if 'dog' in fn]"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "ASSIGN = ['cat','dog']",
                "ASSIGN = [list_cat_fn, list_dog_fn]",
                "for i,c in enumerate(tqdm(ASSIGN)) :",
                "ASSIGN = list_name_fn[i]",
                "ASSIGN = random.sample(list_class_fn, len(list_class_fn))",
                "ASSIGN = pure_random[:int(SPLIT_PROP*len(pure_random))]",
                "ASSIGN = pure_random[int(SPLIT_PROP*len(pure_random)):]",
                "for f in ASSIGN :",
                "copyfile(os.path.join(SOURCE_DIR,f), os.path.join(TRAIN_CLASS_DIR,f))",
                "for f in ASSIGN :",
                "copyfile(os.path.join(SOURCE_DIR,f), os.path.join(VALID_CLASS_DIR,f))",
                "del pure_random, random_train, random_val"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "SETUP",
                "ASSIGN = ['cat','dog']",
                "ASSIGN = [list_cat_fn, list_dog_fn]",
                "for i,c in enumerate(tqdm(ASSIGN)) :",
                "ASSIGN = list_name_fn[i]",
                "ASSIGN = random.sample(list_class_fn, len(list_class_fn))",
                "ASSIGN = pure_random[:int(SPLIT_PROP*len(pure_random))]",
                "ASSIGN = pure_random[int(SPLIT_PROP*len(pure_random)):]",
                "for f in ASSIGN :",
                "copyfile(os.path.join(SOURCE_DIR,f), os.path.join(TRAIN_CLASS_DIR,f))",
                "for f in ASSIGN :",
                "copyfile(os.path.join(SOURCE_DIR,f), os.path.join(VALID_CLASS_DIR,f))",
                "del pure_random, random_train, random_val"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "ASSIGN = ResNet50(weights='imagenet',",
                "ASSIGN=False,",
                "ASSIGN=(HEIGHT, WIDTH, 3))",
                "ASSIGN = tf.keras.applications.resnet50.preprocess_input",
                "ASSIGN = tf.keras.applications.resnet50.decode_predictions"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "SETUP",
                "ASSIGN = ResNet50(weights='imagenet',",
                "ASSIGN=False,",
                "ASSIGN=(HEIGHT, WIDTH, 3))",
                "ASSIGN = tf.keras.applications.resnet50.preprocess_input",
                "ASSIGN = tf.keras.applications.resnet50.decode_predictions"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = ImageDataGenerator(rescale=1path, preprocessing_function=prec_input)",
                "ASSIGN = ImageDataGenerator(rescale=1path, preprocessing_function=prec_input)",
                "ASSIGN = train_datagen.flow_from_directory(TRAINING_DIR,",
                "ASSIGN=BATCH_SIZE,",
                "ASSIGN='bicubic',",
                "ASSIGN='categorical',",
                "ASSIGN=True,",
                "ASSIGN=(HEIGHT, WIDTH))",
                "ASSIGN = val_datagen.flow_from_directory(VALIDATION_DIR,",
                "ASSIGN=BATCH_SIZE,",
                "ASSIGN='bicubic',",
                "ASSIGN='categorical',",
                "ASSIGN=False,",
                "ASSIGN=(HEIGHT, WIDTH))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = ImageDataGenerator(rescale=1path, preprocessing_function=prec_input)",
                "ASSIGN = ImageDataGenerator(rescale=1path, preprocessing_function=prec_input)",
                "ASSIGN = train_datagen.flow_from_directory(TRAINING_DIR,",
                "ASSIGN=BATCH_SIZE,",
                "ASSIGN='bicubic',",
                "ASSIGN='categorical',",
                "ASSIGN=True,",
                "ASSIGN=(HEIGHT, WIDTH))",
                "ASSIGN = val_datagen.flow_from_directory(VALIDATION_DIR,",
                "ASSIGN=BATCH_SIZE,",
                "ASSIGN='bicubic',",
                "ASSIGN='categorical',",
                "ASSIGN=False,",
                "ASSIGN=(HEIGHT, WIDTH))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = []",
                "ASSIGN = 2",
                "ASSIGN = 0.2",
                "def make_model() :",
                "for l in base_model.layers :",
                "l.trainable = False",
                "ASSIGN = Sequential()",
                "ASSIGN.add(base_model)",
                "ASSIGN.add(GlobalAveragePooling2D())",
                "ASSIGN.add(Flatten())",
                "for fc in ASSIGN:",
                "ASSIGN.add(Dense(fc, activation=swish))",
                "ASSIGN.add(Dropout(ASSIGN))",
                "ASSIGN.add(Dense(ASSIGN, activation='softmax'))",
                "ASSIGN.compile(Adam(), loss='categorical_crossentropy', metrics=['acc'])",
                "return model",
                "ASSIGN = make_model()",
                "ASSIGN.summary()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = []",
                "ASSIGN = 2",
                "ASSIGN = 0.2",
                "def make_model() :",
                "for l in base_model.layers :",
                "l.trainable = False",
                "ASSIGN = Sequential()",
                "ASSIGN.add(base_model)",
                "ASSIGN.add(GlobalAveragePooling2D())",
                "ASSIGN.add(Flatten())",
                "for fc in ASSIGN:",
                "ASSIGN.add(Dense(fc, activation=swish))",
                "ASSIGN.add(Dropout(ASSIGN))",
                "ASSIGN.add(Dense(ASSIGN, activation='softmax'))",
                "ASSIGN.compile(Adam(), loss='categorical_crossentropy', metrics=['acc'])",
                "return model",
                "ASSIGN = make_model()",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=EPOCHS,",
                "ASSIGN=1,",
                "ASSIGN=val_gen)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=EPOCHS,",
                "ASSIGN=1,",
                "ASSIGN=val_gen)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = tf.keras.models.Sequential([",
                "tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),",
                "tf.keras.layers.MaxPooling2D(2,2),",
                "tf.keras.layers.Conv2D(32, (3,3), activation='relu'),",
                "tf.keras.layers.MaxPooling2D(2,2),",
                "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),",
                "tf.keras.layers.MaxPooling2D(2,2),",
                "tf.keras.layers.Flatten(),",
                "tf.keras.layers.Dense(512, activation='relu'),",
                "tf.keras.layers.Dense(2, activation='softmax')",
                "])",
                "ASSIGN.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = tf.keras.models.Sequential([",
                "tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),",
                "tf.keras.layers.MaxPooling2D(2,2),",
                "tf.keras.layers.Conv2D(32, (3,3), activation='relu'),",
                "tf.keras.layers.MaxPooling2D(2,2),",
                "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),",
                "tf.keras.layers.MaxPooling2D(2,2),",
                "tf.keras.layers.Flatten(),",
                "tf.keras.layers.Dense(512, activation='relu'),",
                "tf.keras.layers.Dense(2, activation='softmax')",
                "])",
                "ASSIGN.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=EPOCHS,",
                "ASSIGN=1,",
                "ASSIGN=val_gen)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=EPOCHS,",
                "ASSIGN=1,",
                "ASSIGN=val_gen)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(data_zip, 'r')",
                "ASSIGN.extractall('path')",
                "ASSIGN.close()",
                "print('Unzip Train Data Completed')",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(valid_zip, 'r')",
                "ASSIGN.extractall('path')",
                "ASSIGN.close()",
                "print('Unzip Valid Data Completed')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(data_zip, 'r')",
                "ASSIGN.extractall('path')",
                "ASSIGN.close()",
                "print('Unzip Train Data Completed')",
                "ASSIGN = 'path'",
                "ASSIGN = zipfile.ZipFile(valid_zip, 'r')",
                "ASSIGN.extractall('path')",
                "ASSIGN.close()",
                "print('Unzip Valid Data Completed')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print('Total obs on horse class in train :',len(os.listdir(TRAIN_HORSE_DIR)))",
                "print('Total obs on human class in train :',len(os.listdir(TRAIN_HUMAN_DIR)))",
                "print('Total obs on horse class in validation :',len(os.listdir(VAL_HORSE_DIR)))",
                "print('Total obs on human class in validation :',len(os.listdir(VAL_HUMAN_DIR)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print('Total obs on horse class in train :',len(os.listdir(TRAIN_HORSE_DIR)))",
                "print('Total obs on human class in train :',len(os.listdir(TRAIN_HUMAN_DIR)))",
                "print('Total obs on horse class in validation :',len(os.listdir(VAL_HORSE_DIR)))",
                "print('Total obs on human class in validation :',len(os.listdir(VAL_HUMAN_DIR)))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "https:path\\",
                "-O path",
                "ASSIGN = InceptionV3(weights=None,",
                "ASSIGN=False,",
                "ASSIGN=(INPUT_SIZE[0], INPUT_SIZE[1], 3))",
                "ASSIGN = 'path'",
                "ASSIGN.load_weights(ASSIGN)",
                "ASSIGN.trainable = False",
                "ASSIGN.summary()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "SETUP",
                "https:path\\",
                "-O path",
                "ASSIGN = InceptionV3(weights=None,",
                "ASSIGN=False,",
                "ASSIGN=(INPUT_SIZE[0], INPUT_SIZE[1], 3))",
                "ASSIGN = 'path'",
                "ASSIGN.load_weights(ASSIGN)",
                "ASSIGN.trainable = False",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = base_model.get_layer('mixed7')",
                "ASSIGN = last_layer.output",
                "print('Last layer shape :',ASSIGN.output_shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = base_model.get_layer('mixed7')",
                "ASSIGN = last_layer.output",
                "print('Last layer shape :',ASSIGN.output_shape)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "ASSIGN = ImageDataGenerator(rescale = 1.path,",
                "ASSIGN = 40,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = True)",
                "ASSIGN = train_datagen.flow_from_directory(TRAIN_DIR,",
                "ASSIGN = BATCH_SIZE,",
                "ASSIGN = 'binary',",
                "ASSIGN = INPUT_SIZE)",
                "ASSIGN = ImageDataGenerator(rescale = 1path)",
                "ASSIGN = val_datagen.flow_from_directory(VALID_DIR,",
                "ASSIGN = BATCH_SIZE,",
                "ASSIGN = 'binary',",
                "ASSIGN = INPUT_SIZE)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "SETUP",
                "ASSIGN = ImageDataGenerator(rescale = 1.path,",
                "ASSIGN = 40,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = True)",
                "ASSIGN = train_datagen.flow_from_directory(TRAIN_DIR,",
                "ASSIGN = BATCH_SIZE,",
                "ASSIGN = 'binary',",
                "ASSIGN = INPUT_SIZE)",
                "ASSIGN = ImageDataGenerator(rescale = 1path)",
                "ASSIGN = val_datagen.flow_from_directory(VALID_DIR,",
                "ASSIGN = BATCH_SIZE,",
                "ASSIGN = 'binary',",
                "ASSIGN = INPUT_SIZE)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Flatten()(last_output)",
                "ASSIGN = Dense(1024, activation='relu')(ASSIGN)",
                "ASSIGN = Dropout(0.2)(ASSIGN)",
                "ASSIGN = Dense(1, activation='sigmoid')(ASSIGN)",
                "ASSIGN = Model(base_model.input, x)",
                "ASSIGN.compile(optimizer = RMSprop(lr=0.0001),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Flatten()(last_output)",
                "ASSIGN = Dense(1024, activation='relu')(ASSIGN)",
                "ASSIGN = Dropout(0.2)(ASSIGN)",
                "ASSIGN = Dense(1, activation='sigmoid')(ASSIGN)",
                "ASSIGN = Model(base_model.input, x)",
                "ASSIGN.compile(optimizer = RMSprop(lr=0.0001),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,'Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.99)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,'Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.99)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=val_gen,",
                "ASSIGN=100,",
                "ASSIGN=50,",
                "ASSIGN=EPOCHS,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=val_gen,",
                "ASSIGN=100,",
                "ASSIGN=50,",
                "ASSIGN=EPOCHS,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Post Development Phase"
            ],
            "content": [
                "SETUP",
                "def get_data(path) :",
                "ASSIGN = pd.read_csv(path)",
                "ASSIGN = to_categorical(np.array(df['ASSIGN']))",
                "ASSIGN = []",
                "for i in range(len(ASSIGN)) :",
                "ASSIGN = np.array(np.split(df.iloc[i,1:].values, 28))",
                "ASSIGN.append(ASSIGN)",
                "return np.array(image), label"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "def get_data(path) :",
                "ASSIGN = pd.read_csv(path)",
                "ASSIGN = to_categorical(np.array(df['ASSIGN']))",
                "ASSIGN = []",
                "for i in range(len(ASSIGN)) :",
                "ASSIGN = np.array(np.split(df.iloc[i,1:].values, 28))",
                "ASSIGN.append(ASSIGN)",
                "return np.array(image), label"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = get_data('..path')",
                "ASSIGN = get_data('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = get_data('..path')",
                "ASSIGN = get_data('..path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print('Train image shape :',train_img.shape)",
                "print('Train label shape :',train_label.shape)",
                "print('Valid image shape :',val_img.shape)",
                "print('Valid label shape :',val_label.shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print('Train image shape :',train_img.shape)",
                "print('Train label shape :',train_label.shape)",
                "print('Valid image shape :',val_img.shape)",
                "print('Valid label shape :',val_label.shape)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "ASSIGN = np.expand_dims(ASSIGN, 3)",
                "ASSIGN = ImageDataGenerator(rescale = 1.path,",
                "ASSIGN = 40,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = True)",
                "ASSIGN = train_datagen.flow(x=train_img, y=train_label,",
                "ASSIGN = BATCH_SIZE)",
                "ASSIGN = np.expand_dims(ASSIGN, 3)",
                "ASSIGN = ImageDataGenerator(rescale = 1path)",
                "ASSIGN = val_datagen.flow(x=val_img, y=val_label,",
                "ASSIGN = BATCH_SIZE)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "SETUP",
                "ASSIGN = np.expand_dims(ASSIGN, 3)",
                "ASSIGN = ImageDataGenerator(rescale = 1.path,",
                "ASSIGN = 40,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = 0.2,",
                "ASSIGN = True)",
                "ASSIGN = train_datagen.flow(x=train_img, y=train_label,",
                "ASSIGN = BATCH_SIZE)",
                "ASSIGN = np.expand_dims(ASSIGN, 3)",
                "ASSIGN = ImageDataGenerator(rescale = 1path)",
                "ASSIGN = val_datagen.flow(x=val_img, y=val_label,",
                "ASSIGN = BATCH_SIZE)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(64, (3,3), activation='relu', input_shape=(INPUT_SIZE[0], INPUT_SIZE[1], 1)))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Conv2D(128, (3,3), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(256, activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Dense(25, activation='softmax'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'categorical_crossentropy',",
                "ASSIGN = 'accuracy')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(64, (3,3), activation='relu', input_shape=(INPUT_SIZE[0], INPUT_SIZE[1], 1)))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Conv2D(128, (3,3), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(2,2))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(256, activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Dense(25, activation='softmax'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'categorical_crossentropy',",
                "ASSIGN = 'accuracy')"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('val_accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,'Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.9)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "class EarlyStop(tf.keras.callbacks.Callback) :",
                "def __init__(self, threshold) :",
                "self.thres = threshold",
                "def on_epoch_end(self, epoch, logs={}) :",
                "if (logs.get('val_accuracy')>self.thres) :",
                "print('\\nReached',self.thres*100,'Accuracy so stop train!')",
                "self.model.stop_training=True",
                "ASSIGN = EarlyStop(0.9)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=val_gen,",
                "ASSIGN=train_img.shape[0] path,",
                "ASSIGN=val_img.shape[0] path,",
                "ASSIGN=EPOCHS,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = model.fit_generator(train_gen,",
                "ASSIGN=val_gen,",
                "ASSIGN=train_img.shape[0] path,",
                "ASSIGN=val_img.shape[0] path,",
                "ASSIGN=EPOCHS,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "model.evaluate(val_img, val_label)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.evaluate(val_img, val_label)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Loss')",
                "ASSIGN.set_title('Training and Validation Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Acc')",
                "ASSIGN.set_title('Training and Validation Accuracy')",
                "ASSIGN.legend() ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Loss')",
                "ASSIGN.set_title('Training and Validation Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Acc')",
                "ASSIGN.set_title('Training and Validation Accuracy')",
                "ASSIGN.legend() ;"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "https:path\\",
                "-O path"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "https:path\\",
                "-O path"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = list(data['category'])",
                "ASSIGN = list(data['text'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = list(data['category'])",
                "ASSIGN = list(data['text'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(len(sentences_raw))",
                "print(sentences_raw[0])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(len(sentences_raw))",
                "print(sentences_raw[0])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]",
                "ASSIGN = []",
                "for t in tqdm(sentences_raw) :",
                "ASSIGN = word_tokenize(t)",
                "ASSIGN = [i for i in tokenize_text if i not in stopwords]",
                "ASSIGN.append((\" \").join(ASSIGN))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]",
                "ASSIGN = []",
                "for t in tqdm(sentences_raw) :",
                "ASSIGN = word_tokenize(t)",
                "ASSIGN = [i for i in tokenize_text if i not in stopwords]",
                "ASSIGN.append((\" \").join(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = Tokenizer(oov_token='<OOV>',",
                ")",
                "ASSIGN.fit_on_texts(sentences)",
                "ASSIGN = tokenizer.ASSIGN",
                "print(len(ASSIGN))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = Tokenizer(oov_token='<OOV>',",
                ")",
                "ASSIGN.fit_on_texts(sentences)",
                "ASSIGN = tokenizer.ASSIGN",
                "print(len(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = tokenizer.texts_to_sequences(sentences)",
                "ASSIGN = pad_sequences(sequences, padding='post', truncating='pre', maxlen=None)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = tokenizer.texts_to_sequences(sentences)",
                "ASSIGN = pad_sequences(sequences, padding='post', truncating='pre', maxlen=None)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(padded[0])",
                "print(padded.shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(padded[0])",
                "print(padded.shape)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = Tokenizer()",
                "ASSIGN.fit_on_texts(label)",
                "ASSIGN = tokenizer_label.word_index",
                "ASSIGN = tokenizer_label.texts_to_sequences(label)",
                "print(ASSIGN)",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = Tokenizer()",
                "ASSIGN.fit_on_texts(label)",
                "ASSIGN = tokenizer_label.word_index",
                "ASSIGN = tokenizer_label.texts_to_sequences(label)",
                "print(ASSIGN)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "https:path\\",
                "-O path"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "https:path\\",
                "-O path"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = list(data['category'])",
                "ASSIGN = list(data['text'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = list(data['category'])",
                "ASSIGN = list(data['text'])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]",
                "ASSIGN = []",
                "for t in tqdm(sentences_raw) :",
                "ASSIGN = word_tokenize(t)",
                "ASSIGN = [i for i in tokenize_text if i not in stopwords]",
                "ASSIGN.append((\" \").join(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]",
                "ASSIGN = []",
                "for t in tqdm(sentences_raw) :",
                "ASSIGN = word_tokenize(t)",
                "ASSIGN = [i for i in tokenize_text if i not in stopwords]",
                "ASSIGN.append((\" \").join(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "lab_tokenizer.word_index"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "lab_tokenizer.word_index"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = int(TRAIN_PROP * len(sentences))",
                "ASSIGN = sentences[:train_size]",
                "ASSIGN = label[:train_size]",
                "ASSIGN = sentences[train_size:]",
                "ASSIGN = label[train_size:]",
                "print(ASSIGN)",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = int(TRAIN_PROP * len(sentences))",
                "ASSIGN = sentences[:train_size]",
                "ASSIGN = label[:train_size]",
                "ASSIGN = sentences[train_size:]",
                "ASSIGN = label[train_size:]",
                "print(ASSIGN)",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Tokenizer(oov_token=OOV_TOK, num_words=VOCAB_SIZE)",
                "ASSIGN.fit_on_texts(train_sentences)",
                "ASSIGN = text_tokenizer.ASSIGN",
                "ASSIGN = text_tokenizer.texts_to_sequences(train_sentences)",
                "ASSIGN = pad_sequences(train_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Tokenizer(oov_token=OOV_TOK, num_words=VOCAB_SIZE)",
                "ASSIGN.fit_on_texts(train_sentences)",
                "ASSIGN = text_tokenizer.ASSIGN",
                "ASSIGN = text_tokenizer.texts_to_sequences(train_sentences)",
                "ASSIGN = pad_sequences(train_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = text_tokenizer.texts_to_sequences(val_sentences)",
                "ASSIGN = pad_sequences(val_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = text_tokenizer.texts_to_sequences(val_sentences)",
                "ASSIGN = pad_sequences(val_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Tokenizer()",
                "ASSIGN.fit_on_texts(train_label)",
                "ASSIGN = np.array(lab_tokenizer.texts_to_sequences(train_label))",
                "ASSIGN = np.array(lab_tokenizer.texts_to_sequences(val_label))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Tokenizer()",
                "ASSIGN.fit_on_texts(train_label)",
                "ASSIGN = np.array(lab_tokenizer.texts_to_sequences(train_label))",
                "ASSIGN = np.array(lab_tokenizer.texts_to_sequences(val_label))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH))",
                "ASSIGN.add(GlobalAveragePooling1D())",
                "ASSIGN.add(Dense(24, activation='relu'))",
                "ASSIGN.add(Dense(6, activation='softmax'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'sparse_categorical_crossentropy',",
                "ASSIGN = 'accuracy')",
                "ASSIGN.summary()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH))",
                "ASSIGN.add(GlobalAveragePooling1D())",
                "ASSIGN.add(Dense(24, activation='relu'))",
                "ASSIGN.add(Dense(6, activation='softmax'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'sparse_categorical_crossentropy',",
                "ASSIGN = 'accuracy')",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = 30",
                "ASSIGN = model.fit(train_padded,",
                "train_label_seq,",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, val_label_seq),",
                "ASSIGN=1)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = 30",
                "ASSIGN = model.fit(train_padded,",
                "train_label_seq,",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, val_label_seq),",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Loss')",
                "ASSIGN.set_title('Training and Validation Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Acc')",
                "ASSIGN.set_title('Training and Validation Accuracy')",
                "ASSIGN.legend() ;"
            ],
            "output_type": "display_data",
            "content_old": [
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Loss')",
                "ASSIGN.set_title('Training and Validation Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Acc')",
                "ASSIGN.set_title('Training and Validation Accuracy')",
                "ASSIGN.legend() ;"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = dict([(value, key) for (key, value) in word_index.items()])",
                "def decode_sentence(text):",
                "return ' '.join([ASSIGN.get(i, '?') for i in text])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = dict([(value, key) for (key, value) in word_index.items()])",
                "def decode_sentence(text):",
                "return ' '.join([ASSIGN.get(i, '?') for i in text])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Activity"
            ],
            "content": [
                "ASSIGN = model.layers[0]",
                "ASSIGN = e.get_weights()[0]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = model.layers[0]",
                "ASSIGN = e.get_weights()[0]"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = io.open('vecs.tsv', 'w', encoding='utf-8')",
                "ASSIGN = io.open('meta.tsv', 'w', encoding='utf-8')",
                "for word_num in range(1, VOCAB_SIZE):",
                "ASSIGN = reverse_word_index[word_num]",
                "ASSIGN = weights[word_num]",
                "ASSIGN.write(ASSIGN + \"\\n\")",
                "ASSIGN.write('\\t'.join([str(x) for x in ASSIGN]) + \"\\n\")",
                "ASSIGN.close()",
                "ASSIGN.close()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = io.open('vecs.tsv', 'w', encoding='utf-8')",
                "ASSIGN = io.open('meta.tsv', 'w', encoding='utf-8')",
                "for word_num in range(1, VOCAB_SIZE):",
                "ASSIGN = reverse_word_index[word_num]",
                "ASSIGN = weights[word_num]",
                "ASSIGN.write(ASSIGN + \"\\n\")",
                "ASSIGN.write('\\t'.join([str(x) for x in ASSIGN]) + \"\\n\")",
                "ASSIGN.close()",
                "ASSIGN.close()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "https:path\\",
                "-O path"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "https:path\\",
                "-O path"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path', names=['label','id','time','query','handle','text'])",
                "ASSIGN = ASSIGN.sample(frac=1).reset_index(drop=True)",
                "ASSIGN = list(data['text'])",
                "ASSIGN = list(data['ASSIGN'].map({0:0, 4:1}))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('path', names=['label','id','time','query','handle','text'])",
                "ASSIGN = ASSIGN.sample(frac=1).reset_index(drop=True)",
                "ASSIGN = list(data['text'])",
                "ASSIGN = list(data['ASSIGN'].map({0:0, 4:1}))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = int(TRAIN_PROP * len(sentences))",
                "ASSIGN = sentences[:train_size]",
                "ASSIGN = label[:train_size]",
                "ASSIGN = sentences[train_size:]",
                "ASSIGN = label[train_size:]",
                "print(ASSIGN)",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = int(TRAIN_PROP * len(sentences))",
                "ASSIGN = sentences[:train_size]",
                "ASSIGN = label[:train_size]",
                "ASSIGN = sentences[train_size:]",
                "ASSIGN = label[train_size:]",
                "print(ASSIGN)",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))",
                "print(len(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Tokenizer(oov_token=OOV_TOK)",
                "ASSIGN.fit_on_texts(train_sentences)",
                "ASSIGN = text_tokenizer.ASSIGN",
                "ASSIGN = text_tokenizer.texts_to_sequences(train_sentences)",
                "ASSIGN = pad_sequences(train_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Tokenizer(oov_token=OOV_TOK)",
                "ASSIGN.fit_on_texts(train_sentences)",
                "ASSIGN = text_tokenizer.ASSIGN",
                "ASSIGN = text_tokenizer.texts_to_sequences(train_sentences)",
                "ASSIGN = pad_sequences(train_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = text_tokenizer.texts_to_sequences(val_sentences)",
                "ASSIGN = pad_sequences(val_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = text_tokenizer.texts_to_sequences(val_sentences)",
                "ASSIGN = pad_sequences(val_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "https:path\\",
                "-O path",
                "ASSIGN = {};",
                "with open('path') as f:",
                "for line in f:",
                "ASSIGN = line.split();",
                "ASSIGN = values[0];",
                "ASSIGN = np.asarray(values[1:], dtype='float32');",
                "ASSIGN[ASSIGN] = ASSIGN;",
                "ASSIGN = np.zeros((VOCAB_SIZE, EMBEDDING_DIM));",
                "for ASSIGN, i in word_index.items():",
                "ASSIGN = embeddings_index.get(word);",
                "if ASSIGN is not None:",
                "ASSIGN[i] = ASSIGN;"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "https:path\\",
                "-O path",
                "ASSIGN = {};",
                "with open('path') as f:",
                "for line in f:",
                "ASSIGN = line.split();",
                "ASSIGN = values[0];",
                "ASSIGN = np.asarray(values[1:], dtype='float32');",
                "ASSIGN[ASSIGN] = ASSIGN;",
                "ASSIGN = np.zeros((VOCAB_SIZE, EMBEDDING_DIM));",
                "for ASSIGN, i in word_index.items():",
                "ASSIGN = embeddings_index.get(word);",
                "if ASSIGN is not None:",
                "ASSIGN[i] = ASSIGN;"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(GlobalAveragePooling1D())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(Bidirectional(LSTM(64)))",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(Bidirectional(GRU(64)))",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(Conv1D(64, 5, activation='relu'))",
                "ASSIGN.add(GlobalMaxPooling1D())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(GlobalAveragePooling1D())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(Bidirectional(LSTM(64)))",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(Bidirectional(GRU(64)))",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(Conv1D(64, 5, activation='relu'))",
                "ASSIGN.add(GlobalMaxPooling1D())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plot_history(history) :",
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Loss')",
                "ASSIGN.set_title('Training and Validation Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Acc')",
                "ASSIGN.set_title('Training and Validation Accuracy')",
                "ASSIGN.legend() ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plot_history(history) :",
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN = history.history[ 'val_accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN = history.history['ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Loss')",
                "ASSIGN.set_title('Training and Validation Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Validation Acc')",
                "ASSIGN.set_title('Training and Validation Accuracy')",
                "ASSIGN.legend() ;"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = model_simple.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = model_simple.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_history(history_simple)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_history(history_simple)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 10",
                "ASSIGN = model_single_lstm.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = 10",
                "ASSIGN = model_single_lstm.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_history(history_single_lstm)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plot_history(history_single_lstm)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = model_single_gru.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = model_single_gru.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_history(history_single_gru)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_history(history_single_gru)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = model_single_conv.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = model_single_conv.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_history(history_single_conv)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_history(history_single_conv)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Conv1D(64, 5, activation='relu'))",
                "ASSIGN.add(MaxPooling1D(4))",
                "ASSIGN.add(LSTM(64))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH,",
                "ASSIGN=[embeddings_matrix], trainable=False))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Conv1D(64, 5, activation='relu'))",
                "ASSIGN.add(MaxPooling1D(4))",
                "ASSIGN.add(LSTM(64))",
                "ASSIGN.add(Dense(1, activation='sigmoid'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'binary_crossentropy',",
                "ASSIGN = 'accuracy')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = model.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 5",
                "ASSIGN = model.fit(train_padded,",
                "np.array(train_label),",
                "ASSIGN=num_epochs,",
                "ASSIGN=(val_padded, np.array(val_label)),",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_history(history)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_history(history)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "https:path\\",
                "-O path"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "https:path\\",
                "-O path"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = open('path').read()",
                "ASSIGN = data.lower().split('\\n')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = open('path').read()",
                "ASSIGN = data.lower().split('\\n')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "ASSIGN = Tokenizer()",
                "ASSIGN.fit_on_texts(corpus)",
                "ASSIGN = tokenizer.ASSIGN",
                "ASSIGN = []",
                "for text in corpus :",
                "ASSIGN = tokenizer.texts_to_sequences([text])[0]",
                "for i in range(1, len(ASSIGN)) :",
                "ASSIGN = token_list[:i+1]",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = pad_sequences(train_seq, padding=PADDING_TYPE, maxlen=MAX_LENGTH)",
                "ASSIGN = train_padded[:,:-1], train_padded[:,-1]",
                "ASSIGN = to_categorical(ASSIGN, num_classes=VOCAB_SIZE)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "SETUP",
                "ASSIGN = Tokenizer()",
                "ASSIGN.fit_on_texts(corpus)",
                "ASSIGN = tokenizer.ASSIGN",
                "ASSIGN = []",
                "for text in corpus :",
                "ASSIGN = tokenizer.texts_to_sequences([text])[0]",
                "for i in range(1, len(ASSIGN)) :",
                "ASSIGN = token_list[:i+1]",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = pad_sequences(train_seq, padding=PADDING_TYPE, maxlen=MAX_LENGTH)",
                "ASSIGN = train_padded[:,:-1], train_padded[:,-1]",
                "ASSIGN = to_categorical(ASSIGN, num_classes=VOCAB_SIZE)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "https:path\\",
                "-O path",
                "ASSIGN = {};",
                "with open('path') as f:",
                "for line in f:",
                "ASSIGN = line.split();",
                "ASSIGN = values[0];",
                "ASSIGN = np.asarray(values[1:], dtype='float32');",
                "ASSIGN[ASSIGN] = ASSIGN;",
                "ASSIGN = np.zeros((VOCAB_SIZE, EMBEDDING_DIM));",
                "for ASSIGN, i in word_index.items():",
                "ASSIGN = embeddings_index.get(word);",
                "if ASSIGN is not None:",
                "ASSIGN[i] = ASSIGN;"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "https:path\\",
                "-O path",
                "ASSIGN = {};",
                "with open('path') as f:",
                "for line in f:",
                "ASSIGN = line.split();",
                "ASSIGN = values[0];",
                "ASSIGN = np.asarray(values[1:], dtype='float32');",
                "ASSIGN[ASSIGN] = ASSIGN;",
                "ASSIGN = np.zeros((VOCAB_SIZE, EMBEDDING_DIM));",
                "for ASSIGN, i in word_index.items():",
                "ASSIGN = embeddings_index.get(word);",
                "if ASSIGN is not None:",
                "ASSIGN[i] = ASSIGN;"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH-1,",
                "ASSIGN=[embeddings_matrix], trainable=True))",
                "ASSIGN.add(Bidirectional(LSTM(256, return_sequences=True)))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Bidirectional(LSTM(128)))",
                "ASSIGN.add(Dense(VOCAB_SIZE path, activation='relu', kernel_regularizer=l2(0.01)))",
                "ASSIGN.add(Dense(VOCAB_SIZE, activation='softmax'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'categorical_crossentropy',",
                "ASSIGN = 'accuracy')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH-1,",
                "ASSIGN=[embeddings_matrix], trainable=True))",
                "ASSIGN.add(Bidirectional(LSTM(256, return_sequences=True)))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Bidirectional(LSTM(128)))",
                "ASSIGN.add(Dense(VOCAB_SIZE path, activation='relu', kernel_regularizer=l2(0.01)))",
                "ASSIGN.add(Dense(VOCAB_SIZE, activation='softmax'))",
                "ASSIGN.compile(optimizer = Adam(),",
                "ASSIGN = 'categorical_crossentropy',",
                "ASSIGN = 'accuracy')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 100",
                "ASSIGN = model.fit(train_data,",
                "train_label,",
                "ASSIGN=num_epochs,",
                "ASSIGN=1)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = 100",
                "ASSIGN = model.fit(train_data,",
                "train_label,",
                "ASSIGN=num_epochs,",
                "ASSIGN=1)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plot_history(history) :",
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.set_title('Training Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.set_title('Training Accuracy')",
                "ASSIGN.legend() ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plot_history(history) :",
                "rcParams['figure.figsize'] = [10,8]",
                "plt.style.use('fivethirtyeight')",
                "sns.set_style('whitegrid')",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN   = history.history[   'accuracy' ]",
                "ASSIGN   = history.history[  'ASSIGN' ]",
                "ASSIGN  = range(len(acc))",
                "ASSIGN = plt.subplot(grid[0])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Loss')",
                "ASSIGN.set_title('Training Loss')",
                "ASSIGN.legend() ;",
                "ASSIGN = plt.subplot(grid[1])",
                "ASSIGN.plot(ASSIGN, ASSIGN, label='Train Acc')",
                "ASSIGN.set_title('Training Accuracy')",
                "ASSIGN.legend() ;"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_history(history)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plot_history(history)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = \"Help me Obi Wan Kenobi, you're my only hope\"",
                "ASSIGN = 100",
                "for _ in range(ASSIGN):",
                "ASSIGN = tokenizer.texts_to_sequences([seed_text])[0]",
                "ASSIGN = pad_sequences([ASSIGN], maxlen=MAX_LENGTH-1, padding='pre')",
                "ASSIGN = model.predict_classes(token_list, verbose=0)",
                "ASSIGN = \"\"",
                "for word, index in tokenizer.word_index.items():",
                "ASSIGN == predicted:",
                "ASSIGN = word",
                "break",
                "ASSIGN += \" \" + ASSIGN",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = \"Help me Obi Wan Kenobi, you're my only hope\"",
                "ASSIGN = 100",
                "for _ in range(ASSIGN):",
                "ASSIGN = tokenizer.texts_to_sequences([seed_text])[0]",
                "ASSIGN = pad_sequences([ASSIGN], maxlen=MAX_LENGTH-1, padding='pre')",
                "ASSIGN = model.predict_classes(token_list, verbose=0)",
                "ASSIGN = \"\"",
                "for word, index in tokenizer.word_index.items():",
                "ASSIGN == predicted:",
                "ASSIGN = word",
                "break",
                "ASSIGN += \" \" + ASSIGN",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.array([1,2,3,4,3,2,1,1,1,2])",
                "ASSIGN = np.array([0,1,1,2,3,4,3,2,1,1])",
                "ASSIGN = lambda s1,s2: np.abs(s1 - s2)",
                "ASSIGN = dtw( s1,s2, dist=manhattan_distance)",
                "print(d)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.array([1,2,3,4,3,2,1,1,1,2])",
                "ASSIGN = np.array([0,1,1,2,3,4,3,2,1,1])",
                "ASSIGN = lambda s1,s2: np.abs(s1 - s2)",
                "ASSIGN = dtw( s1,s2, dist=manhattan_distance)",
                "print(d)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.arange(0, 20, .5)",
                "ASSIGN = np.sin(x)",
                "ASSIGN = np.sin(x - 1)",
                "random.seed(1)",
                "for idx in range(len(ASSIGN)):",
                "if random.random() < 0.05:",
                "ASSIGN[idx] += (random.random() - 0.5) path",
                "ASSIGN = dtw.warping_paths(s1, s2, window=25, psi=2)",
                "ASSIGN = dtw.ASSIGN(paths)",
                "dtwvis.plot_warpingpaths(ASSIGN, ASSIGN, paths, ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = np.arange(0, 20, .5)",
                "ASSIGN = np.sin(x)",
                "ASSIGN = np.sin(x - 1)",
                "random.seed(1)",
                "for idx in range(len(ASSIGN)):",
                "if random.random() < 0.05:",
                "ASSIGN[idx] += (random.random() - 0.5) path",
                "ASSIGN = dtw.warping_paths(s1, s2, window=25, psi=2)",
                "ASSIGN = dtw.ASSIGN(paths)",
                "dtwvis.plot_warpingpaths(ASSIGN, ASSIGN, paths, ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = dtw.ASSIGN(s1, s2)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = dtw.ASSIGN(s1, s2)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = cv2.CascadeClassifier('..path')",
                "ASSIGN =cv2.imread( \"..path\",0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = cv2.CascadeClassifier('..path')",
                "ASSIGN =cv2.imread( \"..path\",0)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10, 10))",
                "ASSIGN = face_cascade.detectMultiScale(gray, 1.3, 5)",
                "for (x,y,w,h) in ASSIGN:",
                "ASSIGN = plt.gca()",
                "ASSIGN.add_patch( Rectangle((x,y),",
                "w, h,",
                "ASSIGN ='none',",
                "ASSIGN ='b',",
                "ASSIGN = 4) )",
                "plt.imshow(gray,cmap = 'gray')",
                "plt.title('template'), plt.xticks([]), plt.yticks([])",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(10, 10))",
                "ASSIGN = face_cascade.detectMultiScale(gray, 1.3, 5)",
                "for (x,y,w,h) in ASSIGN:",
                "ASSIGN = plt.gca()",
                "ASSIGN.add_patch( Rectangle((x,y),",
                "w, h,",
                "ASSIGN ='none',",
                "ASSIGN ='b',",
                "ASSIGN = 4) )",
                "plt.imshow(gray,cmap = 'gray')",
                "plt.title('template'), plt.xticks([]), plt.yticks([])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(check_output([, ]).decode())"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(check_output([, ]).decode())"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "\"\"\"",
                "A Python Module to do automated Exploratory Data Analysis and some light weight data prep.",
                "https:path",
                "\"\"\"",
                "ASSIGN = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']",
                "def full_report(df, target_column=None):",
                "\"\"\"Tries to run every possible report on the provided dataframe\"\"\"",
                "display(HTML(\"<h1>Lazy EDA Report<path>\"))",
                "breakdown_date(df)",
                "show_dtypes(df)",
                "plot_nulls(df)",
                "plot_long_lat(df, target_column)",
                "if target_column is not None:",
                "plot_scatter_target(df, target_column)",
                "plot_hist_target(df, target_column)",
                "plot_correlations(df, target_column)",
                "def plot_correlations(df, target_column):",
                "display(HTML(\"<h2>Column Data Types<path>\"))",
                "display(HTML(\"<p>Below is a plot of the correlation coefficients of the dataframe's numeric columns and the target column<path>\"))",
                "ASSIGN = df.select_dtypes(include=numerics)",
                "del(ASSIGN[target_column])",
                "ASSIGN.corrwith(df[target_column]).sort_values(ascending=False).plot(",
                "ASSIGN='barh', figsize=(12,12), title=\"Correlation Coefficient with Target\")",
                "plt.show()",
                "def breakdown_date(df):",
                "\"\"\"",
                "Creates new columns in a dataframe representing the components of a date (year, month, day of year, & week day name)",
                "\"\"\"",
                "ASSIGN = df.dtypes[df.dtypes == 'datetime64[ns]'].index",
                "display(HTML(\"<h2>Breaking down date columns<path>\"))",
                "if len(ASSIGN) > 0:",
                "display(HTML(\"<p>The following columns will be broken down into year, month, day of year, and weekday columns<path> <ul>\"))",
                "for date_column in ASSIGN:",
                "display(HTML(\"<li>{}<path>\".format(date_column)))",
                "df['{}_year'.format(date_column)] = df[date_column].dt.year",
                "df['{}_month'.format(date_column)] = df[date_column].dt.month",
                "df['{}_dayofyear'.format(date_column)] = df[date_column].dt.dayofyear",
                "df['{}_weekday'.format(date_column)] = df[date_column].dt.weekday_name",
                "display(HTML(\"<path>\"))",
                "else:",
                "display(HTML(\"<p>No Date columns found to breakdown.<path>\"))",
                "return df",
                "def plot_nulls(df):",
                "\"\"\"",
                "Displays a horizontal bar chart representing the percentage of nulls in each column",
                "\"\"\"",
                "display(HTML(\"<h2>Plot Nulls<path>\"))",
                "ASSIGN = df.isnull().sum()path[0]*100",
                "ASSIGN = null_percentage[null_percentage > 0].sort_values()",
                "if len(ASSIGN) > 0:",
                "display(HTML(\"<p>The plot below shows the percentage of NaNs in each column in the dataframe<path>\"))",
                "ASSIGN.plot(ASSIGN='barh', figsize=(12,12), title=\"Plot Null Percentages\")",
                "plt.show()",
                "else:",
                "display(HTML(\"<p>The dataframe does not contain any missing data<path>\"))",
                "return null_percentage_filtered",
                "def show_dtypes(df):",
                "\"\"\"Shows the data types of all columns\"\"\"",
                "display(HTML(\"<h2>Column Data Types<path>\"))",
                "ASSIGN = pd.options.display.max_rows",
                "pd.options.display.max_rows = len(df.columns)",
                "ASSIGN = pd.DataFrame({\"Column Name\": df.dtypes.index,\"DType\": df.dtypes.values})",
                "display(ASSIGN)",
                "pd.options.display.max_rows = ASSIGN",
                "def plot_scatter_target(df, target_column):",
                "\"\"\"Plots a sorted scatter plot of the values in a numerical target column\"\"\"",
                "display(HTML(\"<h2>Plot Scatter Target<path>\"))",
                "display(HTML(\"<p>Below is a sorted scatter plot of the values in the target column<path>\"))",
                "plt.scatter(range(df[target_column].shape[0]), np.sort(df[target_column].values))",
                "plt.xlabel('index', fontsize=12)",
                "plt.ylabel(target_column, fontsize=12)",
                "plt.show()",
                "def plot_hist_target(df, target_column):",
                "display(HTML(\"<h2>Plot Histogram Target<path>\"))",
                "display(HTML(\"<p>Below is a histogram of the values in the target column<path>\"))",
                "ASSIGN = np.percentile(df.logerror.values, 99)",
                "ASSIGN = np.percentile(df.logerror.values, 1)",
                "ASSIGN = ASSIGN",
                "df['tempTarget'].ix[df['tempTarget']>ASSIGN] = ASSIGN",
                "df['tempTarget'].ix[df['tempTarget']<ASSIGN] = ASSIGN",
                "plt.figure(figsize=(12,8))",
                "sns.distplot(df['tempTarget'])",
                "plt.xlabel(target_column, fontsize=12)",
                "plt.show()",
                "del[df['tempTarget']]",
                "def plot_long_lat(df, target_column):",
                "if 'latitude' in df.columns.str.lower() and 'longitude' in df.columns.str.lower():",
                "display(HTML(\"<h2>Plot longitudepath<path>\"))",
                "display(HTML(\"<p>Below is a scatter plot of longpath<path>\"))",
                "plt.figure(figsize=(12,12))",
                "if target_column is None:",
                "sns.jointplot(x=df.latitude.values, y=df.longitude.values, size=10)",
                "else:",
                "ASSIGN = (ASSIGN - ASSIGN.min())path(ASSIGN.max() - ASSIGN.min())",
                "plt.scatter(x=df.latitude.values, y=df.longitude.values, c=df['tempTarget'].values)",
                "del(df['tempTarget'])",
                "plt.ylabel('Longitude', fontsize=12)",
                "plt.xlabel('Latitude', fontsize=12)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "\"\"\"",
                "A Python Module to do automated Exploratory Data Analysis and some light weight data prep.",
                "https:path",
                "\"\"\"",
                "ASSIGN = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']",
                "def full_report(df, target_column=None):",
                "\"\"\"Tries to run every possible report on the provided dataframe\"\"\"",
                "display(HTML(\"<h1>Lazy EDA Report<path>\"))",
                "breakdown_date(df)",
                "show_dtypes(df)",
                "plot_nulls(df)",
                "plot_long_lat(df, target_column)",
                "if target_column is not None:",
                "plot_scatter_target(df, target_column)",
                "plot_hist_target(df, target_column)",
                "plot_correlations(df, target_column)",
                "def plot_correlations(df, target_column):",
                "display(HTML(\"<h2>Column Data Types<path>\"))",
                "display(HTML(\"<p>Below is a plot of the correlation coefficients of the dataframe's numeric columns and the target column<path>\"))",
                "ASSIGN = df.select_dtypes(include=numerics)",
                "del(ASSIGN[target_column])",
                "ASSIGN.corrwith(df[target_column]).sort_values(ascending=False).plot(",
                "ASSIGN='barh', figsize=(12,12), title=\"Correlation Coefficient with Target\")",
                "plt.show()",
                "def breakdown_date(df):",
                "\"\"\"",
                "Creates new columns in a dataframe representing the components of a date (year, month, day of year, & week day name)",
                "\"\"\"",
                "ASSIGN = df.dtypes[df.dtypes == 'datetime64[ns]'].index",
                "display(HTML(\"<h2>Breaking down date columns<path>\"))",
                "if len(ASSIGN) > 0:",
                "display(HTML(\"<p>The following columns will be broken down into year, month, day of year, and weekday columns<path> <ul>\"))",
                "for date_column in ASSIGN:",
                "display(HTML(\"<li>{}<path>\".format(date_column)))",
                "df['{}_year'.format(date_column)] = df[date_column].dt.year",
                "df['{}_month'.format(date_column)] = df[date_column].dt.month",
                "df['{}_dayofyear'.format(date_column)] = df[date_column].dt.dayofyear",
                "df['{}_weekday'.format(date_column)] = df[date_column].dt.weekday_name",
                "display(HTML(\"<path>\"))",
                "else:",
                "display(HTML(\"<p>No Date columns found to breakdown.<path>\"))",
                "return df",
                "def plot_nulls(df):",
                "\"\"\"",
                "Displays a horizontal bar chart representing the percentage of nulls in each column",
                "\"\"\"",
                "display(HTML(\"<h2>Plot Nulls<path>\"))",
                "ASSIGN = df.isnull().sum()path[0]*100",
                "ASSIGN = null_percentage[null_percentage > 0].sort_values()",
                "if len(ASSIGN) > 0:",
                "display(HTML(\"<p>The plot below shows the percentage of NaNs in each column in the dataframe<path>\"))",
                "ASSIGN.plot(ASSIGN='barh', figsize=(12,12), title=\"Plot Null Percentages\")",
                "plt.show()",
                "else:",
                "display(HTML(\"<p>The dataframe does not contain any missing data<path>\"))",
                "return null_percentage_filtered",
                "def show_dtypes(df):",
                "\"\"\"Shows the data types of all columns\"\"\"",
                "display(HTML(\"<h2>Column Data Types<path>\"))",
                "ASSIGN = pd.options.display.max_rows",
                "pd.options.display.max_rows = len(df.columns)",
                "ASSIGN = pd.DataFrame({\"Column Name\": df.dtypes.index,\"DType\": df.dtypes.values})",
                "display(ASSIGN)",
                "pd.options.display.max_rows = ASSIGN",
                "def plot_scatter_target(df, target_column):",
                "\"\"\"Plots a sorted scatter plot of the values in a numerical target column\"\"\"",
                "display(HTML(\"<h2>Plot Scatter Target<path>\"))",
                "display(HTML(\"<p>Below is a sorted scatter plot of the values in the target column<path>\"))",
                "plt.scatter(range(df[target_column].shape[0]), np.sort(df[target_column].values))",
                "plt.xlabel('index', fontsize=12)",
                "plt.ylabel(target_column, fontsize=12)",
                "plt.show()",
                "def plot_hist_target(df, target_column):",
                "display(HTML(\"<h2>Plot Histogram Target<path>\"))",
                "display(HTML(\"<p>Below is a histogram of the values in the target column<path>\"))",
                "ASSIGN = np.percentile(df.logerror.values, 99)",
                "ASSIGN = np.percentile(df.logerror.values, 1)",
                "ASSIGN = ASSIGN",
                "df['tempTarget'].ix[df['tempTarget']>ASSIGN] = ASSIGN",
                "df['tempTarget'].ix[df['tempTarget']<ASSIGN] = ASSIGN",
                "plt.figure(figsize=(12,8))",
                "sns.distplot(df['tempTarget'])",
                "plt.xlabel(target_column, fontsize=12)",
                "plt.show()",
                "del[df['tempTarget']]",
                "def plot_long_lat(df, target_column):",
                "if 'latitude' in df.columns.str.lower() and 'longitude' in df.columns.str.lower():",
                "display(HTML(\"<h2>Plot longitudepath<path>\"))",
                "display(HTML(\"<p>Below is a scatter plot of longpath<path>\"))",
                "plt.figure(figsize=(12,12))",
                "if target_column is None:",
                "sns.jointplot(x=df.latitude.values, y=df.longitude.values, size=10)",
                "else:",
                "ASSIGN = (ASSIGN - ASSIGN.min())path(ASSIGN.max() - ASSIGN.min())",
                "plt.scatter(x=df.latitude.values, y=df.longitude.values, c=df['tempTarget'].values)",
                "del(df['tempTarget'])",
                "plt.ylabel('Longitude', fontsize=12)",
                "plt.xlabel('Latitude', fontsize=12)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=[\"transactiondate\"])",
                "ASSIGN = pd.read_csv(\"..path\", dtype={",
                "'hashottuborspa': 'object',",
                "'propertycountylandusecode': 'object',",
                "'propertyzoningdesc': 'object',",
                "'fireplaceflag': 'object',",
                "'taxdelinquencyflag': 'object'",
                "})",
                "ASSIGN = pd.merge(ASSIGN, prop_df, on='parcelid', how='left')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=[\"transactiondate\"])",
                "ASSIGN = pd.read_csv(\"..path\", dtype={",
                "'hashottuborspa': 'object',",
                "'propertycountylandusecode': 'object',",
                "'propertyzoningdesc': 'object',",
                "'fireplaceflag': 'object',",
                "'taxdelinquencyflag': 'object'",
                "})",
                "ASSIGN = pd.merge(ASSIGN, prop_df, on='parcelid', how='left')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "full_report(train_df, target_column='logerror')"
            ],
            "output_type": "display_data",
            "content_old": [
                "full_report(train_df, target_column='logerror')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN=datetime.strftime(datetime.today() - timedelta(1), 'https:path%m-%d-%Y.csv')",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN = 'https:path'",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)",
                "ASSIGN=datetime.strftime(datetime.today() - timedelta(1), 'https:path%m-%d-%Y.csv')",
                "ASSIGN = requests.get(url, allow_redirects=True)",
                "open('.path', 'wb').write(ASSIGN.content)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "print(os.listdir())"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "ASSIGN = r'..path'",
                "ASSIGN = r'.path'",
                "shutil.copyfile(ASSIGN, ASSIGN)",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "sns.set(style=\"white\", color_codes=True)",
                "warnings.filterwarnings(\"ignore\")",
                "print(os.listdir())",
                "pio.renderers.default = \"browser\""
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "sns.set(style=\"white\", color_codes=True)",
                "warnings.filterwarnings(\"ignore\")",
                "print(os.listdir())",
                "pio.renderers.default = \"browser\""
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=pd.read_csv('.path')",
                "ASSIGN.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=pd.read_csv('.path')",
                "ASSIGN.sample(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_country.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country.describe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country['Population 2020']=codiv_country['Population 2020']*1000",
                "codiv_country['Tests_per_10kp']=codiv_country['Tests']*10000.0path['Population 2020']",
                "codiv_country['Tests_per_10kp_log1p']=np.log1p(codiv_country['Tests_per_10kp'])",
                "codiv_country['GDP 2018 per_1p_log1p']=np.log1p((codiv_country['GDP 2018']path['Population 2020']))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_country['Population 2020']=codiv_country['Population 2020']*1000",
                "codiv_country['Tests_per_10kp']=codiv_country['Tests']*10000.0path['Population 2020']",
                "codiv_country['Tests_per_10kp_log1p']=np.log1p(codiv_country['Tests_per_10kp'])",
                "codiv_country['GDP 2018 per_1p_log1p']=np.log1p((codiv_country['GDP 2018']path['Population 2020']))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN.drop([",
                "'Sex Ratio','Crime Index','Density','Tests_per_10kp','Test Pop','sex0','sex14','sex25','sex54','sex64','sex65plus','Total Infected','Total Deaths','Total Recovered','Tests','GDP 2018','Population 2020'",
                "], axis=1)",
                "ASSIGN.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=ASSIGN.drop([",
                "'Sex Ratio','Crime Index','Density','Tests_per_10kp','Test Pop','sex0','sex14','sex25','sex54','sex64','sex65plus','Total Infected','Total Deaths','Total Recovered','Tests','GDP 2018','Population 2020'",
                "], axis=1)",
                "ASSIGN.sample(10)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN=pd.read_csv(os.path.join('.path', 'API_SH.XPD.CHEX.GD.ZS_DS2_en_csv_v2_989101.csv'))",
                "ASSIGN=ASSIGN.set_index('Country Name')",
                "ASSIGN.sample(3)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=pd.read_csv(os.path.join('.path', 'API_SH.XPD.CHEX.GD.ZS_DS2_en_csv_v2_989101.csv'))",
                "ASSIGN=ASSIGN.set_index('Country Name')",
                "ASSIGN.sample(3)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country['Health expenditure Ratio'] = 0.0",
                "for countryindex in Health_expenditure.index:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "codiv_country.at[codiv_country['Country']==countryindex,'Health expenditure Ratio']=Health_expenditure[Health_expenditure.index==countryindex]['2017'][0]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_country['Health expenditure Ratio'] = 0.0",
                "for countryindex in Health_expenditure.index:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "codiv_country.at[codiv_country['Country']==countryindex,'Health expenditure Ratio']=Health_expenditure[Health_expenditure.index==countryindex]['2017'][0]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "codiv_country.hist(figsize=(12, 12))",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "codiv_country.hist(figsize=(12, 12))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "codiv_country.dtypes"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "codiv_country.dtypes"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_country.isna().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country.isna().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_country[codiv_country['Health expenditure Ratio'].isnull()]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country[codiv_country['Health expenditure Ratio'].isnull()]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country['Health expenditure Ratio'] = codiv_country['Health expenditure Ratio'].fillna(codiv_country['Health expenditure Ratio'].mean())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_country['Health expenditure Ratio'] = codiv_country['Health expenditure Ratio'].fillna(codiv_country['Health expenditure Ratio'].mean())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country['Tests_per_10kp_log1p'] = codiv_country['Tests_per_10kp_log1p'].fillna(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_country['Tests_per_10kp_log1p'] = codiv_country['Tests_per_10kp_log1p'].fillna(0)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country.Country[codiv_country.Country == \"United States\"] = \"US\""
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_country.Country[codiv_country.Country == \"United States\"] = \"US\""
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN= (codiv_country['Females 2018']- codiv_country['Females 2018'].mean()) path['Females 2018'].std()",
                "ASSIGN.plot()",
                "plt.hlines(-1,0,100,colors=\"red\")",
                "plt.hlines(-2,0,100,colors=\"yellow\")",
                "plt.hlines(-3,0,100,colors=\"green\")",
                "plt.hlines(1,0,100,colors=\"red\")",
                "plt.hlines(2,0,100,colors=\"yellow\")",
                "plt.hlines(3,0,100,colors=\"green\")",
                "plt.ylabel(\"ASSIGN\")",
                "plt.xlabel(\"country index\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN= (codiv_country['Females 2018']- codiv_country['Females 2018'].mean()) path['Females 2018'].std()",
                "ASSIGN.plot()",
                "plt.hlines(-1,0,100,colors=\"red\")",
                "plt.hlines(-2,0,100,colors=\"yellow\")",
                "plt.hlines(-3,0,100,colors=\"green\")",
                "plt.hlines(1,0,100,colors=\"red\")",
                "plt.hlines(2,0,100,colors=\"yellow\")",
                "plt.hlines(3,0,100,colors=\"green\")",
                "plt.ylabel(\"ASSIGN\")",
                "plt.xlabel(\"country index\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "codiv_country['Females 2018'].plot()",
                "plt.ylabel(\"Females %\")",
                "plt.xlabel(\"country index\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country['Females 2018'].plot()",
                "plt.ylabel(\"Females %\")",
                "plt.xlabel(\"country index\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = (np.abs(z_scores_Females) > 2)",
                "codiv_country['Females 2018'][ASSIGN]=codiv_country['Females 2018'].mean()",
                "print('z-scores_Females:', z_scores_Females.shape)",
                "codiv_country['Females 2018'].plot()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = (np.abs(z_scores_Females) > 2)",
                "codiv_country['Females 2018'][ASSIGN]=codiv_country['Females 2018'].mean()",
                "print('z-scores_Females:', z_scores_Females.shape)",
                "codiv_country['Females 2018'].plot()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN= (codiv_country['Female Lung']- codiv_country['Female Lung'].mean()) path['Female Lung'].std()",
                "ASSIGN.plot()",
                "plt.hlines(-1,0,100,colors=\"red\")",
                "plt.hlines(-2,0,100,colors=\"yellow\")",
                "plt.hlines(-3,0,100,colors=\"green\")",
                "plt.hlines(1,0,100,colors=\"red\")",
                "plt.hlines(2,0,100,colors=\"yellow\")",
                "plt.hlines(3,0,100,colors=\"green\")",
                "plt.ylabel(\"ASSIGN\")",
                "plt.xlabel(\"country index\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN= (codiv_country['Female Lung']- codiv_country['Female Lung'].mean()) path['Female Lung'].std()",
                "ASSIGN.plot()",
                "plt.hlines(-1,0,100,colors=\"red\")",
                "plt.hlines(-2,0,100,colors=\"yellow\")",
                "plt.hlines(-3,0,100,colors=\"green\")",
                "plt.hlines(1,0,100,colors=\"red\")",
                "plt.hlines(2,0,100,colors=\"yellow\")",
                "plt.hlines(3,0,100,colors=\"green\")",
                "plt.ylabel(\"ASSIGN\")",
                "plt.xlabel(\"country index\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = (np.abs(z_scores_Female_Lung) > 2)",
                "codiv_country['Female Lung'][ASSIGN]=codiv_country['Female Lung'].mean()",
                "print('z-scores_Female_Lung:', z_scores_Female_Lung.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = (np.abs(z_scores_Female_Lung) > 2)",
                "codiv_country['Female Lung'][ASSIGN]=codiv_country['Female Lung'].mean()",
                "print('z-scores_Female_Lung:', z_scores_Female_Lung.shape)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN= (codiv_country['Male Lung']- codiv_country['Male Lung'].mean()) path['Male Lung'].std()",
                "ASSIGN.plot()",
                "plt.hlines(-1,0,100,colors=\"red\")",
                "plt.hlines(-2,0,100,colors=\"yellow\")",
                "plt.hlines(-3,0,100,colors=\"green\")",
                "plt.hlines(1,0,100,colors=\"red\")",
                "plt.hlines(2,0,100,colors=\"yellow\")",
                "plt.hlines(3,0,100,colors=\"green\")",
                "plt.ylabel(\"ASSIGN\")",
                "plt.xlabel(\"country index\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN= (codiv_country['Male Lung']- codiv_country['Male Lung'].mean()) path['Male Lung'].std()",
                "ASSIGN.plot()",
                "plt.hlines(-1,0,100,colors=\"red\")",
                "plt.hlines(-2,0,100,colors=\"yellow\")",
                "plt.hlines(-3,0,100,colors=\"green\")",
                "plt.hlines(1,0,100,colors=\"red\")",
                "plt.hlines(2,0,100,colors=\"yellow\")",
                "plt.hlines(3,0,100,colors=\"green\")",
                "plt.ylabel(\"ASSIGN\")",
                "plt.xlabel(\"country index\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = (np.abs(z_scores_Male_Lung) > 2)",
                "codiv_country['Male Lung'][ASSIGN]=codiv_country['Male Lung'].mean()",
                "print('z-scores_Male_Lung:', z_scores_Male_Lung.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = (np.abs(z_scores_Male_Lung) > 2)",
                "codiv_country['Male Lung'][ASSIGN]=codiv_country['Male Lung'].mean()",
                "print('z-scores_Male_Lung:', z_scores_Male_Lung.shape)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN= (codiv_country['lung']- codiv_country['lung'].mean()) path['lung'].std()",
                "ASSIGN.plot()",
                "plt.hlines(-1,0,100,colors=\"red\",label=\"np.abs(z_scores_Females) > 1)\")",
                "plt.hlines(-2,0,100,colors=\"yellow\",label=\"np.abs(z_scores_Females) > 2)\")",
                "plt.hlines(-3,0,100,colors=\"green\",label=\"np.abs(z_scores_Females) > 3)\")",
                "plt.hlines(1,0,100,colors=\"red\",label=\"np.abs(z_scores_Females) > 1)\")",
                "plt.hlines(2,0,100,colors=\"yellow\",label=\"np.abs(z_scores_Females) > 2)\")",
                "plt.hlines(3,0,100,colors=\"green\",label=\"np.abs(z_scores_Females) > 3)\")",
                "plt.ylabel(\"ASSIGN\")",
                "plt.xlabel(\"country index\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN= (codiv_country['lung']- codiv_country['lung'].mean()) path['lung'].std()",
                "ASSIGN.plot()",
                "plt.hlines(-1,0,100,colors=\"red\",label=\"np.abs(z_scores_Females) > 1)\")",
                "plt.hlines(-2,0,100,colors=\"yellow\",label=\"np.abs(z_scores_Females) > 2)\")",
                "plt.hlines(-3,0,100,colors=\"green\",label=\"np.abs(z_scores_Females) > 3)\")",
                "plt.hlines(1,0,100,colors=\"red\",label=\"np.abs(z_scores_Females) > 1)\")",
                "plt.hlines(2,0,100,colors=\"yellow\",label=\"np.abs(z_scores_Females) > 2)\")",
                "plt.hlines(3,0,100,colors=\"green\",label=\"np.abs(z_scores_Females) > 3)\")",
                "plt.ylabel(\"ASSIGN\")",
                "plt.xlabel(\"country index\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = (np.abs(z_scores_Lung) > 2)",
                "codiv_country['lung'][ASSIGN]=codiv_country['lung'].mean()",
                "print('z-scores_Lung:', z_scores_Lung.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = (np.abs(z_scores_Lung) > 2)",
                "codiv_country['lung'][ASSIGN]=codiv_country['lung'].mean()",
                "print('z-scores_Lung:', z_scores_Lung.shape)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=pd.read_csv(os.path.join('.path', 'csse_covid_19_daily_reports.csv'))",
                "ASSIGN=ASSIGN.drop(['FIPS','Admin2','Last_Update','Combined_Key','Long_','Lat'], axis=1)",
                "ASSIGN.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=pd.read_csv(os.path.join('.path', 'csse_covid_19_daily_reports.csv'))",
                "ASSIGN=ASSIGN.drop(['FIPS','Admin2','Last_Update','Combined_Key','Long_','Lat'], axis=1)",
                "ASSIGN.sample(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.rename(columns={'Confirmed': 'Infected'})"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.rename(columns={'Confirmed': 'Infected'})"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN.groupby('Country_Region').sum().reset_index()",
                "ASSIGN.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=ASSIGN.groupby('Country_Region').sum().reset_index()",
                "ASSIGN.sample(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_csse[\"Deaths Ratio\"]=codiv_csse[\"Deaths\"]*1000path[\"Infected\"]",
                "codiv_csse.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_csse[\"Deaths Ratio\"]=codiv_csse[\"Deaths\"]*1000path[\"Infected\"]",
                "codiv_csse.sample(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "set(codiv_country['Country'].unique()) - set(codiv_csse['Country_Region'].unique())"
            ],
            "output_type": "execute_result",
            "content_old": [
                "set(codiv_country['Country'].unique()) - set(codiv_csse['Country_Region'].unique())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_csse.Country_Region[codiv_csse.Country_Region == \"Korea, South\"] = \"South Korea\"",
                "codiv_csse.Country_Region[codiv_csse.Country_Region == \"Czechia\"] = \"Czech Republic\""
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_csse.Country_Region[codiv_csse.Country_Region == \"Korea, South\"] = \"South Korea\"",
                "codiv_csse.Country_Region[codiv_csse.Country_Region == \"Czechia\"] = \"Czech Republic\""
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN.set_index('Country_Region')",
                "ASSIGN.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=ASSIGN.set_index('Country_Region')",
                "ASSIGN.sample(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_csse.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_csse.describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "codiv_csse.dtypes"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "codiv_csse.dtypes"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_csse.isna().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_csse.isna().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country['Total Infected'] = 0.0",
                "codiv_country['Total Deaths'] = 0.0",
                "codiv_country['Total Recovered'] = 0.0",
                "codiv_country['Total Active'] = 0.0",
                "codiv_country['Deaths Ratio'] = 0.0",
                "for countryindex in codiv_csse.index:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Infected Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Infected'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Infected']=codiv_csse[codiv_csse.index==countryindex]['Infected'][0]",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Deaths Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Deaths'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Deaths']=codiv_csse[codiv_csse.index==countryindex]['Deaths'][0]",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Recovered Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Recovered'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Recovered']=codiv_csse[codiv_csse.index==countryindex]['Recovered'][0]",
                "codiv_country.at[codiv_country['Country']==countryindex,'Deaths Ratio']=codiv_csse[codiv_csse.index==countryindex]['Deaths Ratio'][0]",
                "if codiv_csse[codiv_csse.index==countryindex]['Active'][0] ==0.0:",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Active Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Infected'][0]-codiv_csse[codiv_csse.index==countryindex]['Deaths'][0]-codiv_csse[codiv_csse.index==countryindex]['Recovered'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Active']=codiv_csse[codiv_csse.index==countryindex]['Infected'][0]-codiv_csse[codiv_csse.index==countryindex]['Deaths'][0]-codiv_csse[codiv_csse.index==countryindex]['Recovered'][0]",
                "else:",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Active Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Active'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Active']=codiv_csse[codiv_csse.index==countryindex]['Active'][0]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_country['Total Infected'] = 0.0",
                "codiv_country['Total Deaths'] = 0.0",
                "codiv_country['Total Recovered'] = 0.0",
                "codiv_country['Total Active'] = 0.0",
                "codiv_country['Deaths Ratio'] = 0.0",
                "for countryindex in codiv_csse.index:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Infected Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Infected'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Infected']=codiv_csse[codiv_csse.index==countryindex]['Infected'][0]",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Deaths Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Deaths'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Deaths']=codiv_csse[codiv_csse.index==countryindex]['Deaths'][0]",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Recovered Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Recovered'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Recovered']=codiv_csse[codiv_csse.index==countryindex]['Recovered'][0]",
                "codiv_country.at[codiv_country['Country']==countryindex,'Deaths Ratio']=codiv_csse[codiv_csse.index==countryindex]['Deaths Ratio'][0]",
                "if codiv_csse[codiv_csse.index==countryindex]['Active'][0] ==0.0:",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Active Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Infected'][0]-codiv_csse[codiv_csse.index==countryindex]['Deaths'][0]-codiv_csse[codiv_csse.index==countryindex]['Recovered'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Active']=codiv_csse[codiv_csse.index==countryindex]['Infected'][0]-codiv_csse[codiv_csse.index==countryindex]['Deaths'][0]-codiv_csse[codiv_csse.index==countryindex]['Recovered'][0]",
                "else:",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Active Log10']=np.log1p(codiv_csse[codiv_csse.index==countryindex]['Active'][0])",
                "codiv_country.at[codiv_country['Country']==countryindex,'Total Active']=codiv_csse[codiv_csse.index==countryindex]['Active'][0]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_country.isnull()[['Total Infected', 'Total Deaths', 'Total Recovered', 'Total Active', 'Deaths Ratio']].sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country.isnull()[['Total Infected', 'Total Deaths', 'Total Recovered', 'Total Active', 'Deaths Ratio']].sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=codiv_country[codiv_country['Quarantine'].notnull()]",
                "ASSIGN=codiv_country[codiv_country['Restrictions'].notnull()]",
                "ASSIGN=codiv_country[codiv_country['Restrictions'].isnull() & codiv_country['Quarantine'].isnull()]",
                "print( , ASSIGN.shape)",
                "print( , ASSIGN.shape)",
                "print( , ASSIGN.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=codiv_country[codiv_country['Quarantine'].notnull()]",
                "ASSIGN=codiv_country[codiv_country['Restrictions'].notnull()]",
                "ASSIGN=codiv_country[codiv_country['Restrictions'].isnull() & codiv_country['Quarantine'].isnull()]",
                "print( , ASSIGN.shape)",
                "print( , ASSIGN.shape)",
                "print( , ASSIGN.shape)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=pd.read_csv(os.path.join('.path', 'time_series_covid19_confirmed_global.csv'))",
                "ASSIGN=ASSIGN.drop(['Lat','Long'], axis=1)",
                "ASSIGN=pd.read_csv(os.path.join('.path', 'time_series_covid19_deaths_global.csv'))",
                "ASSIGN=ASSIGN.drop(['Lat','Long'], axis=1)",
                "ASSIGN=pd.read_csv(os.path.join('.path', 'time_series_covid19_recovered_global.csv'))",
                "ASSIGN=ASSIGN.drop(['Lat','Long'], axis=1)",
                "ASSIGN.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=pd.read_csv(os.path.join('.path', 'time_series_covid19_confirmed_global.csv'))",
                "ASSIGN=ASSIGN.drop(['Lat','Long'], axis=1)",
                "ASSIGN=pd.read_csv(os.path.join('.path', 'time_series_covid19_deaths_global.csv'))",
                "ASSIGN=ASSIGN.drop(['Lat','Long'], axis=1)",
                "ASSIGN=pd.read_csv(os.path.join('.path', 'time_series_covid19_recovered_global.csv'))",
                "ASSIGN=ASSIGN.drop(['Lat','Long'], axis=1)",
                "ASSIGN.sample(10)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=pd.read_csv('.path')",
                "ASSIGN=ASSIGN.drop(['AverageTemperatureUncertainty'], axis=1)",
                "ASSIGN=ASSIGN[((ASSIGN['dt'] > '2013-01-01') & (ASSIGN['dt'] < '2013-04-01')) |",
                "((ASSIGN['dt'] > '2012-01-01') & (ASSIGN['dt'] < '2012-04-01')) |",
                "((ASSIGN['dt'] > '2011-01-01') & (ASSIGN['dt'] < '2011-04-01'))]",
                "ASSIGN = ASSIGN.groupby(['Country'])['AverageTemperature'].mean()",
                "print(ASSIGN.sample(10))",
                "print(,ASSIGN.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=pd.read_csv('.path')",
                "ASSIGN=ASSIGN.drop(['AverageTemperatureUncertainty'], axis=1)",
                "ASSIGN=ASSIGN[((ASSIGN['dt'] > '2013-01-01') & (ASSIGN['dt'] < '2013-04-01')) |",
                "((ASSIGN['dt'] > '2012-01-01') & (ASSIGN['dt'] < '2012-04-01')) |",
                "((ASSIGN['dt'] > '2011-01-01') & (ASSIGN['dt'] < '2011-04-01'))]",
                "ASSIGN = ASSIGN.groupby(['Country'])['AverageTemperature'].mean()",
                "print(ASSIGN.sample(10))",
                "print(,ASSIGN.shape)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(codiv_country_temp.describe())"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(codiv_country_temp.describe())"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=pd.read_csv('.path')",
                "ASSIGN=ASSIGN.drop(['AverageTemperatureUncertainty','Latitude','Longitude'], axis=1)",
                "ASSIGN=ASSIGN[((ASSIGN['dt'] > '2013-01-01') & (ASSIGN['dt'] < '2013-04-01')) |",
                "((ASSIGN['dt'] > '2012-01-01') & (ASSIGN['dt'] < '2012-04-01')) |",
                "((ASSIGN['dt'] > '2011-01-01') & (ASSIGN['dt'] < '2011-04-01'))]",
                "ASSIGN= ASSIGN.groupby(['Country'])['AverageTemperature'].mean()",
                "print(ASSIGN.sample(10))",
                "print(,ASSIGN.shape)",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=pd.read_csv('.path')",
                "ASSIGN=ASSIGN.drop(['AverageTemperatureUncertainty','Latitude','Longitude'], axis=1)",
                "ASSIGN=ASSIGN[((ASSIGN['dt'] > '2013-01-01') & (ASSIGN['dt'] < '2013-04-01')) |",
                "((ASSIGN['dt'] > '2012-01-01') & (ASSIGN['dt'] < '2012-04-01')) |",
                "((ASSIGN['dt'] > '2011-01-01') & (ASSIGN['dt'] < '2011-04-01'))]",
                "ASSIGN= ASSIGN.groupby(['Country'])['AverageTemperature'].mean()",
                "print(ASSIGN.sample(10))",
                "print(,ASSIGN.shape)",
                "print()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN=(codiv_country_tempMajorCity-codiv_country_temp).dropna()",
                "ASSIGN=ASSIGN.sort_values( ascending=False)",
                "ASSIGN=Temperature_difference.index",
                "ASSIGN=Temperature_difference",
                "ASSIGN = plt.subplots(figsize=(20,10))",
                "ax.scatter(ASSIGN, ASSIGN, alpha=0.5)",
                "plt.xticks(rotation=45)",
                "plt.ylabel(\"Delta Temp AvrMaincity-AvrCountry\")",
                "plt.grid(True)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN=(codiv_country_tempMajorCity-codiv_country_temp).dropna()",
                "ASSIGN=ASSIGN.sort_values( ascending=False)",
                "ASSIGN=Temperature_difference.index",
                "ASSIGN=Temperature_difference",
                "ASSIGN = plt.subplots(figsize=(20,10))",
                "ax.scatter(ASSIGN, ASSIGN, alpha=0.5)",
                "plt.xticks(rotation=45)",
                "plt.ylabel(\"Delta Temp AvrMaincity-AvrCountry\")",
                "plt.grid(True)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country['Temp_mean_jan_apr'] = 0.0",
                "for countryindex in codiv_country_tempMajorCity.index:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "codiv_country.at[codiv_country['Country']==countryindex,'Temp_mean_jan_apr']=codiv_country_tempMajorCity.loc[countryindex]",
                "codiv_country['Temp_mean_jan_apr'].sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country['Temp_mean_jan_apr'] = 0.0",
                "for countryindex in codiv_country_tempMajorCity.index:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "codiv_country.at[codiv_country['Country']==countryindex,'Temp_mean_jan_apr']=codiv_country_tempMajorCity.loc[countryindex]",
                "codiv_country['Temp_mean_jan_apr'].sample(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "for countryindex in codiv_country_temp.index:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty:",
                "if codiv_country[codiv_country['Country']==countryindex]['Temp_mean_jan_apr'].values[0] == 0:",
                "codiv_country.at[codiv_country['Country']==countryindex,'Temp_mean_jan_apr']=codiv_country_temp.loc[countryindex]",
                "codiv_country.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "for countryindex in codiv_country_temp.index:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty:",
                "if codiv_country[codiv_country['Country']==countryindex]['Temp_mean_jan_apr'].values[0] == 0:",
                "codiv_country.at[codiv_country['Country']==countryindex,'Temp_mean_jan_apr']=codiv_country_temp.loc[countryindex]",
                "codiv_country.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_country[(codiv_country['Temp_mean_jan_apr'] == 0)]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country[(codiv_country['Temp_mean_jan_apr'] == 0)]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=codiv_country.sort_values(by='Total Infected', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.head(11).style.background_gradient(cmap='Blues')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=codiv_country.sort_values(by='Total Infected', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.head(11).style.background_gradient(cmap='Blues')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=codiv_country.sort_values(by='Total Active', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.head(11).style.background_gradient(cmap='Greens')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=codiv_country.sort_values(by='Total Active', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.head(11).style.background_gradient(cmap='Greens')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=codiv_country.sort_values(by='Total Deaths', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.head(11).style.background_gradient(cmap='Reds')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=codiv_country.sort_values(by='Total Deaths', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.head(11).style.background_gradient(cmap='Reds')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=codiv_country.sort_values(by='Deaths Ratio', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.head(11).style.background_gradient(cmap='Oranges')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=codiv_country.sort_values(by='Deaths Ratio', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.head(11).style.background_gradient(cmap='Oranges')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=codiv_country.sort_values(by='Total Infected', ascending=False).head(n=60).reset_index(drop=True)",
                "codiv_country_short"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=codiv_country.sort_values(by='Total Infected', ascending=False).head(n=60).reset_index(drop=True)",
                "codiv_country_short"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_country_short.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country_short.describe()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.FacetGrid(codiv_country_short, hue=\"Country\", size=6.5) \\",
                ".map(plt.scatter, \"Tests_per_10kp_log1p\", \"Total Infected Log10\") \\",
                ".add_legend()",
                "plt.grid(True)"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.FacetGrid(codiv_country_short, hue=\"Country\", size=6.5) \\",
                ".map(plt.scatter, \"Tests_per_10kp_log1p\", \"Total Infected Log10\") \\",
                ".add_legend()",
                "plt.grid(True)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "codiv_country_short[codiv_country_short[\"Tests_per_10kp_log1p\"] == 0][\"Total Infected Log10\"].hist(figsize=(6, 6), alpha=0.5, density=True)",
                "plt.xlabel('Total Infected Log1p')",
                "plt.ylabel('Nr Country density')",
                "plt.title('Histogram Tests_per_10kp_log1p==0')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country_short[codiv_country_short[\"Tests_per_10kp_log1p\"] == 0][\"Total Infected Log10\"].hist(figsize=(6, 6), alpha=0.5, density=True)",
                "plt.xlabel('Total Infected Log1p')",
                "plt.ylabel('Nr Country density')",
                "plt.title('Histogram Tests_per_10kp_log1p==0')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "codiv_country_short[codiv_country_short[\"Tests_per_10kp_log1p\"] != 0][\"Total Infected Log10\"].hist(figsize=(6,6), alpha=0.5, density=True)",
                "plt.xlabel('Total Infected Log1p')",
                "plt.ylabel('Nr Country density')",
                "plt.title('Histogram Tests_per_10kp_log1p not 0')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country_short[codiv_country_short[\"Tests_per_10kp_log1p\"] != 0][\"Total Infected Log10\"].hist(figsize=(6,6), alpha=0.5, density=True)",
                "plt.xlabel('Total Infected Log1p')",
                "plt.ylabel('Nr Country density')",
                "plt.title('Histogram Tests_per_10kp_log1p not 0')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.FacetGrid(codiv_country_short, hue=\"Country\", size=6.5) \\",
                ".map(plt.scatter, \"Tests_per_10kp_log1p\", \"Total Active Log10\") \\",
                ".add_legend()",
                "plt.grid(True)"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.FacetGrid(codiv_country_short, hue=\"Country\", size=6.5) \\",
                ".map(plt.scatter, \"Tests_per_10kp_log1p\", \"Total Active Log10\") \\",
                ".add_legend()",
                "plt.grid(True)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "codiv_country_short[codiv_country_short[\"Tests_per_10kp_log1p\"] == 0][\"Total Active Log10\"].hist(figsize=(6, 6), alpha=0.5, density=True)",
                "plt.xlabel('Total Active Log10')",
                "plt.ylabel('Nr Country density')",
                "plt.title('Histogram Tests_per_10kp_log1p==0')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country_short[codiv_country_short[\"Tests_per_10kp_log1p\"] == 0][\"Total Active Log10\"].hist(figsize=(6, 6), alpha=0.5, density=True)",
                "plt.xlabel('Total Active Log10')",
                "plt.ylabel('Nr Country density')",
                "plt.title('Histogram Tests_per_10kp_log1p==0')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "codiv_country_short[codiv_country_short[\"Tests_per_10kp_log1p\"] != 0][\"Total Active Log10\"].hist(figsize=(6,6), alpha=0.5, density=True)",
                "plt.xlabel('Total Active Log10')",
                "plt.ylabel('Nr Country density')",
                "plt.title('Histogram Tests_per_10kp_log1p not 0')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country_short[codiv_country_short[\"Tests_per_10kp_log1p\"] != 0][\"Total Active Log10\"].hist(figsize=(6,6), alpha=0.5, density=True)",
                "plt.xlabel('Total Active Log10')",
                "plt.ylabel('Nr Country density')",
                "plt.title('Histogram Tests_per_10kp_log1p not 0')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country_short.drop([   'Total Infected', 'Total Deaths', 'Total Recovered', 'Total Active'], axis=1)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country_short.drop([   'Total Infected', 'Total Deaths', 'Total Recovered', 'Total Active'], axis=1)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN=codiv_country_short.drop([ 'Deaths Ratio','Total Infected', 'Total Deaths', 'Total Recovered', 'Total Active','Total Recovered Log10','Total Infected Log10','Total Deaths Log10','Total Active Log10'], axis=1)",
                "for col in ASSIGN.loc[:, ASSIGN.dtypes == np.number].keys():",
                "sns.jointplot(codiv_country_short['Total Infected Log10'], col, data=codiv_country_short, height=6, s=1, color=\"blue\")",
                "ASSIGN = pearsonr(codiv_country_short['Total Infected Log10'], codiv_country_short[col])",
                "print( %(col, corr))",
                "sns.jointplot(codiv_country_short['Total Deaths Log10'], col, data=codiv_country_short, height=6, s=1, color=\"red\")",
                "ASSIGN = pearsonr(codiv_country_short['Total Deaths Log10'], codiv_country_short[col])",
                "print( %(col, corr))",
                "sns.jointplot(codiv_country_short['Total Active Log10'], col, data=codiv_country_short, height=6, s=1, color=\"green\")",
                "ASSIGN = pearsonr(codiv_country_short['Total Active Log10'], codiv_country_short[col])",
                "print( %(col, corr))",
                "sns.jointplot(codiv_country_short['Deaths Ratio'], col, data=codiv_country_short, height=6, s=1, color=\"orange\")",
                "ASSIGN = pearsonr(codiv_country_short['Deaths Ratio'], codiv_country_short[col])",
                "print( %(col, corr))",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN=codiv_country_short.drop([ 'Deaths Ratio','Total Infected', 'Total Deaths', 'Total Recovered', 'Total Active','Total Recovered Log10','Total Infected Log10','Total Deaths Log10','Total Active Log10'], axis=1)",
                "for col in ASSIGN.loc[:, ASSIGN.dtypes == np.number].keys():",
                "sns.jointplot(codiv_country_short['Total Infected Log10'], col, data=codiv_country_short, height=6, s=1, color=\"blue\")",
                "ASSIGN = pearsonr(codiv_country_short['Total Infected Log10'], codiv_country_short[col])",
                "print( %(col, corr))",
                "sns.jointplot(codiv_country_short['Total Deaths Log10'], col, data=codiv_country_short, height=6, s=1, color=\"red\")",
                "ASSIGN = pearsonr(codiv_country_short['Total Deaths Log10'], codiv_country_short[col])",
                "print( %(col, corr))",
                "sns.jointplot(codiv_country_short['Total Active Log10'], col, data=codiv_country_short, height=6, s=1, color=\"green\")",
                "ASSIGN = pearsonr(codiv_country_short['Total Active Log10'], codiv_country_short[col])",
                "print( %(col, corr))",
                "sns.jointplot(codiv_country_short['Deaths Ratio'], col, data=codiv_country_short, height=6, s=1, color=\"orange\")",
                "ASSIGN = pearsonr(codiv_country_short['Deaths Ratio'], codiv_country_short[col])",
                "print( %(col, corr))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.polyfit(codiv_country_short[\"Temp_mean_jan_apr\"], codiv_country_short[\"Total Infected Log10\"], deg=8)",
                "sns.FacetGrid(codiv_country_short, hue=\"Country\", size=6.5) \\",
                ".map(plt.scatter, \"Temp_mean_jan_apr\", \"Total Infected Log10\") \\",
                ".add_legend()",
                "for indexq in range(-80,300,1):",
                "plt.plot(indexqpath,np.polyval(ASSIGN, indexqpath), '.', color='black')",
                "plt.vlines(7,7,14,colors=\"red\",linestyles='dashed')",
                "plt.vlines(24,7,14,colors=\"red\",linestyles='dashed')",
                "plt.grid(True)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = np.polyfit(codiv_country_short[\"Temp_mean_jan_apr\"], codiv_country_short[\"Total Infected Log10\"], deg=8)",
                "sns.FacetGrid(codiv_country_short, hue=\"Country\", size=6.5) \\",
                ".map(plt.scatter, \"Temp_mean_jan_apr\", \"Total Infected Log10\") \\",
                ".add_legend()",
                "for indexq in range(-80,300,1):",
                "plt.plot(indexqpath,np.polyval(ASSIGN, indexqpath), '.', color='black')",
                "plt.vlines(7,7,14,colors=\"red\",linestyles='dashed')",
                "plt.vlines(24,7,14,colors=\"red\",linestyles='dashed')",
                "plt.grid(True)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.polyfit(codiv_country_short[\"Health expenditure Ratio\"], codiv_country_short[\"Total Infected Log10\"], 1)",
                "sns.FacetGrid(codiv_country_short, hue=\"Country\", size=6.5) \\",
                ".map(plt.scatter, \"Health expenditure Ratio\", \"Total Infected Log10\") \\",
                ".add_legend()",
                "plt.plot(codiv_country_short[\"Health expenditure Ratio\"], m*codiv_country_short[\"Health expenditure Ratio\"]+b, '--k')",
                "plt.grid(True)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = np.polyfit(codiv_country_short[\"Health expenditure Ratio\"], codiv_country_short[\"Total Infected Log10\"], 1)",
                "sns.FacetGrid(codiv_country_short, hue=\"Country\", size=6.5) \\",
                ".map(plt.scatter, \"Health expenditure Ratio\", \"Total Infected Log10\") \\",
                ".add_legend()",
                "plt.plot(codiv_country_short[\"Health expenditure Ratio\"], m*codiv_country_short[\"Health expenditure Ratio\"]+b, '--k')",
                "plt.grid(True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = codiv_country.copy()",
                "ASSIGN['Quarantine_cat'] = ASSIGN['Quarantine'].notnull().astype(int)",
                "ASSIGN['Restrictions_cat'] = ASSIGN['Restrictions'].notnull().astype(int)",
                "ASSIGN['Schools_cat'] = ASSIGN['Schools'].notnull().astype(int)",
                "ASSIGN=ASSIGN.drop([",
                "'Quarantine','Schools','Restrictions',",
                "'Country',",
                "'Total Deaths','Total Infected','Total Active','Total Recovered',",
                "\"Total Deaths Log10\",\"Total Recovered Log10\",\"Total Active Log10\",\"Deaths Ratio\"",
                "], axis=1)",
                "ASSIGN.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = codiv_country.copy()",
                "ASSIGN['Quarantine_cat'] = ASSIGN['Quarantine'].notnull().astype(int)",
                "ASSIGN['Restrictions_cat'] = ASSIGN['Restrictions'].notnull().astype(int)",
                "ASSIGN['Schools_cat'] = ASSIGN['Schools'].notnull().astype(int)",
                "ASSIGN=ASSIGN.drop([",
                "'Quarantine','Schools','Restrictions',",
                "'Country',",
                "'Total Deaths','Total Infected','Total Active','Total Recovered',",
                "\"Total Deaths Log10\",\"Total Recovered Log10\",\"Total Active Log10\",\"Deaths Ratio\"",
                "], axis=1)",
                "ASSIGN.sample(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_country_analyze[codiv_country_analyze.isnull().any(axis=1)]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country_analyze[codiv_country_analyze.isnull().any(axis=1)]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN[ASSIGN.notnull().all(axis=1)]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN[ASSIGN.notnull().all(axis=1)]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['method','Cross-validation']",
                "ASSIGN=range(8)",
                "ASSIGN = pd.DataFrame(index=index, columns=columns)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['method','Cross-validation']",
                "ASSIGN=range(8)",
                "ASSIGN = pd.DataFrame(index=index, columns=columns)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "codiv_country_analyze['category_balanced'], bin_edges_balanced=pd.qcut(codiv_country_analyze['Total Infected Log10'], q=6,labels=False, retbins=True)",
                "print(bin_edges_balanced)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "codiv_country_analyze['category_balanced'], bin_edges_balanced=pd.qcut(codiv_country_analyze['Total Infected Log10'], q=6,labels=False, retbins=True)",
                "print(bin_edges_balanced)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "pd.qcut(codiv_country_analyze['Total Infected Log10'], q=6)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "pd.qcut(codiv_country_analyze['Total Infected Log10'], q=6)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country_analyze['category_balanced'] = codiv_country_analyze['category_balanced'] +1"
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_country_analyze['category_balanced'] = codiv_country_analyze['category_balanced'] +1"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][0]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][1]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][2]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][3]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][4]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][5]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][6]",
                "Level1_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level2_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level3_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level4_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level5_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level6_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "print(,Level1_balanced)",
                "print(,Level2_balanced)",
                "print(,Level3_balanced)",
                "print(,Level4_balanced)",
                "print(,Level5_balanced)",
                "print(,Level6_balanced)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][0]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][1]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][2]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][3]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][4]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][5]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][6]",
                "Level1_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level2_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level3_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level4_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level5_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level6_balanced='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "print(,Level1_balanced)",
                "print(,Level2_balanced)",
                "print(,Level3_balanced)",
                "print(,Level4_balanced)",
                "print(,Level5_balanced)",
                "print(,Level6_balanced)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "list(codiv_country_analyze['category_balanced'].value_counts())"
            ],
            "output_type": "execute_result",
            "content_old": [
                "list(codiv_country_analyze['category_balanced'].value_counts())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=codiv_country_analyze['Total Infected Log10'].values.max()",
                "ASSIGN=ASSIGN+ASSIGN*0.001",
                "print(,ASSIGN)",
                "ASSIGN=(codiv_country_analyze['Total Infected Log10'].values.min())",
                "ASSIGN=ASSIGN-ASSIGN*0.001",
                "print(,ASSIGN)",
                "ASSIGN=(ymax-ymin)path",
                "ASSIGN = ymin",
                "ASSIGN = ymin+yinterval*1",
                "ASSIGN = ymin+yinterval*2",
                "ASSIGN = ymin+yinterval*3",
                "ASSIGN = ymin+yinterval*4",
                "ASSIGN = ymin+yinterval*5",
                "ASSIGN = ymin+yinterval*6",
                "Level1_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level2_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level3_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level4_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level5_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level6_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "codiv_country_analyze['category_equidistant']=np.digitize(codiv_country_analyze['Total Infected Log10'].values,",
                "ASSIGN=[ylevel0_equidistant,ylevel1_equidistant,ylevel2_equidistant,ylevel3_equidistant,ylevel4_equidistant,ylevel5_equidistant,ylevel6_equidistant])",
                "print(,Level1_equidistant)",
                "print(,Level2_equidistant)",
                "print(,Level3_equidistant)",
                "print(,Level4_equidistant)",
                "print(,Level5_equidistant)",
                "print(,Level6_equidistant)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=codiv_country_analyze['Total Infected Log10'].values.max()",
                "ASSIGN=ASSIGN+ASSIGN*0.001",
                "print(,ASSIGN)",
                "ASSIGN=(codiv_country_analyze['Total Infected Log10'].values.min())",
                "ASSIGN=ASSIGN-ASSIGN*0.001",
                "print(,ASSIGN)",
                "ASSIGN=(ymax-ymin)path",
                "ASSIGN = ymin",
                "ASSIGN = ymin+yinterval*1",
                "ASSIGN = ymin+yinterval*2",
                "ASSIGN = ymin+yinterval*3",
                "ASSIGN = ymin+yinterval*4",
                "ASSIGN = ymin+yinterval*5",
                "ASSIGN = ymin+yinterval*6",
                "Level1_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level2_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level3_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level4_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level5_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "Level6_equidistant='%.3f<Infected<%.3f'%(ASSIGN,ASSIGN,)",
                "codiv_country_analyze['category_equidistant']=np.digitize(codiv_country_analyze['Total Infected Log10'].values,",
                "ASSIGN=[ylevel0_equidistant,ylevel1_equidistant,ylevel2_equidistant,ylevel3_equidistant,ylevel4_equidistant,ylevel5_equidistant,ylevel6_equidistant])",
                "print(,Level1_equidistant)",
                "print(,Level2_equidistant)",
                "print(,Level3_equidistant)",
                "print(,Level4_equidistant)",
                "print(,Level5_equidistant)",
                "print(,Level6_equidistant)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = codiv_country_analyze['category_equidistant']",
                "ASSIGN = codiv_country_analyze['category_balanced']",
                "ASSIGN = codiv_country_analyze.drop(['Total Infected Log10','category_balanced','category_equidistant'], axis=1)",
                "sns.countplot(ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = codiv_country_analyze['category_equidistant']",
                "ASSIGN = codiv_country_analyze['category_balanced']",
                "ASSIGN = codiv_country_analyze.drop(['Total Infected Log10','category_balanced','category_equidistant'], axis=1)",
                "sns.countplot(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(y_equidistant)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(y_equidistant)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "X.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "X.sample(10)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "X_tr_equid, X_te_equid, y_tr_equid, y_te_equid = train_test_split(X, y_equidistant, test_size=0.15, random_state=1)",
                "print('Train set equidistant:', X_tr_equid.shape, y_tr_equid.shape)",
                "print('Testn set equidistant:', X_te_equid.shape, y_te_equid.shape)",
                "X_tr_balan, X_te_balan, y_tr_balan, y_te_balan = train_test_split(X, y_balanced, test_size=0.15, random_state=1)",
                "print('Train set balanced:', X_tr_balan.shape, y_tr_balan.shape)",
                "print('Testn set balanced:', X_te_balan.shape, y_te_balan.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "X_tr_equid, X_te_equid, y_tr_equid, y_te_equid = train_test_split(X, y_equidistant, test_size=0.15, random_state=1)",
                "print('Train set equidistant:', X_tr_equid.shape, y_tr_equid.shape)",
                "print('Testn set equidistant:', X_te_equid.shape, y_te_equid.shape)",
                "X_tr_balan, X_te_balan, y_tr_balan, y_te_balan = train_test_split(X, y_balanced, test_size=0.15, random_state=1)",
                "print('Train set balanced:', X_tr_balan.shape, y_tr_balan.shape)",
                "print('Testn set balanced:', X_te_balan.shape, y_te_balan.shape)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(y_te_equid)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(y_te_equid)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(y_te_balan)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(y_te_balan)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = KFold(n_splits=5, shuffle=False, random_state=None)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = KFold(n_splits=5, shuffle=False, random_state=None)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X, y_equidistant)",
                "ASSIGN.predict(X)",
                "print(, ASSIGN.score(X, y_equidistant))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X, y_equidistant)",
                "ASSIGN.predict(X)",
                "print(, ASSIGN.score(X, y_equidistant))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_resultat.at[df_resultat.index==0,\"method\"]=\"baseline_equidistant\"",
                "ASSIGN = cross_validate(dummy_clf, X, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==0,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(, np.mean(ASSIGN['test_score']) )"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "df_resultat.at[df_resultat.index==0,\"method\"]=\"baseline_equidistant\"",
                "ASSIGN = cross_validate(dummy_clf, X, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==0,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(, np.mean(ASSIGN['test_score']) )"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN= DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X_tr_equid, y_tr_equid)",
                "ASSIGN=dummy_clf.predict(X_te_equid)",
                "ASSIGN = confusion_matrix(y_true=y_te_equid, y_pred=y_pred_equid)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN= DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X_tr_equid, y_tr_equid)",
                "ASSIGN=dummy_clf.predict(X_te_equid)",
                "ASSIGN = confusion_matrix(y_true=y_te_equid, y_pred=y_pred_equid)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(dummy_clf, X_te_equid, y_te_equid, cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(dummy_clf, X_te_equid, y_te_equid, cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_resultat.at[df_resultat.index==1,\"method\"]=\"baseline balanced bins\"",
                "ASSIGN = cross_validate(dummy_clf, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==1,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(, np.mean(ASSIGN['test_score']) )"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "df_resultat.at[df_resultat.index==1,\"method\"]=\"baseline balanced bins\"",
                "ASSIGN = cross_validate(dummy_clf, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==1,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(, np.mean(ASSIGN['test_score']) )"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X_tr_balan, y_tr_balan)",
                "ASSIGN=dummy_clf.predict(X_te_balan)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X_tr_balan, y_tr_balan)",
                "ASSIGN=dummy_clf.predict(X_te_balan)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = confusion_matrix(y_true=y_te_balan, y_pred=y_pred_balan)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = confusion_matrix(y_true=y_te_balan, y_pred=y_pred_balan)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(dummy_clf, X_te_balan, y_te_balan, cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(dummy_clf, X_te_balan, y_te_balan, cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=range(1,15)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for depth in ASSIGN:",
                "DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth)",
                "DecisionTree.fit(X, y_equidistant)",
                "ASSIGN = cross_val_score(DecisionTree, X, y_equidistant, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(DecisionTree.score(X, y_equidistant))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_equidistant))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=range(1,15)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for depth in ASSIGN:",
                "DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth)",
                "DecisionTree.fit(X, y_equidistant)",
                "ASSIGN = cross_val_score(DecisionTree, X, y_equidistant, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(DecisionTree.score(X, y_equidistant))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_equidistant))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)",
                "OptDepth=np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)",
                "OptDepth=np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(depths, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(depths, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(depths, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"decision tree accurency\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Tree depth', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(depths)",
                "ax.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(depths, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(depths, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(depths, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"decision tree accurency\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Tree depth', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(depths)",
                "ax.legend()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "DecisionTree = DecisionTreeClassifier(",
                "ASSIGN='gini', random_state=0, max_depth=OptDepth)",
                "DecisionTree.fit(X, y_equidistant)",
                "ASSIGN = cross_validate(DecisionTree, X, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==2,\"method\"]=\"decision-tree equidistant\"",
                "df_resultat.at[df_resultat.index==2,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(,DecisionTree.score(X, y_equidistant))",
                "print(,np.mean(ASSIGN['test_score']))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "DecisionTree = DecisionTreeClassifier(",
                "ASSIGN='gini', random_state=0, max_depth=OptDepth)",
                "DecisionTree.fit(X, y_equidistant)",
                "ASSIGN = cross_validate(DecisionTree, X, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==2,\"method\"]=\"decision-tree equidistant\"",
                "df_resultat.at[df_resultat.index==2,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(,DecisionTree.score(X, y_equidistant))",
                "print(,np.mean(ASSIGN['test_score']))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "DecisionTree_confusion = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=OptDepth)",
                "DecisionTree_confusion.fit(X_tr_equid, y_tr_equid)",
                "confusion_matrix(y_te_equid, DecisionTree_confusion.predict(X_te_equid))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "DecisionTree_confusion = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=OptDepth)",
                "DecisionTree_confusion.fit(X_tr_equid, y_tr_equid)",
                "confusion_matrix(y_te_equid, DecisionTree_confusion.predict(X_te_equid))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(DecisionTree_confusion, X_te_equid, y_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(DecisionTree_confusion, X_te_equid, y_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "os.environ[\"PATH\"] += os.pathsep + 'D:path(x86)path'",
                "ASSIGN = export_graphviz(",
                "DecisionTree, out_file=None,",
                "ASSIGN=X.columns, class_names=[Level1_equidistant,Level2_equidistant, Level3_equidistant,Level4_equidistant,Level5_equidistant,Level6_equidistant],",
                "ASSIGN=True, rounded=True, proportion=True",
                ")",
                "graphviz.Source(ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "os.environ[\"PATH\"] += os.pathsep + 'D:path(x86)path'",
                "ASSIGN = export_graphviz(",
                "DecisionTree, out_file=None,",
                "ASSIGN=X.columns, class_names=[Level1_equidistant,Level2_equidistant, Level3_equidistant,Level4_equidistant,Level5_equidistant,Level6_equidistant],",
                "ASSIGN=True, rounded=True, proportion=True",
                ")",
                "graphviz.Source(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=range(1,15)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for depth in ASSIGN:",
                "DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth)",
                "DecisionTree.fit(X, y_balanced)",
                "ASSIGN = cross_val_score(DecisionTree, X, y_balanced, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(DecisionTree.score(X, y_balanced))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_balanced))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=range(1,15)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for depth in ASSIGN:",
                "DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth)",
                "DecisionTree.fit(X, y_balanced)",
                "ASSIGN = cross_val_score(DecisionTree, X, y_balanced, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(DecisionTree.score(X, y_balanced))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_balanced))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)",
                "OptDepth=np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)",
                "OptDepth=np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(depths, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(depths, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(depths, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"decision tree accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Tree depth', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(depths)",
                "ax.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(depths, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(depths, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(depths, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"decision tree accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Tree depth', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(depths)",
                "ax.legend()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "DecisionTree = DecisionTreeClassifier(",
                "ASSIGN='gini', random_state=0, max_depth=OptDepth)",
                "DecisionTree.fit(X, y_balanced)",
                "ASSIGN = cross_validate(DecisionTree, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==3,\"method\"]=\"decision-tree _balanced bins\"",
                "df_resultat.at[df_resultat.index==3,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(,DecisionTree.score(X, y_balanced))",
                "print(,np.mean(ASSIGN['test_score']))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "DecisionTree = DecisionTreeClassifier(",
                "ASSIGN='gini', random_state=0, max_depth=OptDepth)",
                "DecisionTree.fit(X, y_balanced)",
                "ASSIGN = cross_validate(DecisionTree, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==3,\"method\"]=\"decision-tree _balanced bins\"",
                "df_resultat.at[df_resultat.index==3,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(,DecisionTree.score(X, y_balanced))",
                "print(,np.mean(ASSIGN['test_score']))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "DecisionTree_confusion = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=OptDepth)",
                "DecisionTree_confusion.fit(X_tr_balan, y_tr_balan)",
                "confusion_matrix(y_te_balan, DecisionTree_confusion.predict(X_te_balan))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "DecisionTree_confusion = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=OptDepth)",
                "DecisionTree_confusion.fit(X_tr_balan, y_tr_balan)",
                "confusion_matrix(y_te_balan, DecisionTree_confusion.predict(X_te_balan))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(DecisionTree_confusion, X_te_balan, y_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(DecisionTree_confusion, X_te_balan, y_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "os.environ[\"PATH\"] += os.pathsep + 'D:path(x86)path'",
                "ASSIGN = export_graphviz(",
                "DecisionTree, out_file=None,",
                "ASSIGN=X.columns, class_names=[Level1_balanced,Level2_balanced, Level3_balanced,Level4_balanced,Level5_balanced,Level6_balanced],",
                "ASSIGN=True, rounded=True, proportion=True",
                ")",
                "graphviz.Source(ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "os.environ[\"PATH\"] += os.pathsep + 'D:path(x86)path'",
                "ASSIGN = export_graphviz(",
                "DecisionTree, out_file=None,",
                "ASSIGN=X.columns, class_names=[Level1_balanced,Level2_balanced, Level3_balanced,Level4_balanced,Level5_balanced,Level6_balanced],",
                "ASSIGN=True, rounded=True, proportion=True",
                ")",
                "graphviz.Source(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN=range(100,2000,100)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for Estimator in ASSIGN:",
                "ASSIGN = RandomForestClassifier(n_estimators=Estimator,random_state=0)",
                "ASSIGN.fit(X, y_equidistant)",
                "ASSIGN = cross_val_score(forest, X, y_equidistant, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(ASSIGN.fit(X, y_equidistant).score(X, y_equidistant))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(Estimator,cv_val_scores.mean(),forest.score(X, y_equidistant))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN=range(100,2000,100)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for Estimator in ASSIGN:",
                "ASSIGN = RandomForestClassifier(n_estimators=Estimator,random_state=0)",
                "ASSIGN.fit(X, y_equidistant)",
                "ASSIGN = cross_val_score(forest, X, y_equidistant, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(ASSIGN.fit(X, y_equidistant).score(X, y_equidistant))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(Estimator,cv_val_scores.mean(),forest.score(X, y_equidistant))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100)",
                "OptEstimator=(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100)",
                "OptEstimator=(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(Estimators, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(Estimators, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(Estimators, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"Forest accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Forest Estimator', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(Estimators)",
                "ax.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(Estimators, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(Estimators, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(Estimators, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"Forest accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Forest Estimator', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(Estimators)",
                "ax.legend()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X, y_equidistant)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X, y_equidistant)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = cross_validate(forest, X, y_equidistant, cv=cv_strategy)",
                "print('Forest by equidistant interval score {:.3f}'.format(forest.score(X, y_equidistant)))",
                "df_resultat.at[df_resultat.index==4,\"method\"]=\"Forest equidistant\"",
                "df_resultat.at[df_resultat.index==4,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('Forest by equidistant interval cross validation {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = cross_validate(forest, X, y_equidistant, cv=cv_strategy)",
                "print('Forest by equidistant interval score {:.3f}'.format(forest.score(X, y_equidistant)))",
                "df_resultat.at[df_resultat.index==4,\"method\"]=\"Forest equidistant\"",
                "df_resultat.at[df_resultat.index==4,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('Forest by equidistant interval cross validation {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X_tr_equid, y_tr_equid)",
                "confusion_matrix(y_te_equid, ASSIGN.predict(X_te_equid))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X_tr_equid, y_tr_equid)",
                "confusion_matrix(y_te_equid, ASSIGN.predict(X_te_equid))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "plot_confusion_matrix(forest_confusion, X_te_equid,y_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plot_confusion_matrix(forest_confusion, X_te_equid,y_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = forest.feature_importances_",
                "ASSIGN = np.ASSIGN([tree.feature_importances_ for tree in forest.estimators_],axis=0)",
                "ASSIGN = np.argsort(importances)[::-1]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = forest.feature_importances_",
                "ASSIGN = np.ASSIGN([tree.feature_importances_ for tree in forest.estimators_],axis=0)",
                "ASSIGN = np.argsort(importances)[::-1]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print()",
                "for f in range(X.shape[1]):",
                "print( % (f + 1, X.columns[indices[f]], importances[indices[f]]))",
                "plt.figure(figsize=(20,10))",
                "plt.title(\"Feature importances\")",
                "plt.bar(range(X.shape[1]), importances[indices],",
                "ASSIGN=\"r\", yerr=std[indices], align=\"center\")",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 65)",
                "plt.xlim([-1, X.shape[1]])",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print()",
                "for f in range(X.shape[1]):",
                "print( % (f + 1, X.columns[indices[f]], importances[indices[f]]))",
                "plt.figure(figsize=(20,10))",
                "plt.title(\"Feature importances\")",
                "plt.bar(range(X.shape[1]), importances[indices],",
                "ASSIGN=\"r\", yerr=std[indices], align=\"center\")",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 65)",
                "plt.xlim([-1, X.shape[1]])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=range(100,2000,100)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for Estimator in ASSIGN:",
                "ASSIGN = RandomForestClassifier(n_estimators=Estimator,random_state=0)",
                "ASSIGN.fit(X, y_balanced)",
                "ASSIGN = cross_val_score(forest, X, y_balanced, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(ASSIGN.fit(X, y_balanced).score(X, y_balanced))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(Estimator,cv_val_scores.mean(),forest.score(X, y_balanced))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=range(100,2000,100)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for Estimator in ASSIGN:",
                "ASSIGN = RandomForestClassifier(n_estimators=Estimator,random_state=0)",
                "ASSIGN.fit(X, y_balanced)",
                "ASSIGN = cross_val_score(forest, X, y_balanced, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(ASSIGN.fit(X, y_balanced).score(X, y_balanced))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(Estimator,cv_val_scores.mean(),forest.score(X, y_balanced))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100)",
                "OptEstimator=(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100)",
                "OptEstimator=(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(Estimators, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(Estimators, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(Estimators, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"Forest accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Forest Estimator', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(Estimators)",
                "ax.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(Estimators, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(Estimators, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(Estimators, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"Forest accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Forest Estimator', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(Estimators)",
                "ax.legend()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = cross_validate(forest, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==5,\"method\"]=\"Forest balanced bins\"",
                "df_resultat.at[df_resultat.index==5,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('Forest by balanced bins of element score {:.3f}'.format(forest.score(X, y_balanced)))",
                "print('Forest by balanced bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = cross_validate(forest, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==5,\"method\"]=\"Forest balanced bins\"",
                "df_resultat.at[df_resultat.index==5,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('Forest by balanced bins of element score {:.3f}'.format(forest.score(X, y_balanced)))",
                "print('Forest by balanced bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X_tr_balan, y_tr_balan)",
                "confusion_matrix(y_te_balan, ASSIGN.predict(X_te_balan))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X_tr_balan, y_tr_balan)",
                "confusion_matrix(y_te_balan, ASSIGN.predict(X_te_balan))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(forest_confusion, X_te_balan, y_te_balan,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(forest_confusion, X_te_balan, y_te_balan,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = forest.feature_importances_",
                "ASSIGN = np.ASSIGN([tree.feature_importances_ for tree in forest.estimators_],",
                "ASSIGN=0)",
                "ASSIGN = np.argsort(importances)[::-1]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = forest.feature_importances_",
                "ASSIGN = np.ASSIGN([tree.feature_importances_ for tree in forest.estimators_],",
                "ASSIGN=0)",
                "ASSIGN = np.argsort(importances)[::-1]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print()",
                "for f in range(X.shape[1]):",
                "print( % (f + 1, X.columns[indices[f]], importances[indices[f]]))",
                "plt.figure(figsize=(20,10))",
                "plt.title(\"Feature importances\")",
                "plt.bar(range(X.shape[1]), importances[indices],",
                "ASSIGN=\"r\", yerr=std[indices], align=\"center\")",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 65)",
                "plt.xlim([-1, X.shape[1]])",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print()",
                "for f in range(X.shape[1]):",
                "print( % (f + 1, X.columns[indices[f]], importances[indices[f]]))",
                "plt.figure(figsize=(20,10))",
                "plt.title(\"Feature importances\")",
                "plt.bar(range(X.shape[1]), importances[indices],",
                "ASSIGN=\"r\", yerr=std[indices], align=\"center\")",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 65)",
                "plt.xlim([-1, X.shape[1]])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = PCA(n_components=2)",
                "ASSIGN.fit(X, y=None);",
                "ASSIGN= pca.transform(X)",
                "ASSIGN=pd.DataFrame(feature_2)",
                "ASSIGN=feature_2_df.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = PCA(n_components=2)",
                "ASSIGN.fit(X, y=None);",
                "ASSIGN= pca.transform(X)",
                "ASSIGN=pd.DataFrame(feature_2)",
                "ASSIGN=feature_2_df.shape"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "X_fea_2_tr_equid, X_fea_2_te_equid, y_fea_2_tr_equid, y_fea_2_te_equid = train_test_split(feature_2, y_equidistant, test_size=0.15, random_state=1)",
                "print('Train set equidistant:', X_fea_2_tr_equid.shape, y_fea_2_tr_equid.shape)",
                "print('Testn set equidistant:', X_fea_2_te_equid.shape, y_fea_2_te_equid.shape)",
                "X_fea_2_tr_balan, X_fea_2_te_balan, y_fea_2_tr_balan, y_fea_2_te_balan = train_test_split(feature_2, y_balanced, test_size=0.15, random_state=1)",
                "print('Train set balanced:', X_fea_2_tr_balan.shape, y_fea_2_tr_balan.shape)",
                "print('Testn set balanced:', X_fea_2_te_balan.shape, y_fea_2_te_balan.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "X_fea_2_tr_equid, X_fea_2_te_equid, y_fea_2_tr_equid, y_fea_2_te_equid = train_test_split(feature_2, y_equidistant, test_size=0.15, random_state=1)",
                "print('Train set equidistant:', X_fea_2_tr_equid.shape, y_fea_2_tr_equid.shape)",
                "print('Testn set equidistant:', X_fea_2_te_equid.shape, y_fea_2_te_equid.shape)",
                "X_fea_2_tr_balan, X_fea_2_te_balan, y_fea_2_tr_balan, y_fea_2_te_balan = train_test_split(feature_2, y_balanced, test_size=0.15, random_state=1)",
                "print('Train set balanced:', X_fea_2_tr_balan.shape, y_fea_2_tr_balan.shape)",
                "print('Testn set balanced:', X_fea_2_te_balan.shape, y_fea_2_te_balan.shape)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Pipeline([",
                "('scaler', None),",
                "('knn', KNeighborsClassifier(",
                "ASSIGN=-1",
                "))",
                "])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = Pipeline([",
                "('scaler', None),",
                "('knn', KNeighborsClassifier(",
                "ASSIGN=-1",
                "))",
                "])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = list(range(1,35))",
                "ASSIGN = []",
                "for n_neighborss in ASSIGN:",
                "ASSIGN='distance'",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=n_neighborss, ASSIGN=ASSIGN)) ])",
                "ASSIGN.fit(feature_2, y_equidistant)",
                "ASSIGN = cross_val_score(knn_pipe,feature_2,y_equidistant,cv=cv_strategy )",
                "ASSIGN.append(ASSIGN.mean())",
                "Missclassification_Error = [1-x for x in ASSIGN]",
                "print(,format(Missclassification_Error.index(min(Missclassification_Error))))",
                "ASSIGN=Missclassification_Error.index(min(Missclassification_Error))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = list(range(1,35))",
                "ASSIGN = []",
                "for n_neighborss in ASSIGN:",
                "ASSIGN='distance'",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=n_neighborss, ASSIGN=ASSIGN)) ])",
                "ASSIGN.fit(feature_2, y_equidistant)",
                "ASSIGN = cross_val_score(knn_pipe,feature_2,y_equidistant,cv=cv_strategy )",
                "ASSIGN.append(ASSIGN.mean())",
                "Missclassification_Error = [1-x for x in ASSIGN]",
                "print(,format(Missclassification_Error.index(min(Missclassification_Error))))",
                "ASSIGN=Missclassification_Error.index(min(Missclassification_Error))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "plt.plot(Missclassification_Error)",
                "plt.xlabel(\"number of neighbors K\")",
                "plt.ylabel(\"Missclassification Error\")",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "plt.plot(Missclassification_Error)",
                "plt.xlabel(\"number of neighbors K\")",
                "plt.ylabel(\"Missclassification Error\")",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = ListedColormap(['",
                "ASSIGN = ListedColormap(['",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN='distance'",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal))",
                "])",
                "ASSIGN.fit(feature_2, y_equidistant)",
                "feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))",
                "ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])",
                "ASSIGN = Z.reshape(xx.shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = ListedColormap(['",
                "ASSIGN = ListedColormap(['",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN='distance'",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal))",
                "])",
                "ASSIGN.fit(feature_2, y_equidistant)",
                "feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))",
                "ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])",
                "ASSIGN = Z.reshape(xx.shape)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(18, 10))",
                "plt.pcolormesh(xx, yy, Zo, cmap=cmap_light)",
                "Label1=pd.DataFrame([1,2,3,4,5])",
                "plt.scatter(feature1, feature2, c=y_equidistant, cmap=cmap_bold)",
                "ASSIGN = plt.colorbar()",
                "ASSIGN.ax.set_yticklabels([Level1_equidistant,Level2_equidistant,Level3_equidistant,Level4_equidistant,Level5_equidistant,Level6_equidistant])",
                "plt.xlim(xx.min(), xx.max())",
                "plt.ylim(yy.min(), yy.max())",
                "plt.xlabel(\"feature 1\")",
                "plt.ylabel(\"feature 2\")",
                "plt.title(\"6-Class classification,  equidistant bins - total infected log10 (k = %i, weights = '%s')\" % (k_Optimal, weights))",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(18, 10))",
                "plt.pcolormesh(xx, yy, Zo, cmap=cmap_light)",
                "Label1=pd.DataFrame([1,2,3,4,5])",
                "plt.scatter(feature1, feature2, c=y_equidistant, cmap=cmap_bold)",
                "ASSIGN = plt.colorbar()",
                "ASSIGN.ax.set_yticklabels([Level1_equidistant,Level2_equidistant,Level3_equidistant,Level4_equidistant,Level5_equidistant,Level6_equidistant])",
                "plt.xlim(xx.min(), xx.max())",
                "plt.ylim(yy.min(), yy.max())",
                "plt.xlabel(\"feature 1\")",
                "plt.ylabel(\"feature 2\")",
                "plt.title(\"6-Class classification,  equidistant bins - total infected log10 (k = %i, weights = '%s')\" % (k_Optimal, weights))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = cross_validate(knn_pipe, feature_2, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==6,\"method\"]=\"knn equidistant bins\"",
                "df_resultat.at[df_resultat.index==6,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('knn by equidistant bins of element score {:.3f}'.format(knn_pipe.score(feature_2, y_equidistant)))",
                "print('knn by equidistant bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = cross_validate(knn_pipe, feature_2, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==6,\"method\"]=\"knn equidistant bins\"",
                "df_resultat.at[df_resultat.index==6,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('knn by equidistant bins of element score {:.3f}'.format(knn_pipe.score(feature_2, y_equidistant)))",
                "print('knn by equidistant bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))",
                "])",
                "ASSIGN=knn_pipe.fit(X_fea_2_tr_equid, y_fea_2_tr_equid)",
                "ASSIGN = knn_pipe.predict(X_fea_2_te_equid)",
                "confusion_matrix(y_fea_2_te_equid, ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))",
                "])",
                "ASSIGN=knn_pipe.fit(X_fea_2_tr_equid, y_fea_2_tr_equid)",
                "ASSIGN = knn_pipe.predict(X_fea_2_te_equid)",
                "confusion_matrix(y_fea_2_te_equid, ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "plot_confusion_matrix(knn_confusion, X_fea_2_te_equid, y_fea_2_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plot_confusion_matrix(knn_confusion, X_fea_2_te_equid, y_fea_2_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(classification_report(y_true=y_fea_2_te_equid, y_pred=knn_predict))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(classification_report(y_true=y_fea_2_te_equid, y_pred=knn_predict))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = list(range(1,35))",
                "ASSIGN = []",
                "for n_neighborss in ASSIGN:",
                "ASSIGN='distance'",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=n_neighborss, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_balanced)",
                "ASSIGN = cross_val_score(knn_pipe,feature_2,y_balanced,cv=cv_strategy )",
                "ASSIGN.append(ASSIGN.mean())",
                "Missclassification_Error = [1-x for x in ASSIGN]",
                "print(,format(Missclassification_Error.index(min(Missclassification_Error))))",
                "ASSIGN=Missclassification_Error.index(min(Missclassification_Error))",
                "plt.plot( Missclassification_Error)",
                "plt.xlabel(\"number of ASSIGN K\")",
                "plt.ylabel(\"Missclassification Error\")",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = list(range(1,35))",
                "ASSIGN = []",
                "for n_neighborss in ASSIGN:",
                "ASSIGN='distance'",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=n_neighborss, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_balanced)",
                "ASSIGN = cross_val_score(knn_pipe,feature_2,y_balanced,cv=cv_strategy )",
                "ASSIGN.append(ASSIGN.mean())",
                "Missclassification_Error = [1-x for x in ASSIGN]",
                "print(,format(Missclassification_Error.index(min(Missclassification_Error))))",
                "ASSIGN=Missclassification_Error.index(min(Missclassification_Error))",
                "plt.plot( Missclassification_Error)",
                "plt.xlabel(\"number of ASSIGN K\")",
                "plt.ylabel(\"Missclassification Error\")",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = ListedColormap(['",
                "ASSIGN = ListedColormap(['",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN='distance'",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_balanced)",
                "feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))",
                "ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])",
                "ASSIGN = Z.reshape(xx.shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ListedColormap(['",
                "ASSIGN = ListedColormap(['",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN='distance'",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_balanced)",
                "feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))",
                "ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])",
                "ASSIGN = Z.reshape(xx.shape)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(18, 10))",
                "plt.pcolormesh(xx, yy, Zo, cmap=cmap_light)",
                "Label1=pd.DataFrame([1,2,3,4,5])",
                "plt.scatter(feature1, feature2, c=y_balanced, cmap=cmap_bold)",
                "ASSIGN = plt.colorbar()",
                "ASSIGN.ax.set_yticklabels([Level1_balanced,Level2_balanced,Level3_balanced,Level4_balanced,Level5_balanced,Level6_balanced])",
                "plt.xlim(xx.min(), xx.max())",
                "plt.ylim(yy.min(), yy.max())",
                "plt.xlabel(\"feature 1\")",
                "plt.ylabel(\"feature 2\")",
                "plt.title(\"6-Class classification,  balanced bins - total infected log10 (k = %i, weights = '%s')\" % (k_Optimal, weights))",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(18, 10))",
                "plt.pcolormesh(xx, yy, Zo, cmap=cmap_light)",
                "Label1=pd.DataFrame([1,2,3,4,5])",
                "plt.scatter(feature1, feature2, c=y_balanced, cmap=cmap_bold)",
                "ASSIGN = plt.colorbar()",
                "ASSIGN.ax.set_yticklabels([Level1_balanced,Level2_balanced,Level3_balanced,Level4_balanced,Level5_balanced,Level6_balanced])",
                "plt.xlim(xx.min(), xx.max())",
                "plt.ylim(yy.min(), yy.max())",
                "plt.xlabel(\"feature 1\")",
                "plt.ylabel(\"feature 2\")",
                "plt.title(\"6-Class classification,  balanced bins - total infected log10 (k = %i, weights = '%s')\" % (k_Optimal, weights))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = cross_validate(knn_pipe, feature_2, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==7,\"method\"]=\"knn balanced bins\"",
                "df_resultat.at[df_resultat.index==7,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('knn by equidistant bins of element score {:.3f}'.format(knn_pipe.score(feature_2, y_balanced)))",
                "print('knn by equidistant bins of element - mean test_score {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = cross_validate(knn_pipe, feature_2, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==7,\"method\"]=\"knn balanced bins\"",
                "df_resultat.at[df_resultat.index==7,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('knn by equidistant bins of element score {:.3f}'.format(knn_pipe.score(feature_2, y_balanced)))",
                "print('knn by equidistant bins of element - mean test_score {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))",
                "])",
                "ASSIGN=knn_pipe.fit(X_fea_2_tr_balan, y_fea_2_tr_balan)",
                "ASSIGN = knn_pipe.predict(X_fea_2_te_balan)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))",
                "])",
                "ASSIGN=knn_pipe.fit(X_fea_2_tr_balan, y_fea_2_tr_balan)",
                "ASSIGN = knn_pipe.predict(X_fea_2_te_balan)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "confusion_matrix(y_fea_2_te_balan, knn_predict)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "confusion_matrix(y_fea_2_te_balan, knn_predict)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "plot_confusion_matrix(knn_confusion, X_fea_2_te_balan, y_fea_2_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plot_confusion_matrix(knn_confusion, X_fea_2_te_balan, y_fea_2_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_resultat"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df_resultat"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.barplot(x=df_resultat[\"Cross-validation\"],y=df_resultat['method'])",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.barplot(x=df_resultat[\"Cross-validation\"],y=df_resultat['method'])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = codiv_country.copy()",
                "ASSIGN['Quarantine_cat'] = ASSIGN['Quarantine'].notnull().astype(int)",
                "ASSIGN['Restrictions_cat'] = ASSIGN['Restrictions'].notnull().astype(int)",
                "ASSIGN['Schools_cat'] = ASSIGN['Schools'].notnull().astype(int)",
                "ASSIGN=ASSIGN.drop([",
                "'Quarantine','Schools','Restrictions',",
                "'Country',",
                "'Total Deaths','Total Infected','Total Active','Total Recovered',",
                "\"Total Deaths Log10\",\"Total Recovered Log10\",\"Total Active Log10\",\"Total Infected Log10\"",
                "], axis=1)",
                "ASSIGN.sample(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = codiv_country.copy()",
                "ASSIGN['Quarantine_cat'] = ASSIGN['Quarantine'].notnull().astype(int)",
                "ASSIGN['Restrictions_cat'] = ASSIGN['Restrictions'].notnull().astype(int)",
                "ASSIGN['Schools_cat'] = ASSIGN['Schools'].notnull().astype(int)",
                "ASSIGN=ASSIGN.drop([",
                "'Quarantine','Schools','Restrictions',",
                "'Country',",
                "'Total Deaths','Total Infected','Total Active','Total Recovered',",
                "\"Total Deaths Log10\",\"Total Recovered Log10\",\"Total Active Log10\",\"Total Infected Log10\"",
                "], axis=1)",
                "ASSIGN.sample(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['method','Cross-validation']",
                "ASSIGN=range(8)",
                "ASSIGN = pd.DataFrame(index=index, columns=columns)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['method','Cross-validation']",
                "ASSIGN=range(8)",
                "ASSIGN = pd.DataFrame(index=index, columns=columns)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "codiv_country_analyze['Deaths Ratio'].describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "codiv_country_analyze['Deaths Ratio'].describe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "codiv_country_analyze['category_balanced'], bin_edges_balanced=pd.qcut(codiv_country_analyze['Deaths Ratio'], q=6,labels=False, retbins=True)",
                "codiv_country_analyze['category_balanced'] = codiv_country_analyze['category_balanced'] +1"
            ],
            "output_type": "not_existent",
            "content_old": [
                "codiv_country_analyze['category_balanced'], bin_edges_balanced=pd.qcut(codiv_country_analyze['Deaths Ratio'], q=6,labels=False, retbins=True)",
                "codiv_country_analyze['category_balanced'] = codiv_country_analyze['category_balanced'] +1"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][0]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][1]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][2]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][3]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][4]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][5]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][6]",
                "Level1_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level2_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level3_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level4_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level5_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level6_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "print(,Level1_balanced)",
                "print(,Level2_balanced)",
                "print(,Level3_balanced)",
                "print(,Level4_balanced)",
                "print(,Level5_balanced)",
                "print(,Level6_balanced)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][0]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][1]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][2]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][3]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][4]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][5]",
                "ASSIGN=pd.DataFrame(zip(bin_edges_balanced),columns=['Threshold'])['Threshold'][6]",
                "Level1_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level2_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level3_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level4_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level5_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level6_balanced='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "print(,Level1_balanced)",
                "print(,Level2_balanced)",
                "print(,Level3_balanced)",
                "print(,Level4_balanced)",
                "print(,Level5_balanced)",
                "print(,Level6_balanced)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=codiv_country_analyze['Deaths Ratio'].values.max()",
                "print(ASSIGN)",
                "ASSIGN=ASSIGN+ASSIGN*0.001",
                "print(,ASSIGN)",
                "ASSIGN=(codiv_country_analyze['Deaths Ratio'].values.min())",
                "ASSIGN=ASSIGN-ASSIGN*0.001",
                "print(,ASSIGN)",
                "ASSIGN=(ymax-ymin)path",
                "print(ASSIGN,ASSIGN)",
                "ASSIGN = ymin",
                "ASSIGN = ymin+yinterval*1",
                "ASSIGN = ymin+yinterval*2",
                "ASSIGN = ymin+yinterval*3",
                "ASSIGN = ymin+yinterval*4",
                "ASSIGN = ymin+yinterval*5",
                "ASSIGN = ymin+yinterval*6",
                "Level1_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level2_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level3_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level4_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level5_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level6_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "codiv_country_analyze['category_equidistant']=np.digitize(codiv_country_analyze['Deaths Ratio'].values,",
                "ASSIGN=[ylevel0_equidistant,ylevel1_equidistant,ylevel2_equidistant,ylevel3_equidistant,ylevel4_equidistant,ylevel5_equidistant,ylevel6_equidistant])",
                "print(,Level1_equidistant)",
                "print(,Level2_equidistant)",
                "print(,Level3_equidistant)",
                "print(,Level4_equidistant)",
                "print(,Level5_equidistant)",
                "print(,Level6_equidistant)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=codiv_country_analyze['Deaths Ratio'].values.max()",
                "print(ASSIGN)",
                "ASSIGN=ASSIGN+ASSIGN*0.001",
                "print(,ASSIGN)",
                "ASSIGN=(codiv_country_analyze['Deaths Ratio'].values.min())",
                "ASSIGN=ASSIGN-ASSIGN*0.001",
                "print(,ASSIGN)",
                "ASSIGN=(ymax-ymin)path",
                "print(ASSIGN,ASSIGN)",
                "ASSIGN = ymin",
                "ASSIGN = ymin+yinterval*1",
                "ASSIGN = ymin+yinterval*2",
                "ASSIGN = ymin+yinterval*3",
                "ASSIGN = ymin+yinterval*4",
                "ASSIGN = ymin+yinterval*5",
                "ASSIGN = ymin+yinterval*6",
                "Level1_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level2_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level3_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level4_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level5_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "Level6_equidistant='%.3f<Deaths Ratio<%.3f'%(ASSIGN,ASSIGN,)",
                "codiv_country_analyze['category_equidistant']=np.digitize(codiv_country_analyze['Deaths Ratio'].values,",
                "ASSIGN=[ylevel0_equidistant,ylevel1_equidistant,ylevel2_equidistant,ylevel3_equidistant,ylevel4_equidistant,ylevel5_equidistant,ylevel6_equidistant])",
                "print(,Level1_equidistant)",
                "print(,Level2_equidistant)",
                "print(,Level3_equidistant)",
                "print(,Level4_equidistant)",
                "print(,Level5_equidistant)",
                "print(,Level6_equidistant)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = codiv_country_analyze['category_equidistant']",
                "ASSIGN = codiv_country_analyze['category_balanced']",
                "ASSIGN = codiv_country_analyze.drop(['Deaths Ratio','category_balanced','category_equidistant'], axis=1)",
                "sns.countplot(ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = codiv_country_analyze['category_equidistant']",
                "ASSIGN = codiv_country_analyze['category_balanced']",
                "ASSIGN = codiv_country_analyze.drop(['Deaths Ratio','category_balanced','category_equidistant'], axis=1)",
                "sns.countplot(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(y_equidistant)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(y_equidistant)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "X_tr_equid, X_te_equid, y_tr_equid, y_te_equid = train_test_split(X, y_equidistant, test_size=0.15, random_state=1)",
                "print('Train set equidistant:', X_tr_equid.shape, y_tr_equid.shape)",
                "print('Testn set equidistant:', X_te_equid.shape, y_te_equid.shape)",
                "X_tr_balan, X_te_balan, y_tr_balan, y_te_balan = train_test_split(X, y_balanced, test_size=0.15, random_state=1)",
                "print('Train set balanced:', X_tr_balan.shape, y_tr_balan.shape)",
                "print('Testn set balanced:', X_te_balan.shape, y_te_balan.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "X_tr_equid, X_te_equid, y_tr_equid, y_te_equid = train_test_split(X, y_equidistant, test_size=0.15, random_state=1)",
                "print('Train set equidistant:', X_tr_equid.shape, y_tr_equid.shape)",
                "print('Testn set equidistant:', X_te_equid.shape, y_te_equid.shape)",
                "X_tr_balan, X_te_balan, y_tr_balan, y_te_balan = train_test_split(X, y_balanced, test_size=0.15, random_state=1)",
                "print('Train set balanced:', X_tr_balan.shape, y_tr_balan.shape)",
                "print('Testn set balanced:', X_te_balan.shape, y_te_balan.shape)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(y_te_equid)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(y_te_equid)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(y_te_balan)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(y_te_balan)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X, y_equidistant)",
                "ASSIGN.predict(X)",
                "print(, ASSIGN.score(X, y_equidistant))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X, y_equidistant)",
                "ASSIGN.predict(X)",
                "print(, ASSIGN.score(X, y_equidistant))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_resultat.at[df_resultat.index==0,\"method\"]=\"baseline_equidistant\"",
                "ASSIGN = cross_validate(dummy_clf, X, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==0,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(, np.mean(ASSIGN['test_score']) )"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "df_resultat.at[df_resultat.index==0,\"method\"]=\"baseline_equidistant\"",
                "ASSIGN = cross_validate(dummy_clf, X, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==0,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(, np.mean(ASSIGN['test_score']) )"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN= DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X_tr_equid, y_tr_equid)",
                "ASSIGN=dummy_clf.predict(X_te_equid)",
                "ASSIGN = confusion_matrix(y_true=y_te_equid, y_pred=y_pred_equid)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN= DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X_tr_equid, y_tr_equid)",
                "ASSIGN=dummy_clf.predict(X_te_equid)",
                "ASSIGN = confusion_matrix(y_true=y_te_equid, y_pred=y_pred_equid)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(dummy_clf, X_te_equid, y_te_equid, cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(dummy_clf, X_te_equid, y_te_equid, cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X, y_balanced)",
                "ASSIGN.predict(X)",
                "print(, ASSIGN.score(X, y_balanced))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X, y_balanced)",
                "ASSIGN.predict(X)",
                "print(, ASSIGN.score(X, y_balanced))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_resultat.at[df_resultat.index==1,\"method\"]=\"baseline balanced bins\"",
                "ASSIGN = cross_validate(dummy_clf, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==1,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(, np.mean(ASSIGN['test_score']) )"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "df_resultat.at[df_resultat.index==1,\"method\"]=\"baseline balanced bins\"",
                "ASSIGN = cross_validate(dummy_clf, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==1,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(, np.mean(ASSIGN['test_score']) )"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X_tr_balan, y_tr_balan)",
                "ASSIGN=dummy_clf.predict(X_te_balan)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = DummyClassifier(strategy=\"most_frequent\")",
                "ASSIGN.fit(X_tr_balan, y_tr_balan)",
                "ASSIGN=dummy_clf.predict(X_te_balan)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = confusion_matrix(y_true=y_te_balan, y_pred=y_pred_balan)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = confusion_matrix(y_true=y_te_balan, y_pred=y_pred_balan)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(dummy_clf, X_te_balan, y_te_balan, cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(dummy_clf, X_te_balan, y_te_balan, cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=range(1,15)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for depth in ASSIGN:",
                "DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth)",
                "DecisionTree.fit(X, y_equidistant)",
                "ASSIGN = cross_val_score(DecisionTree, X, y_equidistant, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(DecisionTree.score(X, y_equidistant))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f std %f score %f\"%(depth,cv_val_scores.mean(),cv_val_scores.std(),DecisionTree.score(X, y_equidistant))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=range(1,15)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for depth in ASSIGN:",
                "DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth)",
                "DecisionTree.fit(X, y_equidistant)",
                "ASSIGN = cross_val_score(DecisionTree, X, y_equidistant, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(DecisionTree.score(X, y_equidistant))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f std %f score %f\"%(depth,cv_val_scores.mean(),cv_val_scores.std(),DecisionTree.score(X, y_equidistant))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)",
                "OptDepth=np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)",
                "OptDepth=np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(depths, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(depths, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(depths, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"decision tree accurency\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Tree depth', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(depths)",
                "ax.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(depths, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(depths, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(depths, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"decision tree accurency\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Tree depth', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(depths)",
                "ax.legend()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "DecisionTree = DecisionTreeClassifier(",
                "ASSIGN='gini', random_state=0, max_depth=OptDepth)",
                "DecisionTree.fit(X, y_equidistant)",
                "ASSIGN = cross_validate(DecisionTree, X, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==2,\"method\"]=\"decision-tree equidistant\"",
                "df_resultat.at[df_resultat.index==2,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(,DecisionTree.score(X, y_equidistant))",
                "print(,np.mean(ASSIGN['test_score']))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "DecisionTree = DecisionTreeClassifier(",
                "ASSIGN='gini', random_state=0, max_depth=OptDepth)",
                "DecisionTree.fit(X, y_equidistant)",
                "ASSIGN = cross_validate(DecisionTree, X, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==2,\"method\"]=\"decision-tree equidistant\"",
                "df_resultat.at[df_resultat.index==2,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(,DecisionTree.score(X, y_equidistant))",
                "print(,np.mean(ASSIGN['test_score']))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "DecisionTree_confusion = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=OptDepth)",
                "DecisionTree_confusion.fit(X_tr_equid, y_tr_equid)",
                "confusion_matrix(y_te_equid, DecisionTree_confusion.predict(X_te_equid))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "DecisionTree_confusion = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=OptDepth)",
                "DecisionTree_confusion.fit(X_tr_equid, y_tr_equid)",
                "confusion_matrix(y_te_equid, DecisionTree_confusion.predict(X_te_equid))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(DecisionTree_confusion, X_te_equid, y_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(DecisionTree_confusion, X_te_equid, y_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Post Development Phase"
            ],
            "content": [
                "SETUP",
                "os.environ[\"PATH\"] += os.pathsep + 'D:path(x86)path'",
                "ASSIGN = export_graphviz(",
                "DecisionTree, out_file=None,",
                "ASSIGN=X.columns, class_names=[Level1_equidistant,Level2_equidistant, Level3_equidistant,Level4_equidistant,Level5_equidistant,Level6_equidistant],",
                "ASSIGN=True, rounded=True, proportion=True",
                ")",
                "graphviz.Source(ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "os.environ[\"PATH\"] += os.pathsep + 'D:path(x86)path'",
                "ASSIGN = export_graphviz(",
                "DecisionTree, out_file=None,",
                "ASSIGN=X.columns, class_names=[Level1_equidistant,Level2_equidistant, Level3_equidistant,Level4_equidistant,Level5_equidistant,Level6_equidistant],",
                "ASSIGN=True, rounded=True, proportion=True",
                ")",
                "graphviz.Source(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=range(1,15)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for depth in ASSIGN:",
                "DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth)",
                "DecisionTree.fit(X, y_balanced)",
                "ASSIGN = cross_val_score(DecisionTree, X, y_balanced, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(DecisionTree.score(X, y_balanced))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_balanced))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=range(1,15)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for depth in ASSIGN:",
                "DecisionTree = DecisionTreeClassifier(criterion='gini', random_state=0, max_depth=depth)",
                "DecisionTree.fit(X, y_balanced)",
                "ASSIGN = cross_val_score(DecisionTree, X, y_balanced, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(DecisionTree.score(X, y_balanced))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(depth,cv_val_scores.mean(),DecisionTree.score(X, y_balanced))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)",
                "OptDepth=np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)",
                "OptDepth=np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(depths, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(depths, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(depths, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"decision tree accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Tree depth', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(depths)",
                "ax.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(depths, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(depths, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(depths, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"decision tree accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Tree depth', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(depths)",
                "ax.legend()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "DecisionTree = DecisionTreeClassifier(",
                "ASSIGN='gini', random_state=0, max_depth=OptDepth)",
                "DecisionTree.fit(X, y_balanced)",
                "ASSIGN = cross_validate(DecisionTree, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==3,\"method\"]=\"decision-tree _balanced bins\"",
                "df_resultat.at[df_resultat.index==3,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(,DecisionTree.score(X, y_balanced))",
                "print(,np.mean(ASSIGN['test_score']))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "DecisionTree = DecisionTreeClassifier(",
                "ASSIGN='gini', random_state=0, max_depth=OptDepth)",
                "DecisionTree.fit(X, y_balanced)",
                "ASSIGN = cross_validate(DecisionTree, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==3,\"method\"]=\"decision-tree _balanced bins\"",
                "df_resultat.at[df_resultat.index==3,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print(,DecisionTree.score(X, y_balanced))",
                "print(,np.mean(ASSIGN['test_score']))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "DecisionTree_confusion = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=OptDepth)",
                "DecisionTree_confusion.fit(X_tr_balan, y_tr_balan)",
                "confusion_matrix(y_te_balan, DecisionTree_confusion.predict(X_te_balan))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "DecisionTree_confusion = DecisionTreeClassifier(criterion='gini',  random_state=0, max_depth=OptDepth)",
                "DecisionTree_confusion.fit(X_tr_balan, y_tr_balan)",
                "confusion_matrix(y_te_balan, DecisionTree_confusion.predict(X_te_balan))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(DecisionTree_confusion, X_te_balan, y_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(DecisionTree_confusion, X_te_balan, y_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "os.environ[\"PATH\"] += os.pathsep + 'D:path(x86)path'",
                "ASSIGN = export_graphviz(",
                "DecisionTree, out_file=None,",
                "ASSIGN=X.columns, class_names=[Level1_balanced,Level2_balanced, Level3_balanced,Level4_balanced,Level5_balanced,Level6_balanced],",
                "ASSIGN=True, rounded=True, proportion=True",
                ")",
                "graphviz.Source(ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "os.environ[\"PATH\"] += os.pathsep + 'D:path(x86)path'",
                "ASSIGN = export_graphviz(",
                "DecisionTree, out_file=None,",
                "ASSIGN=X.columns, class_names=[Level1_balanced,Level2_balanced, Level3_balanced,Level4_balanced,Level5_balanced,Level6_balanced],",
                "ASSIGN=True, rounded=True, proportion=True",
                ")",
                "graphviz.Source(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=range(100,2000,100)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for Estimator in ASSIGN:",
                "ASSIGN = RandomForestClassifier(n_estimators=Estimator,random_state=0)",
                "ASSIGN.fit(X, y_equidistant)",
                "ASSIGN = cross_val_score(forest, X, y_equidistant, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(ASSIGN.fit(X, y_equidistant).score(X, y_equidistant))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(Estimator,cv_val_scores.mean(),forest.score(X, y_equidistant))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=range(100,2000,100)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for Estimator in ASSIGN:",
                "ASSIGN = RandomForestClassifier(n_estimators=Estimator,random_state=0)",
                "ASSIGN.fit(X, y_equidistant)",
                "ASSIGN = cross_val_score(forest, X, y_equidistant, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(ASSIGN.fit(X, y_equidistant).score(X, y_equidistant))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(Estimator,cv_val_scores.mean(),forest.score(X, y_equidistant))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100)",
                "OptEstimator=(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100)",
                "OptEstimator=(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(Estimators, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(Estimators, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(Estimators, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"Forest accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Forest Estimator', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(Estimators)",
                "ax.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(Estimators, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(Estimators, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(Estimators, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"Forest accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Forest Estimator', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(Estimators)",
                "ax.legend()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X, y_equidistant)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X, y_equidistant)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = cross_validate(forest, X, y_equidistant, cv=cv_strategy)",
                "print('Forest by equidistant interval score {:.3f}'.format(forest.score(X, y_equidistant)))",
                "df_resultat.at[df_resultat.index==4,\"method\"]=\"Forest equidistant\"",
                "df_resultat.at[df_resultat.index==4,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('Forest by equidistant interval cross validation {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = cross_validate(forest, X, y_equidistant, cv=cv_strategy)",
                "print('Forest by equidistant interval score {:.3f}'.format(forest.score(X, y_equidistant)))",
                "df_resultat.at[df_resultat.index==4,\"method\"]=\"Forest equidistant\"",
                "df_resultat.at[df_resultat.index==4,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('Forest by equidistant interval cross validation {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X_tr_equid, y_tr_equid)",
                "confusion_matrix(y_te_equid, ASSIGN.predict(X_te_equid))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X_tr_equid, y_tr_equid)",
                "confusion_matrix(y_te_equid, ASSIGN.predict(X_te_equid))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "plot_confusion_matrix(forest_confusion, X_te_equid,y_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plot_confusion_matrix(forest_confusion, X_te_equid,y_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = forest.feature_importances_",
                "ASSIGN = np.ASSIGN([tree.feature_importances_ for tree in forest.estimators_],",
                "ASSIGN=0)",
                "ASSIGN = np.argsort(importances)[::-1]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = forest.feature_importances_",
                "ASSIGN = np.ASSIGN([tree.feature_importances_ for tree in forest.estimators_],",
                "ASSIGN=0)",
                "ASSIGN = np.argsort(importances)[::-1]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print()",
                "for f in range(X.shape[1]):",
                "print( % (f + 1, X.columns[indices[f]], importances[indices[f]]))",
                "plt.figure(figsize=(20,10))",
                "plt.title(\"Feature importances\")",
                "plt.bar(range(X.shape[1]), importances[indices],",
                "ASSIGN=\"r\", yerr=std[indices], align=\"center\")",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 65)",
                "plt.xlim([-1, X.shape[1]])",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print()",
                "for f in range(X.shape[1]):",
                "print( % (f + 1, X.columns[indices[f]], importances[indices[f]]))",
                "plt.figure(figsize=(20,10))",
                "plt.title(\"Feature importances\")",
                "plt.bar(range(X.shape[1]), importances[indices],",
                "ASSIGN=\"r\", yerr=std[indices], align=\"center\")",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 65)",
                "plt.xlim([-1, X.shape[1]])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=range(100,2000,100)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for Estimator in ASSIGN:",
                "ASSIGN = RandomForestClassifier(n_estimators=Estimator,random_state=0)",
                "ASSIGN.fit(X, y_balanced)",
                "ASSIGN = cross_val_score(forest, X, y_balanced, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(ASSIGN.fit(X, y_balanced).score(X, y_balanced))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(Estimator,cv_val_scores.mean(),forest.score(X, y_balanced))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=range(100,2000,100)",
                "ASSIGN='accuracy'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for Estimator in ASSIGN:",
                "ASSIGN = RandomForestClassifier(n_estimators=Estimator,random_state=0)",
                "ASSIGN.fit(X, y_balanced)",
                "ASSIGN = cross_val_score(forest, X, y_balanced, cv=cv_strategy, scoring=scoring)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN.mean())",
                "ASSIGN.append(ASSIGN.std())",
                "ASSIGN.append(ASSIGN.fit(X, y_balanced).score(X, y_balanced))",
                "ASSIGN=\"depth %d, cv_val_scores_mean %f score %f\"%(Estimator,cv_val_scores.mean(),forest.score(X, y_balanced))",
                "print(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100)",
                "OptEstimator=(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100)",
                "OptEstimator=(np.where(cv_val_scores_mean==cv_val_scores_mean.max())[0][0]+1)*100"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(Estimators, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(Estimators, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(Estimators, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"Forest accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Forest Estimator', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(Estimators)",
                "ax.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(1,1, figsize=(15,5))",
                "ax.plot(Estimators, cv_val_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)",
                "ax.fill_between(Estimators, cv_val_scores_mean-2*cv_val_scores_std, cv_val_scores_mean+2*cv_val_scores_std, alpha=0.2)",
                "ASSIGN = plt.ASSIGN()",
                "ax.plot(Estimators, accuracy_scores, '-*', label='training_scores', alpha=0.9)",
                "ASSIGN=\"Forest accurency - _balanced bins\"",
                "ax.set_title(ASSIGN, fontsize=16)",
                "ax.set_xlabel('Forest Estimator', fontsize=14)",
                "ax.set_ylabel('accuracy', fontsize=14)",
                "ax.set_xticks(Estimators)",
                "ax.legend()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = cross_validate(forest, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==5,\"method\"]=\"Forest balanced bins\"",
                "df_resultat.at[df_resultat.index==5,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('Forest by balanced bins of element score {:.3f}'.format(forest.score(X, y_balanced)))",
                "print('Forest by balanced bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = cross_validate(forest, X, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==5,\"method\"]=\"Forest balanced bins\"",
                "df_resultat.at[df_resultat.index==5,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('Forest by balanced bins of element score {:.3f}'.format(forest.score(X, y_balanced)))",
                "print('Forest by balanced bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X_tr_balan, y_tr_balan)",
                "confusion_matrix(y_te_balan, ASSIGN.predict(X_te_balan))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = RandomForestClassifier(n_estimators=OptEstimator,random_state=0)",
                "ASSIGN.fit(X_tr_balan, y_tr_balan)",
                "confusion_matrix(y_te_balan, ASSIGN.predict(X_te_balan))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "plot_confusion_matrix(forest_confusion, X_te_balan, y_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plot_confusion_matrix(forest_confusion, X_te_balan, y_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = forest.feature_importances_",
                "ASSIGN = np.ASSIGN([tree.feature_importances_ for tree in forest.estimators_],",
                "ASSIGN=0)",
                "ASSIGN = np.argsort(importances)[::-1]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = forest.feature_importances_",
                "ASSIGN = np.ASSIGN([tree.feature_importances_ for tree in forest.estimators_],",
                "ASSIGN=0)",
                "ASSIGN = np.argsort(importances)[::-1]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print()",
                "for f in range(X.shape[1]):",
                "print( % (f + 1, X.columns[indices[f]], importances[indices[f]]))",
                "plt.figure(figsize=(20,10))",
                "plt.title(\"Feature importances\")",
                "plt.bar(range(X.shape[1]), importances[indices],",
                "ASSIGN=\"r\", yerr=std[indices], align=\"center\")",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 65)",
                "plt.xlim([-1, X.shape[1]])",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print()",
                "for f in range(X.shape[1]):",
                "print( % (f + 1, X.columns[indices[f]], importances[indices[f]]))",
                "plt.figure(figsize=(20,10))",
                "plt.title(\"Feature importances\")",
                "plt.bar(range(X.shape[1]), importances[indices],",
                "ASSIGN=\"r\", yerr=std[indices], align=\"center\")",
                "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 65)",
                "plt.xlim([-1, X.shape[1]])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = PCA(n_components=2)",
                "ASSIGN.fit(X, y=None);",
                "ASSIGN= pca.transform(X)",
                "ASSIGN=pd.DataFrame(feature_2)",
                "ASSIGN=feature_2_df.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = PCA(n_components=2)",
                "ASSIGN.fit(X, y=None);",
                "ASSIGN= pca.transform(X)",
                "ASSIGN=pd.DataFrame(feature_2)",
                "ASSIGN=feature_2_df.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_fea_2_tr_equid, X_fea_2_te_equid, y_fea_2_tr_equid, y_fea_2_te_equid = train_test_split(feature_2, y_equidistant, test_size=0.15, random_state=1)",
                "print('Train set equidistant:', X_fea_2_tr_equid.shape, y_fea_2_tr_equid.shape)",
                "print('Testn set equidistant:', X_fea_2_te_equid.shape, y_fea_2_te_equid.shape)",
                "X_fea_2_tr_balan, X_fea_2_te_balan, y_fea_2_tr_balan, y_fea_2_te_balan = train_test_split(feature_2, y_balanced, test_size=0.15, random_state=1)",
                "print('Train set balanced:', X_fea_2_tr_balan.shape, y_fea_2_tr_balan.shape)",
                "print('Testn set balanced:', X_fea_2_te_balan.shape, y_fea_2_te_balan.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "X_fea_2_tr_equid, X_fea_2_te_equid, y_fea_2_tr_equid, y_fea_2_te_equid = train_test_split(feature_2, y_equidistant, test_size=0.15, random_state=1)",
                "print('Train set equidistant:', X_fea_2_tr_equid.shape, y_fea_2_tr_equid.shape)",
                "print('Testn set equidistant:', X_fea_2_te_equid.shape, y_fea_2_te_equid.shape)",
                "X_fea_2_tr_balan, X_fea_2_te_balan, y_fea_2_tr_balan, y_fea_2_te_balan = train_test_split(feature_2, y_balanced, test_size=0.15, random_state=1)",
                "print('Train set balanced:', X_fea_2_tr_balan.shape, y_fea_2_tr_balan.shape)",
                "print('Testn set balanced:', X_fea_2_te_balan.shape, y_fea_2_te_balan.shape)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = list(range(1,25))",
                "ASSIGN = []",
                "for n_neighborss in ASSIGN:",
                "ASSIGN='distance'",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=n_neighborss, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_equidistant)",
                "ASSIGN = knn_pipe.predict(feature_2)",
                "ASSIGN = cross_val_score(knn_pipe,feature_2,y_equidistant,cv=cv_strategy )",
                "ASSIGN.append(ASSIGN.mean())",
                "Missclassification_Error = [1-x for x in ASSIGN]",
                "print(,format(Missclassification_Error.index(min(Missclassification_Error))))",
                "ASSIGN=Missclassification_Error.index(min(Missclassification_Error))",
                "plt.plot( Missclassification_Error)",
                "plt.xlabel(\"number of ASSIGN K\")",
                "plt.ylabel(\"Missclassification Error\")",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = list(range(1,25))",
                "ASSIGN = []",
                "for n_neighborss in ASSIGN:",
                "ASSIGN='distance'",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=n_neighborss, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_equidistant)",
                "ASSIGN = knn_pipe.predict(feature_2)",
                "ASSIGN = cross_val_score(knn_pipe,feature_2,y_equidistant,cv=cv_strategy )",
                "ASSIGN.append(ASSIGN.mean())",
                "Missclassification_Error = [1-x for x in ASSIGN]",
                "print(,format(Missclassification_Error.index(min(Missclassification_Error))))",
                "ASSIGN=Missclassification_Error.index(min(Missclassification_Error))",
                "plt.plot( Missclassification_Error)",
                "plt.xlabel(\"number of ASSIGN K\")",
                "plt.ylabel(\"Missclassification Error\")",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = ListedColormap(['",
                "ASSIGN = ListedColormap(['",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN='distance'",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_equidistant)",
                "feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))",
                "ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])",
                "ASSIGN = Z.reshape(xx.shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ListedColormap(['",
                "ASSIGN = ListedColormap(['",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN='distance'",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_equidistant)",
                "feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))",
                "ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])",
                "ASSIGN = Z.reshape(xx.shape)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(18, 10))",
                "plt.pcolormesh(xx, yy, Zo, cmap=cmap_light)",
                "Label1=pd.DataFrame([1,2,3,4,5])",
                "plt.scatter(feature1, feature2, c=y_equidistant, cmap=cmap_bold)",
                "ASSIGN = plt.colorbar()",
                "ASSIGN.ax.set_yticklabels([Level1_equidistant,Level2_equidistant,Level3_equidistant,Level4_equidistant,Level5_equidistant,Level6_equidistant])",
                "plt.xlim(xx.min(), xx.max())",
                "plt.ylim(yy.min(), yy.max())",
                "plt.xlabel(\"feature 1\")",
                "plt.ylabel(\"feature 2\")",
                "plt.title(\"6-Class classification,  equidistant bins - total infected log10 (k = %i, weights = '%s')\" % (k_Optimal, weights))",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(18, 10))",
                "plt.pcolormesh(xx, yy, Zo, cmap=cmap_light)",
                "Label1=pd.DataFrame([1,2,3,4,5])",
                "plt.scatter(feature1, feature2, c=y_equidistant, cmap=cmap_bold)",
                "ASSIGN = plt.colorbar()",
                "ASSIGN.ax.set_yticklabels([Level1_equidistant,Level2_equidistant,Level3_equidistant,Level4_equidistant,Level5_equidistant,Level6_equidistant])",
                "plt.xlim(xx.min(), xx.max())",
                "plt.ylim(yy.min(), yy.max())",
                "plt.xlabel(\"feature 1\")",
                "plt.ylabel(\"feature 2\")",
                "plt.title(\"6-Class classification,  equidistant bins - total infected log10 (k = %i, weights = '%s')\" % (k_Optimal, weights))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = cross_validate(knn_pipe, feature_2, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==6,\"method\"]=\"knn equidistant bins\"",
                "df_resultat.at[df_resultat.index==6,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('knn by equidistant bins of element score {:.3f}'.format(knn_pipe.score(feature_2, y_equidistant)))",
                "print('knn by equidistant bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = cross_validate(knn_pipe, feature_2, y_equidistant, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==6,\"method\"]=\"knn equidistant bins\"",
                "df_resultat.at[df_resultat.index==6,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('knn by equidistant bins of element score {:.3f}'.format(knn_pipe.score(feature_2, y_equidistant)))",
                "print('knn by equidistant bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))",
                "])",
                "ASSIGN=knn_pipe.fit(X_fea_2_tr_equid, y_fea_2_tr_equid)",
                "ASSIGN = knn_pipe.predict(X_fea_2_te_equid)",
                "confusion_matrix(y_fea_2_te_equid, ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))",
                "])",
                "ASSIGN=knn_pipe.fit(X_fea_2_tr_equid, y_fea_2_tr_equid)",
                "ASSIGN = knn_pipe.predict(X_fea_2_te_equid)",
                "confusion_matrix(y_fea_2_te_equid, ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "plot_confusion_matrix(knn_confusion, X_fea_2_te_equid, y_fea_2_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plot_confusion_matrix(knn_confusion, X_fea_2_te_equid, y_fea_2_te_equid,cmap=plt.cm.Blues,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = list(range(1,25))",
                "ASSIGN = []",
                "for n_neighborss in ASSIGN:",
                "ASSIGN='distance'",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=n_neighborss, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_balanced)",
                "ASSIGN = knn_pipe.predict(feature_2)",
                "ASSIGN = cross_val_score(knn_pipe,feature_2,y_balanced,cv=cv_strategy )",
                "ASSIGN.append(ASSIGN.mean())",
                "Missclassification_Error = [1-x for x in ASSIGN]",
                "print(,format(Missclassification_Error.index(min(Missclassification_Error))))",
                "ASSIGN=Missclassification_Error.index(min(Missclassification_Error))",
                "plt.plot( Missclassification_Error)",
                "plt.xlabel(\"number of ASSIGN K\")",
                "plt.ylabel(\"Missclassification Error\")",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = list(range(1,25))",
                "ASSIGN = []",
                "for n_neighborss in ASSIGN:",
                "ASSIGN='distance'",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=n_neighborss, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_balanced)",
                "ASSIGN = knn_pipe.predict(feature_2)",
                "ASSIGN = cross_val_score(knn_pipe,feature_2,y_balanced,cv=cv_strategy )",
                "ASSIGN.append(ASSIGN.mean())",
                "Missclassification_Error = [1-x for x in ASSIGN]",
                "print(,format(Missclassification_Error.index(min(Missclassification_Error))))",
                "ASSIGN=Missclassification_Error.index(min(Missclassification_Error))",
                "plt.plot( Missclassification_Error)",
                "plt.xlabel(\"number of ASSIGN K\")",
                "plt.ylabel(\"Missclassification Error\")",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = ListedColormap(['",
                "ASSIGN = ListedColormap(['",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN='distance'",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_balanced)",
                "feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))",
                "ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])",
                "ASSIGN = Z.reshape(xx.shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ListedColormap(['",
                "ASSIGN = ListedColormap(['",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][0]",
                "ASSIGN=pd.DataFrame(feature_2).loc[:][1]",
                "ASSIGN='distance'",
                "ASSIGN = .02",
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, ASSIGN=ASSIGN))",
                "])",
                "ASSIGN.fit(feature_2, y_balanced)",
                "feature1_min, feature1_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "feature2_min, feature2_max = ASSIGN.min() - 1, ASSIGN.max() + 1",
                "ASSIGN = np.meshgrid(np.arange(feature1_min, feature1_max, h), np.arange(feature2_min, feature2_max, h))",
                "ASSIGN = knn_pipe.predict(np.c_[xx.ravel(), yy.ravel()])",
                "ASSIGN = Z.reshape(xx.shape)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(18, 10))",
                "plt.pcolormesh(xx, yy, Zo, cmap=cmap_light)",
                "Label1=pd.DataFrame([1,2,3,4,5])",
                "plt.scatter(feature1, feature2, c=y_balanced, cmap=cmap_bold)",
                "ASSIGN = plt.colorbar()",
                "ASSIGN.ax.set_yticklabels([Level1_balanced,Level2_balanced,Level3_balanced,Level4_balanced,Level5_balanced,Level6_balanced])",
                "plt.xlim(xx.min(), xx.max())",
                "plt.ylim(yy.min(), yy.max())",
                "plt.xlabel(\"feature 1\")",
                "plt.ylabel(\"feature 2\")",
                "plt.title(\"6-Class classification,  balanced bins - total infected log10 (k = %i, weights = '%s')\" % (k_Optimal, weights))",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(18, 10))",
                "plt.pcolormesh(xx, yy, Zo, cmap=cmap_light)",
                "Label1=pd.DataFrame([1,2,3,4,5])",
                "plt.scatter(feature1, feature2, c=y_balanced, cmap=cmap_bold)",
                "ASSIGN = plt.colorbar()",
                "ASSIGN.ax.set_yticklabels([Level1_balanced,Level2_balanced,Level3_balanced,Level4_balanced,Level5_balanced,Level6_balanced])",
                "plt.xlim(xx.min(), xx.max())",
                "plt.ylim(yy.min(), yy.max())",
                "plt.xlabel(\"feature 1\")",
                "plt.ylabel(\"feature 2\")",
                "plt.title(\"6-Class classification,  balanced bins - total infected log10 (k = %i, weights = '%s')\" % (k_Optimal, weights))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = cross_validate(knn_pipe, feature_2, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==7,\"method\"]=\"knn balanced bins\"",
                "df_resultat.at[df_resultat.index==7,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('knn by equidistant bins of element score {:.3f}'.format(knn_pipe.score(feature_2, y_balanced)))",
                "print('knn by equidistant bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = cross_validate(knn_pipe, feature_2, y_balanced, cv=cv_strategy)",
                "df_resultat.at[df_resultat.index==7,\"method\"]=\"knn balanced bins\"",
                "df_resultat.at[df_resultat.index==7,\"Cross-validation\"]=np.mean(ASSIGN['test_score'])",
                "print('knn by equidistant bins of element score {:.3f}'.format(knn_pipe.score(feature_2, y_balanced)))",
                "print('knn by equidistant bins of element - mean test {:.3f}'.format(np.mean(ASSIGN['test_score'])))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))",
                "])",
                "ASSIGN=knn_pipe.fit(X_fea_2_tr_balan, y_fea_2_tr_balan)",
                "ASSIGN = knn_pipe.predict(X_fea_2_te_balan)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Pipeline([",
                "('scaler', StandardScaler()),",
                "('knn', KNeighborsClassifier(n_neighbors=k_Optimal, weights=weights))",
                "])",
                "ASSIGN=knn_pipe.fit(X_fea_2_tr_balan, y_fea_2_tr_balan)",
                "ASSIGN = knn_pipe.predict(X_fea_2_te_balan)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "confusion_matrix(y_fea_2_te_balan, knn_predict)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "confusion_matrix(y_fea_2_te_balan, knn_predict)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "plot_confusion_matrix(knn_confusion, X_fea_2_te_balan, y_fea_2_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plot_confusion_matrix(knn_confusion, X_fea_2_te_balan, y_fea_2_te_balan,cmap=plt.cm.Greens,display_labels=[1,2,3,4,5,6])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_resultat"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df_resultat"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.barplot(x=df_resultat[\"Cross-validation\"],y=df_resultat['method'])",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.barplot(x=df_resultat[\"Cross-validation\"],y=df_resultat['method'])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "codiv_time_confirmed"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "codiv_time_confirmed"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=codiv_time_confirmed.groupby('Countrypath').sum().reset_index()",
                "ASSIGN=codiv_time_confirmed_grouped.agg(['sum'])",
                "SLICE=\"total_confirmed\"",
                "ASSIGN=codiv_time_confirmed_grouped.append(dfsum)",
                "ASSIGN=codiv_time_recovered.groupby('Countrypath').sum().reset_index()",
                "ASSIGN=codiv_time_recovered_grouped.agg(['sum'])",
                "SLICE=\"total_recovered\"",
                "ASSIGN=codiv_time_recovered_grouped.append(dfsum)",
                "ASSIGN=codiv_time_deaths.groupby('Countrypath').sum().reset_index()",
                "ASSIGN=codiv_time_deaths_grouped.agg(['sum'])",
                "SLICE=\"total_deaths\"",
                "ASSIGN=codiv_time_deaths_grouped.append(dfsum)",
                "codiv_time_deaths_grouped_sum"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=codiv_time_confirmed.groupby('Countrypath').sum().reset_index()",
                "ASSIGN=codiv_time_confirmed_grouped.agg(['sum'])",
                "SLICE=\"total_confirmed\"",
                "ASSIGN=codiv_time_confirmed_grouped.append(dfsum)",
                "ASSIGN=codiv_time_recovered.groupby('Countrypath').sum().reset_index()",
                "ASSIGN=codiv_time_recovered_grouped.agg(['sum'])",
                "SLICE=\"total_recovered\"",
                "ASSIGN=codiv_time_recovered_grouped.append(dfsum)",
                "ASSIGN=codiv_time_deaths.groupby('Countrypath').sum().reset_index()",
                "ASSIGN=codiv_time_deaths_grouped.agg(['sum'])",
                "SLICE=\"total_deaths\"",
                "ASSIGN=codiv_time_deaths_grouped.append(dfsum)",
                "codiv_time_deaths_grouped_sum"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "ASSIGN=1",
                "for countryInd in codiv_country_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_Restrictions['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_without_Restrictions_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_Restrictions['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_without_Restrictions_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_Restrictions['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_without_Restrictions_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=1",
                "for countryInd in codiv_country_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_Restrictions['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_without_Restrictions_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_recovered_grouped_sum[codiv_time_recovered_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_Restrictions['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_without_Restrictions_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_deaths_grouped_sum[codiv_time_deaths_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_Restrictions['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd])",
                "ASSIGN=1",
                "for countryInd in codiv_country_without_Restrictions_qurantine['Country']:",
                "if not codiv_country_short[codiv_country_short['Country']==countryInd].empty:",
                "ASSIGN==1:",
                "ASSIGN=codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd]",
                "ASSIGN=0",
                "else:",
                "ASSIGN=ASSIGN.append(codiv_time_confirmed_grouped_sum[codiv_time_confirmed_grouped_sum['Countrypath']==countryInd])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN= codiv_country_without_Restrictions_qurantine_confirmed.set_index('Countrypath')-codiv_country_without_Restrictions_qurantine_deaths.set_index('Countrypath')-codiv_country_without_Restrictions_qurantine_recovered.set_index('Countrypath')",
                "ASSIGN= codiv_country_qurantine_confirmed.set_index('Countrypath')-codiv_country_qurantine_deaths.set_index('Countrypath')-codiv_country_qurantine_recovered.set_index('Countrypath')",
                "ASSIGN= codiv_country_Restrictions_confirmed.set_index('Countrypath')- codiv_country_Restrictions_deaths.set_index('Countrypath')-codiv_country_Restrictions_recovered.set_index('Countrypath')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN= codiv_country_without_Restrictions_qurantine_confirmed.set_index('Countrypath')-codiv_country_without_Restrictions_qurantine_deaths.set_index('Countrypath')-codiv_country_without_Restrictions_qurantine_recovered.set_index('Countrypath')",
                "ASSIGN= codiv_country_qurantine_confirmed.set_index('Countrypath')-codiv_country_qurantine_deaths.set_index('Countrypath')-codiv_country_qurantine_recovered.set_index('Countrypath')",
                "ASSIGN= codiv_country_Restrictions_confirmed.set_index('Countrypath')- codiv_country_Restrictions_deaths.set_index('Countrypath')-codiv_country_Restrictions_recovered.set_index('Countrypath')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "AutoMinorLocator)",
                "ASSIGN= codiv_country_qurantine_confirmed.shape",
                "fig, (ax0,ax1,ax2) = plt.subplots(3, sharey=True,figsize=(25,40))",
                "ASSIGN = pd.Series(",
                "np.random.randn(col-1),",
                "ASSIGN=pd.date_range('20path', periods=col-1))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_qurantine_confirmed.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_qurantine_confirmed.set_index('Countrypath').index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_Restrictions_confirmed.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_Restrictions_confirmed.set_index('Countrypath').index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_without_Restrictions_qurantine_confirmed.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_without_Restrictions_qurantine_confirmed.set_index('Countrypath').index))",
                "ax0.plot(ASSIGN.ASSIGN,ASSIGN)",
                "ax1.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax2.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax0.set_title(\"quarantine_confirmed\")",
                "ax1.set_title(\"Restrictions_confirmed\")",
                "ax2.set_title(\"without_Restrictions_quarantine_confirmed\")",
                "ax0.legend(codiv_country_qurantine_confirmed['Countrypath'].tolist(),loc='upper left')",
                "ax1.legend(codiv_country_Restrictions_confirmed['Countrypath'].tolist(),loc='upper left')",
                "ax2.legend(codiv_country_without_Restrictions_qurantine_confirmed['Countrypath'].tolist(),loc='upper left')",
                "ax0.set_ylabel(\"quarantine_confirmed\")",
                "ax1.set_ylabel(\"Restrictions_confirmed\")",
                "ax2.set_ylabel(\"without_Restrictions_quarantine_confirmed\")",
                "ax0.grid(True)",
                "ax0.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax1.grid(True)",
                "ax1.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax2.grid(True)",
                "ax2.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax0.tick_params(axis=\"x\", rotation=45)",
                "ax1.tick_params(axis=\"x\", rotation=45)",
                "ax2.tick_params(axis=\"x\", rotation=45)",
                "for countryindex in codiv_country_qurantine_confirmed['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]!=\"2000-01-01\" and countryindex!=\"New Zealand\":",
                "QuarantineTime=codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]",
                "QuarantineTimeD = datetime.datetime.strptime(str(QuarantineTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_qua_conf[df_qua_conf.index==QuarantineTimeD][countryindex].values[0]",
                "ax0.annotate('Quarantine', (QuarantineTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')",
                "for countryindex in codiv_country_Restrictions_confirmed['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]!=\"2000-01-01\":",
                "RestrictionsTime=codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]",
                "RestrictionsTimeD = datetime.datetime.strptime(str(RestrictionsTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_res_conf[df_res_conf.index==RestrictionsTimeD][countryindex].values[0]",
                "ax1.annotate('Restrictions', (RestrictionsTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "AutoMinorLocator)",
                "ASSIGN= codiv_country_qurantine_confirmed.shape",
                "fig, (ax0,ax1,ax2) = plt.subplots(3, sharey=True,figsize=(25,40))",
                "ASSIGN = pd.Series(",
                "np.random.randn(col-1),",
                "ASSIGN=pd.date_range('20path', periods=col-1))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_qurantine_confirmed.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_qurantine_confirmed.set_index('Countrypath').index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_Restrictions_confirmed.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_Restrictions_confirmed.set_index('Countrypath').index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_without_Restrictions_qurantine_confirmed.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_without_Restrictions_qurantine_confirmed.set_index('Countrypath').index))",
                "ax0.plot(ASSIGN.ASSIGN,ASSIGN)",
                "ax1.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax2.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax0.set_title(\"quarantine_confirmed\")",
                "ax1.set_title(\"Restrictions_confirmed\")",
                "ax2.set_title(\"without_Restrictions_quarantine_confirmed\")",
                "ax0.legend(codiv_country_qurantine_confirmed['Countrypath'].tolist(),loc='upper left')",
                "ax1.legend(codiv_country_Restrictions_confirmed['Countrypath'].tolist(),loc='upper left')",
                "ax2.legend(codiv_country_without_Restrictions_qurantine_confirmed['Countrypath'].tolist(),loc='upper left')",
                "ax0.set_ylabel(\"quarantine_confirmed\")",
                "ax1.set_ylabel(\"Restrictions_confirmed\")",
                "ax2.set_ylabel(\"without_Restrictions_quarantine_confirmed\")",
                "ax0.grid(True)",
                "ax0.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax1.grid(True)",
                "ax1.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax2.grid(True)",
                "ax2.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax0.tick_params(axis=\"x\", rotation=45)",
                "ax1.tick_params(axis=\"x\", rotation=45)",
                "ax2.tick_params(axis=\"x\", rotation=45)",
                "for countryindex in codiv_country_qurantine_confirmed['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]!=\"2000-01-01\" and countryindex!=\"New Zealand\":",
                "QuarantineTime=codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]",
                "QuarantineTimeD = datetime.datetime.strptime(str(QuarantineTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_qua_conf[df_qua_conf.index==QuarantineTimeD][countryindex].values[0]",
                "ax0.annotate('Quarantine', (QuarantineTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')",
                "for countryindex in codiv_country_Restrictions_confirmed['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]!=\"2000-01-01\":",
                "RestrictionsTime=codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]",
                "RestrictionsTimeD = datetime.datetime.strptime(str(RestrictionsTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_res_conf[df_res_conf.index==RestrictionsTimeD][countryindex].values[0]",
                "ax1.annotate('Restrictions', (RestrictionsTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "AutoMinorLocator)",
                "ASSIGN= codiv_country_qurantine_deaths.shape",
                "fig, (ax0,ax1,ax2) = plt.subplots(3, sharey=True,figsize=(25,40))",
                "ASSIGN = pd.Series(",
                "np.random.randn(col-1),",
                "ASSIGN=pd.date_range('20path', periods=col-1))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_qurantine_deaths.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_qurantine_deaths.set_index('Countrypath').index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_Restrictions_deaths.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_Restrictions_deaths.set_index('Countrypath').index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_without_Restrictions_qurantine_deaths.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_without_Restrictions_qurantine_deaths.set_index('Countrypath').index))",
                "ax0.plot(ASSIGN.ASSIGN,ASSIGN)",
                "ax1.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax2.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax0.set_title(\"quarantine_deaths\")",
                "ax1.set_title(\"Restrictions_deaths\")",
                "ax2.set_title(\"without_Restrictions_quarantine_deaths\")",
                "ax0.legend(codiv_country_qurantine_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax1.legend(codiv_country_Restrictions_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax2.legend(codiv_country_without_Restrictions_qurantine_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax0.set_ylabel(\"quarantine_deaths\")",
                "ax1.set_ylabel(\"Restrictions_deaths\")",
                "ax2.set_ylabel(\"without_Restrictions_quarantine_deaths\")",
                "ax0.grid(True)",
                "ax0.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax1.grid(True)",
                "ax1.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax2.grid(True)",
                "ax2.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax0.tick_params(axis=\"x\", rotation=45)",
                "ax1.tick_params(axis=\"x\", rotation=45)",
                "ax2.tick_params(axis=\"x\", rotation=45)",
                "for countryindex in codiv_country_qurantine_deaths['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]!=\"2000-01-01\" and countryindex!=\"New Zealand\":",
                "QuarantineTime=codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]",
                "QuarantineTimeD = datetime.datetime.strptime(str(QuarantineTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_qua_conf[df_qua_conf.index==QuarantineTimeD][countryindex].values[0]",
                "ax0.annotate('Quarantine', (QuarantineTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')",
                "for countryindex in codiv_country_Restrictions_deaths['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]!=\"2000-01-01\":",
                "RestrictionsTime=codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]",
                "RestrictionsTimeD = datetime.datetime.strptime(str(RestrictionsTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_res_conf[df_res_conf.index==RestrictionsTimeD][countryindex].values[0]",
                "ax1.annotate('Restrictions', (RestrictionsTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "AutoMinorLocator)",
                "ASSIGN= codiv_country_qurantine_deaths.shape",
                "fig, (ax0,ax1,ax2) = plt.subplots(3, sharey=True,figsize=(25,40))",
                "ASSIGN = pd.Series(",
                "np.random.randn(col-1),",
                "ASSIGN=pd.date_range('20path', periods=col-1))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_qurantine_deaths.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_qurantine_deaths.set_index('Countrypath').index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_Restrictions_deaths.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_Restrictions_deaths.set_index('Countrypath').index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_without_Restrictions_qurantine_deaths.set_index('Countrypath').T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_without_Restrictions_qurantine_deaths.set_index('Countrypath').index))",
                "ax0.plot(ASSIGN.ASSIGN,ASSIGN)",
                "ax1.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax2.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax0.set_title(\"quarantine_deaths\")",
                "ax1.set_title(\"Restrictions_deaths\")",
                "ax2.set_title(\"without_Restrictions_quarantine_deaths\")",
                "ax0.legend(codiv_country_qurantine_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax1.legend(codiv_country_Restrictions_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax2.legend(codiv_country_without_Restrictions_qurantine_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax0.set_ylabel(\"quarantine_deaths\")",
                "ax1.set_ylabel(\"Restrictions_deaths\")",
                "ax2.set_ylabel(\"without_Restrictions_quarantine_deaths\")",
                "ax0.grid(True)",
                "ax0.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax1.grid(True)",
                "ax1.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax2.grid(True)",
                "ax2.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax0.tick_params(axis=\"x\", rotation=45)",
                "ax1.tick_params(axis=\"x\", rotation=45)",
                "ax2.tick_params(axis=\"x\", rotation=45)",
                "for countryindex in codiv_country_qurantine_deaths['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]!=\"2000-01-01\" and countryindex!=\"New Zealand\":",
                "QuarantineTime=codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]",
                "QuarantineTimeD = datetime.datetime.strptime(str(QuarantineTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_qua_conf[df_qua_conf.index==QuarantineTimeD][countryindex].values[0]",
                "ax0.annotate('Quarantine', (QuarantineTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')",
                "for countryindex in codiv_country_Restrictions_deaths['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]!=\"2000-01-01\":",
                "RestrictionsTime=codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]",
                "RestrictionsTimeD = datetime.datetime.strptime(str(RestrictionsTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_res_conf[df_res_conf.index==RestrictionsTimeD][countryindex].values[0]",
                "ax1.annotate('Restrictions', (RestrictionsTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "AutoMinorLocator)",
                "ASSIGN= codiv_country_qurantine_active.shape",
                "fig, (ax0,ax1,ax2) = plt.subplots(3, sharey=True,figsize=(25,40))",
                "ASSIGN = pd.Series(",
                "np.random.randn(col),",
                "ASSIGN=pd.date_range('20path', periods=col))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_qurantine_active.T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_qurantine_active.index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_Restrictions_active.T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_Restrictions_active.index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_without_Restrictions_qurantine_active.T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_without_Restrictions_qurantine_active.index))",
                "ax0.plot(ASSIGN.ASSIGN,ASSIGN)",
                "ax1.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax2.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax0.set_title(\"quarantine_active\")",
                "ax1.set_title(\"Restrictions_active\")",
                "ax2.set_title(\"without_Restrictions_quarantine_active\")",
                "ax0.legend(codiv_country_qurantine_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax1.legend(codiv_country_Restrictions_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax2.legend(codiv_country_without_Restrictions_qurantine_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax0.set_ylabel(\"quarantine_active\")",
                "ax1.set_ylabel(\"Restrictions_active\")",
                "ax2.set_ylabel(\"without_Restrictions_qurantine_active\")",
                "ax0.grid(True)",
                "ax0.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax1.grid(True)",
                "ax1.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax2.grid(True)",
                "ax2.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax0.tick_params(axis=\"x\", rotation=45)",
                "ax1.tick_params(axis=\"x\", rotation=45)",
                "ax2.tick_params(axis=\"x\", rotation=45)",
                "for countryindex in codiv_country_qurantine_deaths['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]!=\"2000-01-01\" and countryindex!=\"New Zealand\":",
                "QuarantineTime=codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]",
                "QuarantineTimeD = datetime.datetime.strptime(str(QuarantineTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_qua_conf[df_qua_conf.index==QuarantineTimeD][countryindex].values[0]",
                "ax0.annotate('Quarantine', (QuarantineTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')",
                "for countryindex in codiv_country_Restrictions_deaths['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]!=\"2000-01-01\":",
                "RestrictionsTime=codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]",
                "RestrictionsTimeD = datetime.datetime.strptime(str(RestrictionsTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_res_conf[df_res_conf.index==RestrictionsTimeD][countryindex].values[0]",
                "ax1.annotate('Restrictions', (RestrictionsTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "AutoMinorLocator)",
                "ASSIGN= codiv_country_qurantine_active.shape",
                "fig, (ax0,ax1,ax2) = plt.subplots(3, sharey=True,figsize=(25,40))",
                "ASSIGN = pd.Series(",
                "np.random.randn(col),",
                "ASSIGN=pd.date_range('20path', periods=col))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_qurantine_active.T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_qurantine_active.index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_Restrictions_active.T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_Restrictions_active.index))",
                "ASSIGN = pd.DataFrame((np.log1p(codiv_country_without_Restrictions_qurantine_active.T).to_numpy()),",
                "ASSIGN=ts.ASSIGN,",
                "ASSIGN=list(codiv_country_without_Restrictions_qurantine_active.index))",
                "ax0.plot(ASSIGN.ASSIGN,ASSIGN)",
                "ax1.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax2.plot(ASSIGN.ASSIGN, ASSIGN)",
                "ax0.set_title(\"quarantine_active\")",
                "ax1.set_title(\"Restrictions_active\")",
                "ax2.set_title(\"without_Restrictions_quarantine_active\")",
                "ax0.legend(codiv_country_qurantine_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax1.legend(codiv_country_Restrictions_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax2.legend(codiv_country_without_Restrictions_qurantine_deaths['Countrypath'].tolist(),loc='upper left')",
                "ax0.set_ylabel(\"quarantine_active\")",
                "ax1.set_ylabel(\"Restrictions_active\")",
                "ax2.set_ylabel(\"without_Restrictions_qurantine_active\")",
                "ax0.grid(True)",
                "ax0.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax1.grid(True)",
                "ax1.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax2.grid(True)",
                "ax2.xaxis.set_minor_locator(AutoMinorLocator())",
                "ax0.tick_params(axis=\"x\", rotation=45)",
                "ax1.tick_params(axis=\"x\", rotation=45)",
                "ax2.tick_params(axis=\"x\", rotation=45)",
                "for countryindex in codiv_country_qurantine_deaths['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]!=\"2000-01-01\" and countryindex!=\"New Zealand\":",
                "QuarantineTime=codiv_country[codiv_country['Country']==countryindex]['Quarantine'].values[0]",
                "QuarantineTimeD = datetime.datetime.strptime(str(QuarantineTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_qua_conf[df_qua_conf.index==QuarantineTimeD][countryindex].values[0]",
                "ax0.annotate('Quarantine', (QuarantineTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')",
                "for countryindex in codiv_country_Restrictions_deaths['Countrypath']:",
                "if not codiv_country[codiv_country['Country']==countryindex].empty :",
                "if codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]!=\"2000-01-01\":",
                "RestrictionsTime=codiv_country[codiv_country['Country']==countryindex]['Restrictions'].values[0]",
                "RestrictionsTimeD = datetime.datetime.strptime(str(RestrictionsTime), \"%mpath%dpath%Y\")",
                "ASSIGN=df_res_conf[df_res_conf.index==RestrictionsTimeD][countryindex].values[0]",
                "ax1.annotate('Restrictions', (RestrictionsTimeD, ASSIGN),",
                "ASSIGN=(0.2, 0.95), textcoords='axes fraction',",
                "ASSIGN=dict(facecolor='red', shrink=0.001),",
                "ASSIGN=16,",
                "ASSIGN='right', verticalalignment='top')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "Image(filename=os.path.join('.path', 'shift.JPG'))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "Image(filename=os.path.join('.path', 'shift.JPG'))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "StartDate=codiv_country_Restrictions_active.T.index[0]",
                "print(,StartDate)",
                "ASSIGN = [\"date\"]",
                "ASSIGN = pd.DataFrame(columns = column_names)",
                "for Dateindex in range(20):",
                "ASSIGN = pd.DataFrame ([[str(pd.Timestamp(StartDate,unit=\"D\")+ pd.Timedelta(days=Dateindex))]], columns = [\"date\"])",
                "ASSIGN=ASSIGN.append(df_date1, ignore_index = True)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "StartDate=codiv_country_Restrictions_active.T.index[0]",
                "print(,StartDate)",
                "ASSIGN = [\"date\"]",
                "ASSIGN = pd.DataFrame(columns = column_names)",
                "for Dateindex in range(20):",
                "ASSIGN = pd.DataFrame ([[str(pd.Timestamp(StartDate,unit=\"D\")+ pd.Timedelta(days=Dateindex))]], columns = [\"date\"])",
                "ASSIGN=ASSIGN.append(df_date1, ignore_index = True)"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "def rmse(y, y_pred):",
                "return np.sqrt(np.mean(np.square(y - y_pred)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def rmse(y, y_pred):",
                "return np.sqrt(np.mean(np.square(y - y_pred)))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "def Polifq(Country,Version=\"restrictions\",shift=0,trigger=40):",
                "ASSIGN==\"restrictions\":",
                "ASSIGN=codiv_country_Restrictions_active.T[Country]",
                "else:",
                "ASSIGN==\"quarantine\":",
                "ASSIGN=codiv_country_qurantine_active.T[Country]",
                "else:",
                "ASSIGN=codiv_country_without_Restrictions_qurantine_active.T[Country]",
                "StartCountryIndex=0",
                "ShiftIndex=0",
                "ASSIGN=0",
                "ASSIGN=0",
                "ASSIGN=1.0",
                "LargeFactor=1.0",
                "ASSIGN = np.abs(df_codiv - df_codiv.mean()) > (3 * df_codiv.std())",
                "ASSIGN = df_codiv.loc[filter0]",
                "ASSIGN = ASSIGN.drop(outliers.index, axis=0)",
                "ASSIGN=max(df_codiv)",
                "ASSIGN = pd.DataFrame(columns = [Country,\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [Country,\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[Country]",
                "ASSIGN = np.polyfit(x_tr1_Country, y_tr1_Country, deg=10)",
                "ASSIGN=0",
                "ASSIGN==1:",
                "ASSIGN=1",
                "ASSIGN=max(codiv_country_qurantine_active.T[\"China\"])",
                "for Index in range(0,len(ASSIGN)):",
                "if ASSIGN[Index]>trigger*(ASSIGN*1.0path) and ASSIGN==1 and shift==1:",
                "if ASSIGN>ASSIGN:",
                "ASSIGN=ASSIGN*(maxCountry*1.5path)",
                "StartCountryIndex=Index",
                "ASSIGN=0",
                "if ASSIGN[Index]==ASSIGN:",
                "ASSIGN=Index",
                "LargeCountry=ASSIGN-StartCountryIndex",
                "ASSIGN=codiv_country_qurantine_active.T[\"China\"]",
                "ASSIGN = np.abs(df_codiv_China_ref - df_codiv_China_ref.mean()) > (3 * df_codiv_China_ref.std())",
                "ASSIGN = df_codiv_China_ref.loc[filter0]",
                "ASSIGN = df_codiv_China_ref.drop(outliers.index, axis=0)",
                "ASSIGN=max(df_codiv_China_ref)",
                "ASSIGN=1",
                "for Index in range(0,len(ASSIGN)):",
                "if ASSIGN[Index]>60 and ASSIGN==1 and shift==1:",
                "StartChinaIndex=Index",
                "ASSIGN=0",
                "if ASSIGN[Index]==ASSIGN:",
                "ASSIGN=Index",
                "ASSIGN=maxCountry*1.0path",
                "LargeChina=ASSIGN-StartChinaIndex",
                "LargeFactor=LargeCountry*1.0path",
                "ShiftIndex=StartCountryIndex-StartChinaIndex",
                "ASSIGN=0.02",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "ASSIGN=0",
                "for runNr in range(1,60,1):",
                "if ASSIGN<ASSIGN:",
                "LargeFactor=LargeFactor+ASSIGN",
                "ASSIGN=error1",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "if ASSIGN<ASSIGN:",
                "LargeFactor=LargeFactor+ASSIGN",
                "ASSIGN=error1",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "if ASSIGN<ASSIGN:",
                "ASSIGN=ASSIGN+step",
                "ASSIGN=error1",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "if ASSIGN<ASSIGN:",
                "ASSIGN=ASSIGN+step",
                "ASSIGN=error1",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "ASSIGN = np.polyfit(x_tr1_China_model, y_tr1_China_model, deg=10)",
                "return coefs_Country_poly10,x_tr1_Country,y_tr1_Country,coefs_predict_poly10,x_tr1_China_model,y_tr1_China_model,StartCountryIndex"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "def Polifq(Country,Version=\"restrictions\",shift=0,trigger=40):",
                "ASSIGN==\"restrictions\":",
                "ASSIGN=codiv_country_Restrictions_active.T[Country]",
                "else:",
                "ASSIGN==\"quarantine\":",
                "ASSIGN=codiv_country_qurantine_active.T[Country]",
                "else:",
                "ASSIGN=codiv_country_without_Restrictions_qurantine_active.T[Country]",
                "StartCountryIndex=0",
                "ShiftIndex=0",
                "ASSIGN=0",
                "ASSIGN=0",
                "ASSIGN=1.0",
                "LargeFactor=1.0",
                "ASSIGN = np.abs(df_codiv - df_codiv.mean()) > (3 * df_codiv.std())",
                "ASSIGN = df_codiv.loc[filter0]",
                "ASSIGN = ASSIGN.drop(outliers.index, axis=0)",
                "ASSIGN=max(df_codiv)",
                "ASSIGN = pd.DataFrame(columns = [Country,\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [Country,\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[Country]",
                "ASSIGN = np.polyfit(x_tr1_Country, y_tr1_Country, deg=10)",
                "ASSIGN=0",
                "ASSIGN==1:",
                "ASSIGN=1",
                "ASSIGN=max(codiv_country_qurantine_active.T[\"China\"])",
                "for Index in range(0,len(ASSIGN)):",
                "if ASSIGN[Index]>trigger*(ASSIGN*1.0path) and ASSIGN==1 and shift==1:",
                "if ASSIGN>ASSIGN:",
                "ASSIGN=ASSIGN*(maxCountry*1.5path)",
                "StartCountryIndex=Index",
                "ASSIGN=0",
                "if ASSIGN[Index]==ASSIGN:",
                "ASSIGN=Index",
                "LargeCountry=ASSIGN-StartCountryIndex",
                "ASSIGN=codiv_country_qurantine_active.T[\"China\"]",
                "ASSIGN = np.abs(df_codiv_China_ref - df_codiv_China_ref.mean()) > (3 * df_codiv_China_ref.std())",
                "ASSIGN = df_codiv_China_ref.loc[filter0]",
                "ASSIGN = df_codiv_China_ref.drop(outliers.index, axis=0)",
                "ASSIGN=max(df_codiv_China_ref)",
                "ASSIGN=1",
                "for Index in range(0,len(ASSIGN)):",
                "if ASSIGN[Index]>60 and ASSIGN==1 and shift==1:",
                "StartChinaIndex=Index",
                "ASSIGN=0",
                "if ASSIGN[Index]==ASSIGN:",
                "ASSIGN=Index",
                "ASSIGN=maxCountry*1.0path",
                "LargeChina=ASSIGN-StartChinaIndex",
                "LargeFactor=LargeCountry*1.0path",
                "ShiftIndex=StartCountryIndex-StartChinaIndex",
                "ASSIGN=0.02",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "ASSIGN=0",
                "for runNr in range(1,60,1):",
                "if ASSIGN<ASSIGN:",
                "LargeFactor=LargeFactor+ASSIGN",
                "ASSIGN=error1",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "if ASSIGN<ASSIGN:",
                "LargeFactor=LargeFactor+ASSIGN",
                "ASSIGN=error1",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "if ASSIGN<ASSIGN:",
                "ASSIGN=ASSIGN+step",
                "ASSIGN=error1",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "if ASSIGN<ASSIGN:",
                "ASSIGN=ASSIGN+step",
                "ASSIGN=error1",
                "ASSIGN = pd.DataFrame(columns = [\"China\",\"Value\",\"time\"], dtype='int')",
                "for Index in range(0,len(ASSIGN)):",
                "ASSIGN = pd.DataFrame ([[int(df_codiv[Index]*highfactor),int((Index)*LargeFactor)+ShiftIndex,str(pd.Timestamp(df_codiv.index[Index])+ pd.Timedelta(days=ShiftIndex))]], columns = [\"China\",\"Value\",\"time\"])",
                "ASSIGN=ASSIGN.append(df_codiv1, ignore_index = True)",
                "ASSIGN=df_country[\"Value\"]",
                "ASSIGN=df_country[\"China\"]",
                "ASSIGN = rmse(y_tr1_China_model,y_tr1_Country)",
                "ASSIGN = np.polyfit(x_tr1_China_model, y_tr1_China_model, deg=10)",
                "return coefs_Country_poly10,x_tr1_Country,y_tr1_Country,coefs_predict_poly10,x_tr1_China_model,y_tr1_China_model,StartCountryIndex"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=codiv_country_Restrictions_active.shape",
                "ASSIGN = np.linspace(0, lendata+40, num=lendata+30)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=codiv_country_Restrictions_active.shape",
                "ASSIGN = np.linspace(0, lendata+40, num=lendata+30)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "coefs_China,x_tr_China,y_tr_China,coefs_China_prev,x_tr_China_prev,y_tr_China_prev,StartCountryIndex=Polifq(\"China\",shift=0,Version=\"quarantine\",trigger=70)",
                "ASSIGN=max(x_tr_China)-7",
                "ASSIGN = np.polyval(coefs_China, x_values)",
                "ASSIGN=int(max(y_tr_China)*1.5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "coefs_China,x_tr_China,y_tr_China,coefs_China_prev,x_tr_China_prev,y_tr_China_prev,StartCountryIndex=Polifq(\"China\",shift=0,Version=\"quarantine\",trigger=70)",
                "ASSIGN=max(x_tr_China)-7",
                "ASSIGN = np.polyval(coefs_China, x_values)",
                "ASSIGN=int(max(y_tr_China)*1.5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "StartDate=codiv_country_Restrictions_active.T.index[0]",
                "ASSIGN = [\"date\"]",
                "ASSIGN = pd.DataFrame(columns = column_names)",
                "for Dateindex in range(0,lendata*20,10):",
                "ASSIGN = pd.DataFrame ([[str(pd.Timestamp(StartDate,unit=\"D\")+ pd.Timedelta(days=Dateindex))]], columns = [\"date\"])",
                "ASSIGN=ASSIGN.append(df_date1, ignore_index = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "StartDate=codiv_country_Restrictions_active.T.index[0]",
                "ASSIGN = [\"date\"]",
                "ASSIGN = pd.DataFrame(columns = column_names)",
                "for Dateindex in range(0,lendata*20,10):",
                "ASSIGN = pd.DataFrame ([[str(pd.Timestamp(StartDate,unit=\"D\")+ pd.Timedelta(days=Dateindex))]], columns = [\"date\"])",
                "ASSIGN=ASSIGN.append(df_date1, ignore_index = True)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "for countryindex in codiv_country_qurantine_active.T:",
                "ASSIGN==\"China\":",
                "coefs_Country,x_tr_Country,y_tr_Country,coefs_Country_prev,x_tr_Country_prev,y_tr_Country_prev,StartCountryIndex=Polifq(countryindex,shift=0,Version=\"quarantine\",trigger=70)",
                "ASSIGN = np.polyval(coefs_Country, x_values)",
                "ASSIGN=0",
                "else:",
                "coefs_Country,x_tr_Country,y_tr_Country,coefs_Country_prev,x_tr_Country_prev,y_tr_Country_prev,StartCountryIndex=Polifq(countryindex,shift=1,Version=\"quarantine\",trigger=170)",
                "ASSIGN = np.polyval(coefs_Country, x_values)",
                "ASSIGN = np.polyval(coefs_Country_prev, x_values)",
                "ASSIGN=int(max(y_Country_prev[StartCountryIndex:lendataChina])*1.40)",
                "if ymaxchina>ASSIGN:",
                "ASSIGN=ymaxchina",
                "ASSIGN = plt.figure(figsize= (18, 10))",
                "plt.scatter(x_tr_China, y_tr_China, s=10)",
                "plt.plot(x_values[0:lendataChina], y_China[0:lendataChina], label='China',c=\"blue\")",
                "ASSIGN!=\"China\":",
                "plt.scatter(x_tr_Country, y_tr_Country, s=10)",
                "plt.plot(x_values[0:lendataChina], ASSIGN[0:lendataChina], label=countryindex,c=\"magenta\")",
                "plt.scatter(x_tr_Country_prev,y_tr_Country_prev, s=10,c=\"black\")",
                "PredictionName='%s-prediction'%(countryindex,)",
                "plt.plot(x_values, ASSIGN, label=PredictionName,c=\"brown\",ls='dashed')",
                "plt.ylim(-5,ASSIGN)",
                "plt.ylabel(\"Number\")",
                "plt.grid(True)",
                "ASSIGN = range(0,len(dfdate),10)",
                "plt.xticks(ticks = ASSIGN ,labels = dfdate[\"date\"], rotation = 75)",
                "ASSIGN!=\"China\":",
                "ASSIGN='%s-prediction - Quarantine'%(countryindex,)",
                "plt.title(ASSIGN)",
                "else:",
                "plt.title(\"China\")",
                "ASSIGN=\"\"",
                "ASSIGN==\"Belgium\":",
                "ASSIGN=\"Belgium only success to slow the infection. The model wait for the peak to fit better\"",
                "ASSIGN==\"France\":",
                "ASSIGN=\"France was relaxing the quarantine? the model need the next days data to fit better. the datas are not clear\"",
                "ASSIGN==\"Germany\" or countryindex==\"Austria\":",
                "ASSIGN=\"Germany was relaxing the quarantine. but the model fit mostly good\"",
                "ASSIGN==\"India\" or countryindex==\"Argentina\" or countryindex==\"Peru\" or countryindex==\"Colombia\":",
                "ASSIGN=\" The model wait for the peak to fit better\"",
                "ASSIGN==\"Spain\":",
                "ASSIGN=\" Spain had no clear data, the model need the next days data to fit better\"",
                "ASSIGN==\"China\":",
                "ASSIGN=\" China is the reference country, but we see they have to face to some epidemic restart ( imported case).\"",
                "plt.text(1, ASSIGN-10000, ASSIGN, fontsize=15)",
                "plt.legend()",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "for countryindex in codiv_country_qurantine_active.T:",
                "ASSIGN==\"China\":",
                "coefs_Country,x_tr_Country,y_tr_Country,coefs_Country_prev,x_tr_Country_prev,y_tr_Country_prev,StartCountryIndex=Polifq(countryindex,shift=0,Version=\"quarantine\",trigger=70)",
                "ASSIGN = np.polyval(coefs_Country, x_values)",
                "ASSIGN=0",
                "else:",
                "coefs_Country,x_tr_Country,y_tr_Country,coefs_Country_prev,x_tr_Country_prev,y_tr_Country_prev,StartCountryIndex=Polifq(countryindex,shift=1,Version=\"quarantine\",trigger=170)",
                "ASSIGN = np.polyval(coefs_Country, x_values)",
                "ASSIGN = np.polyval(coefs_Country_prev, x_values)",
                "ASSIGN=int(max(y_Country_prev[StartCountryIndex:lendataChina])*1.40)",
                "if ymaxchina>ASSIGN:",
                "ASSIGN=ymaxchina",
                "ASSIGN = plt.figure(figsize= (18, 10))",
                "plt.scatter(x_tr_China, y_tr_China, s=10)",
                "plt.plot(x_values[0:lendataChina], y_China[0:lendataChina], label='China',c=\"blue\")",
                "ASSIGN!=\"China\":",
                "plt.scatter(x_tr_Country, y_tr_Country, s=10)",
                "plt.plot(x_values[0:lendataChina], ASSIGN[0:lendataChina], label=countryindex,c=\"magenta\")",
                "plt.scatter(x_tr_Country_prev,y_tr_Country_prev, s=10,c=\"black\")",
                "PredictionName='%s-prediction'%(countryindex,)",
                "plt.plot(x_values, ASSIGN, label=PredictionName,c=\"brown\",ls='dashed')",
                "plt.ylim(-5,ASSIGN)",
                "plt.ylabel(\"Number\")",
                "plt.grid(True)",
                "ASSIGN = range(0,len(dfdate),10)",
                "plt.xticks(ticks = ASSIGN ,labels = dfdate[\"date\"], rotation = 75)",
                "ASSIGN!=\"China\":",
                "ASSIGN='%s-prediction - Quarantine'%(countryindex,)",
                "plt.title(ASSIGN)",
                "else:",
                "plt.title(\"China\")",
                "ASSIGN=\"\"",
                "ASSIGN==\"Belgium\":",
                "ASSIGN=\"Belgium only success to slow the infection. The model wait for the peak to fit better\"",
                "ASSIGN==\"France\":",
                "ASSIGN=\"France was relaxing the quarantine? the model need the next days data to fit better. the datas are not clear\"",
                "ASSIGN==\"Germany\" or countryindex==\"Austria\":",
                "ASSIGN=\"Germany was relaxing the quarantine. but the model fit mostly good\"",
                "ASSIGN==\"India\" or countryindex==\"Argentina\" or countryindex==\"Peru\" or countryindex==\"Colombia\":",
                "ASSIGN=\" The model wait for the peak to fit better\"",
                "ASSIGN==\"Spain\":",
                "ASSIGN=\" Spain had no clear data, the model need the next days data to fit better\"",
                "ASSIGN==\"China\":",
                "ASSIGN=\" China is the reference country, but we see they have to face to some epidemic restart ( imported case).\"",
                "plt.text(1, ASSIGN-10000, ASSIGN, fontsize=15)",
                "plt.legend()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=codiv_country_Restrictions_active.shape",
                "ASSIGN = np.linspace(0, lendata+40, num=lendata+30)",
                "coefs_China,x_tr_China,y_tr_China,coefs_China_prev,x_tr_China_prev,y_tr_China_prev,StartCountryIndex=Polifq(\"China\",shift=0,Version=\"quarantine\",trigger=70)",
                "ASSIGN=max(x_tr_China)-7",
                "ASSIGN = np.polyval(coefs_China, x_values)",
                "ASSIGN=int(max(y_tr_China)*1.5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=codiv_country_Restrictions_active.shape",
                "ASSIGN = np.linspace(0, lendata+40, num=lendata+30)",
                "coefs_China,x_tr_China,y_tr_China,coefs_China_prev,x_tr_China_prev,y_tr_China_prev,StartCountryIndex=Polifq(\"China\",shift=0,Version=\"quarantine\",trigger=70)",
                "ASSIGN=max(x_tr_China)-7",
                "ASSIGN = np.polyval(coefs_China, x_values)",
                "ASSIGN=int(max(y_tr_China)*1.5)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "for countryindex in codiv_country_Restrictions_active.T:",
                "ASSIGN==\"Japan\":",
                "ASSIGN=4500",
                "else:",
                "ASSIGN=250",
                "coefs_Country,x_tr_Country,y_tr_Country,coefs_Country_prev,x_tr_Country_prev,y_tr_Country_prev,StartCountryIndex=Polifq(countryindex,shift=1,Version=\"restrictions\",ASSIGN=ASSIGN)",
                "ASSIGN = np.polyval(coefs_Country, x_values)",
                "ASSIGN = np.polyval(coefs_Country_prev, x_values)",
                "ASSIGN=int(max(y_Country_prev[StartCountryIndex:lendataChina])*1.40)",
                "if ymaxchina>ASSIGN:",
                "ASSIGN=ymaxchina",
                "ASSIGN = plt.figure(figsize= (18, 10))",
                "plt.scatter(x_tr_China, y_tr_China, s=10)",
                "plt.plot(x_values[0:lendataChina], y_China[0:lendataChina], label='China',c=\"blue\")",
                "ASSIGN!=\"China\":",
                "plt.scatter(x_tr_Country, y_tr_Country, s=10)",
                "plt.plot(x_values[0:lendataChina], ASSIGN[0:lendataChina], label=countryindex,c=\"magenta\")",
                "plt.scatter(x_tr_Country_prev,y_tr_Country_prev, s=10,c=\"black\")",
                "PredictionName='%s-prediction'%(countryindex,)",
                "plt.plot(x_values, ASSIGN, label=PredictionName,c=\"brown\",ls='dashed')",
                "plt.ylim(-5,ASSIGN)",
                "plt.ylabel(\"Number\")",
                "plt.grid(True)",
                "ASSIGN = range(0,len(dfdate),10)",
                "plt.xticks(ticks = ASSIGN ,labels = dfdate[\"date\"], rotation = 75)",
                "ASSIGN!=\"China\":",
                "ASSIGN='%s-prediction - Restrictions'%(countryindex,)",
                "plt.title(ASSIGN)",
                "else:",
                "plt.title(\"China\")",
                "ASSIGN=\"\"",
                "ASSIGN==\"Ireland\":",
                "ASSIGN=\"Ireland had no clear data, the model need the next days data to fit better. Are the information trustfull?\"",
                "ASSIGN==\"Japan\":",
                "ASSIGN=\"Japan tried long time to contain the epidemy, after it gone up. the start threshold should be higher\"",
                "ASSIGN==\"Canada\" or countryindex==\"Netherlands\" or countryindex==\"Peru\" or countryindex==\"Colombia\"or countryindex==\"Portugal\"or countryindex==\"Sweden\"or countryindex==\"United Kingdom\":",
                "ASSIGN=\" The model wait for the peak to fit better\"",
                "ASSIGN==\"Norway\" or countryindex==\"Poland\":",
                "ASSIGN=\" The model wait for the peak to fit better,they take long time to reach it\"",
                "plt.text(1, ASSIGN-10000, ASSIGN, fontsize=15)",
                "plt.legend()",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "for countryindex in codiv_country_Restrictions_active.T:",
                "ASSIGN==\"Japan\":",
                "ASSIGN=4500",
                "else:",
                "ASSIGN=250",
                "coefs_Country,x_tr_Country,y_tr_Country,coefs_Country_prev,x_tr_Country_prev,y_tr_Country_prev,StartCountryIndex=Polifq(countryindex,shift=1,Version=\"restrictions\",ASSIGN=ASSIGN)",
                "ASSIGN = np.polyval(coefs_Country, x_values)",
                "ASSIGN = np.polyval(coefs_Country_prev, x_values)",
                "ASSIGN=int(max(y_Country_prev[StartCountryIndex:lendataChina])*1.40)",
                "if ymaxchina>ASSIGN:",
                "ASSIGN=ymaxchina",
                "ASSIGN = plt.figure(figsize= (18, 10))",
                "plt.scatter(x_tr_China, y_tr_China, s=10)",
                "plt.plot(x_values[0:lendataChina], y_China[0:lendataChina], label='China',c=\"blue\")",
                "ASSIGN!=\"China\":",
                "plt.scatter(x_tr_Country, y_tr_Country, s=10)",
                "plt.plot(x_values[0:lendataChina], ASSIGN[0:lendataChina], label=countryindex,c=\"magenta\")",
                "plt.scatter(x_tr_Country_prev,y_tr_Country_prev, s=10,c=\"black\")",
                "PredictionName='%s-prediction'%(countryindex,)",
                "plt.plot(x_values, ASSIGN, label=PredictionName,c=\"brown\",ls='dashed')",
                "plt.ylim(-5,ASSIGN)",
                "plt.ylabel(\"Number\")",
                "plt.grid(True)",
                "ASSIGN = range(0,len(dfdate),10)",
                "plt.xticks(ticks = ASSIGN ,labels = dfdate[\"date\"], rotation = 75)",
                "ASSIGN!=\"China\":",
                "ASSIGN='%s-prediction - Restrictions'%(countryindex,)",
                "plt.title(ASSIGN)",
                "else:",
                "plt.title(\"China\")",
                "ASSIGN=\"\"",
                "ASSIGN==\"Ireland\":",
                "ASSIGN=\"Ireland had no clear data, the model need the next days data to fit better. Are the information trustfull?\"",
                "ASSIGN==\"Japan\":",
                "ASSIGN=\"Japan tried long time to contain the epidemy, after it gone up. the start threshold should be higher\"",
                "ASSIGN==\"Canada\" or countryindex==\"Netherlands\" or countryindex==\"Peru\" or countryindex==\"Colombia\"or countryindex==\"Portugal\"or countryindex==\"Sweden\"or countryindex==\"United Kingdom\":",
                "ASSIGN=\" The model wait for the peak to fit better\"",
                "ASSIGN==\"Norway\" or countryindex==\"Poland\":",
                "ASSIGN=\" The model wait for the peak to fit better,they take long time to reach it\"",
                "plt.text(1, ASSIGN-10000, ASSIGN, fontsize=15)",
                "plt.legend()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=codiv_country_Restrictions_active.shape",
                "ASSIGN = np.linspace(0, lendata+40, num=lendata+30)",
                "coefs_China,x_tr_China,y_tr_China,coefs_China_prev,x_tr_China_prev,y_tr_China_prev,StartCountryIndex=Polifq(\"China\",shift=0,Version=\"quarantine\",trigger=70)",
                "ASSIGN=max(x_tr_China)-7",
                "ASSIGN = np.polyval(coefs_China, x_values)",
                "ASSIGN=int(max(y_tr_China)*1.5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=codiv_country_Restrictions_active.shape",
                "ASSIGN = np.linspace(0, lendata+40, num=lendata+30)",
                "coefs_China,x_tr_China,y_tr_China,coefs_China_prev,x_tr_China_prev,y_tr_China_prev,StartCountryIndex=Polifq(\"China\",shift=0,Version=\"quarantine\",trigger=70)",
                "ASSIGN=max(x_tr_China)-7",
                "ASSIGN = np.polyval(coefs_China, x_values)",
                "ASSIGN=int(max(y_tr_China)*1.5)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "for countryindex in codiv_country_without_Restrictions_qurantine_active.T:",
                "ASSIGN==\"Singapore\" or countryindex==\"Qatar\" or countryindex==\"Kuwait\":",
                "ASSIGN=2000",
                "else:",
                "ASSIGN=300",
                "coefs_Country,x_tr_Country,y_tr_Country,coefs_Country_prev,x_tr_Country_prev,y_tr_Country_prev,StartCountryIndex=Polifq(countryindex,shift=1,Version=\"NoQuaNoRES\",ASSIGN=ASSIGN)",
                "ASSIGN = np.polyval(coefs_Country, x_values)",
                "ASSIGN = np.polyval(coefs_Country_prev, x_values)",
                "ASSIGN==\"US\":",
                "ASSIGN=1500000",
                "else:",
                "ASSIGN==\"Brazil\":",
                "ASSIGN=180000",
                "else:",
                "ASSIGN=60000",
                "ASSIGN = plt.figure(figsize= (18, 10))",
                "plt.scatter(x_tr_China, y_tr_China, s=10)",
                "plt.plot(x_values[0:lendataChina], y_China[0:lendataChina], label='China',c=\"blue\")",
                "ASSIGN!=\"China\":",
                "plt.scatter(x_tr_Country, y_tr_Country, s=10)",
                "plt.plot(x_values[0:lendataChina], ASSIGN[0:lendataChina], label=countryindex,c=\"magenta\")",
                "plt.scatter(x_tr_Country_prev,y_tr_Country_prev, s=10,c=\"black\")",
                "PredictionName='%s-prediction'%(countryindex,)",
                "plt.plot(x_values, ASSIGN, label=PredictionName,c=\"brown\",ls='dashed')",
                "plt.ylim(-5,ASSIGN)",
                "plt.ylabel(\"Number\")",
                "plt.grid(True)",
                "ASSIGN = range(0,len(dfdate),10)",
                "plt.xticks(ticks = ASSIGN ,labels = dfdate[\"date\"], rotation = 75)",
                "ASSIGN!=\"China\":",
                "ASSIGN='%s-prediction - No-Restrictions No-quarantine'%(countryindex,)",
                "plt.title(ASSIGN)",
                "else:",
                "plt.title(\"China\")",
                "ASSIGN=\"\"",
                "ASSIGN==\"Armenia\" or countryindex==\"Bahrain\" or countryindex==\"Bangladesh\" or countryindex==\"Belarus\"or countryindex==\"Brazil\"or countryindex==\"Chile\"or countryindex==\"United Kingdom\"or countryindex==\"US\":",
                "ASSIGN=\" The model wait for the peak to fit better\"",
                "ASSIGN==\"Ecuador\" or countryindex==\"Indonesia\" or countryindex==\"Kuwait\" or countryindex==\"Mexico\" or countryindex==\"Oman\" or countryindex==\"Pakistan\" or countryindex==\"Quatar\" or countryindex==\"South Africa\":",
                "ASSIGN=\" The model wait for the peak to fit better\"",
                "ASSIGN==\"Dominican Republic\" or countryindex==\"Ghana\":",
                "ASSIGN=\" The model wait for more data to fit better\"",
                "plt.text(1, ASSIGN-10000, ASSIGN, fontsize=15)",
                "plt.legend()",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "for countryindex in codiv_country_without_Restrictions_qurantine_active.T:",
                "ASSIGN==\"Singapore\" or countryindex==\"Qatar\" or countryindex==\"Kuwait\":",
                "ASSIGN=2000",
                "else:",
                "ASSIGN=300",
                "coefs_Country,x_tr_Country,y_tr_Country,coefs_Country_prev,x_tr_Country_prev,y_tr_Country_prev,StartCountryIndex=Polifq(countryindex,shift=1,Version=\"NoQuaNoRES\",ASSIGN=ASSIGN)",
                "ASSIGN = np.polyval(coefs_Country, x_values)",
                "ASSIGN = np.polyval(coefs_Country_prev, x_values)",
                "ASSIGN==\"US\":",
                "ASSIGN=1500000",
                "else:",
                "ASSIGN==\"Brazil\":",
                "ASSIGN=180000",
                "else:",
                "ASSIGN=60000",
                "ASSIGN = plt.figure(figsize= (18, 10))",
                "plt.scatter(x_tr_China, y_tr_China, s=10)",
                "plt.plot(x_values[0:lendataChina], y_China[0:lendataChina], label='China',c=\"blue\")",
                "ASSIGN!=\"China\":",
                "plt.scatter(x_tr_Country, y_tr_Country, s=10)",
                "plt.plot(x_values[0:lendataChina], ASSIGN[0:lendataChina], label=countryindex,c=\"magenta\")",
                "plt.scatter(x_tr_Country_prev,y_tr_Country_prev, s=10,c=\"black\")",
                "PredictionName='%s-prediction'%(countryindex,)",
                "plt.plot(x_values, ASSIGN, label=PredictionName,c=\"brown\",ls='dashed')",
                "plt.ylim(-5,ASSIGN)",
                "plt.ylabel(\"Number\")",
                "plt.grid(True)",
                "ASSIGN = range(0,len(dfdate),10)",
                "plt.xticks(ticks = ASSIGN ,labels = dfdate[\"date\"], rotation = 75)",
                "ASSIGN!=\"China\":",
                "ASSIGN='%s-prediction - No-Restrictions No-quarantine'%(countryindex,)",
                "plt.title(ASSIGN)",
                "else:",
                "plt.title(\"China\")",
                "ASSIGN=\"\"",
                "ASSIGN==\"Armenia\" or countryindex==\"Bahrain\" or countryindex==\"Bangladesh\" or countryindex==\"Belarus\"or countryindex==\"Brazil\"or countryindex==\"Chile\"or countryindex==\"United Kingdom\"or countryindex==\"US\":",
                "ASSIGN=\" The model wait for the peak to fit better\"",
                "ASSIGN==\"Ecuador\" or countryindex==\"Indonesia\" or countryindex==\"Kuwait\" or countryindex==\"Mexico\" or countryindex==\"Oman\" or countryindex==\"Pakistan\" or countryindex==\"Quatar\" or countryindex==\"South Africa\":",
                "ASSIGN=\" The model wait for the peak to fit better\"",
                "ASSIGN==\"Dominican Republic\" or countryindex==\"Ghana\":",
                "ASSIGN=\" The model wait for more data to fit better\"",
                "plt.text(1, ASSIGN-10000, ASSIGN, fontsize=15)",
                "plt.legend()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN=pd.read_csv(\"C:path\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN=pd.read_csv(\"C:path\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "stores"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "stores"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"C:\\\\Users\\\\sony\\\\OneDrive\\\\Documentos\\\\ASSIGN.csv\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.read_csv(\"C:\\\\Users\\\\sony\\\\OneDrive\\\\Documentos\\\\ASSIGN.csv\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "features"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "features"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"C:\\\\Users\\\\sony\\\\OneDrive\\\\Documentos\\\\ASSIGN.csv\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.read_csv(\"C:\\\\Users\\\\sony\\\\OneDrive\\\\Documentos\\\\ASSIGN.csv\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "test"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "test"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"C:\\\\Users\\\\sony\\\\OneDrive\\\\Documentos\\\\ASSIGN.csv\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.read_csv(\"C:\\\\Users\\\\sony\\\\OneDrive\\\\Documentos\\\\ASSIGN.csv\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "train"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(, train.shape)",
                "print(, test.shape)",
                "print(, (round(train.shape[0]*100path(train.shape[0]+test.shape[0])),100-round(train.shape[0]*100path(train.shape[0]+test.shape[0]))))"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "print(, train.shape)",
                "print(, test.shape)",
                "print(, (round(train.shape[0]*100path(train.shape[0]+test.shape[0])),100-round(train.shape[0]*100path(train.shape[0]+test.shape[0]))))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN.merge(stores, on='Store', how='left')",
                "ASSIGN.head()"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN=ASSIGN.merge(stores, on='Store', how='left')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.merge(stores, features)",
                "dataset"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.merge(stores, features)",
                "dataset"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.pairplot(dataset)"
            ],
            "output_type": "error",
            "content_old": [
                "sns.pairplot(dataset)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def scatter(dataset, column):",
                "plt.figure()",
                "plt.scatter(dataset[column] , dataset['weeklySales'])",
                "plt.ylabel('weeklySales')",
                "plt.xlabel(column)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def scatter(dataset, column):",
                "plt.figure()",
                "plt.scatter(dataset[column] , dataset['weeklySales'])",
                "plt.ylabel('weeklySales')",
                "plt.xlabel(column)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def scatter(dataset, column):",
                "plt.figure()",
                "plt.scatter(dataset[column] , dataset['weeklySales'])",
                "plt.ylabel('weeklySales')",
                "plt.xlabel(column)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def scatter(dataset, column):",
                "plt.figure()",
                "plt.scatter(dataset[column] , dataset['weeklySales'])",
                "plt.ylabel('weeklySales')",
                "plt.xlabel(column)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.figure(figsize=(18, 14))",
                "ASSIGN = dataset.ASSIGN()",
                "ASSIGN = plt.pcolor(corr)",
                "plt.yticks(np.arange(0.5, len(ASSIGN.index), 1), ASSIGN.index)",
                "plt.xticks(np.arange(0.5, len(ASSIGN.columns), 1), ASSIGN.columns)",
                "ASSIGN.colorbar(ASSIGN)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = plt.figure(figsize=(18, 14))",
                "ASSIGN = dataset.ASSIGN()",
                "ASSIGN = plt.pcolor(corr)",
                "plt.yticks(np.arange(0.5, len(ASSIGN.index), 1), ASSIGN.index)",
                "plt.xticks(np.arange(0.5, len(ASSIGN.columns), 1), ASSIGN.columns)",
                "ASSIGN.colorbar(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.pairplot(dataset, vars=['weeklySales', 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature', 'Unemployment'])"
            ],
            "output_type": "error",
            "content_old": [
                "sns.pairplot(dataset, vars=['weeklySales', 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature', 'Unemployment'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.pairplot(dataset, vars=[ 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature', 'Unemployment'])"
            ],
            "output_type": "error",
            "content_old": [
                "sns.pairplot(dataset, vars=[ 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature', 'Unemployment'])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=pd.Series(train['ASSIGN'].unique())",
                "ASSIGN=pd.Series(train['ASSIGN'].unique())",
                "ASSIGN=pd.Series(train['ASSIGN'].unique())",
                "ASSIGN=pd.Series(train['ASSIGN'].unique())",
                "ASSIGN=pd.Series(train['ASSIGN'].unique())"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN=pd.Series(train['ASSIGN'].unique())",
                "ASSIGN=pd.Series(train['ASSIGN'].unique())",
                "ASSIGN=pd.Series(train['ASSIGN'].unique())",
                "ASSIGN=pd.Series(train['ASSIGN'].unique())",
                "ASSIGN=pd.Series(train['ASSIGN'].unique())"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(, stores.shape)",
                "print(, stores['Store'].unique())",
                "print(, stores['Type'].unique())"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "print(, stores.shape)",
                "print(, stores['Store'].unique())",
                "print(, stores['Type'].unique())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(stores.head())",
                "ASSIGN=stores.groupby('Type')",
                "print(ASSIGN.describe()['Size'].round(2))"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "print(stores.head())",
                "ASSIGN=stores.groupby('Type')",
                "print(ASSIGN.describe()['Size'].round(2))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.style.use('ggplot')",
                "ASSIGN=['A store','B store','C store']",
                "ASSIGN=grouped.describe()['Size'].round(1)",
                "ASSIGN=[(22path(17+6+22))*100,(17path(17+6+22))*100,(6path(17+6+22))*100]",
                "ASSIGN = plt.subplots(1,1, figsize=(10,10))",
                "ASSIGN={'edgecolor':'black',",
                "'linewidth':2}",
                "ASSIGN = {'fontsize':30}",
                "axes.pie(ASSIGN,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=(0.02,0,0),",
                "ASSIGN='%1.1f%%',",
                "ASSIGN=0.6,",
                "ASSIGN=1.2,",
                "ASSIGN=wprops,",
                "ASSIGN=tprops,",
                "ASSIGN=0.8,",
                "ASSIGN=(0.5,0.5))",
                "plt.show()"
            ],
            "output_type": "error",
            "content_old": [
                "plt.style.use('ggplot')",
                "ASSIGN=['A store','B store','C store']",
                "ASSIGN=grouped.describe()['Size'].round(1)",
                "ASSIGN=[(22path(17+6+22))*100,(17path(17+6+22))*100,(6path(17+6+22))*100]",
                "ASSIGN = plt.subplots(1,1, figsize=(10,10))",
                "ASSIGN={'edgecolor':'black',",
                "'linewidth':2}",
                "ASSIGN = {'fontsize':30}",
                "axes.pie(ASSIGN,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=(0.02,0,0),",
                "ASSIGN='%1.1f%%',",
                "ASSIGN=0.6,",
                "ASSIGN=1.2,",
                "ASSIGN=wprops,",
                "ASSIGN=tprops,",
                "ASSIGN=0.8,",
                "ASSIGN=(0.5,0.5))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([stores['Type'], stores['Size']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Type', y='Size', data=data)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([stores['Type'], stores['Size']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Type', y='Size', data=data)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Type'], train['Weekly_Sales']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Type', y='Weekly_Sales', data=data, showfliers=False)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Type'], train['Weekly_Sales']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Type', y='Weekly_Sales', data=data, showfliers=False)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.style.use('ggplot')",
                "ASSIGN=plt.figure()",
                "ASSIGN=fig.add_subplot(111)",
                "ASSIGN.scatter(train['Size'],train['Weekly_Sales'], alpha=0.5)",
                "plt.show()"
            ],
            "output_type": "error",
            "content_old": [
                "plt.style.use('ggplot')",
                "ASSIGN=plt.figure()",
                "ASSIGN=fig.add_subplot(111)",
                "ASSIGN.scatter(train['Size'],train['Weekly_Sales'], alpha=0.5)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN=stores['Type'].unique()",
                "plt.style.use('ggplot')",
                "ASSIGN=plt.figure(figsize=(10,5))",
                "ASSIGN=fig.add_subplot(111)",
                "for t in ASSIGN:",
                "ASSIGN=train.loc[train['Type']==t, 'Size']",
                "ASSIGN=train.loc[train['Type']==t, 'Weekly_Sales']",
                "ASSIGN.scatter(ASSIGN,ASSIGN,alpha=0.5, label=t)",
                "ASSIGN.set_title('Scatter plot size and sales by store type')",
                "ASSIGN.set_xlabel('Size')",
                "ASSIGN.set_ylabel('Weekly_Sales')",
                "ASSIGN.legend(loc='higher right',fontsize=12)",
                "plt.show()"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN=stores['Type'].unique()",
                "plt.style.use('ggplot')",
                "ASSIGN=plt.figure(figsize=(10,5))",
                "ASSIGN=fig.add_subplot(111)",
                "for t in ASSIGN:",
                "ASSIGN=train.loc[train['Type']==t, 'Size']",
                "ASSIGN=train.loc[train['Type']==t, 'Weekly_Sales']",
                "ASSIGN.scatter(ASSIGN,ASSIGN,alpha=0.5, label=t)",
                "ASSIGN.set_title('Scatter plot size and sales by store type')",
                "ASSIGN.set_xlabel('Size')",
                "ASSIGN.set_ylabel('Weekly_Sales')",
                "ASSIGN.legend(loc='higher right',fontsize=12)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "error",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Store'], train['Weekly_Sales'], train['Type']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(25, 8))",
                "ASSIGN = sns.boxplot(x='Store', y='Weekly_Sales', data=data, showfliers=False, hue=\"Type\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Store'], train['Weekly_Sales'], train['Type']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(25, 8))",
                "ASSIGN = sns.boxplot(x='Store', y='Weekly_Sales', data=data, showfliers=False, hue=\"Type\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Store'], train['Weekly_Sales'], train['IsHoliday']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(25, 8))",
                "ASSIGN = sns.boxplot(x='Store', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Store'], train['Weekly_Sales'], train['IsHoliday']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(25, 8))",
                "ASSIGN = sns.boxplot(x='Store', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Dept'], train['Weekly_Sales'], train['Type']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(25, 10))",
                "ASSIGN = sns.boxplot(x='Dept', y='Weekly_Sales', data=data, showfliers=False)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Dept'], train['Weekly_Sales'], train['Type']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(25, 10))",
                "ASSIGN = sns.boxplot(x='Dept', y='Weekly_Sales', data=data, showfliers=False)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Dept'], train['Weekly_Sales'], train['Type']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(10, 50))",
                "ASSIGN = sns.boxplot(y='Dept', x='Weekly_Sales', data=data, showfliers=False, hue=\"Type\",orient=\"h\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Dept'], train['Weekly_Sales'], train['Type']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(10, 50))",
                "ASSIGN = sns.boxplot(y='Dept', x='Weekly_Sales', data=data, showfliers=False, hue=\"Type\",orient=\"h\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Dept'], train['Weekly_Sales'], train['IsHoliday']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(25, 10))",
                "ASSIGN = sns.boxplot(x='Dept', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Dept'], train['Weekly_Sales'], train['IsHoliday']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(25, 10))",
                "ASSIGN = sns.boxplot(x='Dept', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "error",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.style.use('ggplot')",
                "ASSIGN = plt.subplots(1,2, figsize = (20,5))",
                "fig.subplots_adjust(wspace=1, hspace=1)",
                "fig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)",
                "ASSIGN=train[['IsHoliday','Weekly_Sales']]",
                "ASSIGN=[sales_holiday['Weekly_Sales'].loc[sales_holiday['IsHoliday']==True],sales_holiday['Weekly_Sales'].loc[sales_holiday['IsHoliday']==False]]",
                "ASSIGN=['Holiday','Not Holiday']",
                "ASSIGN={'color':'",
                "'linewidth': 2,",
                "'linestyle':'-'}",
                "ASSIGN={'color' : '",
                "'marker' : 'o',",
                "'markerfacecolor': '",
                "'markeredgecolor':'white',",
                "'markersize' : 3,",
                "'linestyle' : 'None',",
                "'linewidth' : 0.1}",
                "axes[0].boxplot(ASSIGN,ASSIGN=ASSIGN, patch_artist = 'Patch',",
                "ASSIGN=True,",
                "ASSIGN=flierprop,",
                "ASSIGN=medianprop)",
                "axes[1].boxplot(ASSIGN,ASSIGN=ASSIGN, patch_artist = 'Patch',",
                "ASSIGN=True,",
                "ASSIGN=flierprop,",
                "ASSIGN=medianprop)",
                "axes[1].set_ylim(-6000,80000)",
                "plt.show()"
            ],
            "output_type": "error",
            "content_old": [
                "plt.style.use('ggplot')",
                "ASSIGN = plt.subplots(1,2, figsize = (20,5))",
                "fig.subplots_adjust(wspace=1, hspace=1)",
                "fig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)",
                "ASSIGN=train[['IsHoliday','Weekly_Sales']]",
                "ASSIGN=[sales_holiday['Weekly_Sales'].loc[sales_holiday['IsHoliday']==True],sales_holiday['Weekly_Sales'].loc[sales_holiday['IsHoliday']==False]]",
                "ASSIGN=['Holiday','Not Holiday']",
                "ASSIGN={'color':'",
                "'linewidth': 2,",
                "'linestyle':'-'}",
                "ASSIGN={'color' : '",
                "'marker' : 'o',",
                "'markerfacecolor': '",
                "'markeredgecolor':'white',",
                "'markersize' : 3,",
                "'linestyle' : 'None',",
                "'linewidth' : 0.1}",
                "axes[0].boxplot(ASSIGN,ASSIGN=ASSIGN, patch_artist = 'Patch',",
                "ASSIGN=True,",
                "ASSIGN=flierprop,",
                "ASSIGN=medianprop)",
                "axes[1].boxplot(ASSIGN,ASSIGN=ASSIGN, patch_artist = 'Patch',",
                "ASSIGN=True,",
                "ASSIGN=flierprop,",
                "ASSIGN=medianprop)",
                "axes[1].set_ylim(-6000,80000)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(train[train['IsHoliday']==True]['Weekly_Sales'].describe().round(1))",
                "print(train[train['IsHoliday']==False]['Weekly_Sales'].describe().round(1))"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "print(train[train['IsHoliday']==True]['Weekly_Sales'].describe().round(1))",
                "print(train[train['IsHoliday']==False]['Weekly_Sales'].describe().round(1))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "error",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Month'], train['Weekly_Sales']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Month', y=\"Weekly_Sales\", data=data, showfliers=False)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Month'], train['Weekly_Sales']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Month', y=\"Weekly_Sales\", data=data, showfliers=False)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Month'], train['Weekly_Sales'],train['IsHoliday']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Month', y=\"Weekly_Sales\", data=data, showfliers=False, hue='IsHoliday')"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Month'], train['Weekly_Sales'],train['IsHoliday']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Month', y=\"Weekly_Sales\", data=data, showfliers=False, hue='IsHoliday')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Month'], train['Weekly_Sales'],train['Type']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Month', y=\"Weekly_Sales\", data=data, showfliers=False, hue='Type')"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Month'], train['Weekly_Sales'],train['Type']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Month', y=\"Weekly_Sales\", data=data, showfliers=False, hue='Type')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Year'], train['Weekly_Sales']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Year', y=\"Weekly_Sales\", data=data, showfliers=False)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Year'], train['Weekly_Sales']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "ASSIGN = sns.boxplot(x='Year', y=\"Weekly_Sales\", data=data, showfliers=False)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([train['Week'], train['Weekly_Sales']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(20, 6))",
                "ASSIGN = sns.boxplot(x='Week', y=\"Weekly_Sales\", data=data, showfliers=False)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.concat([train['Week'], train['Weekly_Sales']], axis=1)",
                "ASSIGN = plt.subplots(figsize=(20, 6))",
                "ASSIGN = sns.boxplot(x='Week', y=\"Weekly_Sales\", data=data, showfliers=False)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "sns.distplot(train['Weekly_Sales'])"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "sns.distplot(train['Weekly_Sales'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(, train['Weekly_Sales'].skew()) #skewness",
                "print(, train['Weekly_Sales'].kurt()) #kurtosis"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "print(, train['Weekly_Sales'].skew()) #skewness",
                "print(, train['Weekly_Sales'].kurt()) #kurtosis"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train['Weekly_Sales'].min()"
            ],
            "output_type": "error",
            "content_old": [
                "train['Weekly_Sales'].min()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.figure(figsize = (10,5))",
                "ASSIGN.add_subplot(1,2,1)",
                "ASSIGN = stats.probplot(train.loc[train['Weekly_Sales']>0,'Weekly_Sales'], plot=plt)",
                "ASSIGN.add_subplot(1,2,2)",
                "ASSIGN = stats.probplot(np.log1p(train.loc[train['Weekly_Sales']>0,'Weekly_Sales']), plot=plt)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = plt.figure(figsize = (10,5))",
                "ASSIGN.add_subplot(1,2,1)",
                "ASSIGN = stats.probplot(train.loc[train['Weekly_Sales']>0,'Weekly_Sales'], plot=plt)",
                "ASSIGN.add_subplot(1,2,2)",
                "ASSIGN = stats.probplot(np.log1p(train.loc[train['Weekly_Sales']>0,'Weekly_Sales']), plot=plt)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.describe()['Weekly_Sales']"
            ],
            "output_type": "error",
            "content_old": [
                "train.describe()['Weekly_Sales']"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN=train[train['Weekly_Sales']>0]",
                "ASSIGN=train[train['Weekly_Sales']<=0]",
                "ASSIGN = np.log1p(train_over_zero['Weekly_Sales'])",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "sns.distplot(ASSIGN)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN=train[train['Weekly_Sales']>0]",
                "ASSIGN=train[train['Weekly_Sales']<=0]",
                "ASSIGN = np.log1p(train_over_zero['Weekly_Sales'])",
                "ASSIGN = plt.subplots(figsize=(8, 6))",
                "sns.distplot(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(, sales_over_zero.skew()) #skewness",
                "print(, sales_over_zero.kurt()) #kurtosis"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "print(, sales_over_zero.skew()) #skewness",
                "print(, sales_over_zero.kurt()) #kurtosis"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=train.groupby(['Dept','Date']).mean().round(0).reset_index()",
                "print(ASSIGN.shape)",
                "print(ASSIGN.head())",
                "ASSIGN=grouped[['Dept','Date','Weekly_Sales']]",
                "ASSIGN=train['Dept'].unique()",
                "ASSIGN.sort()",
                "ASSIGN=dept[0:20]",
                "ASSIGN=dept[20:40]",
                "ASSIGN=dept[40:60]",
                "ASSIGN=dept[60:]",
                "ASSIGN = plt.subplots(2,2,figsize=(20,10))",
                "fig.subplots_adjust(wspace=0.5, hspace=0.5)",
                "fig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Dept']==i]",
                "ax[0,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'],label='Dept_1_mean_sales')",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Dept']==i]",
                "ax[0,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'],label='Dept_1_mean_sales')",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Dept']==i]",
                "ax[1,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'],label='Dept_1_mean_sales')",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Dept']==i]",
                "ax[1,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'],label='Dept_1_mean_sales')",
                "ax[0,0].set_title('Mean sales record by department(0~19)')",
                "ax[0,1].set_title('Mean sales record by department(20~39)')",
                "ax[1,0].set_title('Mean sales record by department(40~59)')",
                "ax[1,1].set_title('Mean sales record by department(60~)')",
                "ax[0,0].set_ylabel('Mean sales')",
                "ax[0,0].set_xlabel('Date')",
                "ax[0,1].set_ylabel('Mean sales')",
                "ax[0,1].set_xlabel('Date')",
                "ax[1,0].set_ylabel('Mean sales')",
                "ax[1,0].set_xlabel('Date')",
                "ax[1,1].set_ylabel('Mean sales')",
                "ax[1,1].set_xlabel('Date')",
                "plt.show()"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=train.groupby(['Dept','Date']).mean().round(0).reset_index()",
                "print(ASSIGN.shape)",
                "print(ASSIGN.head())",
                "ASSIGN=grouped[['Dept','Date','Weekly_Sales']]",
                "ASSIGN=train['Dept'].unique()",
                "ASSIGN.sort()",
                "ASSIGN=dept[0:20]",
                "ASSIGN=dept[20:40]",
                "ASSIGN=dept[40:60]",
                "ASSIGN=dept[60:]",
                "ASSIGN = plt.subplots(2,2,figsize=(20,10))",
                "fig.subplots_adjust(wspace=0.5, hspace=0.5)",
                "fig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Dept']==i]",
                "ax[0,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'],label='Dept_1_mean_sales')",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Dept']==i]",
                "ax[0,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'],label='Dept_1_mean_sales')",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Dept']==i]",
                "ax[1,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'],label='Dept_1_mean_sales')",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Dept']==i]",
                "ax[1,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'],label='Dept_1_mean_sales')",
                "ax[0,0].set_title('Mean sales record by department(0~19)')",
                "ax[0,1].set_title('Mean sales record by department(20~39)')",
                "ax[1,0].set_title('Mean sales record by department(40~59)')",
                "ax[1,1].set_title('Mean sales record by department(60~)')",
                "ax[0,0].set_ylabel('Mean sales')",
                "ax[0,0].set_xlabel('Date')",
                "ax[0,1].set_ylabel('Mean sales')",
                "ax[0,1].set_xlabel('Date')",
                "ax[1,0].set_ylabel('Mean sales')",
                "ax[1,0].set_xlabel('Date')",
                "ax[1,1].set_ylabel('Mean sales')",
                "ax[1,1].set_xlabel('Date')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN=train.groupby(['Store','Date']).mean().round(0).reset_index()",
                "grouped.shape",
                "ASSIGN.head()",
                "ASSIGN=grouped[['Store','Date','Weekly_Sales']]",
                "type(ASSIGN)",
                "ASSIGN=train['Store'].unique()",
                "ASSIGN.sort()",
                "ASSIGN=store[0:5]",
                "ASSIGN=store[5:10]",
                "ASSIGN=store[10:15]",
                "ASSIGN=store[15:20]",
                "ASSIGN=store[20:25]",
                "ASSIGN=store[25:30]",
                "ASSIGN=store[30:35]",
                "ASSIGN=store[35:40]",
                "ASSIGN=store[40:]",
                "ASSIGN = plt.subplots(5,2,figsize=(20,15))",
                "fig.subplots_adjust(wspace=0.5, hspace=0.5)",
                "fig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[0,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[0,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[1,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[1,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[2,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[2,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[3,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[3,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[4,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "ax[0,0].set_title('Mean sales record by ASSIGN(0~4)')",
                "ax[0,1].set_title('Mean sales record by ASSIGN(5~9)')",
                "ax[1,0].set_title('Mean sales record by ASSIGN(10~14)')",
                "ax[1,1].set_title('Mean sales record by ASSIGN(15~19)')",
                "ax[2,0].set_title('Mean sales record by ASSIGN(20~24)')",
                "ax[2,1].set_title('Mean sales record by ASSIGN(25~29)')",
                "ax[3,0].set_title('Mean sales record by ASSIGN(30~34)')",
                "ax[3,1].set_title('Mean sales record by ASSIGN(35~39)')",
                "ax[4,0].set_title('Mean sales record by ASSIGN(40~)')",
                "ax[0,0].set_ylabel('Mean sales')",
                "ax[0,0].set_xlabel('Date')",
                "ax[0,1].set_ylabel('Mean sales')",
                "ax[0,1].set_xlabel('Date')",
                "ax[1,0].set_ylabel('Mean sales')",
                "ax[1,0].set_xlabel('Date')",
                "ax[1,1].set_ylabel('Mean sales')",
                "ax[1,1].set_xlabel('Date')",
                "ax[2,0].set_ylabel('Mean sales')",
                "ax[2,0].set_xlabel('Date')",
                "ax[2,1].set_ylabel('Mean sales')",
                "ax[2,1].set_xlabel('Date')",
                "ax[3,0].set_ylabel('Mean sales')",
                "ax[3,0].set_xlabel('Date')",
                "ax[3,1].set_ylabel('Mean sales')",
                "ax[3,1].set_xlabel('Date')",
                "ax[4,0].set_ylabel('Mean sales')",
                "ax[4,0].set_xlabel('Date')",
                "plt.show()"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN=train.groupby(['Store','Date']).mean().round(0).reset_index()",
                "grouped.shape",
                "ASSIGN.head()",
                "ASSIGN=grouped[['Store','Date','Weekly_Sales']]",
                "type(ASSIGN)",
                "ASSIGN=train['Store'].unique()",
                "ASSIGN.sort()",
                "ASSIGN=store[0:5]",
                "ASSIGN=store[5:10]",
                "ASSIGN=store[10:15]",
                "ASSIGN=store[15:20]",
                "ASSIGN=store[20:25]",
                "ASSIGN=store[25:30]",
                "ASSIGN=store[30:35]",
                "ASSIGN=store[35:40]",
                "ASSIGN=store[40:]",
                "ASSIGN = plt.subplots(5,2,figsize=(20,15))",
                "fig.subplots_adjust(wspace=0.5, hspace=0.5)",
                "fig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[0,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[0,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[1,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[1,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[2,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[2,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[3,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[3,1].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "for i in ASSIGN :",
                "ASSIGN=data[data['Store']==i]",
                "ax[4,0].plot(ASSIGN['Date'], ASSIGN['Weekly_Sales'])",
                "ax[0,0].set_title('Mean sales record by ASSIGN(0~4)')",
                "ax[0,1].set_title('Mean sales record by ASSIGN(5~9)')",
                "ax[1,0].set_title('Mean sales record by ASSIGN(10~14)')",
                "ax[1,1].set_title('Mean sales record by ASSIGN(15~19)')",
                "ax[2,0].set_title('Mean sales record by ASSIGN(20~24)')",
                "ax[2,1].set_title('Mean sales record by ASSIGN(25~29)')",
                "ax[3,0].set_title('Mean sales record by ASSIGN(30~34)')",
                "ax[3,1].set_title('Mean sales record by ASSIGN(35~39)')",
                "ax[4,0].set_title('Mean sales record by ASSIGN(40~)')",
                "ax[0,0].set_ylabel('Mean sales')",
                "ax[0,0].set_xlabel('Date')",
                "ax[0,1].set_ylabel('Mean sales')",
                "ax[0,1].set_xlabel('Date')",
                "ax[1,0].set_ylabel('Mean sales')",
                "ax[1,0].set_xlabel('Date')",
                "ax[1,1].set_ylabel('Mean sales')",
                "ax[1,1].set_xlabel('Date')",
                "ax[2,0].set_ylabel('Mean sales')",
                "ax[2,0].set_xlabel('Date')",
                "ax[2,1].set_ylabel('Mean sales')",
                "ax[2,1].set_xlabel('Date')",
                "ax[3,0].set_ylabel('Mean sales')",
                "ax[3,0].set_xlabel('Date')",
                "ax[3,1].set_ylabel('Mean sales')",
                "ax[3,1].set_xlabel('Date')",
                "ax[4,0].set_ylabel('Mean sales')",
                "ax[4,0].set_xlabel('Date')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path(v4).csv\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "np.random.seed(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path(v4).csv\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "np.random.seed(0)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "nfl_data.sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "nfl_data.sample(5)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "sf_permits.sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sf_permits.sample(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = nfl_data.isnull().sum()",
                "ASSIGN[0:10]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = nfl_data.isnull().sum()",
                "ASSIGN[0:10]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = np.product(nfl_data.shape)",
                "ASSIGN = missing_values_count.sum()",
                "(total_missingpath) * 100"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.product(nfl_data.shape)",
                "ASSIGN = missing_values_count.sum()",
                "(total_missingpath) * 100"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = sf_permits.isnull().sum()",
                "ASSIGN = np.product(sf_permits.shape)",
                "ASSIGN = missing_values_count_sf_permits.sum()",
                "(total_missing_sf_permitspath) * 100"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = sf_permits.isnull().sum()",
                "ASSIGN = np.product(sf_permits.shape)",
                "ASSIGN = missing_values_count_sf_permits.sum()",
                "(total_missing_sf_permitspath) * 100"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "missing_values_count[0:10]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "missing_values_count[0:10]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(.format((sf_permits['Street Number Suffix'].isnull().sum()path['Street Number Suffix'].shape[0])*100))",
                "print(.format((sf_permits['Zipcode'].isnull().sum()path['Zipcode'].shape[0])*100))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(.format((sf_permits['Street Number Suffix'].isnull().sum()path['Street Number Suffix'].shape[0])*100))",
                "print(.format((sf_permits['Zipcode'].isnull().sum()path['Zipcode'].shape[0])*100))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "nfl_data.dropna()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "nfl_data.dropna()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = nfl_data.dropna(axis=1)",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = nfl_data.dropna(axis=1)",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print( % nfl_data.shape[1])",
                "print( % columns_with_na_dropped.shape[1])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print( % nfl_data.shape[1])",
                "print( % columns_with_na_dropped.shape[1])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "sf_permits.dropna()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sf_permits.dropna()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = sf_permits.dropna(axis=1)",
                "print( % sf_permits.shape[1])",
                "print( % ASSIGN.shape[1])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = sf_permits.dropna(axis=1)",
                "print( % sf_permits.shape[1])",
                "print( % ASSIGN.shape[1])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = nfl_data.loc[:, 'EPA':'Season'].head()",
                "subset_nfl_data"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = nfl_data.loc[:, 'EPA':'Season'].head()",
                "subset_nfl_data"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "subset_nfl_data.fillna(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "subset_nfl_data.fillna(0)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "subset_nfl_data.fillna(method = 'bfill', axis=0).fillna(\"0\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "subset_nfl_data.fillna(method = 'bfill', axis=0).fillna(\"0\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = sf_permits.fillna(method=\"bfill\", axis=0).fillna(0)",
                "ASSIGN.sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = sf_permits.fillna(method=\"bfill\", axis=0).fillna(0)",
                "ASSIGN.sample(5)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('..path', header=0, sep=',')",
                "ASSIGN = ASSIGN.loc[:,'MSSubClass':]",
                "print('Training data columns:', ASSIGN.columns)",
                "print('Training data shape', ASSIGN.shape)",
                "ASSIGN = pd.read_csv('..path', header=0, sep=',')",
                "ASSIGN = ASSIGN.loc[:,'MSSubClass':]",
                "print('Training data columns:', ASSIGN.columns)",
                "print('Test data shape\\n', ASSIGN.shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('..path', header=0, sep=',')",
                "ASSIGN = ASSIGN.loc[:,'MSSubClass':]",
                "print('Training data columns:', ASSIGN.columns)",
                "print('Training data shape', ASSIGN.shape)",
                "ASSIGN = pd.read_csv('..path', header=0, sep=',')",
                "ASSIGN = ASSIGN.loc[:,'MSSubClass':]",
                "print('Training data columns:', ASSIGN.columns)",
                "print('Test data shape\\n', ASSIGN.shape)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print('Missing data points in every features')",
                "ASSIGN = train_df.isnull().sum().sort_values(ascending=False)",
                "ASSIGN = (train_df.isnull().sum()path().count()).sort_values(ascending=False)",
                "ASSIGN = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])",
                "print(ASSIGN[:20])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print('Missing data points in every features')",
                "ASSIGN = train_df.isnull().sum().sort_values(ascending=False)",
                "ASSIGN = (train_df.isnull().sum()path().count()).sort_values(ascending=False)",
                "ASSIGN = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])",
                "print(ASSIGN[:20])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = missing_data[missing_data['Percent'] > 0.0].index",
                "ASSIGN = train_df[missing_data[missing_data['Percent'] <= 0.0].index]",
                "ASSIGN = filr_train_df.dtypes[filr_train_df.dtypes != \"object\"].index # Numerical columns",
                "ASSIGN = filr_train_df.dtypes[filr_train_df.dtypes == \"object\"].index # Categorical columns",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = missing_data[missing_data['Percent'] > 0.0].index",
                "ASSIGN = train_df[missing_data[missing_data['Percent'] <= 0.0].index]",
                "ASSIGN = filr_train_df.dtypes[filr_train_df.dtypes != \"object\"].index # Numerical columns",
                "ASSIGN = filr_train_df.dtypes[filr_train_df.dtypes == \"object\"].index # Categorical columns",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for ind, col in filr_train_df[catg_cols].iteritems():",
                "print(ind, set(list(col)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "for ind, col in filr_train_df[catg_cols].iteritems():",
                "print(ind, set(list(col)))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print('Number of features:', len(filr_train_df.columns))",
                "ASSIGN = filr_train_df.corr()",
                "ASSIGN = filr_train_df_corr[(filr_train_df_corr['SalePrice'] > 0.1)].index",
                "ASSIGN = filr_train_df.loc[:,highly_corr].corr()",
                "print('Number of features with corr:', len(ASSIGN))",
                "plt.figure(figsize=(10,10))",
                "sns.heatmap(ASSIGN, annot=True, square=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print('Number of features:', len(filr_train_df.columns))",
                "ASSIGN = filr_train_df.corr()",
                "ASSIGN = filr_train_df_corr[(filr_train_df_corr['SalePrice'] > 0.1)].index",
                "ASSIGN = filr_train_df.loc[:,highly_corr].corr()",
                "print('Number of features with corr:', len(ASSIGN))",
                "plt.figure(figsize=(10,10))",
                "sns.heatmap(ASSIGN, annot=True, square=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = filr_train_df[highly_corr].apply(lambda x: skew(x.dropna()))",
                "print('Skewness in feature data\\n',ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = filr_train_df[highly_corr].apply(lambda x: skew(x.dropna()))",
                "print('Skewness in feature data\\n',ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = pd.DataFrame()",
                "for ind, skew in skewed_feats.iteritems():",
                "if (skew > 0.5):",
                "ASSIGN = pd.concat([ASSIGN, np.log1p(filr_train_df[ind])], axis=1)",
                "ASSIGN.append(ind)",
                "else:",
                "ASSIGN = pd.concat([ASSIGN, filr_train_df[ind]], axis=1)",
                "print('Example feature:', ASSIGN[0])",
                "ASSIGN = pd.DataFrame({'Not_trsf': filr_train_df[LT_columns[0]], 'log_trsf':numLT_train_df[LT_columns[0]]})",
                "ASSIGN.hist()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = pd.DataFrame()",
                "for ind, skew in skewed_feats.iteritems():",
                "if (skew > 0.5):",
                "ASSIGN = pd.concat([ASSIGN, np.log1p(filr_train_df[ind])], axis=1)",
                "ASSIGN.append(ind)",
                "else:",
                "ASSIGN = pd.concat([ASSIGN, filr_train_df[ind]], axis=1)",
                "print('Example feature:', ASSIGN[0])",
                "ASSIGN = pd.DataFrame({'Not_trsf': filr_train_df[LT_columns[0]], 'log_trsf':numLT_train_df[LT_columns[0]]})",
                "ASSIGN.hist()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "sns.set()",
                "sns.distplot(numLT_train_df[LT_columns[0]], fit=norm);",
                "ASSIGN = plt.figure()",
                "ASSIGN = stats.probplot(numLT_train_df[LT_columns[0]], plot=plt)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sns.set()",
                "sns.distplot(numLT_train_df[LT_columns[0]], fit=norm);",
                "ASSIGN = plt.figure()",
                "ASSIGN = stats.probplot(numLT_train_df[LT_columns[0]], plot=plt)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print(numLT_train_df.shape)",
                "sns.pairplot(numLT_train_df.iloc[:,:5])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(numLT_train_df.shape)",
                "sns.pairplot(numLT_train_df.iloc[:,:5])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "catg_cols",
                "highly_corr",
                "LT_columns"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "catg_cols",
                "highly_corr",
                "LT_columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.concat([train_df.loc[:,'MSSubClass':], test_df.loc[:,'MSSubClass':]], ignore_index=True)",
                "print(ASSIGN.shape)",
                "print(ASSIGN.head())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.concat([train_df.loc[:,'MSSubClass':], test_df.loc[:,'MSSubClass':]], ignore_index=True)",
                "print(ASSIGN.shape)",
                "print(ASSIGN.head())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.get_dummies(tot_data[catg_cols])",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.get_dummies(tot_data[catg_cols])",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = tot_data[highly_corr]",
                "print(ASSIGN.shape)",
                "for cols in LT_columns:",
                "ASSIGN.loc[:,cols] = np.log1p(ASSIGN.loc[:,cols])",
                "print(ASSIGN.shape)",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = tot_data[highly_corr]",
                "print(ASSIGN.shape)",
                "for cols in LT_columns:",
                "ASSIGN.loc[:,cols] = np.log1p(ASSIGN.loc[:,cols])",
                "print(ASSIGN.shape)",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.concat([tot_data_cat, tot_data_num],axis=1)",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.concat([tot_data_cat, tot_data_num],axis=1)",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = tot_data_pro[:1000]",
                "ASSIGN = tot_data_pro[1000:1400]",
                "ASSIGN = ASSIGN.fillna(ASSIGN.mean())",
                "print(ASSIGN.shape, ASSIGN.shape)",
                "ASSIGN = pr_trainData['SalePrice']",
                "X_trainData = ASSIGN.drop('SalePrice', axis=1)",
                "X_testData = ASSIGN.drop('SalePrice', axis=1)",
                "print(X_trainData.shape, X_testData.shape)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = tot_data_pro[:1000]",
                "ASSIGN = tot_data_pro[1000:1400]",
                "ASSIGN = ASSIGN.fillna(ASSIGN.mean())",
                "print(ASSIGN.shape, ASSIGN.shape)",
                "ASSIGN = pr_trainData['SalePrice']",
                "X_trainData = ASSIGN.drop('SalePrice', axis=1)",
                "X_testData = ASSIGN.drop('SalePrice', axis=1)",
                "print(X_trainData.shape, X_testData.shape)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = make_scorer(mean_squared_error, greater_is_better = False)",
                "def rmse_cv_train(model):",
                "ASSIGN= np.sqrt(-cross_val_score(model, X_trainData, Y, scoring = scorer, cv = 5))",
                "return(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = make_scorer(mean_squared_error, greater_is_better = False)",
                "def rmse_cv_train(model):",
                "ASSIGN= np.sqrt(-cross_val_score(model, X_trainData, Y, scoring = scorer, cv = 5))",
                "return(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = RidgeCV(alphas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60])",
                "ASSIGN.fit(X_trainData, Y)",
                "ASSIGN = ridge.alpha_",
                "print(, ASSIGN)",
                "print( + str(ASSIGN))",
                "ASSIGN = RidgeCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85,",
                "ASSIGN * .9, ASSIGN * .95, ASSIGN, ASSIGN * 1.05, ASSIGN * 1.1, ASSIGN * 1.15,",
                "ASSIGN * 1.25, ASSIGN * 1.3, ASSIGN * 1.35, ASSIGN * 1.4],",
                "ASSIGN = 5)",
                "ASSIGN.fit(X_trainData, Y)",
                "ASSIGN = ridge.alpha_",
                "print(, ASSIGN)",
                "print(, rmse_cv_train(ASSIGN).mean())",
                "ASSIGN = ridge.predict(X_trainData)",
                "ASSIGN = ridge.predict(X_testData)",
                "sns.set()",
                "plt.scatter(ASSIGN, ASSIGN - Y, c = \"blue\", marker = \"o\", label = \"Training data\", ASSIGN=0.7)",
                "plt.scatter(ASSIGN, ASSIGN - pr_testData['SalePrice'], c = \"green\", marker = \"o\", label = \"Validation data\", ASSIGN=0.7)",
                "plt.title(\"Linear regression with Ridge regularization\")",
                "plt.xlabel(\"Predicted values\")",
                "plt.ylabel(\"Residuals\")",
                "plt.legend(loc = \"upper left\")",
                "plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")",
                "plt.show()",
                "plt.scatter(ASSIGN, Y, c = \"blue\", marker = \"o\", label = \"Training data\", ASSIGN=0.7)",
                "plt.scatter(ASSIGN, pr_testData['SalePrice'], c = \"green\", marker = \"o\", label = \"Validation data\", ASSIGN=0.7)",
                "plt.title(\"Linear regression with Ridge regularization\")",
                "plt.xlabel(\"Predicted values\")",
                "plt.ylabel(\"Real values\")",
                "plt.legend(loc = \"upper left\")",
                "plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")",
                "plt.show()",
                "ASSIGN = pd.Series(ridge.coef_, index = X_trainData.columns)",
                "print( + str(sum(ASSIGN != 0)) + + \\",
                "str(sum(ASSIGN == 0)) + \" features\")",
                "ASSIGN = pd.concat([coefs.sort_values().head(10),",
                "ASSIGN.sort_values().tail(10)])",
                "ASSIGN.plot(kind = \"barh\")",
                "plt.title(\"Coefficients in the Ridge Model\")",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = RidgeCV(alphas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60])",
                "ASSIGN.fit(X_trainData, Y)",
                "ASSIGN = ridge.alpha_",
                "print(, ASSIGN)",
                "print( + str(ASSIGN))",
                "ASSIGN = RidgeCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85,",
                "ASSIGN * .9, ASSIGN * .95, ASSIGN, ASSIGN * 1.05, ASSIGN * 1.1, ASSIGN * 1.15,",
                "ASSIGN * 1.25, ASSIGN * 1.3, ASSIGN * 1.35, ASSIGN * 1.4],",
                "ASSIGN = 5)",
                "ASSIGN.fit(X_trainData, Y)",
                "ASSIGN = ridge.alpha_",
                "print(, ASSIGN)",
                "print(, rmse_cv_train(ASSIGN).mean())",
                "ASSIGN = ridge.predict(X_trainData)",
                "ASSIGN = ridge.predict(X_testData)",
                "sns.set()",
                "plt.scatter(ASSIGN, ASSIGN - Y, c = \"blue\", marker = \"o\", label = \"Training data\", ASSIGN=0.7)",
                "plt.scatter(ASSIGN, ASSIGN - pr_testData['SalePrice'], c = \"green\", marker = \"o\", label = \"Validation data\", ASSIGN=0.7)",
                "plt.title(\"Linear regression with Ridge regularization\")",
                "plt.xlabel(\"Predicted values\")",
                "plt.ylabel(\"Residuals\")",
                "plt.legend(loc = \"upper left\")",
                "plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")",
                "plt.show()",
                "plt.scatter(ASSIGN, Y, c = \"blue\", marker = \"o\", label = \"Training data\", ASSIGN=0.7)",
                "plt.scatter(ASSIGN, pr_testData['SalePrice'], c = \"green\", marker = \"o\", label = \"Validation data\", ASSIGN=0.7)",
                "plt.title(\"Linear regression with Ridge regularization\")",
                "plt.xlabel(\"Predicted values\")",
                "plt.ylabel(\"Real values\")",
                "plt.legend(loc = \"upper left\")",
                "plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")",
                "plt.show()",
                "ASSIGN = pd.Series(ridge.coef_, index = X_trainData.columns)",
                "print( + str(sum(ASSIGN != 0)) + + \\",
                "str(sum(ASSIGN == 0)) + \" features\")",
                "ASSIGN = pd.concat([coefs.sort_values().head(10),",
                "ASSIGN.sort_values().tail(10)])",
                "ASSIGN.plot(kind = \"barh\")",
                "plt.title(\"Coefficients in the Ridge Model\")",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = LassoCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1],",
                "ASSIGN = 50000, cv = 10)",
                "ASSIGN.fit(X_trainData, Y)",
                "ASSIGN = lasso.alpha_",
                "print(, ASSIGN)",
                "print( + str(ASSIGN))",
                "ASSIGN = LassoCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8,",
                "ASSIGN * .85, ASSIGN * .9, ASSIGN * .95, ASSIGN, ASSIGN * 1.05,",
                "ASSIGN * 1.1, ASSIGN * 1.15, ASSIGN * 1.25, ASSIGN * 1.3, ASSIGN * 1.35,",
                "ASSIGN * 1.4],",
                "ASSIGN = 50000, cv = 10)",
                "ASSIGN.fit(X_trainData, Y)",
                "ASSIGN = lasso.alpha_",
                "print(, ASSIGN)",
                "print(, rmse_cv_train(ASSIGN).mean())",
                "ASSIGN = lasso.predict(X_trainData)",
                "ASSIGN = lasso.predict(X_testData)",
                "plt.scatter(ASSIGN, ASSIGN - Y, c = \"blue\", marker = \"s\", label = \"Training data\", ASSIGN=0.7)",
                "plt.scatter(ASSIGN, ASSIGN - pr_testData['SalePrice'], c = \"green\", marker = \"s\", label = \"Validation data\", ASSIGN=0.7)",
                "plt.title(\"Linear regression with Lasso regularization\")",
                "plt.xlabel(\"Predicted values\")",
                "plt.ylabel(\"Residuals\")",
                "plt.legend(loc = \"upper left\")",
                "plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")",
                "plt.show()",
                "plt.scatter(ASSIGN, Y, c = \"blue\", marker = \"s\", label = \"Training data\", ASSIGN=0.7)",
                "plt.scatter(ASSIGN, pr_testData['SalePrice'], c = \"green\", marker = \"s\", label = \"Validation data\", ASSIGN=0.7)",
                "plt.title(\"Linear regression with Lasso regularization\")",
                "plt.xlabel(\"Predicted values\")",
                "plt.ylabel(\"Real values\")",
                "plt.legend(loc = \"upper left\")",
                "plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")",
                "plt.show()",
                "ASSIGN = pd.Series(lasso.coef_, index = X_trainData.columns)",
                "print( + str(sum(ASSIGN != 0)) + + \\",
                "str(sum(ASSIGN == 0)) + \" features\")",
                "ASSIGN = pd.concat([coefs.sort_values().head(10),",
                "ASSIGN.sort_values().tail(10)])",
                "ASSIGN.plot(kind = \"barh\")",
                "plt.title(\"Coefficients in the Lasso Model\")",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = LassoCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1],",
                "ASSIGN = 50000, cv = 10)",
                "ASSIGN.fit(X_trainData, Y)",
                "ASSIGN = lasso.alpha_",
                "print(, ASSIGN)",
                "print( + str(ASSIGN))",
                "ASSIGN = LassoCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8,",
                "ASSIGN * .85, ASSIGN * .9, ASSIGN * .95, ASSIGN, ASSIGN * 1.05,",
                "ASSIGN * 1.1, ASSIGN * 1.15, ASSIGN * 1.25, ASSIGN * 1.3, ASSIGN * 1.35,",
                "ASSIGN * 1.4],",
                "ASSIGN = 50000, cv = 10)",
                "ASSIGN.fit(X_trainData, Y)",
                "ASSIGN = lasso.alpha_",
                "print(, ASSIGN)",
                "print(, rmse_cv_train(ASSIGN).mean())",
                "ASSIGN = lasso.predict(X_trainData)",
                "ASSIGN = lasso.predict(X_testData)",
                "plt.scatter(ASSIGN, ASSIGN - Y, c = \"blue\", marker = \"s\", label = \"Training data\", ASSIGN=0.7)",
                "plt.scatter(ASSIGN, ASSIGN - pr_testData['SalePrice'], c = \"green\", marker = \"s\", label = \"Validation data\", ASSIGN=0.7)",
                "plt.title(\"Linear regression with Lasso regularization\")",
                "plt.xlabel(\"Predicted values\")",
                "plt.ylabel(\"Residuals\")",
                "plt.legend(loc = \"upper left\")",
                "plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")",
                "plt.show()",
                "plt.scatter(ASSIGN, Y, c = \"blue\", marker = \"s\", label = \"Training data\", ASSIGN=0.7)",
                "plt.scatter(ASSIGN, pr_testData['SalePrice'], c = \"green\", marker = \"s\", label = \"Validation data\", ASSIGN=0.7)",
                "plt.title(\"Linear regression with Lasso regularization\")",
                "plt.xlabel(\"Predicted values\")",
                "plt.ylabel(\"Real values\")",
                "plt.legend(loc = \"upper left\")",
                "plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")",
                "plt.show()",
                "ASSIGN = pd.Series(lasso.coef_, index = X_trainData.columns)",
                "print( + str(sum(ASSIGN != 0)) + + \\",
                "str(sum(ASSIGN == 0)) + \" features\")",
                "ASSIGN = pd.concat([coefs.sort_values().head(10),",
                "ASSIGN.sort_values().tail(10)])",
                "ASSIGN.plot(kind = \"barh\")",
                "plt.title(\"Coefficients in the Lasso Model\")",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "py.init_notebook_mode(connected=True)"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "py.init_notebook_mode(connected=True)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\",parse_dates=['date'])",
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=['date'])"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\",parse_dates=['date'])",
                "ASSIGN = pd.read_csv(\"..path\", parse_dates=['date'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(train.shape)",
                "train.head()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(train.shape)",
                "train.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(.format(train.columns.values, train.isnull().any().values))",
                "print('---')",
                "print(.format(oil.columns.values,oil.isnull().any().values))",
                "print('---')",
                "print(.format(holiday_events.columns.values,holiday_events.isnull().any().values))",
                "print('---')",
                "print(.format(stores.columns.values,stores.isnull().any().values))",
                "print('---')",
                "print(.format(transactions.columns.values,transactions.isnull().any().values))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(.format(train.columns.values, train.isnull().any().values))",
                "print('---')",
                "print(.format(oil.columns.values,oil.isnull().any().values))",
                "print('---')",
                "print(.format(holiday_events.columns.values,holiday_events.isnull().any().values))",
                "print('---')",
                "print(.format(stores.columns.values,stores.isnull().any().values))",
                "print('---')",
                "print(.format(transactions.columns.values,transactions.isnull().any().values))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "oil.head(3)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "oil.head(3)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = go.Scatter(",
                "ASSIGN='Oil prices',",
                "ASSIGN=oil['date'],",
                "ASSIGN=oil['dcoilwtico'].dropna(),",
                "ASSIGN='lines',",
                ")",
                "ASSIGN = [trace]",
                "ASSIGN = go.Layout(",
                "ASSIGN = dict(title = 'Daily Oil price'),",
                "ASSIGN = True)",
                "ASSIGN = go.Figure(data = data, layout = layout)",
                "py.iplot(ASSIGN, filename='pandas-time-series-error-bars')"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = go.Scatter(",
                "ASSIGN='Oil prices',",
                "ASSIGN=oil['date'],",
                "ASSIGN=oil['dcoilwtico'].dropna(),",
                "ASSIGN='lines',",
                ")",
                "ASSIGN = [trace]",
                "ASSIGN = go.Layout(",
                "ASSIGN = dict(title = 'Daily Oil price'),",
                "ASSIGN = True)",
                "ASSIGN = go.Figure(data = data, layout = layout)",
                "py.iplot(ASSIGN, filename='pandas-time-series-error-bars')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "holiday_events.head(3)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "holiday_events.head(3)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "holiday_events.type.unique()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "holiday_events.type.unique()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.style.use('seaborn-white')",
                "ASSIGN = holiday_events.groupby(['locale_name', 'type']).size()",
                "ASSIGN.unstack().plot(kind='bar',stacked=True, colormap= 'magma_r', figsize=(12,10), grid=False)",
                "plt.ylabel('Count of entries')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.style.use('seaborn-white')",
                "ASSIGN = holiday_events.groupby(['locale_name', 'type']).size()",
                "ASSIGN.unstack().plot(kind='bar',stacked=True, colormap= 'magma_r', figsize=(12,10), grid=False)",
                "plt.ylabel('Count of entries')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "items.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "items.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = (list(x) for x in zip(*sorted(zip(items.family.value_counts().index,",
                "items.family.value_counts().values),",
                "ASSIGN = False)))",
                "ASSIGN = go.Bar(",
                "ASSIGN = items.family.value_counts().values,",
                "ASSIGN = items.family.value_counts().index",
                ")",
                "ASSIGN = dict(",
                "ASSIGN='Counts of items per family category',",
                "ASSIGN = 900, height = 600,",
                "ASSIGN=dict(",
                "ASSIGN = True,",
                "ASSIGN = True,",
                "ASSIGN = True",
                "))",
                "ASSIGN = go.Figure(data=[trace2])",
                "ASSIGN['ASSIGN'].update(ASSIGN)",
                "py.iplot(ASSIGN, filename='plots')"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = (list(x) for x in zip(*sorted(zip(items.family.value_counts().index,",
                "items.family.value_counts().values),",
                "ASSIGN = False)))",
                "ASSIGN = go.Bar(",
                "ASSIGN = items.family.value_counts().values,",
                "ASSIGN = items.family.value_counts().index",
                ")",
                "ASSIGN = dict(",
                "ASSIGN='Counts of items per family category',",
                "ASSIGN = 900, height = 600,",
                "ASSIGN=dict(",
                "ASSIGN = True,",
                "ASSIGN = True,",
                "ASSIGN = True",
                "))",
                "ASSIGN = go.Figure(data=[trace2])",
                "ASSIGN['ASSIGN'].update(ASSIGN)",
                "py.iplot(ASSIGN, filename='plots')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.style.use('seaborn-white')",
                "ASSIGN = items.groupby(['family', 'perishable']).size()",
                "ASSIGN.unstack().plot(kind='bar',stacked=True, colormap = 'coolwarm', figsize=(12,10), grid = True)",
                "plt.ylabel('count')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.style.use('seaborn-white')",
                "ASSIGN = items.groupby(['family', 'perishable']).size()",
                "ASSIGN.unstack().plot(kind='bar',stacked=True, colormap = 'coolwarm', figsize=(12,10), grid = True)",
                "plt.ylabel('count')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "stores.head(3)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "stores.head(3)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots()",
                "fig.set_size_inches(8, 8)",
                "ASSIGN = sns.countplot(y = stores['state'], data = stores)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.subplots()",
                "fig.set_size_inches(8, 8)",
                "ASSIGN = sns.countplot(y = stores['state'], data = stores)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots()",
                "fig.set_size_inches(8, 8)",
                "ASSIGN = sns.countplot(y = stores['city'], data = stores)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.subplots()",
                "fig.set_size_inches(8, 8)",
                "ASSIGN = sns.countplot(y = stores['city'], data = stores)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "stores.state.unique()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "stores.state.unique()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "stores.city.unique()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "stores.city.unique()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots()",
                "fig.set_size_inches(8, 5)",
                "ASSIGN = sns.countplot(x = \"type\", data = stores, palette=\"Paired\")"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.subplots()",
                "fig.set_size_inches(8, 5)",
                "ASSIGN = sns.countplot(x = \"type\", data = stores, palette=\"Paired\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.crosstab(stores.state, stores.type)",
                "ASSIGN.plot.bar(figsize = (12, 6), stacked=True)",
                "plt.legend(title='type')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.crosstab(stores.state, stores.type)",
                "ASSIGN.plot.bar(figsize = (12, 6), stacked=True)",
                "plt.legend(title='type')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.crosstab(stores.city, stores.type)",
                "ASSIGN.plot.bar(figsize = (12, 6), stacked=True)",
                "plt.legend(title='type')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.crosstab(stores.city, stores.type)",
                "ASSIGN.plot.bar(figsize = (12, 6), stacked=True)",
                "plt.legend(title='type')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "stores.store_nbr.nunique()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "stores.store_nbr.nunique()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "stores.cluster.sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "stores.cluster.sum()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots()",
                "fig.set_size_inches(12, 7)",
                "ASSIGN = sns.countplot(x = \"cluster\", data = stores)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.subplots()",
                "fig.set_size_inches(12, 7)",
                "ASSIGN = sns.countplot(x = \"cluster\", data = stores)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "transactions.head(3)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "transactions.head(3)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "print(\"There are {0} transactions\".",
                "format(transactions.shape[0], transactions.shape[1]))"
            ],
            "output_type": "stream",
            "content_old": [
                "print(\"There are {0} transactions\".",
                "format(transactions.shape[0], transactions.shape[1]))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.style.use('seaborn-white')",
                "plt.figure(figsize=(13,11))",
                "plt.plot(transactions.date.values, transactions.transactions.values, color='grey')",
                "plt.axvline(x='2015-12-23',color='red',alpha=0.3)",
                "plt.axvline(x='2016-12-23',color='red',alpha=0.3)",
                "plt.axvline(x='2014-12-23',color='red',alpha=0.3)",
                "plt.axvline(x='2013-12-23',color='red',alpha=0.3)",
                "plt.axvline(x='2013-05-12',color='green',alpha=0.2, linestyle= '--')",
                "plt.axvline(x='2015-05-10',color='green',alpha=0.2, linestyle= '--')",
                "plt.axvline(x='2016-05-08',color='green',alpha=0.2, linestyle= '--')",
                "plt.axvline(x='2014-05-11',color='green',alpha=0.2, linestyle= '--')",
                "plt.axvline(x='2017-05-14',color='green',alpha=0.2, linestyle= '--')",
                "plt.ylabel('Transactions per day', fontsize= 16)",
                "plt.xlabel('Date', fontsize= 16)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.style.use('seaborn-white')",
                "plt.figure(figsize=(13,11))",
                "plt.plot(transactions.date.values, transactions.transactions.values, color='grey')",
                "plt.axvline(x='2015-12-23',color='red',alpha=0.3)",
                "plt.axvline(x='2016-12-23',color='red',alpha=0.3)",
                "plt.axvline(x='2014-12-23',color='red',alpha=0.3)",
                "plt.axvline(x='2013-12-23',color='red',alpha=0.3)",
                "plt.axvline(x='2013-05-12',color='green',alpha=0.2, linestyle= '--')",
                "plt.axvline(x='2015-05-10',color='green',alpha=0.2, linestyle= '--')",
                "plt.axvline(x='2016-05-08',color='green',alpha=0.2, linestyle= '--')",
                "plt.axvline(x='2014-05-11',color='green',alpha=0.2, linestyle= '--')",
                "plt.axvline(x='2017-05-14',color='green',alpha=0.2, linestyle= '--')",
                "plt.ylabel('Transactions per day', fontsize= 16)",
                "plt.xlabel('Date', fontsize= 16)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "np.random.seed(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "np.random.seed(0)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = \"This is the euro symbol: €\"",
                "type(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = \"This is the euro symbol: €\"",
                "type(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = before.encode(\"utf-8\", errors = \"replace\")",
                "type(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = before.encode(\"utf-8\", errors = \"replace\")",
                "type(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "after"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "after"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(after.decode())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(after.decode())"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(after.decode())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(after.decode())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = \"This is the euro symbol: €\"",
                "ASSIGN = before.encode(\"ascii\", errors = \"replace\")",
                "print(ASSIGN.decode())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = \"This is the euro symbol: €\"",
                "ASSIGN = before.encode(\"ascii\", errors = \"replace\")",
                "print(ASSIGN.decode())"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = \"i'll try the recommended $, #, 你好 and नमस्ते and see what happens.\"",
                "ASSIGN = my_text.encode(\"ascii\", errors = \"replace\")",
                "print(ASSIGN.decode())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = \"i'll try the recommended $, #, 你好 and नमस्ते and see what happens.\"",
                "ASSIGN = my_text.encode(\"ascii\", errors = \"replace\")",
                "print(ASSIGN.decode())"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "with open(\"..path\", 'rb') as rawdata:",
                "ASSIGN = chardet.detect(rawdata.read(10000))",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "with open(\"..path\", 'rb') as rawdata:",
                "ASSIGN = chardet.detect(rawdata.read(10000))",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\", encoding='Windows-1252')",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\", encoding='Windows-1252')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=[1,10,100,1000,10000,100000,1000000]",
                "with open(\"..path\", 'rb') as rawdata1:",
                "for i in ASSIGN:",
                "ASSIGN = chardet.detect(rawdata1.read(i))",
                "print (i, ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=[1,10,100,1000,10000,100000,1000000]",
                "with open(\"..path\", 'rb') as rawdata1:",
                "for i in ASSIGN:",
                "ASSIGN = chardet.detect(rawdata1.read(i))",
                "print (i, ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\", encoding='Windows-1252')",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\", encoding='Windows-1252')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "kickstarter_2016.to_csv(\"ks-projects-201801-utf8.csv\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "kickstarter_2016.to_csv(\"ks-projects-201801-utf8.csv\")"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "police_killings.to_csv(\"PoliceKillingsUS-utf8.csv\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "police_killings.to_csv(\"PoliceKillingsUS-utf8.csv\")"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(f\"{BASE_PATH}path\")",
                "ASSIGN = pd.read_csv(f\"{BASE_PATH}path\")",
                "ASSIGN = pd.read_csv(f\"{BASE_PATH}path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(f\"{BASE_PATH}path\")",
                "ASSIGN = pd.read_csv(f\"{BASE_PATH}path\")",
                "ASSIGN = pd.read_csv(f\"{BASE_PATH}path\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = list(fnc_df.columns[1:]), list(loading_df.columns[1:])",
                "ASSIGN = fnc_df.merge(loading_df, on=\"Id\")",
                "labels_df[\"is_train\"] = True",
                "ASSIGN = ASSIGN.merge(labels_df, on=\"Id\", how=\"left\")",
                "ASSIGN = df[df[\"is_train\"] != True].copy()",
                "ASSIGN = ASSIGN[ASSIGN[\"is_train\"] == True].copy()",
                "print(f'Shape of train data: {ASSIGN.shape}, Shape of test data: {ASSIGN.shape}')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = list(fnc_df.columns[1:]), list(loading_df.columns[1:])",
                "ASSIGN = fnc_df.merge(loading_df, on=\"Id\")",
                "labels_df[\"is_train\"] = True",
                "ASSIGN = ASSIGN.merge(labels_df, on=\"Id\", how=\"left\")",
                "ASSIGN = df[df[\"is_train\"] != True].copy()",
                "ASSIGN = ASSIGN[ASSIGN[\"is_train\"] == True].copy()",
                "print(f'Shape of train data: {ASSIGN.shape}, Shape of test data: {ASSIGN.shape}')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']",
                "df.drop(['is_train'], axis=1, inplace=True)",
                "ASSIGN = ASSIGN.drop(target_cols + ['is_train'], axis=1)",
                "df[fnc_features] *= FNC_SCALE",
                "ASSIGN[fnc_features] *= FNC_SCALE"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']",
                "df.drop(['is_train'], axis=1, inplace=True)",
                "ASSIGN = ASSIGN.drop(target_cols + ['is_train'], axis=1)",
                "df[fnc_features] *= FNC_SCALE",
                "ASSIGN[fnc_features] *= FNC_SCALE"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def get_train_data(target):",
                "ASSIGN = [tar for tar in target_cols if tar != target]",
                "ASSIGN = df.drop( other_targets, axis=1)",
                "return train_df"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def get_train_data(target):",
                "ASSIGN = [tar for tar in target_cols if tar != target]",
                "ASSIGN = df.drop( other_targets, axis=1)",
                "return train_df"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 'age'",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 'age'",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['tr']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['tr']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = create_model(",
                "ASSIGN='br',",
                "ASSIGN=10",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = create_model(",
                "ASSIGN='br',",
                "ASSIGN=10",
                ")"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = tune_model(",
                "ASSIGN='br',",
                "ASSIGN=10,",
                "ASSIGN = 'mae',",
                "ASSIGN=50",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = tune_model(",
                "ASSIGN='br',",
                "ASSIGN=10,",
                "ASSIGN = 'mae',",
                "ASSIGN=50",
                ")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_model(estimator = tuned_br_age, plot = 'learning')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_model(estimator = tuned_br_age, plot = 'learning')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_model(estimator = tuned_br_age, plot = 'residuals')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_model(estimator = tuned_br_age, plot = 'residuals')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_model(estimator = tuned_br_age, plot = 'feature')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_model(estimator = tuned_br_age, plot = 'feature')"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "evaluate_model(estimator=tuned_br_age)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "evaluate_model(estimator=tuned_br_age)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = predict_model(tuned_br_age, data=test_df)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = predict_model(tuned_br_age, data=test_df)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "predictions.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "predictions.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = target_cols[0]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[0]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = target_cols[1]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[1]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = target_cols[2]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[2]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = target_cols[3]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[3]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = target_cols[4]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[4]",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "compare_models(",
                "ASSIGN = blacklist_models,",
                "ASSIGN = 10,",
                "ASSIGN = 'MAE',",
                "ASSIGN = True",
                ")"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = {",
                "'age': 'br',",
                "'domain1_var1':'catboost',",
                "'domain1_var2':'svm',",
                "'domain2_var1':'catboost',",
                "'domain2_var2':'catboost',",
                "}",
                "def tune_and_ensemble(target):",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "ASSIGN = target_models_dict[target]",
                "ASSIGN = tune_model(model_name, fold=10)",
                "ASSIGN = ensemble_model(tuned_model, fold=10)",
                "return model"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = {",
                "'age': 'br',",
                "'domain1_var1':'catboost',",
                "'domain1_var2':'svm',",
                "'domain2_var1':'catboost',",
                "'domain2_var2':'catboost',",
                "}",
                "def tune_and_ensemble(target):",
                "ASSIGN = get_train_data(target)",
                "ASSIGN = setup(",
                "ASSIGN = train_df,",
                "ASSIGN = ASSIGN,",
                "ASSIGN=0.8,",
                "ASSIGN = 'mean',",
                "ASSIGN = True",
                ")",
                "ASSIGN = target_models_dict[target]",
                "ASSIGN = tune_model(model_name, fold=10)",
                "ASSIGN = ensemble_model(tuned_model, fold=10)",
                "return model"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = target_cols[0]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[0]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = target_cols[1]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = target_cols[1]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "target"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = target_cols[2]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[2]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = target_cols[3]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[3]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = target_cols[4]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = target_cols[4]",
                "ASSIGN = tune_and_ensemble(target)",
                "models.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Post Development Phase"
            ],
            "content": [
                "def finalize_model_pipeline(model, target):",
                "finalize_model(model)",
                "save_model(model, f'{target}_{target_models_dict[target]}', verbose=True)",
                "ASSIGN = predict_model(model, data=test_df)",
                "test_df[target] = ASSIGN['Label'].values"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def finalize_model_pipeline(model, target):",
                "finalize_model(model)",
                "save_model(model, f'{target}_{target_models_dict[target]}', verbose=True)",
                "ASSIGN = predict_model(model, data=test_df)",
                "test_df[target] = ASSIGN['Label'].values"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for index, target in enumerate(target_cols):",
                "ASSIGN = models[index]",
                "finalize_model_pipeline(ASSIGN,target)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for index, target in enumerate(target_cols):",
                "ASSIGN = models[index]",
                "finalize_model_pipeline(ASSIGN,target)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Post Development Phase",
                "Data Validation Activtiy"
            ],
            "content": [
                "ASSIGN = pd.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")",
                "ASSIGN[\"Id\"] = ASSIGN[\"Id\"].astype(\"str\") + \"_\" + ASSIGN[\"variable\"].astype(\"str\")",
                "ASSIGN = ASSIGN.drop(\"variable\", axis=1).sort_values(\"Id\")",
                "assert ASSIGN.shape[0] == test_df.shape[0]*5",
                "ASSIGN.to_csv(\"submission1.csv\", index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")",
                "ASSIGN[\"Id\"] = ASSIGN[\"Id\"].astype(\"str\") + \"_\" + ASSIGN[\"variable\"].astype(\"str\")",
                "ASSIGN = ASSIGN.drop(\"variable\", axis=1).sort_values(\"Id\")",
                "assert ASSIGN.shape[0] == test_df.shape[0]*5",
                "ASSIGN.to_csv(\"submission1.csv\", index=False)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "sub_df.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "sub_df.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path', encoding='latin-1')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path', encoding='latin-1')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "Rest.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Rest.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "Rest.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "Rest.shape"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "Rest.to_csv(\"Rest.csv\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "Rest.to_csv(\"Rest.csv\")"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "InteractiveShell.ast_node_interactivity = \"all\"",
                "warnings.filterwarnings(\"ignore\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "InteractiveShell.ast_node_interactivity = \"all\"",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Post Development Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN.info()",
                "cc[cc.columns[cc.isna().any()]].isna().sum().to_frame().T",
                "ASSIGN.sample(5)",
                "ASSIGN.describe()"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN.info()",
                "cc[cc.columns[cc.isna().any()]].isna().sum().to_frame().T",
                "ASSIGN.sample(5)",
                "ASSIGN.describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "cc.quantile([0.75,0.8,.85,.9,.95,1])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "cc.quantile([0.75,0.8,.85,.9,.95,1])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "display(HTML('<h4>There are '+str(np.sum(cc.BALANCE>cc.CREDIT_LIMIT))",
                "+' customers in the list who have more balance than the credit limit assigned. '",
                "+'It may be due to more payament than usage andpath<path>'))"
            ],
            "output_type": "display_data",
            "content_old": [
                "display(HTML('<h4>There are '+str(np.sum(cc.BALANCE>cc.CREDIT_LIMIT))",
                "+' customers in the list who have more balance than the credit limit assigned. '",
                "+'It may be due to more payament than usage andpath<path>'))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "cc.rename(columns = {col:col.lower() for col in cc.columns.values},inplace=True)",
                "sns.jointplot(cc.credit_limit,cc.minimum_payments,kind = 'kde', dropna=True)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "cc.rename(columns = {col:col.lower() for col in cc.columns.values},inplace=True)",
                "sns.jointplot(cc.credit_limit,cc.minimum_payments,kind = 'kde', dropna=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "cc.fillna(cc.median(),inplace=True)",
                "ASSIGN = cc.cust_id",
                "cc.drop(columns = ['cust_id'],inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "cc.fillna(cc.median(),inplace=True)",
                "ASSIGN = cc.cust_id",
                "cc.drop(columns = ['cust_id'],inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = StandardScaler()",
                "X= normalize(ASSIGN.fit_transform(cc.copy()))",
                "ASSIGN = pd.DataFrame(ASSIGN,columns=cc.columns.values)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = StandardScaler()",
                "X= normalize(ASSIGN.fit_transform(cc.copy()))",
                "ASSIGN = pd.DataFrame(ASSIGN,columns=cc.columns.values)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(6,3, figsize=(20, 20))",
                "for i in range(17):",
                "ASSIGN = sns.distplot(cc[cc.columns[i]], ax=axs[ipath,i%3],kde_kws = {'bw':2})",
                "ASSIGN = sns.despine()",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.subplots(6,3, figsize=(20, 20))",
                "for i in range(17):",
                "ASSIGN = sns.distplot(cc[cc.columns[i]], ax=axs[ipath,i%3],kde_kws = {'bw':2})",
                "ASSIGN = sns.despine()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "X.boxplot(figsize = (30,25),grid=True,fontsize=25,rot=90)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "X.boxplot(figsize = (30,25),grid=True,fontsize=25,rot=90)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,12))",
                "ASSIGN = sns.heatmap(cc.corr(),annot=True,cmap='jet').set_title(\"Correlation of credit card data\\'s features\",fontsize=20)",
                "plt.show()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(16,12))",
                "ASSIGN = sns.heatmap(cc.corr(),annot=True,cmap='jet').set_title(\"Correlation of credit card data\\'s features\",fontsize=20)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = [GMM(n,random_state=0).fit(X) for n in range(1,12)]",
                "ASSIGN = pd.DataFrame({'BIC Score':[m.bic(X) for m in models],",
                "'AIC Score': [m.aic(X) for m in ASSIGN]},index=np.arange(1,12))",
                "ASSIGN.plot(use_index=True,title='AIC and BIC Scores for GMM wrt n_Compnents',figsize = (10,5),fontsize=12)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = [GMM(n,random_state=0).fit(X) for n in range(1,12)]",
                "ASSIGN = pd.DataFrame({'BIC Score':[m.bic(X) for m in models],",
                "'AIC Score': [m.aic(X) for m in ASSIGN]},index=np.arange(1,12))",
                "ASSIGN.plot(use_index=True,title='AIC and BIC Scores for GMM wrt n_Compnents',figsize = (10,5),fontsize=12)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "class GMClusters(GMM, ClusterMixin):",
                "def __init__(self, n_clusters=1, **kwargs):",
                "kwargs[\"n_components\"] = n_clusters",
                "kwargs['covariance_type'] = 'full'",
                "super(GMClusters, self).__init__(**kwargs)",
                "def fit(self, X):",
                "super(GMClusters, self).fit(X)",
                "self.labels_ = self.predict(X)",
                "return self",
                "ASSIGN = KElbow(GMClusters(), k=(2,12), force_model=True)",
                "ASSIGN.fit(X)",
                "ASSIGN.show()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "class GMClusters(GMM, ClusterMixin):",
                "def __init__(self, n_clusters=1, **kwargs):",
                "kwargs[\"n_components\"] = n_clusters",
                "kwargs['covariance_type'] = 'full'",
                "super(GMClusters, self).__init__(**kwargs)",
                "def fit(self, X):",
                "super(GMClusters, self).fit(X)",
                "self.labels_ = self.predict(X)",
                "return self",
                "ASSIGN = KElbow(GMClusters(), k=(2,12), force_model=True)",
                "ASSIGN.fit(X)",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN= models[6]",
                "ASSIGN.n_init = 10",
                "model"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN= models[6]",
                "ASSIGN.n_init = 10",
                "model"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = model.fit_predict(X)",
                "display(HTML('<b>The model has converged :<path>'+str(model.converged_)))",
                "display(HTML('<b>The model has taken iterations :<path>'+str(model.n_iter_)))"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = model.fit_predict(X)",
                "display(HTML('<b>The model has converged :<path>'+str(model.converged_)))",
                "display(HTML('<b>The model has taken iterations :<path>'+str(model.n_iter_)))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(clusters).set_title('Cluster sizes',fontsize=20)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(clusters).set_title('Cluster sizes',fontsize=20)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = cc.copy()",
                "ASSIGN['cluster']=clusters",
                "for c in ASSIGN:",
                "if c != 'cluster':",
                "ASSIGN= sns.FacetGrid(cc1, col='cluster',sharex=False,sharey=False)",
                "ASSIGN = grid.map(sns.distplot, c,kde_kws = {'bw':2})",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = cc.copy()",
                "ASSIGN['cluster']=clusters",
                "for c in ASSIGN:",
                "if c != 'cluster':",
                "ASSIGN= sns.FacetGrid(cc1, col='cluster',sharex=False,sharey=False)",
                "ASSIGN = grid.map(sns.distplot, c,kde_kws = {'bw':2})",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "for i in range(7):",
                "display(HTML('<h2>Cluster'+str(i)+'<path>'))",
                "cc1[cc1.cluster == i].describe()"
            ],
            "output_type": "display_data",
            "content_old": [
                "for i in range(7):",
                "display(HTML('<h2>Cluster'+str(i)+'<path>'))",
                "cc1[cc1.cluster == i].describe()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = TSNE(n_components = 2)",
                "ASSIGN = tsne.fit_transform(X.copy())",
                "plt.scatter(ASSIGN[:, 0], ASSIGN[:, 1],",
                "ASSIGN=10,",
                "ASSIGN=10,",
                "ASSIGN=5,",
                "ASSIGN=clusters",
                ")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = TSNE(n_components = 2)",
                "ASSIGN = tsne.fit_transform(X.copy())",
                "plt.scatter(ASSIGN[:, 0], ASSIGN[:, 1],",
                "ASSIGN=10,",
                "ASSIGN=10,",
                "ASSIGN=5,",
                "ASSIGN=clusters",
                ")"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = model.score_samples(X)",
                "ASSIGN = np.percentile(density,4)",
                "cc1['cluster']=clusters",
                "cc1['Anamoly'] = ASSIGN<ASSIGN",
                "cc1"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = model.score_samples(X)",
                "ASSIGN = np.percentile(density,4)",
                "cc1['cluster']=clusters",
                "cc1['Anamoly'] = ASSIGN<ASSIGN",
                "cc1"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = cc1.melt(['Anamoly'], var_name='cols', value_name='vals')",
                "ASSIGN = sns.FacetGrid(df, row='cols', hue=\"Anamoly\", palette=\"Set1\",sharey=False,sharex=False,aspect=3)",
                "ASSIGN = (ASSIGN.map(sns.distplot, \"vals\", hist=True, rug=True,kde_kws = {'bw':2}).add_legend())"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = cc1.melt(['Anamoly'], var_name='cols', value_name='vals')",
                "ASSIGN = sns.FacetGrid(df, row='cols', hue=\"Anamoly\", palette=\"Set1\",sharey=False,sharex=False,aspect=3)",
                "ASSIGN = (ASSIGN.map(sns.distplot, \"vals\", hist=True, rug=True,kde_kws = {'bw':2}).add_legend())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = X[density>=density_threshold]",
                "ASSIGN = clusters[density>=density_threshold]",
                "ASSIGN = TSNE(n_components = 2)",
                "ASSIGN = tsne.fit_transform(unanomaly)",
                "plt.figure(figsize=(15,10))",
                "plt.scatter(ASSIGN[:, 0], ASSIGN[:, 1],marker='x',s=10, linewidths=5, ASSIGN=ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = X[density>=density_threshold]",
                "ASSIGN = clusters[density>=density_threshold]",
                "ASSIGN = TSNE(n_components = 2)",
                "ASSIGN = tsne.fit_transform(unanomaly)",
                "plt.figure(figsize=(15,10))",
                "plt.scatter(ASSIGN[:, 0], ASSIGN[:, 1],marker='x',s=10, linewidths=5, ASSIGN=ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = pd.read_csv('path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = pd.read_csv('path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "train.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "test.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "test.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "train.info()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "test.info()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def grafico(feature):",
                "ASSIGN = train[train['Survived']==1][feature].value_counts()",
                "ASSIGN = train[train['Survived']==0][feature].value_counts()",
                "ASSIGN = pd.DataFrame([survived,dead])",
                "ASSIGN.index = ['Survived','Dead']",
                "ASSIGN.plot(kind='bar', stacked=True, figsize=(10,5))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def grafico(feature):",
                "ASSIGN = train[train['Survived']==1][feature].value_counts()",
                "ASSIGN = train[train['Survived']==0][feature].value_counts()",
                "ASSIGN = pd.DataFrame([survived,dead])",
                "ASSIGN.index = ['Survived','Dead']",
                "ASSIGN.plot(kind='bar', stacked=True, figsize=(10,5))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "grafico('Sex')"
            ],
            "output_type": "display_data",
            "content_old": [
                "grafico('Sex')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "grafico('Pclass')"
            ],
            "output_type": "display_data",
            "content_old": [
                "grafico('Pclass')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "grafico('SibSp')"
            ],
            "output_type": "display_data",
            "content_old": [
                "grafico('SibSp')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "grafico('Parch')"
            ],
            "output_type": "display_data",
            "content_old": [
                "grafico('Parch')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "grafico('Embarked')"
            ],
            "output_type": "display_data",
            "content_old": [
                "grafico('Embarked')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = [train, test]",
                "for dataset in ASSIGN:",
                "ASSIGN = ASSIGN.str.extract(' ([A-Za-z]+)\\.', expand=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = [train, test]",
                "for dataset in ASSIGN:",
                "ASSIGN = ASSIGN.str.extract(' ([A-Za-z]+)\\.', expand=False)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train['Title'].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train['Title'].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test['Title'].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test['Title'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {\"Mr\": 0,",
                "\"Miss\": 1,",
                "\"Mrs\": 2,",
                "\"Master\": 3,",
                "\"Dr\": 3,",
                "\"Rev\": 3,",
                "\"Col\": 3,",
                "\"Major\": 3,",
                "\"Mlle\": 3,",
                "\"Ms\": 3,",
                "\"Don\": 3,",
                "\"Lady\": 3,",
                "\"Jonkheer\": 3,",
                "\"Countess\": 3,",
                "\"Mme\": 3,",
                "\"Sir\": 3,",
                "\"Capt\": 3}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(title_map)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {\"Mr\": 0,",
                "\"Miss\": 1,",
                "\"Mrs\": 2,",
                "\"Master\": 3,",
                "\"Dr\": 3,",
                "\"Rev\": 3,",
                "\"Col\": 3,",
                "\"Major\": 3,",
                "\"Mlle\": 3,",
                "\"Ms\": 3,",
                "\"Don\": 3,",
                "\"Lady\": 3,",
                "\"Jonkheer\": 3,",
                "\"Countess\": 3,",
                "\"Mme\": 3,",
                "\"Sir\": 3,",
                "\"Capt\": 3}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(title_map)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "test[\"Title\"].fillna(0, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "test[\"Title\"].fillna(0, inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "grafico('Title')"
            ],
            "output_type": "display_data",
            "content_old": [
                "grafico('Title')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "train.drop('Name', axis=1, inplace=True)",
                "test.drop('Name', axis=1, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train.drop('Name', axis=1, inplace=True)",
                "test.drop('Name', axis=1, inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {\"male\": 0, \"female\": 1}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(sex_map)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {\"male\": 0, \"female\": 1}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(sex_map)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "grafico('Sex')"
            ],
            "output_type": "display_data",
            "content_old": [
                "grafico('Sex')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head(100)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head(100)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)",
                "test[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)",
                "test[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = sb.FacetGrid(train, hue=\"Survived\", aspect=4)",
                "ASSIGN.map(sb.kdeplot, 'Age', shade=True)",
                "ASSIGN.set(xlim=(0, train['Age'].max()))",
                "ASSIGN.add_legend()",
                "pl.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = sb.FacetGrid(train, hue=\"Survived\", aspect=4)",
                "ASSIGN.map(sb.kdeplot, 'Age', shade=True)",
                "ASSIGN.set(xlim=(0, train['Age'].max()))",
                "ASSIGN.add_legend()",
                "pl.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for dataset in train_test:",
                "dataset.loc[ dataset['Age'] <= 16, 'Age'] =0",
                "dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1",
                "dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2",
                "dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3",
                "dataset.loc[(dataset['Age'] > 62), 'Age'] = 4"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for dataset in train_test:",
                "dataset.loc[ dataset['Age'] <= 16, 'Age'] =0",
                "dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1",
                "dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2",
                "dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3",
                "dataset.loc[(dataset['Age'] > 62), 'Age'] = 4"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "grafico('Age')"
            ],
            "output_type": "display_data",
            "content_old": [
                "grafico('Age')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Activity"
            ],
            "content": [
                "Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()",
                "Pclass2 = train[train['Pclass']==2]['Embarked'].value_counts()",
                "Pclass3 = train[train['Pclass']==3]['Embarked'].value_counts()",
                "ASSIGN = pd.DataFrame([Pclass1,Pclass2,Pclass3])",
                "ASSIGN.index = ['1st class', '2nd class', '3rd class']",
                "ASSIGN.plot(kind='bar', stacked=True, figsize=(10,5))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()",
                "Pclass2 = train[train['Pclass']==2]['Embarked'].value_counts()",
                "Pclass3 = train[train['Pclass']==3]['Embarked'].value_counts()",
                "ASSIGN = pd.DataFrame([Pclass1,Pclass2,Pclass3])",
                "ASSIGN.index = ['1st class', '2nd class', '3rd class']",
                "ASSIGN.plot(kind='bar', stacked=True, figsize=(10,5))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.fillna('S')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.fillna('S')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {\"S\": 0,",
                "\"C\": 1,",
                "\"Q\": 2}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(emb_map)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {\"S\": 0,",
                "\"C\": 1,",
                "\"Q\": 2}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(emb_map)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)",
                "test[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)",
                "test[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for dataset in train_test:",
                "dataset.loc[ dataset['Fare'] <= 17, 'Fare'] =0",
                "dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1",
                "dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2",
                "dataset.loc[(dataset['Fare'] > 100), 'Fare'] = 3"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for dataset in train_test:",
                "dataset.loc[ dataset['Fare'] <= 17, 'Fare'] =0",
                "dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1",
                "dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2",
                "dataset.loc[(dataset['Fare'] > 100), 'Fare'] = 3"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.Cabin.value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.Cabin.value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.str[:1]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.str[:1]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization"
            ],
            "content": [
                "Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()",
                "Pclass2 = train[train['Pclass']==2]['Cabin'].value_counts()",
                "Pclass3 = train[train['Pclass']==3]['Cabin'].value_counts()",
                "ASSIGN = pd.DataFrame([Pclass1,Pclass2,Pclass3])",
                "ASSIGN.index = ['1st class', '2nd class', '3rd class']",
                "ASSIGN.plot(kind='bar', stacked=True, figsize=(10,5))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()",
                "Pclass2 = train[train['Pclass']==2]['Cabin'].value_counts()",
                "Pclass3 = train[train['Pclass']==3]['Cabin'].value_counts()",
                "ASSIGN = pd.DataFrame([Pclass1,Pclass2,Pclass3])",
                "ASSIGN.index = ['1st class', '2nd class', '3rd class']",
                "ASSIGN.plot(kind='bar', stacked=True, figsize=(10,5))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {\"A\": 0,",
                "\"B\": 0.4,",
                "\"C\": 0.8,",
                "\"D\": 1.2,",
                "\"E\": 1.6,",
                "\"F\": 2.0,",
                "\"G\": 2.4,",
                "\"T\": 2.8}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(cab_map)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {\"A\": 0,",
                "\"B\": 0.4,",
                "\"C\": 0.8,",
                "\"D\": 1.2,",
                "\"E\": 1.6,",
                "\"F\": 2.0,",
                "\"G\": 2.4,",
                "\"T\": 2.8}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(cab_map)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)",
                "test[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)",
                "test[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN + ASSIGN + 1",
                "ASSIGN = ASSIGN + ASSIGN + 1"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN + ASSIGN + 1",
                "ASSIGN = ASSIGN + ASSIGN + 1"
            ]
        },
        {
            "tags": [
                "Data Visualization Activity"
            ],
            "content": [
                "ASSIGN = sb.FacetGrid(train, hue=\"Survived\", aspect=4)",
                "ASSIGN.map(sb.kdeplot, 'FamilySize', shade= True)",
                "ASSIGN.set(xlim=(0, train['FamilySize'].max()))",
                "ASSIGN.add_legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = sb.FacetGrid(train, hue=\"Survived\", aspect=4)",
                "ASSIGN.map(sb.kdeplot, 'FamilySize', shade= True)",
                "ASSIGN.set(xlim=(0, train['FamilySize'].max()))",
                "ASSIGN.add_legend()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(family_map)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}",
                "for dataset in train_test:",
                "ASSIGN = ASSIGN.map(family_map)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = ['Ticket', 'SibSp', 'Parch']",
                "ASSIGN = ASSIGN.drop(features_drop, axis=1)",
                "ASSIGN = ASSIGN.drop(features_drop, axis=1)",
                "ASSIGN = ASSIGN.drop(['PassengerId'], axis=1)",
                "ASSIGN = train.drop('Survived', axis=1)",
                "ASSIGN = train['Survived']",
                "train_data.shape, target.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = ['Ticket', 'SibSp', 'Parch']",
                "ASSIGN = ASSIGN.drop(features_drop, axis=1)",
                "ASSIGN = ASSIGN.drop(features_drop, axis=1)",
                "ASSIGN = ASSIGN.drop(['PassengerId'], axis=1)",
                "ASSIGN = train.drop('Survived', axis=1)",
                "ASSIGN = train['Survived']",
                "train_data.shape, target.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train_data.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train_data.head(10)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "train.info()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = KFold(n_splits=10, shuffle=True, random_state=0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = KFold(n_splits=10, shuffle=True, random_state=0)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = KNeighborsClassifier(n_neighbors = 13)",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100, 2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = KNeighborsClassifier(n_neighbors = 13)",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100, 2)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = DecisionTreeClassifier()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100, 2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = DecisionTreeClassifier()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100, 2)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = RandomForestClassifier(n_estimators=13)",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100, 2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = RandomForestClassifier(n_estimators=13)",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100, 2)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = GaussianNB()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100, 2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = GaussianNB()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100, 2)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = SVC()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100,2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = SVC()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100,2)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = QuadraticDiscriminantAnalysis()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100,2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = QuadraticDiscriminantAnalysis()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100,2)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = linear_model.LinearRegression()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100,2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = linear_model.LinearRegression()",
                "ASSIGN = 'accuracy'",
                "ASSIGN = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1)",
                "print(ASSIGN)",
                "round(np.mean(ASSIGN)*100,2)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = SVC()",
                "ASSIGN.fit(train_data, target)",
                "ASSIGN = test.drop(\"PassengerId\", axis=1).copy()",
                "ASSIGN = clf.predict(test_data)",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = clf.predict(test_data2)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = SVC()",
                "ASSIGN.fit(train_data, target)",
                "ASSIGN = test.drop(\"PassengerId\", axis=1).copy()",
                "ASSIGN = clf.predict(test_data)",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = clf.predict(test_data2)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({",
                "\"PassengerId\": test[\"PassengerId\"],",
                "\"Survived\": prediction",
                "})",
                "ASSIGN.to_csv('path', index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame({",
                "\"PassengerId\": test[\"PassengerId\"],",
                "\"Survived\": prediction",
                "})",
                "ASSIGN.to_csv('path', index=False)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(TRAIN_DATASET_PATH)",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(TRAIN_DATASET_PATH)",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_train.dtypes"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df_train.dtypes"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_train.describe()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "msno.matrix(df_train.sample(250));"
            ],
            "output_type": "display_data",
            "content_old": [
                "msno.matrix(df_train.sample(250));"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = df_train.isnull().sum().sort_values(ascending=False)",
                "ASSIGN = (df_train.isnull().sum()path().count()).sort_values(ascending=False)",
                "ASSIGN = pd.concat([total, percentage], axis=1, keys=['Total', 'Persent'])",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df_train.isnull().sum().sort_values(ascending=False)",
                "ASSIGN = (df_train.isnull().sum()path().count()).sort_values(ascending=False)",
                "ASSIGN = pd.concat([total, percentage], axis=1, keys=['Total', 'Persent'])",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_train.corr()",
                "ASSIGN = plt.subplots(figsize=(12, 9))",
                "sns.heatmap(ASSIGN, vmax=.8, annot=True, fmt=' .2f', square=True);"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_train.corr()",
                "ASSIGN = plt.subplots(figsize=(12, 9))",
                "sns.heatmap(ASSIGN, vmax=.8, annot=True, fmt=' .2f', square=True);"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = 10",
                "ASSIGN = corrmat.nlargest(k, 'Price')['Price'].index",
                "sns.set(font_scale=1.5)",
                "ASSIGN = sns.heatmap(df_train[cols].corr(), annot=True, square=True, fmt='.2f', annot_kws={'size': 8}, yticklabels=cols.values, xticklabels=cols.values);"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = 10",
                "ASSIGN = corrmat.nlargest(k, 'Price')['Price'].index",
                "sns.set(font_scale=1.5)",
                "ASSIGN = sns.heatmap(df_train[cols].corr(), annot=True, square=True, fmt='.2f', annot_kws={'size': 8}, yticklabels=cols.values, xticklabels=cols.values);"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.set()",
                "ASSIGN = ['Price','DistrictId', 'Rooms', 'Square', 'Social_3', 'Floor', 'Helthcare_2', 'Shops_1', 'Healthcare_1']",
                "sns.pairplot(df_train[ASSIGN], size = 2.8)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.set()",
                "ASSIGN = ['Price','DistrictId', 'Rooms', 'Square', 'Social_3', 'Floor', 'Helthcare_2', 'Shops_1', 'Healthcare_1']",
                "sns.pairplot(df_train[ASSIGN], size = 2.8)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['Price','DistrictId', 'Rooms', 'Square', 'LifeSquare', 'Social_1', 'Shops_1']",
                "ASSIGN = pd.concat([df_train[cols], pd.Series(np.int8(df_train['Rooms'] == 0), name='flag')], axis=1)",
                "ASSIGN.loc[ASSIGN['Rooms'] == 0]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = ['Price','DistrictId', 'Rooms', 'Square', 'LifeSquare', 'Social_1', 'Shops_1']",
                "ASSIGN = pd.concat([df_train[cols], pd.Series(np.int8(df_train['Rooms'] == 0), name='flag')], axis=1)",
                "ASSIGN.loc[ASSIGN['Rooms'] == 0]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.pairplot(df_train_temp, size = 2.5, hue='flag')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.pairplot(df_train_temp, size = 2.5, hue='flag')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize = (45, 10))",
                "sns.countplot(x = 'DistrictId', data = df_train)",
                "ASSIGN = plt.xticks(rotation=90)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize = (45, 10))",
                "sns.countplot(x = 'DistrictId', data = df_train)",
                "ASSIGN = plt.xticks(rotation=90)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_train['DistrictId'].value_counts()",
                "ASSIGN = district[district > 50]",
                "ASSIGN = district[district <= 50]",
                "ASSIGN = {'count_districts_gr_50': district_gr_50.count(), 'count_districts_ls_50': district_ls_50.count()}",
                "ASSIGN = {'pop_districts_gr_50': district_gr_50.sum(), 'pop_districts_ls_50': district_ls_50.sum()}",
                "ASSIGN = plt.subplots(1, 2)",
                "fig.set_size_inches(15, 8)",
                "fig.subplots_adjust(wspace=0.3, hspace=0.3)",
                "ax[0].set_title('Districts count')",
                "sns.barplot(list(ASSIGN.keys()), list(ASSIGN.values()), ax=ax[0])",
                "ax[1].set_title('Districts pop')",
                "sns.barplot(list(ASSIGN.keys()), list(ASSIGN.values()), ax=ax[1])",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_train['DistrictId'].value_counts()",
                "ASSIGN = district[district > 50]",
                "ASSIGN = district[district <= 50]",
                "ASSIGN = {'count_districts_gr_50': district_gr_50.count(), 'count_districts_ls_50': district_ls_50.count()}",
                "ASSIGN = {'pop_districts_gr_50': district_gr_50.sum(), 'pop_districts_ls_50': district_ls_50.sum()}",
                "ASSIGN = plt.subplots(1, 2)",
                "fig.set_size_inches(15, 8)",
                "fig.subplots_adjust(wspace=0.3, hspace=0.3)",
                "ax[0].set_title('Districts count')",
                "sns.barplot(list(ASSIGN.keys()), list(ASSIGN.values()), ax=ax[0])",
                "ax[1].set_title('Districts pop')",
                "sns.barplot(list(ASSIGN.keys()), list(ASSIGN.values()), ax=ax[1])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.distplot(df_train['Square']);"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.distplot(df_train['Square']);"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.distplot(df_train.loc[df_train['Square'] < 200,'Square'])",
                "plt.plot([25 for x in range(330)], [xpath(330)], ls='--', c='r')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.distplot(df_train.loc[df_train['Square'] < 200,'Square'])",
                "plt.plot([25 for x in range(330)], [xpath(330)], ls='--', c='r')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train.loc[df_train['Square'] < 25, 'Square'].count()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_train.loc[df_train['Square'] < 25, 'Square'].count()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train.loc[df_train['Rooms'] > 5, ['DistrictId', 'Square', 'KitchenSquare', 'Rooms', 'Price']]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_train.loc[df_train['Rooms'] > 5, ['DistrictId', 'Square', 'KitchenSquare', 'Rooms', 'Price']]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_train.loc[df_train['Rooms'] == 0, ['DistrictId', 'Square', 'KitchenSquare', 'Rooms', 'Price']]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_train.loc[df_train['Rooms'] == 0, ['DistrictId', 'Square', 'KitchenSquare', 'Rooms', 'Price']]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(df_train['Square'], df_train['KitchenSquare'])",
                "plt.plot([x for x in range(120)], [y for y in range(120)], c = 'r')",
                "plt.plot([y for y in range(200)], [ 0 for x in range(200)], c = 'g')",
                "plt.xlabel('Square')",
                "plt.ylabel('KitchenSquare')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.scatter(df_train['Square'], df_train['KitchenSquare'])",
                "plt.plot([x for x in range(120)], [y for y in range(120)], c = 'r')",
                "plt.plot([y for y in range(200)], [ 0 for x in range(200)], c = 'g')",
                "plt.xlabel('Square')",
                "plt.ylabel('KitchenSquare')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_train['KitchenSquare'] < df_train['Square'] + 0.5*df_train['Square'].std()",
                "plt.scatter(df_train.loc[ASSIGN, 'Square'], df_train.loc[ASSIGN, 'KitchenSquare'])",
                "plt.plot([x for x in range(120)], [y for y in range(120)], c = 'r')",
                "plt.plot([y for y in range(300)], [ 0 for x in range(300)], c = 'g')",
                "plt.xlabel('Square')",
                "plt.ylabel('KitchenSquare')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_train['KitchenSquare'] < df_train['Square'] + 0.5*df_train['Square'].std()",
                "plt.scatter(df_train.loc[ASSIGN, 'Square'], df_train.loc[ASSIGN, 'KitchenSquare'])",
                "plt.plot([x for x in range(120)], [y for y in range(120)], c = 'r')",
                "plt.plot([y for y in range(300)], [ 0 for x in range(300)], c = 'g')",
                "plt.xlabel('Square')",
                "plt.ylabel('KitchenSquare')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = (df_train['KitchenSquare'] >= 3) & (abs(df_train['Square'] - df_train['KitchenSquare']) > 10) &\\",
                "(df_train['KitchenSquare'] < 50) & (df_train['Square'] < 200)",
                "ASSIGN = df_train.loc[cond, ['Square', 'KitchenSquare']]",
                "ASSIGN = sns.jointplot(temp['Square'], temp['KitchenSquare'], kind='reg')",
                "plt.plot(np.arange(0, 40), np.arange(0, 40), color = 'red', linestyle='--')",
                "ASSIGN.fig.set_figwidth(8)",
                "ASSIGN.fig.set_figheight(8)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = (df_train['KitchenSquare'] >= 3) & (abs(df_train['Square'] - df_train['KitchenSquare']) > 10) &\\",
                "(df_train['KitchenSquare'] < 50) & (df_train['Square'] < 200)",
                "ASSIGN = df_train.loc[cond, ['Square', 'KitchenSquare']]",
                "ASSIGN = sns.jointplot(temp['Square'], temp['KitchenSquare'], kind='reg')",
                "plt.plot(np.arange(0, 40), np.arange(0, 40), color = 'red', linestyle='--')",
                "ASSIGN.fig.set_figwidth(8)",
                "ASSIGN.fig.set_figheight(8)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ~df_train['LifeSquare'].isna()",
                "plt.plot([x for x in range(600)], [y for y in range(600)], c = 'r')",
                "sns.scatterplot(df_train.loc[ASSIGN, 'Square'], df_train.loc[ASSIGN, 'LifeSquare']);"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = ~df_train['LifeSquare'].isna()",
                "plt.plot([x for x in range(600)], [y for y in range(600)], c = 'r')",
                "sns.scatterplot(df_train.loc[ASSIGN, 'Square'], df_train.loc[ASSIGN, 'LifeSquare']);"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = (~df_train['LifeSquare'].isna()) & (df_train['LifeSquare'] < df_train['LifeSquare'].quantile(q = 0.999)) & \\",
                "(df_train['Square'] < df_train['Square'].quantile(q = 0.999))",
                "ASSIGN = sns.jointplot(df_train.loc[cond, 'Square'], df_train.loc[cond, 'LifeSquare'], kind='reg')",
                "plt.plot(np.arange(0, 200), np.arange(0, 200), color = 'red', linestyle='--')",
                "ASSIGN.fig.set_figwidth(8)",
                "ASSIGN.fig.set_figheight(8)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = (~df_train['LifeSquare'].isna()) & (df_train['LifeSquare'] < df_train['LifeSquare'].quantile(q = 0.999)) & \\",
                "(df_train['Square'] < df_train['Square'].quantile(q = 0.999))",
                "ASSIGN = sns.jointplot(df_train.loc[cond, 'Square'], df_train.loc[cond, 'LifeSquare'], kind='reg')",
                "plt.plot(np.arange(0, 200), np.arange(0, 200), color = 'red', linestyle='--')",
                "ASSIGN.fig.set_figwidth(8)",
                "ASSIGN.fig.set_figheight(8)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train['HouseYear'].unique()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_train['HouseYear'].unique()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_train.loc[(df_train['HouseYear'] == 20052011) | (df_train['HouseYear'] == 4968), 'HouseYear'].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_train.loc[(df_train['HouseYear'] == 20052011) | (df_train['HouseYear'] == 4968), 'HouseYear'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['g' if i == 0.0 else 'b' for i in df_train.loc[df_train['HouseFloor'] < 60, 'HouseFloor']]",
                "ASSIGN.count('g')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = ['g' if i == 0.0 else 'b' for i in df_train.loc[df_train['HouseFloor'] < 60, 'HouseFloor']]",
                "ASSIGN.count('g')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(df_train.loc[df_train['HouseFloor'] < 60, 'HouseFloor'], df_train.loc[df_train['HouseFloor'] < 60, 'Floor'], c=colors)",
                "plt.plot([x for x in range(40)], [y for y in range(40)], c = 'r')",
                "plt.plot([x for x in range(40)], [y + 2 for y in range(40)], c = 'black')",
                "plt.xlabel('HouseFloor')",
                "plt.ylabel('Floor')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.scatter(df_train.loc[df_train['HouseFloor'] < 60, 'HouseFloor'], df_train.loc[df_train['HouseFloor'] < 60, 'Floor'], c=colors)",
                "plt.plot([x for x in range(40)], [y for y in range(40)], c = 'r')",
                "plt.plot([x for x in range(40)], [y + 2 for y in range(40)], c = 'black')",
                "plt.xlabel('HouseFloor')",
                "plt.ylabel('Floor')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.scatterplot(df_train.loc[~df_train['Healthcare_1'].isna(), 'Healthcare_1'], df_train.loc[~df_train['Healthcare_1'].isna(), 'DistrictId']);"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.scatterplot(df_train.loc[~df_train['Healthcare_1'].isna(), 'Healthcare_1'], df_train.loc[~df_train['Healthcare_1'].isna(), 'DistrictId']);"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(35, 8))",
                "ASSIGN = ~df_train['Healthcare_1'].isna()",
                "ASSIGN = sns.boxplot(df_train.loc[cond, 'DistrictId'], df_train.loc[cond, 'Healthcare_1'])",
                "ASSIGN.set_xticklabels(ASSIGN.get_xticklabels(), rotation=90)",
                "plt.xlabel('DistrictId')",
                "plt.ylabel('Healthcare_1')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(35, 8))",
                "ASSIGN = ~df_train['Healthcare_1'].isna()",
                "ASSIGN = sns.boxplot(df_train.loc[cond, 'DistrictId'], df_train.loc[cond, 'Healthcare_1'])",
                "ASSIGN.set_xticklabels(ASSIGN.get_xticklabels(), rotation=90)",
                "plt.xlabel('DistrictId')",
                "plt.ylabel('Healthcare_1')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train['Price'].describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_train['Price'].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print( % df_train['Price'].skew())",
                "print( % df_train['Price'].kurt())"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print( % df_train['Price'].skew())",
                "print( % df_train['Price'].kurt())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_train['Price']",
                "ASSIGN = plt.subplots(1, 2)",
                "fig.set_size_inches(14, 6)",
                "fig.subplots_adjust(wspace=0.3, hspace=0.3)",
                "sns.distplot(ASSIGN, kde=False, fit=st.norm, ax=ax[0])",
                "sns.distplot(pd.Series(np.log(ASSIGN), name ='LogPrice'), kde=False, fit=st.norm, ax=ax[1])",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_train['Price']",
                "ASSIGN = plt.subplots(1, 2)",
                "fig.set_size_inches(14, 6)",
                "fig.subplots_adjust(wspace=0.3, hspace=0.3)",
                "sns.distplot(ASSIGN, kde=False, fit=st.norm, ax=ax[0])",
                "sns.distplot(pd.Series(np.log(ASSIGN), name ='LogPrice'), kde=False, fit=st.norm, ax=ax[1])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_train['Price']",
                "ASSIGN = plt.subplots(1, 2)",
                "fig.set_size_inches(14, 6)",
                "fig.subplots_adjust(wspace=0.3, hspace=0.3)",
                "sns.distplot(ASSIGN, kde=False, fit=st.johnsonsu, ax=ax[0])",
                "ASSIGN = st.johnsonsu.fit(y)",
                "ASSIGN = (y-params[2])path[3]",
                "ASSIGN = params[0] + params[1]*np.log(t + np.sqrt(np.power(t, 2) + 1))",
                "sns.distplot(pd.Series(ASSIGN, name ='TransformedToNormalPrice'), fit=st.norm, ax=ax[1])",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_train['Price']",
                "ASSIGN = plt.subplots(1, 2)",
                "fig.set_size_inches(14, 6)",
                "fig.subplots_adjust(wspace=0.3, hspace=0.3)",
                "sns.distplot(ASSIGN, kde=False, fit=st.johnsonsu, ax=ax[0])",
                "ASSIGN = st.johnsonsu.fit(y)",
                "ASSIGN = (y-params[2])path[3]",
                "ASSIGN = params[0] + params[1]*np.log(t + np.sqrt(np.power(t, 2) + 1))",
                "sns.distplot(pd.Series(ASSIGN, name ='TransformedToNormalPrice'), fit=st.norm, ax=ax[1])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = params[2]*np.sinh((y_norm - params[0])path[1]) + params[3]",
                "sns.distplot(ASSIGN, fit=st.johnsonsu)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = params[2]*np.sinh((y_norm - params[0])path[1]) + params[3]",
                "sns.distplot(ASSIGN, fit=st.johnsonsu)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "warnings.filterwarnings(\"ignore\")",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "warnings.filterwarnings(\"ignore\")",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.info()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = data.isnull().sum().sum()",
                "data.columns"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = data.isnull().sum().sum()",
                "data.columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = data.Species",
                "Counter(ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = data.Species",
                "Counter(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = \"Perch\" , \"Bream\" , \"Roach\" , \"Pike\" , \"Smelt\" , \"Parkki\" , \"Whitefish\"",
                "ASSIGN = [56,35,20,17,14,11,6]",
                "ASSIGN = (0,0,0,0,0,0,0)",
                "fig1,ax1 = plt.subplots()",
                "ax1.pie(ASSIGN, ASSIGN=ASSIGN, ASSIGN=ASSIGN, autopct='%1.1f%%',shadow=True, startangle=90)",
                "ax1.axis('equal')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = \"Perch\" , \"Bream\" , \"Roach\" , \"Pike\" , \"Smelt\" , \"Parkki\" , \"Whitefish\"",
                "ASSIGN = [56,35,20,17,14,11,6]",
                "ASSIGN = (0,0,0,0,0,0,0)",
                "fig1,ax1 = plt.subplots()",
                "ax1.pie(ASSIGN, ASSIGN=ASSIGN, ASSIGN=ASSIGN, autopct='%1.1f%%',shadow=True, startangle=90)",
                "ax1.axis('equal')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Weight[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Weight[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Weight[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Weight[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Weight[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Weight[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Weight[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"weight of fish in Gram g\")",
                "plt.grid()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Weight[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Weight[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Weight[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Weight[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Weight[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Weight[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Weight[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"weight of fish in Gram g\")",
                "plt.grid()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Length1[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Length1[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Length1[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Length1[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Length1[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Length1[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Length1[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"vertical length in cm\")",
                "plt.grid()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Length1[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Length1[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Length1[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Length1[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Length1[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Length1[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Length1[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"vertical length in cm\")",
                "plt.grid()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Length2[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Length2[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Length2[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Length2[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Length2[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Length2[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Length2[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"diagonal length in cm\")",
                "plt.grid()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Length2[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Length2[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Length2[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Length2[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Length2[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Length2[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Length2[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"diagonal length in cm\")",
                "plt.grid()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Length3[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Length3[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Length3[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Length3[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Length3[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Length3[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Length3[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"cross length in cm\")",
                "plt.grid()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Length3[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Length3[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Length3[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Length3[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Length3[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Length3[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Length3[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"cross length in cm\")",
                "plt.grid()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Height[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Height[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Height[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Height[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Height[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Height[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Height[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"height in cm\")",
                "plt.grid()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Height[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Height[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Height[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Height[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Height[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Height[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Height[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"height in cm\")",
                "plt.grid()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Width[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Width[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Width[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Width[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Width[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Width[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Width[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"diagonal width in cm\")",
                "plt.grid()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.scatter(data.index[data.Species == \"Bream\"] , data.Width[data.Species == \"Bream\"],c=\"red\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Perch\"] , data.Width[data.Species == \"Perch\"],c=\"aqua\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Roach\"] , data.Width[data.Species == \"Roach\"],c=\"orange\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Pike\"] , data.Width[data.Species == \"Pike\"],c=\"purple\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Smelt\"] , data.Width[data.Species == \"Smelt\"],c=\"black\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Parkki\"] , data.Width[data.Species == \"Parkki\"],c=\"green\" , alpha = 0.5)",
                "plt.scatter(data.index[data.Species == \"Whitefish\"] , data.Width[data.Species == \"Whitefish\"],c=\"brown\" , alpha = 0.5)",
                "plt.xlabel(\"index of Spices\")",
                "plt.ylabel(\"diagonal width in cm\")",
                "plt.grid()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = data.Species",
                "ASSIGN = data.drop([\"Species\"],axis = 1)",
                "ASSIGN = train_test_split(x,y,test_size = 0.2,random_state = 42)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = data.Species",
                "ASSIGN = data.drop([\"Species\"],axis = 1)",
                "ASSIGN = train_test_split(x,y,test_size = 0.2,random_state = 42)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 0.0",
                "ASSIGN = 1",
                "ASSIGN = []",
                "for each in range(1,100):",
                "ASSIGN = KNeighborsClassifier(n_neighbors = each)",
                "ASSIGN.fit(x_train,y_train)",
                "ASSIGN.append(ASSIGN.score(x_test,y_test))",
                "if (ASSIGN < ASSIGN.score(x_test,y_test) ):",
                "ASSIGN = knn.score(x_test,y_test)",
                "ASSIGN = ASSIGN+1",
                "plt.plot(ASSIGN,color = \"purple\" , alpha = 1 )",
                "plt.grid()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = 0.0",
                "ASSIGN = 1",
                "ASSIGN = []",
                "for each in range(1,100):",
                "ASSIGN = KNeighborsClassifier(n_neighbors = each)",
                "ASSIGN.fit(x_train,y_train)",
                "ASSIGN.append(ASSIGN.score(x_test,y_test))",
                "if (ASSIGN < ASSIGN.score(x_test,y_test) ):",
                "ASSIGN = knn.score(x_test,y_test)",
                "ASSIGN = ASSIGN+1",
                "plt.plot(ASSIGN,color = \"purple\" , alpha = 1 )",
                "plt.grid()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(,knn_score)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(,knn_score)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = LogisticRegression()",
                "ASSIGN.fit(x_train,y_train)",
                "ASSIGN = lr.score(x_test,y_test)",
                "print(,ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = LogisticRegression()",
                "ASSIGN.fit(x_train,y_train)",
                "ASSIGN = lr.score(x_test,y_test)",
                "print(,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = GaussianNB()",
                "ASSIGN.fit(x_train,y_train)",
                "ASSIGN = naive_bayes.score(x_test,y_test)",
                "print(,ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = GaussianNB()",
                "ASSIGN.fit(x_train,y_train)",
                "ASSIGN = naive_bayes.score(x_test,y_test)",
                "print(,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = RandomForestClassifier(n_estimators = 100)",
                "ASSIGN.fit(x_train,y_train)",
                "ASSIGN = rfc.score(x_test,y_test)",
                "print(,ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = RandomForestClassifier(n_estimators = 100)",
                "ASSIGN.fit(x_train,y_train)",
                "ASSIGN = rfc.score(x_test,y_test)",
                "print(,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = {\"Logistic Regression\" : lr_score,\"Random Forest\" : rf_score,\"K-Nearest Neighbour\" : knn_score ,\"Naive Bayes\": nb_score ,\"K-Nearest Neighbour\" : knn_score }",
                "dict1"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = {\"Logistic Regression\" : lr_score,\"Random Forest\" : rf_score,\"K-Nearest Neighbour\" : knn_score ,\"Naive Bayes\": nb_score ,\"K-Nearest Neighbour\" : knn_score }",
                "dict1"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "H.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "H.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "H.info()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[H.duplicated()]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[H.duplicated()]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[H.loc[:,~H.columns.isin(['SalePrice'])].duplicated()]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[H.loc[:,~H.columns.isin(['SalePrice'])].duplicated()]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = H.apply(pd.Series.nunique)",
                "ASSIGN[ASSIGN == 1]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = H.apply(pd.Series.nunique)",
                "ASSIGN[ASSIGN == 1]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = H.isnull().sum().sort_values(ascending = False)",
                "ASSIGN = ((H.isnull().sum()*100)path()[0]).sort_values(ascending = False)",
                "NullValues = pd.concat([ASSIGN, ASSIGN], axis = 1, keys = [\"ASSIGN\", \"ASSIGN\"])",
                "NullValues[NullValues.ASSIGN > 0]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = H.isnull().sum().sort_values(ascending = False)",
                "ASSIGN = ((H.isnull().sum()*100)path()[0]).sort_values(ascending = False)",
                "NullValues = pd.concat([ASSIGN, ASSIGN], axis = 1, keys = [\"ASSIGN\", \"ASSIGN\"])",
                "NullValues[NullValues.ASSIGN > 0]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.drop(['Id','Alley', 'PoolQC', 'Fence','MiscFeature','MiscVal','FireplaceQu','LotFrontage'], axis = 1, inplace = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.drop(['Id','Alley', 'PoolQC', 'Fence','MiscFeature','MiscVal','FireplaceQu','LotFrontage'], axis = 1, inplace = True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = H.isnull().sum().sort_values(ascending = False)",
                "ASSIGN = ((H.isnull().sum()*100)path()[0]).sort_values(ascending = False)",
                "NullValues = pd.concat([ASSIGN, ASSIGN], axis = 1, keys = [\"ASSIGN\", \"ASSIGN\"])",
                "NullValues[NullValues.ASSIGN > 0]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = H.isnull().sum().sort_values(ascending = False)",
                "ASSIGN = ((H.isnull().sum()*100)path()[0]).sort_values(ascending = False)",
                "NullValues = pd.concat([ASSIGN, ASSIGN], axis = 1, keys = [\"ASSIGN\", \"ASSIGN\"])",
                "NullValues[NullValues.ASSIGN > 0]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H[H[\"GarageArea\"] == 0][['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual','GarageCond']]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[H[\"GarageArea\"] == 0][['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual','GarageCond']]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.fillna({'GarageType': 'NoGarage', 'GarageYrBlt': 0, 'GarageFinish': 'NoGarage', 'GarageQual': 'NoGarage','GarageCond': 'NoGarage'} , inplace = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.fillna({'GarageType': 'NoGarage', 'GarageYrBlt': 0, 'GarageFinish': 'NoGarage', 'GarageQual': 'NoGarage','GarageCond': 'NoGarage'} , inplace = True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[H[\"GarageArea\"] == 0][['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual','GarageCond']]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[H[\"GarageArea\"] == 0][['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual','GarageCond']]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "H[H['TotalBsmtSF'] == 0][['BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[H['TotalBsmtSF'] == 0][['BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[H['TotalBsmtSF'] > 0][['BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[H['TotalBsmtSF'] > 0][['BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = H['BsmtExposure'].ASSIGN()[0]",
                "H.loc[(H['TotalBsmtSF'] > 0) & (H['BsmtExposure'].isnull()), 'BsmtExposure'] = ASSIGN",
                "ASSIGN = H['BsmtFinType2'].ASSIGN()[0]",
                "H.loc[(H['TotalBsmtSF'] > 0) & (H['BsmtFinType2'].isnull()), 'BsmtFinType2'] = ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = H['BsmtExposure'].ASSIGN()[0]",
                "H.loc[(H['TotalBsmtSF'] > 0) & (H['BsmtExposure'].isnull()), 'BsmtExposure'] = ASSIGN",
                "ASSIGN = H['BsmtFinType2'].ASSIGN()[0]",
                "H.loc[(H['TotalBsmtSF'] > 0) & (H['BsmtFinType2'].isnull()), 'BsmtFinType2'] = ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.fillna({'BsmtQual': 'NoBasement', 'BsmtCond': 'NoBasement','BsmtExposure': 'NoBasement', 'BsmtFinType1': 'NoBasement', 'BsmtFinType2': 'NoBasement'} , inplace = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.fillna({'BsmtQual': 'NoBasement', 'BsmtCond': 'NoBasement','BsmtExposure': 'NoBasement', 'BsmtFinType1': 'NoBasement', 'BsmtFinType2': 'NoBasement'} , inplace = True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = H['Electrical'].ASSIGN()[0]",
                "H['Electrical'].fillna(ASSIGN, inplace = True)",
                "ASSIGN = H['MasVnrType'].ASSIGN()[0]",
                "H['MasVnrType'].fillna(ASSIGN, inplace = True)",
                "ASSIGN = H['MasVnrArea'].ASSIGN()",
                "H['MasVnrArea'].fillna(ASSIGN, inplace = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = H['Electrical'].ASSIGN()[0]",
                "H['Electrical'].fillna(ASSIGN, inplace = True)",
                "ASSIGN = H['MasVnrType'].ASSIGN()[0]",
                "H['MasVnrType'].fillna(ASSIGN, inplace = True)",
                "ASSIGN = H['MasVnrArea'].ASSIGN()",
                "H['MasVnrArea'].fillna(ASSIGN, inplace = True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = H.isnull().sum().sort_values(ascending = False)",
                "ASSIGN = ((H.isnull().sum()*100)path()[0]).sort_values(ascending = False)",
                "NullValues = pd.concat([ASSIGN, ASSIGN], axis = 1, keys = [\"ASSIGN\", \"ASSIGN\"])",
                "NullValues[NullValues.ASSIGN > 0]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = H.isnull().sum().sort_values(ascending = False)",
                "ASSIGN = ((H.isnull().sum()*100)path()[0]).sort_values(ascending = False)",
                "NullValues = pd.concat([ASSIGN, ASSIGN], axis = 1, keys = [\"ASSIGN\", \"ASSIGN\"])",
                "NullValues[NullValues.ASSIGN > 0]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 2011 - ASSIGN",
                "ASSIGN = 2011 - ASSIGN",
                "ASSIGN = 2011 - ASSIGN",
                "ASSIGN = 2011 - ASSIGN",
                "H.loc[H['AgeOfGarage'] > 100 , 'AgeOfGarage'] = 0",
                "H.drop(['YearBuilt','YearRemodAdd','YrSold','GarageYrBlt'], axis = 1, inplace = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 2011 - ASSIGN",
                "ASSIGN = 2011 - ASSIGN",
                "ASSIGN = 2011 - ASSIGN",
                "ASSIGN = 2011 - ASSIGN",
                "H.loc[H['AgeOfGarage'] > 100 , 'AgeOfGarage'] = 0",
                "H.drop(['YearBuilt','YearRemodAdd','YrSold','GarageYrBlt'], axis = 1, inplace = True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN + (0.5 * ASSIGN)",
                "ASSIGN = ASSIGN + (0.5 * ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN + (0.5 * ASSIGN)",
                "ASSIGN = ASSIGN + (0.5 * ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN + ASSIGN + ASSIGN + ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN + ASSIGN + ASSIGN + ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['SalePrice','LotArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','TotalPorchArea','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MasVnrArea','AgeOfGarage', 'AgeOfHouse', 'AgeOfRemod','AgeOfSell']",
                "ASSIGN = ['BsmtBath','Bath','BedroomAbvGr','BldgType','BsmtHalfBath','BsmtFullBath','Condition1','Condition2','Electrical','Exterior1st','Exterior2nd','Fireplaces','Foundation','FullBath','Functional','GarageCars','GarageFinish','GarageType','HalfBath','Heating','HouseStyle','KitchenAbvGr','LandContour','LandSlope','LotConfig','LotShape','MSSubClass','MSZoning','MasVnrType','MoSold','Neighborhood','PavedDrive','RoofMatl','RoofStyle','SaleCondition','SaleType','Street','TotRmsAbvGrd','Utilities']",
                "ASSIGN = [ \"OverallQual\",\"OverallCond\",\"ExterQual\",\"ExterCond\",\"BsmtQual\",'BsmtCond',\"BsmtExposure\",\"HeatingQC\",\"KitchenQual\",\"GarageQual\",\"GarageCond\", 'BsmtFinType1', 'BsmtFinType2','CentralAir']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['SalePrice','LotArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','TotalPorchArea','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MasVnrArea','AgeOfGarage', 'AgeOfHouse', 'AgeOfRemod','AgeOfSell']",
                "ASSIGN = ['BsmtBath','Bath','BedroomAbvGr','BldgType','BsmtHalfBath','BsmtFullBath','Condition1','Condition2','Electrical','Exterior1st','Exterior2nd','Fireplaces','Foundation','FullBath','Functional','GarageCars','GarageFinish','GarageType','HalfBath','Heating','HouseStyle','KitchenAbvGr','LandContour','LandSlope','LotConfig','LotShape','MSSubClass','MSZoning','MasVnrType','MoSold','Neighborhood','PavedDrive','RoofMatl','RoofStyle','SaleCondition','SaleType','Street','TotRmsAbvGrd','Utilities']",
                "ASSIGN = [ \"OverallQual\",\"OverallCond\",\"ExterQual\",\"ExterCond\",\"BsmtQual\",'BsmtCond',\"BsmtExposure\",\"HeatingQC\",\"KitchenQual\",\"GarageQual\",\"GarageCond\", 'BsmtFinType1', 'BsmtFinType2','CentralAir']"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[ordinal_columns]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[ordinal_columns]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'NoBasement' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'NoBasement' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'Gd' : 4, 'Av' : 3, 'Mn' : 2, 'No' : 1, 'NoBasement' : 0})",
                "ASSIGN = ASSIGN.map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'NoGarage' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'NoGarage' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "H['BsmtFinType1'] = H['BsmtFinType1'].map({'GLQ' : 6, 'ALQ' : 5, 'BLQ' : 4, 'Rec' : 3, 'LwQ' : 2, 'Unf' : 1, 'NoBasement' : 0})",
                "H['BsmtFinType2'] = H['BsmtFinType2'].map({'GLQ' : 6, 'ALQ' : 5, 'BLQ' : 4, 'Rec' : 3, 'LwQ' : 2, 'Unf' : 1, 'NoBasement' : 0})",
                "ASSIGN = ASSIGN.map({'N' : 0, 'Y' : 1})"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'NoBasement' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'NoBasement' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'Gd' : 4, 'Av' : 3, 'Mn' : 2, 'No' : 1, 'NoBasement' : 0})",
                "ASSIGN = ASSIGN.map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'NoGarage' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "ASSIGN = ASSIGN.map({'NoGarage' : 0, 'NA' : 0, 'Po' : 1, 'Fa': 2, 'TA' : 3, 'Gd': 4 , 'Ex' : 5})",
                "H['BsmtFinType1'] = H['BsmtFinType1'].map({'GLQ' : 6, 'ALQ' : 5, 'BLQ' : 4, 'Rec' : 3, 'LwQ' : 2, 'Unf' : 1, 'NoBasement' : 0})",
                "H['BsmtFinType2'] = H['BsmtFinType2'].map({'GLQ' : 6, 'ALQ' : 5, 'BLQ' : 4, 'Rec' : 3, 'LwQ' : 2, 'Unf' : 1, 'NoBasement' : 0})",
                "ASSIGN = ASSIGN.map({'N' : 0, 'Y' : 1})"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[ordinal_columns].head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[ordinal_columns].head(5)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[ordinal_columns].isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[ordinal_columns].isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "H[categorical_columns].dtypes"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "H[categorical_columns].dtypes"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for i in range(0, len(categorical_columns)):",
                "if (H[categorical_columns[i]].dtype == 'int64') | (H[categorical_columns[i]].dtype == 'float64'):",
                "H[categorical_columns[i]] = H[categorical_columns[i]].apply(str)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for i in range(0, len(categorical_columns)):",
                "if (H[categorical_columns[i]].dtype == 'int64') | (H[categorical_columns[i]].dtype == 'float64'):",
                "H[categorical_columns[i]] = H[categorical_columns[i]].apply(str)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[categorical_columns].head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[categorical_columns].head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"BsmtBath\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"BsmtBath\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"BsmtBath\"] == '3.0', 'BsmtBath'] = '2.0'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"BsmtBath\"] == '3.0', 'BsmtBath'] = '2.0'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"BedroomAbvGr\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"BedroomAbvGr\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"BedroomAbvGr\"] == '8', 'BedroomAbvGr'] = '6'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"BedroomAbvGr\"] == '8', 'BedroomAbvGr'] = '6'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"BsmtFullBath\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"BsmtFullBath\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"BsmtFullBath\"] == '3', 'BsmtFullBath'] = '2'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"BsmtFullBath\"] == '3', 'BsmtFullBath'] = '2'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"Condition1\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"Condition1\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"Condition2\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"Condition2\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"Condition2\"].isin(['PosA','RRAn','RRAe']), 'Condition2'] = 'PosA_RRAn_RRAe'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"Condition2\"].isin(['PosA','RRAn','RRAe']), 'Condition2'] = 'PosA_RRAn_RRAe'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"Electrical\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"Electrical\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"Exterior1st\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"Exterior1st\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"Exterior1st\"].isin(['Stone','BrkComm','CBlock','AsphShn','ImStucc']), 'Exterior1st'] = 'Other'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"Exterior1st\"].isin(['Stone','BrkComm','CBlock','AsphShn','ImStucc']), 'Exterior1st'] = 'Other'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"Exterior2nd\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"Exterior2nd\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"Exterior2nd\"].isin(['Stone','Brk Cmn','CBlock','AsphShn','ImStucc','Other']), 'Exterior2nd'] = 'Other'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"Exterior2nd\"].isin(['Stone','Brk Cmn','CBlock','AsphShn','ImStucc','Other']), 'Exterior2nd'] = 'Other'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"Utilities\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"Utilities\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.drop(['Utilities'], axis = 1, inplace = True)",
                "categorical_columns.remove('Utilities')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.drop(['Utilities'], axis = 1, inplace = True)",
                "categorical_columns.remove('Utilities')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"Heating\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"Heating\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"Heating\"] == 'Floor', 'Heating'] = 'OthW'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"Heating\"] == 'Floor', 'Heating'] = 'OthW'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"RoofMatl\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"RoofMatl\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"RoofMatl\"].isin(['Roll','Membran','Metal','ClyTile']), 'RoofMatl'] = 'Other'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"RoofMatl\"].isin(['Roll','Membran','Metal','ClyTile']), 'RoofMatl'] = 'Other'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H[\"TotRmsAbvGrd\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H[\"TotRmsAbvGrd\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "H.loc[H[\"TotRmsAbvGrd\"] == '2', 'TotRmsAbvGrd'] = '3'",
                "H.loc[H[\"TotRmsAbvGrd\"] == '14', 'TotRmsAbvGrd'] = '12'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "H.loc[H[\"TotRmsAbvGrd\"] == '2', 'TotRmsAbvGrd'] = '3'",
                "H.loc[H[\"TotRmsAbvGrd\"] == '14', 'TotRmsAbvGrd'] = '12'"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ['SalePrice','LotArea','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','WoodDeckSF','TotalPorchArea','MasVnrArea','AgeOfGarage', 'AgeOfHouse', 'AgeOfRemod','AgeOfSell']",
                "plt.figure(figsize=(15,60))",
                "for i in range(0, len(ASSIGN)):",
                "plt.subplot(12,2,(i+1))",
                "sns.distplot(H[ASSIGN[i]])"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = ['SalePrice','LotArea','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','WoodDeckSF','TotalPorchArea','MasVnrArea','AgeOfGarage', 'AgeOfHouse', 'AgeOfRemod','AgeOfSell']",
                "plt.figure(figsize=(15,60))",
                "for i in range(0, len(ASSIGN)):",
                "plt.subplot(12,2,(i+1))",
                "sns.distplot(H[ASSIGN[i]])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "H['SalePrice'], fitted_lambda = stats.boxcox(H['SalePrice'])",
                "H['LotArea'], fitted_lambda = stats.boxcox(H['LotArea'])",
                "H['1stFlrSF'], fitted_lambda = stats.boxcox(H['1stFlrSF'])",
                "H['GrLivArea'], fitted_lambda = stats.boxcox(H['GrLivArea'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "H['SalePrice'], fitted_lambda = stats.boxcox(H['SalePrice'])",
                "H['LotArea'], fitted_lambda = stats.boxcox(H['LotArea'])",
                "H['1stFlrSF'], fitted_lambda = stats.boxcox(H['1stFlrSF'])",
                "H['GrLivArea'], fitted_lambda = stats.boxcox(H['GrLivArea'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "H['TotalBsmtSF'].describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "H['TotalBsmtSF'].describe()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.distplot(H['1stFlrSF'])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.distplot(H['1stFlrSF'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.distplot(H['GrLivArea'])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.distplot(H['GrLivArea'])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,15))",
                "ASSIGN = H[numerical_columns].corr()",
                "sns.heatmap(ASSIGN, annot = True)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(15,15))",
                "ASSIGN = H[numerical_columns].corr()",
                "sns.heatmap(ASSIGN, annot = True)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,60))",
                "for i in range(0, len(categorical_columns)):",
                "plt.subplot(20,2,(i+1))",
                "sns.boxplot(data = H, x = categorical_columns[i], y = 'SalePrice'  )"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,60))",
                "for i in range(0, len(categorical_columns)):",
                "plt.subplot(20,2,(i+1))",
                "sns.boxplot(data = H, x = categorical_columns[i], y = 'SalePrice'  )"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,60))",
                "for i in range(0, len(numerical_columns)):",
                "plt.subplot(12,2,(i+1))",
                "sns.scatterplot(data = H, x = numerical_columns[i], y = 'SalePrice'  )"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,60))",
                "for i in range(0, len(numerical_columns)):",
                "plt.subplot(12,2,(i+1))",
                "sns.scatterplot(data = H, x = numerical_columns[i], y = 'SalePrice'  )"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,35))",
                "for i in range(0, len(ordinal_columns)):",
                "plt.subplot(7,2,(i+1))",
                "sns.barplot(data = H, x = ordinal_columns[i], y = 'SalePrice'  )"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,35))",
                "for i in range(0, len(ordinal_columns)):",
                "plt.subplot(7,2,(i+1))",
                "sns.barplot(data = H, x = ordinal_columns[i], y = 'SalePrice'  )"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = H['SalePrice']",
                "ASSIGN = H.drop(['SalePrice'], axis = 1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = H['SalePrice']",
                "ASSIGN = H.drop(['SalePrice'], axis = 1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "House_Dummies = pd.get_dummies(H[categorical_columns], drop_first = True)",
                "House_Dummies.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "House_Dummies = pd.get_dummies(H[categorical_columns], drop_first = True)",
                "House_Dummies.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(categorical_columns)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "len(categorical_columns)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.drop(categorical_columns, axis = 1)",
                "ASSIGN = pd.concat([ASSIGN, House_Dummies], axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.drop(categorical_columns, axis = 1)",
                "ASSIGN = pd.concat([ASSIGN, House_Dummies], axis=1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.7, test_size = 0.3, random_state = 100)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.7, test_size = 0.3, random_state = 100)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = StandardScaler()",
                "numerical_columns.remove('SalePrice')",
                "X_train[numerical_columns+ordinal_columns] = ASSIGN.fit_transform(X_train[numerical_columns+ordinal_columns])",
                "X_test[numerical_columns+ordinal_columns] = ASSIGN.transform(X_test[numerical_columns+ordinal_columns])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = StandardScaler()",
                "numerical_columns.remove('SalePrice')",
                "X_train[numerical_columns+ordinal_columns] = ASSIGN.fit_transform(X_train[numerical_columns+ordinal_columns])",
                "X_test[numerical_columns+ordinal_columns] = ASSIGN.transform(X_test[numerical_columns+ordinal_columns])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_train.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X_train.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_test.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X_test.shape"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = {'alpha': [0.00001,0.00005,0.0001, 0.0005,0.001,0.01, 0.02]}",
                "ASSIGN = Lasso()",
                "ASSIGN = 5",
                "ASSIGN = GridSearchCV(estimator = lasso,",
                "ASSIGN = params,",
                "ASSIGN= 'neg_mean_absolute_error',",
                "ASSIGN = folds,",
                "ASSIGN=True,",
                "ASSIGN = 1)",
                "ASSIGN.fit(X_train, y_train)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = {'alpha': [0.00001,0.00005,0.0001, 0.0005,0.001,0.01, 0.02]}",
                "ASSIGN = Lasso()",
                "ASSIGN = 5",
                "ASSIGN = GridSearchCV(estimator = lasso,",
                "ASSIGN = params,",
                "ASSIGN= 'neg_mean_absolute_error',",
                "ASSIGN = folds,",
                "ASSIGN=True,",
                "ASSIGN = 1)",
                "ASSIGN.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(model_cv.cv_results_)",
                "ASSIGN['param_alpha'] = ASSIGN['param_alpha'].astype('float32')",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_train_score'])",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_test_score'])",
                "plt.xlabel('alpha')",
                "plt.ylabel('Negative Mean Absolute Error')",
                "plt.title(\"Negative Mean Absolute Error and alpha\")",
                "plt.legend(['train score', 'test score'], loc='upper left')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.DataFrame(model_cv.cv_results_)",
                "ASSIGN['param_alpha'] = ASSIGN['param_alpha'].astype('float32')",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_train_score'])",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_test_score'])",
                "plt.xlabel('alpha')",
                "plt.ylabel('Negative Mean Absolute Error')",
                "plt.title(\"Negative Mean Absolute Error and alpha\")",
                "plt.legend(['train score', 'test score'], loc='upper left')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN =0.001",
                "ASSIGN = Lasso(alpha=alpha)",
                "ASSIGN.fit(X_train, y_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN =0.001",
                "ASSIGN = Lasso(alpha=alpha)",
                "ASSIGN.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":lasso.coef_})",
                "ASSIGN[ASSIGN['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":lasso.coef_})",
                "ASSIGN[ASSIGN['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = lasso.predict(X_test)",
                "ASSIGN = lasso.predict(X_train)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = lasso.predict(X_test)",
                "ASSIGN = lasso.predict(X_train)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(metrics.r2_score(y_true=y_test, y_pred=y_test_lasso_predict))",
                "print(metrics.r2_score(y_true=y_train, y_pred=y_train_lasso_predict))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(metrics.r2_score(y_true=y_test, y_pred=y_test_lasso_predict))",
                "print(metrics.r2_score(y_true=y_train, y_pred=y_train_lasso_predict))"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = {'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 1.5, 2, 10, 100, 1000]}",
                "ASSIGN = Ridge()",
                "ASSIGN = 5",
                "ASSIGN = GridSearchCV(estimator = ridge,",
                "ASSIGN = params,",
                "ASSIGN= 'neg_mean_absolute_error',",
                "ASSIGN = folds,",
                "ASSIGN=True,",
                "ASSIGN = 1)",
                "ASSIGN.fit(X_train, y_train)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = {'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 1.5, 2, 10, 100, 1000]}",
                "ASSIGN = Ridge()",
                "ASSIGN = 5",
                "ASSIGN = GridSearchCV(estimator = ridge,",
                "ASSIGN = params,",
                "ASSIGN= 'neg_mean_absolute_error',",
                "ASSIGN = folds,",
                "ASSIGN=True,",
                "ASSIGN = 1)",
                "ASSIGN.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(model_cv.cv_results_)",
                "ASSIGN['param_alpha'] = ASSIGN['param_alpha'].astype('float32')",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_train_score'])",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_test_score'])",
                "plt.xlabel('alpha')",
                "plt.ylabel('Negative Mean Absolute Error')",
                "plt.title(\"Negative Mean Absolute Error and alpha\")",
                "plt.legend(['train score', 'test score'], loc='upper left')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.DataFrame(model_cv.cv_results_)",
                "ASSIGN['param_alpha'] = ASSIGN['param_alpha'].astype('float32')",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_train_score'])",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_test_score'])",
                "plt.xlabel('alpha')",
                "plt.ylabel('Negative Mean Absolute Error')",
                "plt.title(\"Negative Mean Absolute Error and alpha\")",
                "plt.legend(['train score', 'test score'], loc='upper left')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN =100",
                "ASSIGN = Ridge(alpha=alpha)",
                "ASSIGN.fit(X_train, y_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN =100",
                "ASSIGN = Ridge(alpha=alpha)",
                "ASSIGN.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = ridge.predict(X_test)",
                "ASSIGN = ridge.predict(X_train)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ridge.predict(X_test)",
                "ASSIGN = ridge.predict(X_train)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(metrics.r2_score(y_true=y_test, y_pred=y_test_ridge_predict))",
                "print(metrics.r2_score(y_true=y_train, y_pred=y_train_ridge_predict))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(metrics.r2_score(y_true=y_test, y_pred=y_test_ridge_predict))",
                "print(metrics.r2_score(y_true=y_train, y_pred=y_train_ridge_predict))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":ridge.coef_})",
                "ASSIGN[ASSIGN['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":ridge.coef_})",
                "ASSIGN[ASSIGN['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = {'alpha': [0,0.0001, 0.0005, 0.001, 0.01]}",
                "ASSIGN = ElasticNet()",
                "ASSIGN = GridSearchCV(estimator = elasticnet,",
                "ASSIGN = params,",
                "ASSIGN= 'neg_mean_absolute_error',",
                "ASSIGN = folds,",
                "ASSIGN=True,",
                "ASSIGN = 1)",
                "ASSIGN.fit(X_train, y_train)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = {'alpha': [0,0.0001, 0.0005, 0.001, 0.01]}",
                "ASSIGN = ElasticNet()",
                "ASSIGN = GridSearchCV(estimator = elasticnet,",
                "ASSIGN = params,",
                "ASSIGN= 'neg_mean_absolute_error',",
                "ASSIGN = folds,",
                "ASSIGN=True,",
                "ASSIGN = 1)",
                "ASSIGN.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(model_cv.cv_results_)",
                "ASSIGN['param_alpha'] = ASSIGN['param_alpha'].astype('float32')",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_train_score'])",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_test_score'])",
                "plt.xlabel('alpha')",
                "plt.ylabel('Negative Mean Absolute Error')",
                "plt.title(\"Negative Mean Absolute Error and alpha\")",
                "plt.legend(['train score', 'test score'], loc='upper left')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.DataFrame(model_cv.cv_results_)",
                "ASSIGN['param_alpha'] = ASSIGN['param_alpha'].astype('float32')",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_train_score'])",
                "plt.plot(ASSIGN['param_alpha'], ASSIGN['mean_test_score'])",
                "plt.xlabel('alpha')",
                "plt.ylabel('Negative Mean Absolute Error')",
                "plt.title(\"Negative Mean Absolute Error and alpha\")",
                "plt.legend(['train score', 'test score'], loc='upper left')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN =0.001",
                "ASSIGN = ElasticNet(alpha=alpha)",
                "ASSIGN.fit(X_train, y_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN =0.001",
                "ASSIGN = ElasticNet(alpha=alpha)",
                "ASSIGN.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = elasticnet.predict(X_test)",
                "ASSIGN = elasticnet.predict(X_train)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = elasticnet.predict(X_test)",
                "ASSIGN = elasticnet.predict(X_train)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(metrics.r2_score(y_true=y_test, y_pred=y_test_elasticnet_predict))",
                "print(metrics.r2_score(y_true=y_train, y_pred=y_train_elasticnet_predict))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(metrics.r2_score(y_true=y_test, y_pred=y_test_elasticnet_predict))",
                "print(metrics.r2_score(y_true=y_train, y_pred=y_train_elasticnet_predict))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":elasticnet.coef_})",
                "ASSIGN[ASSIGN['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\"Coefficients\":elasticnet.coef_})",
                "ASSIGN[ASSIGN['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).count()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN[ASSIGN['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).reset_index()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN[ASSIGN['Coefficients'] != 0 ].sort_values(by = \"Coefficients\" , ascending = False).reset_index()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "Lasso_coef.drop(['index'], axis = 1, inplace = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "Lasso_coef.drop(['index'], axis = 1, inplace = True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "Lasso_coef.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Lasso_coef.head(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "Lasso_coef.tail(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Lasso_coef.tail(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "Lasso_coef['Feature'].to_list()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Lasso_coef['Feature'].to_list()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,15))",
                "sns.barplot(x=\"Coefficients\", y=\"Feature\", data=Lasso_coef, palette=\"vlag\")",
                "plt.xlabel(\"Feature Importance\")",
                "plt.tight_layout()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,15))",
                "sns.barplot(x=\"Coefficients\", y=\"Feature\", data=Lasso_coef, palette=\"vlag\")",
                "plt.xlabel(\"Feature Importance\")",
                "plt.tight_layout()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN='course_project'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN='course_project'"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = '..path'",
                "print(os.listdir(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = '..path'",
                "print(os.listdir(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ImageFolder(data_dir, transform=ToTensor())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ImageFolder(data_dir, transform=ToTensor())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "CHECKPOINT",
                "ASSIGN = dataset[0]",
                "print(img.shape, label)",
                "img"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "CHECKPOINT",
                "ASSIGN = dataset[0]",
                "print(img.shape, label)",
                "img"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(dataset.classes)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(dataset.classes)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "def show_example(img, label):",
                "print('Label: ', dataset.classes[label], +str(label)+)",
                "plt.imshow(img.permute(1, 2, 0))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "def show_example(img, label):",
                "print('Label: ', dataset.classes[label], +str(label)+)",
                "plt.imshow(img.permute(1, 2, 0))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "show_example(*dataset[0])"
            ],
            "output_type": "stream",
            "content_old": [
                "show_example(*dataset[0])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))",
                "ASSIGN = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'),",
                "tt.RandomHorizontalFlip(),",
                "tt.ToTensor(),",
                "tt.Normalize(*ASSIGN,inplace=True)])",
                "ASSIGN = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))",
                "ASSIGN = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'),",
                "tt.RandomHorizontalFlip(),",
                "tt.ToTensor(),",
                "tt.Normalize(*ASSIGN,inplace=True)])",
                "ASSIGN = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 400"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 400"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 5000",
                "ASSIGN = len(dataset) - val_size",
                "ASSIGN = random_split(dataset, [train_size, val_size])",
                "len(train_ds), len(val_ds)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = 5000",
                "ASSIGN = len(dataset) - val_size",
                "ASSIGN = random_split(dataset, [train_size, val_size])",
                "len(train_ds), len(val_ds)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)",
                "ASSIGN = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)",
                "ASSIGN = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 42",
                "torch.manual_seed(ASSIGN);"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 42",
                "torch.manual_seed(ASSIGN);"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 784",
                "ASSIGN = 256",
                "ASSIGN = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)",
                "ASSIGN = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 784",
                "ASSIGN = 256",
                "ASSIGN = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)",
                "ASSIGN = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "SETUP",
                "def show_batch(dl):",
                "for images, labels in dl:",
                "ASSIGN = plt.subplots(figsize=(12, 12))",
                "ax.set_xticks([]); ax.set_yticks([])",
                "ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))",
                "break"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "SETUP",
                "def show_batch(dl):",
                "for images, labels in dl:",
                "ASSIGN = plt.subplots(figsize=(12, 12))",
                "ax.set_xticks([]); ax.set_yticks([])",
                "ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))",
                "break"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "show_batch(train_dl)"
            ],
            "output_type": "display_data",
            "content_old": [
                "show_batch(train_dl)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def get_default_device():",
                "\"\"\"Pick GPU if available, else CPU\"\"\"",
                "if torch.cuda.is_available():",
                "return torch.device('cuda')",
                "else:",
                "return torch.device('cpu')",
                "def to_device(data, device):",
                "\"\"\"Move tensor(s) to chosen device\"\"\"",
                "if isinstance(data, (list,tuple)):",
                "return [to_device(x, device) for x in data]",
                "return data.to(device, non_blocking=True)",
                "class DeviceDataLoader():",
                "\"\"\"Wrap a dataloader to move data to a device\"\"\"",
                "def __init__(self, dl, device):",
                "self.dl = dl",
                "self.device = device",
                "def __iter__(self):",
                "\"\"\"Yield a batch of data after moving it to device\"\"\"",
                "for b in self.dl:",
                "yield to_device(b, self.device)",
                "def __len__(self):",
                "\"\"\"Number of batches\"\"\"",
                "return len(self.dl)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def get_default_device():",
                "\"\"\"Pick GPU if available, else CPU\"\"\"",
                "if torch.cuda.is_available():",
                "return torch.device('cuda')",
                "else:",
                "return torch.device('cpu')",
                "def to_device(data, device):",
                "\"\"\"Move tensor(s) to chosen device\"\"\"",
                "if isinstance(data, (list,tuple)):",
                "return [to_device(x, device) for x in data]",
                "return data.to(device, non_blocking=True)",
                "class DeviceDataLoader():",
                "\"\"\"Wrap a dataloader to move data to a device\"\"\"",
                "def __init__(self, dl, device):",
                "self.dl = dl",
                "self.device = device",
                "def __iter__(self):",
                "\"\"\"Yield a batch of data after moving it to device\"\"\"",
                "for b in self.dl:",
                "yield to_device(b, self.device)",
                "def __len__(self):",
                "\"\"\"Number of batches\"\"\"",
                "return len(self.dl)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = get_default_device()",
                "device"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = get_default_device()",
                "device"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = DeviceDataLoader(ASSIGN, device)",
                "ASSIGN = DeviceDataLoader(ASSIGN, device)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = DeviceDataLoader(ASSIGN, device)",
                "ASSIGN = DeviceDataLoader(ASSIGN, device)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "class SimpleResidualBlock(nn.Module):",
                "def __init__(self):",
                "super().__init__()",
                "self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)",
                "self.relu1 = nn.ReLU()",
                "self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)",
                "self.relu2 = nn.ReLU()",
                "def forward(self, x):",
                "ASSIGN = self.conv1(x)",
                "ASSIGN = self.relu1(ASSIGN)",
                "ASSIGN = self.conv2(ASSIGN)",
                "return self.relu2(out) + x"
            ],
            "output_type": "not_existent",
            "content_old": [
                "class SimpleResidualBlock(nn.Module):",
                "def __init__(self):",
                "super().__init__()",
                "self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)",
                "self.relu1 = nn.ReLU()",
                "self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)",
                "self.relu2 = nn.ReLU()",
                "def forward(self, x):",
                "ASSIGN = self.conv1(x)",
                "ASSIGN = self.relu1(ASSIGN)",
                "ASSIGN = self.conv2(ASSIGN)",
                "return self.relu2(out) + x"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = to_device(SimpleResidualBlock(), device)",
                "for images, labels in train_dl:",
                "ASSIGN = simple_resnet(images)",
                "print(ASSIGN.shape)",
                "break",
                "del simple_resnet, images, labels",
                "torch.cuda.empty_cache()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = to_device(SimpleResidualBlock(), device)",
                "for images, labels in train_dl:",
                "ASSIGN = simple_resnet(images)",
                "print(ASSIGN.shape)",
                "break",
                "del simple_resnet, images, labels",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "def accuracy(outputs, labels):",
                "ASSIGN = torch.max(outputs, dim=1)",
                "return torch.tensor(torch.sum(preds == labels).item() path(preds))",
                "class ImageClassificationBase(nn.Module):",
                "def training_step(self, batch):",
                "ASSIGN = batch",
                "ASSIGN = self(images)",
                "ASSIGN = F.cross_entropy(out, labels)",
                "return loss",
                "def validation_step(self, batch):",
                "ASSIGN = batch",
                "ASSIGN = self(images)",
                "ASSIGN = F.cross_entropy(out, labels)",
                "ASSIGN = accuracy(out, labels)",
                "return {'val_loss': ASSIGN.detach(), 'val_acc': ASSIGN}",
                "def validation_epoch_end(self, outputs):",
                "ASSIGN = [x['val_loss'] for x in outputs]",
                "ASSIGN = torch.stack(batch_losses).mean()",
                "ASSIGN = [x['val_acc'] for x in outputs]",
                "ASSIGN = torch.stack(batch_accs).mean()",
                "return {'val_loss': ASSIGN.item(), 'val_acc': ASSIGN.item()}",
                "def epoch_end(self, epoch, result):",
                "print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(",
                "epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def accuracy(outputs, labels):",
                "ASSIGN = torch.max(outputs, dim=1)",
                "return torch.tensor(torch.sum(preds == labels).item() path(preds))",
                "class ImageClassificationBase(nn.Module):",
                "def training_step(self, batch):",
                "ASSIGN = batch",
                "ASSIGN = self(images)",
                "ASSIGN = F.cross_entropy(out, labels)",
                "return loss",
                "def validation_step(self, batch):",
                "ASSIGN = batch",
                "ASSIGN = self(images)",
                "ASSIGN = F.cross_entropy(out, labels)",
                "ASSIGN = accuracy(out, labels)",
                "return {'val_loss': ASSIGN.detach(), 'val_acc': ASSIGN}",
                "def validation_epoch_end(self, outputs):",
                "ASSIGN = [x['val_loss'] for x in outputs]",
                "ASSIGN = torch.stack(batch_losses).mean()",
                "ASSIGN = [x['val_acc'] for x in outputs]",
                "ASSIGN = torch.stack(batch_accs).mean()",
                "return {'val_loss': ASSIGN.item(), 'val_acc': ASSIGN.item()}",
                "def epoch_end(self, epoch, result):",
                "print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(",
                "epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "def conv_block(in_channels, out_channels, pool=False):",
                "ASSIGN = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),",
                "nn.BatchNorm2d(out_channels),",
                "nn.ReLU(inplace=True)]",
                "if pool: ASSIGN.append(nn.MaxPool2d(2))",
                "return nn.Sequential(*ASSIGN)",
                "class ResNet9(ImageClassificationBase):",
                "def __init__(self, in_channels, num_classes):",
                "super().__init__()",
                "self.conv1 = conv_block(in_channels, 64)",
                "self.conv2 = conv_block(64, 128, pool=True)",
                "self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))",
                "self.conv3 = conv_block(128, 256, pool=True)",
                "self.conv4 = conv_block(256, 512, pool=True)",
                "self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))",
                "self.classifier = nn.Sequential(nn.MaxPool2d(4),",
                "nn.Flatten(),",
                "nn.Linear(512, num_classes))",
                "def forward(self, xb):",
                "ASSIGN = self.conv1(xb)",
                "ASSIGN = self.conv2(ASSIGN)",
                "ASSIGN = self.res1(ASSIGN) + ASSIGN",
                "ASSIGN = self.conv3(ASSIGN)",
                "ASSIGN = self.conv4(ASSIGN)",
                "ASSIGN = self.res2(ASSIGN) + ASSIGN",
                "ASSIGN = self.classifier(ASSIGN)",
                "return out"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def conv_block(in_channels, out_channels, pool=False):",
                "ASSIGN = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),",
                "nn.BatchNorm2d(out_channels),",
                "nn.ReLU(inplace=True)]",
                "if pool: ASSIGN.append(nn.MaxPool2d(2))",
                "return nn.Sequential(*ASSIGN)",
                "class ResNet9(ImageClassificationBase):",
                "def __init__(self, in_channels, num_classes):",
                "super().__init__()",
                "self.conv1 = conv_block(in_channels, 64)",
                "self.conv2 = conv_block(64, 128, pool=True)",
                "self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))",
                "self.conv3 = conv_block(128, 256, pool=True)",
                "self.conv4 = conv_block(256, 512, pool=True)",
                "self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))",
                "self.classifier = nn.Sequential(nn.MaxPool2d(4),",
                "nn.Flatten(),",
                "nn.Linear(512, num_classes))",
                "def forward(self, xb):",
                "ASSIGN = self.conv1(xb)",
                "ASSIGN = self.conv2(ASSIGN)",
                "ASSIGN = self.res1(ASSIGN) + ASSIGN",
                "ASSIGN = self.conv3(ASSIGN)",
                "ASSIGN = self.conv4(ASSIGN)",
                "ASSIGN = self.res2(ASSIGN) + ASSIGN",
                "ASSIGN = self.classifier(ASSIGN)",
                "return out"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = to_device(ResNet9(3, 10), device)",
                "model"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = to_device(ResNet9(3, 10), device)",
                "model"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "@torch.no_grad()",
                "def evaluate(model, val_loader):",
                "model.eval()",
                "ASSIGN = [model.validation_step(batch) for batch in val_loader]",
                "return model.validation_epoch_end(ASSIGN)",
                "def get_lr(optimizer):",
                "for param_group in optimizer.param_groups:",
                "return param_group['lr']",
                "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,",
                "ASSIGN=0, grad_clip=None, opt_func=torch.optim.SGD):",
                "torch.cuda.empty_cache()",
                "ASSIGN = []",
                "ASSIGN = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)",
                "ASSIGN = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,",
                "ASSIGN=len(train_loader))",
                "for epoch in range(epochs):",
                "model.train()",
                "ASSIGN = []",
                "ASSIGN = []",
                "for batch in train_loader:",
                "ASSIGN = model.training_step(batch)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.backward()",
                "if grad_clip:",
                "nn.utils.clip_grad_value_(model.parameters(), grad_clip)",
                "ASSIGN.step()",
                "ASSIGN.zero_grad()",
                "ASSIGN.append(get_lr(ASSIGN))",
                "ASSIGN.step()",
                "ASSIGN = evaluate(model, val_loader)",
                "ASSIGN['train_loss'] = torch.stack(ASSIGN).mean().item()",
                "ASSIGN = lrs",
                "model.epoch_end(epoch, ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "return history"
            ],
            "output_type": "not_existent",
            "content_old": [
                "@torch.no_grad()",
                "def evaluate(model, val_loader):",
                "model.eval()",
                "ASSIGN = [model.validation_step(batch) for batch in val_loader]",
                "return model.validation_epoch_end(ASSIGN)",
                "def get_lr(optimizer):",
                "for param_group in optimizer.param_groups:",
                "return param_group['lr']",
                "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,",
                "ASSIGN=0, grad_clip=None, opt_func=torch.optim.SGD):",
                "torch.cuda.empty_cache()",
                "ASSIGN = []",
                "ASSIGN = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)",
                "ASSIGN = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,",
                "ASSIGN=len(train_loader))",
                "for epoch in range(epochs):",
                "model.train()",
                "ASSIGN = []",
                "ASSIGN = []",
                "for batch in train_loader:",
                "ASSIGN = model.training_step(batch)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.backward()",
                "if grad_clip:",
                "nn.utils.clip_grad_value_(model.parameters(), grad_clip)",
                "ASSIGN.step()",
                "ASSIGN.zero_grad()",
                "ASSIGN.append(get_lr(ASSIGN))",
                "ASSIGN.step()",
                "ASSIGN = evaluate(model, val_loader)",
                "ASSIGN['train_loss'] = torch.stack(ASSIGN).mean().item()",
                "ASSIGN = lrs",
                "model.epoch_end(epoch, ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "return history"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = 8",
                "ASSIGN = 0.01",
                "ASSIGN = 0.1",
                "ASSIGN = 1e-4",
                "ASSIGN = torch.optim.Adam"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 8",
                "ASSIGN = 0.01",
                "ASSIGN = 0.1",
                "ASSIGN = 1e-4",
                "ASSIGN = torch.optim.Adam"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, grad_clip=grad_clip, weight_decay=weight_decay, opt_func=opt_func)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, grad_clip=grad_clip, weight_decay=weight_decay, opt_func=opt_func)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plot_accuracies(history):",
                "ASSIGN = [x['val_acc'] for x in history]",
                "plt.plot(ASSIGN, '-x')",
                "plt.xlabel('epoch')",
                "plt.ylabel('accuracy')",
                "plt.title('Accuracy vs. No. of epochs');"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plot_accuracies(history):",
                "ASSIGN = [x['val_acc'] for x in history]",
                "plt.plot(ASSIGN, '-x')",
                "plt.xlabel('epoch')",
                "plt.ylabel('accuracy')",
                "plt.title('Accuracy vs. No. of epochs');"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [evaluate(model, valid_dl)]",
                "history"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [evaluate(model, valid_dl)]",
                "history"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_accuracies(history)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_accuracies(history)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plot_losses(history):",
                "ASSIGN = [x.get('train_loss') for x in history]",
                "ASSIGN = [x['val_loss'] for x in history]",
                "plt.plot(ASSIGN, '-bx')",
                "plt.plot(ASSIGN, '-rx')",
                "plt.xlabel('epoch')",
                "plt.ylabel('loss')",
                "plt.legend(['Training', 'Validation'])",
                "plt.title('Loss vs. No. of epochs');"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plot_losses(history):",
                "ASSIGN = [x.get('train_loss') for x in history]",
                "ASSIGN = [x['val_loss'] for x in history]",
                "plt.plot(ASSIGN, '-bx')",
                "plt.plot(ASSIGN, '-rx')",
                "plt.xlabel('epoch')",
                "plt.ylabel('loss')",
                "plt.legend(['Training', 'Validation'])",
                "plt.title('Loss vs. No. of epochs');"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_losses(history)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_losses(history)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plot_lrs(history):",
                "ASSIGN = np.concatenate([x.get('ASSIGN', []) for x in history])",
                "plt.plot(ASSIGN)",
                "plt.xlabel('Batch no.')",
                "plt.ylabel('Learning rate')",
                "plt.title('Learning Rate vs. Batch no.');"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plot_lrs(history):",
                "ASSIGN = np.concatenate([x.get('ASSIGN', []) for x in history])",
                "plt.plot(ASSIGN)",
                "plt.xlabel('Batch no.')",
                "plt.ylabel('Learning rate')",
                "plt.title('Learning Rate vs. Batch no.');"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plot_lrs(history)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plot_lrs(history)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "jovian.commit(project=project_name)",
                "ASSIGN='..path'",
                "jovian.log_dataset(ASSIGN=ASSIGN, val_size=val_size, random_seed=random_seed)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "jovian.commit(project=project_name)",
                "ASSIGN='..path'",
                "jovian.log_dataset(ASSIGN=ASSIGN, val_size=val_size, random_seed=random_seed)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN=tf.keras.regularizers.l2(0.01)",
                "print(tf.__version__)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN=tf.keras.regularizers.l2(0.01)",
                "print(tf.__version__)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = '..path'",
                "ASSIGN = '..path'",
                "ASSIGN = 150",
                "ASSIGN = 150",
                "ASSIGN = 100",
                "ASSIGN = 32",
                "ASSIGN = 5736",
                "ASSIGN = 2460",
                "ASSIGN = ImageDataGenerator(rescale=1. path,",
                "ASSIGN=40,",
                "ASSIGN=0.2,",
                "ASSIGN=0.2,",
                "ASSIGN=0.2,",
                "ASSIGN=0.2,",
                "ASSIGN=True,",
                "ASSIGN='nearest')",
                "ASSIGN = ImageDataGenerator(rescale=1. path)",
                "ASSIGN = train_datagen.flow_from_directory(train_data_path,",
                "ASSIGN=(img_rows, img_cols),",
                "ASSIGN=ASSIGN,",
                "ASSIGN='categorical')",
                "ASSIGN = test_datagen.flow_from_directory(test_data_path,",
                "ASSIGN=(img_rows, img_cols),",
                "ASSIGN=ASSIGN,",
                "ASSIGN='categorical')"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = '..path'",
                "ASSIGN = '..path'",
                "ASSIGN = 150",
                "ASSIGN = 150",
                "ASSIGN = 100",
                "ASSIGN = 32",
                "ASSIGN = 5736",
                "ASSIGN = 2460",
                "ASSIGN = ImageDataGenerator(rescale=1. path,",
                "ASSIGN=40,",
                "ASSIGN=0.2,",
                "ASSIGN=0.2,",
                "ASSIGN=0.2,",
                "ASSIGN=0.2,",
                "ASSIGN=True,",
                "ASSIGN='nearest')",
                "ASSIGN = ImageDataGenerator(rescale=1. path)",
                "ASSIGN = train_datagen.flow_from_directory(train_data_path,",
                "ASSIGN=(img_rows, img_cols),",
                "ASSIGN=ASSIGN,",
                "ASSIGN='categorical')",
                "ASSIGN = test_datagen.flow_from_directory(test_data_path,",
                "ASSIGN=(img_rows, img_cols),",
                "ASSIGN=ASSIGN,",
                "ASSIGN='categorical')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = image_dataset_from_directory(",
                "ASSIGN=r\"..path\",",
                "ASSIGN = \"inferred\", label_mode = 'int',",
                "ASSIGN = 0.2,",
                "ASSIGN = \"training\",",
                "ASSIGN = 1337,",
                "ASSIGN=(224, 224),",
                "ASSIGN=32",
                ")",
                "plt.figure(figsize=(10, 10))",
                "for images, ASSIGN in ASSIGN.take(1):",
                "for i in range(9):",
                "ASSIGN = plt.subplot(3, 3, i + 1)",
                "plt.imshow(images[i].numpy().astype(\"uint8\"))",
                "plt.title(int(ASSIGN[i]))",
                "plt.axis(\"off\")"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = image_dataset_from_directory(",
                "ASSIGN=r\"..path\",",
                "ASSIGN = \"inferred\", label_mode = 'int',",
                "ASSIGN = 0.2,",
                "ASSIGN = \"training\",",
                "ASSIGN = 1337,",
                "ASSIGN=(224, 224),",
                "ASSIGN=32",
                ")",
                "plt.figure(figsize=(10, 10))",
                "for images, ASSIGN in ASSIGN.take(1):",
                "for i in range(9):",
                "ASSIGN = plt.subplot(3, 3, i + 1)",
                "plt.imshow(images[i].numpy().astype(\"uint8\"))",
                "plt.title(int(ASSIGN[i]))",
                "plt.axis(\"off\")"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=STEP_SIZE_TRAIN",
                "ASSIGN = tf.keras.optimizers.schedules.InverseTimeDecay(",
                "0.005, decay_steps=ASSIGN*1000,decay_rate=1,staircase=False)",
                "ASSIGN = SGD(lr_schedule)",
                "ASSIGN= SGD(lr = 0.01)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN=STEP_SIZE_TRAIN",
                "ASSIGN = tf.keras.optimizers.schedules.InverseTimeDecay(",
                "0.005, decay_steps=ASSIGN*1000,decay_rate=1,staircase=False)",
                "ASSIGN = SGD(lr_schedule)",
                "ASSIGN= SGD(lr = 0.01)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,",
                "ASSIGN=5, min_lr=0.001)",
                "ASSIGN=[reduce_lr]",
                "ASSIGN = EarlyStopping(",
                "ASSIGN='val_loss', min_delta=0, patience=10, verbose=0, mode='auto',",
                "ASSIGN=None, restore_best_weights=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,",
                "ASSIGN=5, min_lr=0.001)",
                "ASSIGN=[reduce_lr]",
                "ASSIGN = EarlyStopping(",
                "ASSIGN='val_loss', min_delta=0, patience=10, verbose=0, mode='auto',",
                "ASSIGN=None, restore_best_weights=True)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Flatten(input_shape=(224, 224, 3)))",
                "ASSIGN.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l1(0.01)))",
                "ASSIGN.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l1(0.01)))",
                "ASSIGN.add(Dropout(0.5))",
                "ASSIGN.add(BatchNormalization())",
                "ASSIGN.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l1(0.01)))",
                "ASSIGN.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l1(0.01)))",
                "ASSIGN.add(Dropout(0.5))",
                "ASSIGN.add(BatchNormalization())",
                "ASSIGN.add(Dense(5, activation='softmax'))",
                "ASSIGN.summary()",
                "ASSIGN.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Flatten(input_shape=(224, 224, 3)))",
                "ASSIGN.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l1(0.01)))",
                "ASSIGN.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l1(0.01)))",
                "ASSIGN.add(Dropout(0.5))",
                "ASSIGN.add(BatchNormalization())",
                "ASSIGN.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l1(0.01)))",
                "ASSIGN.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l1(0.01)))",
                "ASSIGN.add(Dropout(0.5))",
                "ASSIGN.add(BatchNormalization())",
                "ASSIGN.add(Dense(5, activation='softmax'))",
                "ASSIGN.summary()",
                "ASSIGN.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Convolution2D(32, (3, 3), input_shape=(img_rows, img_cols, 3), padding='valid'))",
                "ASSIGN.add(Activation('relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2)))",
                "ASSIGN.add(Convolution2D(32, (3, 3), padding='valid'))",
                "ASSIGN.add(Activation('relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2)))",
                "ASSIGN.add(Convolution2D(64, (3, 3), padding='valid'))",
                "ASSIGN.add(Activation('relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2)))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(64))",
                "ASSIGN.add(Activation('relu'))",
                "ASSIGN.add(Dropout(0.5))",
                "ASSIGN.add(Dense(5))",
                "ASSIGN.add(Activation('softmax'))",
                "ASSIGN.summary()",
                "ASSIGN.compile(loss='categorical_crossentropy',",
                "ASSIGN='rmsprop',",
                "ASSIGN=['accuracy'])"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Convolution2D(32, (3, 3), input_shape=(img_rows, img_cols, 3), padding='valid'))",
                "ASSIGN.add(Activation('relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2)))",
                "ASSIGN.add(Convolution2D(32, (3, 3), padding='valid'))",
                "ASSIGN.add(Activation('relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2)))",
                "ASSIGN.add(Convolution2D(64, (3, 3), padding='valid'))",
                "ASSIGN.add(Activation('relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2)))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(64))",
                "ASSIGN.add(Activation('relu'))",
                "ASSIGN.add(Dropout(0.5))",
                "ASSIGN.add(Dense(5))",
                "ASSIGN.add(Activation('softmax'))",
                "ASSIGN.summary()",
                "ASSIGN.compile(loss='categorical_crossentropy',",
                "ASSIGN='rmsprop',",
                "ASSIGN=['accuracy'])"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "model.fit_generator(train_generator,",
                "ASSIGN=num_of_train_samples path,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=validation_generator,",
                "ASSIGN=num_of_test_samples path)"
            ],
            "output_type": "stream",
            "content_old": [
                "model.fit_generator(train_generator,",
                "ASSIGN=num_of_train_samples path,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=validation_generator,",
                "ASSIGN=num_of_test_samples path)"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "model.save_weights('model.h5')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.save_weights('model.h5')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(tf.__version__)",
                "ASSIGN = \"logspath\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")",
                "ASSIGN = TensorBoard(log_dir=log_dir, histogram_freq=1)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(tf.__version__)",
                "ASSIGN = \"logspath\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")",
                "ASSIGN = TensorBoard(log_dir=log_dir, histogram_freq=1)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "model.evaluate(validation_generator,",
                "ASSIGN=STEP_SIZE_VALID)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "model.evaluate(validation_generator,",
                "ASSIGN=STEP_SIZE_VALID)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = model.predict_generator(validation_generator, num_of_test_samples)",
                "ASSIGN = np.argmax(Y_pred, axis=1)",
                "ASSIGN[200]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = model.predict_generator(validation_generator, num_of_test_samples)",
                "ASSIGN = np.argmax(Y_pred, axis=1)",
                "ASSIGN[200]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y_pred.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y_pred.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [labels[i] for i in y_pred]",
                "predictions"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [labels[i] for i in y_pred]",
                "predictions"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ['elefante_train', 'farfalla_train', 'mucca_train','pecora_train','scoiattolo_train']",
                "print(classification_report(validation_generator.labels, y_pred, ASSIGN=ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ['elefante_train', 'farfalla_train', 'mucca_train','pecora_train','scoiattolo_train']",
                "print(classification_report(validation_generator.labels, y_pred, ASSIGN=ASSIGN))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0path)",
                "ASSIGN = test_datagen.flow_from_directory(\"..path\",",
                "ASSIGN = 'categorical',",
                "ASSIGN = (150, 150))"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0path)",
                "ASSIGN = test_datagen.flow_from_directory(\"..path\",",
                "ASSIGN = 'categorical',",
                "ASSIGN = (150, 150))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 9106",
                "ASSIGN = model.predict_generator(test_generator)",
                "ASSIGN = np.argmax(Y_pred_test, axis=1)",
                "y_pred_test"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 9106",
                "ASSIGN = model.predict_generator(test_generator)",
                "ASSIGN = np.argmax(Y_pred_test, axis=1)",
                "y_pred_test"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "Y_pred_test"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "Y_pred_test"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = y_pred_test[0:910]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = y_pred_test[0:910]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(*y_final, sep = )"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(*y_final, sep = )"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(y_final)",
                "ASSIGN.columns = [\"prediction\"]",
                "ASSIGN.to_csv(\"prediction_results.csv\")   # the csv file will be saved locally on the same location where this notebook is located."
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(y_final)",
                "ASSIGN.columns = [\"prediction\"]",
                "ASSIGN.to_csv(\"prediction_results.csv\")   # the csv file will be saved locally on the same location where this notebook is located."
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "res"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "res"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('..path')",
                "im"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('..path')",
                "im"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.concat([im,res], axis = 1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.concat([im,res], axis = 1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "rei.drop('target', axis = 1)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "rei.drop('target', axis = 1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN",
                "rei"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN",
                "rei"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN =ASSIGN.replace(to_replace=2,value = \"mucca\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN =ASSIGN.replace(to_replace=2,value = \"mucca\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "rei.head(100)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "rei.head(100)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN =ASSIGN.replace(to_replace=3,value = \"pecora\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN =ASSIGN.replace(to_replace=3,value = \"pecora\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN =ASSIGN.replace(to_replace=4,value = \"scoiattolo\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN =ASSIGN.replace(to_replace=4,value = \"scoiattolo\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN =ASSIGN.replace(to_replace=0,value = \"elefante\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN =ASSIGN.replace(to_replace=0,value = \"elefante\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "rei"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "rei"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN =ASSIGN.replace(to_replace=1,value = \"farfalla\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN =ASSIGN.replace(to_replace=1,value = \"farfalla\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "rei.head(200)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "rei.head(200)"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "rei.to_csv('final')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "rei.to_csv('final')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y_final.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y_final.shape"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'IRIS_TYPE_CLF.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'IRIS_TYPE_CLF.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df1.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df1.head(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotCorrelationMatrix(df1, 8)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotCorrelationMatrix(df1, 8)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotScatterMatrix(df1, 12, 10)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotScatterMatrix(df1, 12, 10)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "def DisplayImage(image,title,cols=1):",
                "ASSIGN=len(image)+1",
                "ASSIGN=0",
                "plt.figure(figsize=(8, 8))",
                "for i in range(1,ASSIGN):",
                "ASSIGN+=1",
                "plt.subplot(1,cols,ASSIGN),plt.imshow(image[i-1],cmap = 'gray'), plt.title(title[i-1]), plt.axis('off')",
                "if ( i%cols==0):",
                "plt.show(),plt.figure(figsize=(8, 8))",
                "ASSIGN=0"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "def DisplayImage(image,title,cols=1):",
                "ASSIGN=len(image)+1",
                "ASSIGN=0",
                "plt.figure(figsize=(8, 8))",
                "for i in range(1,ASSIGN):",
                "ASSIGN+=1",
                "plt.subplot(1,cols,ASSIGN),plt.imshow(image[i-1],cmap = 'gray'), plt.title(title[i-1]), plt.axis('off')",
                "if ( i%cols==0):",
                "plt.show(),plt.figure(figsize=(8, 8))",
                "ASSIGN=0"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN=[]",
                "ASSIGN=[]",
                "for dirname, _, filenames in os.walk('..path'):",
                "for filename in filenames[0:9]:",
                "ASSIGN.append( cv2.imread(dirname+\"path\"+ filename,0))",
                "ASSIGN.append(\"1\")",
                "DisplayImage(ASSIGN,ASSIGN,3)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN=[]",
                "ASSIGN=[]",
                "for dirname, _, filenames in os.walk('..path'):",
                "for filename in filenames[0:9]:",
                "ASSIGN.append( cv2.imread(dirname+\"path\"+ filename,0))",
                "ASSIGN.append(\"1\")",
                "DisplayImage(ASSIGN,ASSIGN,3)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "warnings.filterwarnings(\"ignore\")",
                "init_notebook_mode(connected=True)",
                "matplotlib.rc('font', size=20)",
                "matplotlib.rc('axes', titlesize=20)",
                "matplotlib.rc('axes', labelsize=20)",
                "matplotlib.rc('xtick', labelsize=20)",
                "matplotlib.rc('ytick', labelsize=20)",
                "matplotlib.rc('legend', fontsize=20)",
                "matplotlib.rc('figure', titlesize=20)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "warnings.filterwarnings(\"ignore\")",
                "init_notebook_mode(connected=True)",
                "matplotlib.rc('font', size=20)",
                "matplotlib.rc('axes', titlesize=20)",
                "matplotlib.rc('axes', labelsize=20)",
                "matplotlib.rc('xtick', labelsize=20)",
                "matplotlib.rc('ytick', labelsize=20)",
                "matplotlib.rc('legend', fontsize=20)",
                "matplotlib.rc('figure', titlesize=20)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "def file_len(fname):",
                "ASSIGN = subprocess.Popen(['wc', '-l', fname], stdout=subprocess.PIPE,",
                "ASSIGN=subprocess.PIPE)",
                "ASSIGN = p.communicate()",
                "if ASSIGN.returncode != 0:",
                "raise IOError(err)",
                "return int(result.strip().split()[0])",
                "ASSIGN = file_len('..path')",
                "print('Number of ASSIGN in is:', ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "def file_len(fname):",
                "ASSIGN = subprocess.Popen(['wc', '-l', fname], stdout=subprocess.PIPE,",
                "ASSIGN=subprocess.PIPE)",
                "ASSIGN = p.communicate()",
                "if ASSIGN.returncode != 0:",
                "raise IOError(err)",
                "return int(result.strip().split()[0])",
                "ASSIGN = file_len('..path')",
                "print('Number of ASSIGN in is:', ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.random.choice(np.arange(1, lines), size=lines-1-1000000, replace=False)",
                "ASSIGN=np.sort(ASSIGN)",
                "print('lines to skip:', len(ASSIGN))",
                "ASSIGN = pd.read_csv(\"..path\", skiprows=skiplines)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.random.choice(np.arange(1, lines), size=lines-1-1000000, replace=False)",
                "ASSIGN=np.sort(ASSIGN)",
                "print('lines to skip:', len(ASSIGN))",
                "ASSIGN = pd.read_csv(\"..path\", skiprows=skiplines)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "data.sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "data.sample(5)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "data.isnull().sum(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "data.isnull().sum(0)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN={",
                "1:\"Jan\",",
                "2:\"Feb\",",
                "3:\"Mar\",",
                "4:\"Apr\",",
                "5:\"May\",",
                "6:\"June\",",
                "7:\"July\",",
                "8:\"Aug\",",
                "9:\"Sept\",",
                "10:\"Oct\",",
                "11:\"Nov\",",
                "12:\"Dec\"",
                "}",
                "ASSIGN = data.month.apply(lambda x: ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN={",
                "1:\"Jan\",",
                "2:\"Feb\",",
                "3:\"Mar\",",
                "4:\"Apr\",",
                "5:\"May\",",
                "6:\"June\",",
                "7:\"July\",",
                "8:\"Aug\",",
                "9:\"Sept\",",
                "10:\"Oct\",",
                "11:\"Nov\",",
                "12:\"Dec\"",
                "}",
                "ASSIGN = data.month.apply(lambda x: ASSIGN)"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "gc.collect()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "gc.collect()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = data.pivot_table(index='year', columns='month', values='day', aggfunc=len)",
                "ASSIGN = [\"#8B8B00\", \"#8B7E66\", \"#EE82EE\", \"#00C78C\",",
                "\"#00E5EE\", \"#FF6347\", \"#EED2EE\",",
                "\"#63B8FF\", \"#00FF7F\", \"#B9D3EE\",",
                "\"#836FFF\", \"#7D26CD\"]",
                "ASSIGN.loc[:,['Jan','Feb', 'Mar',",
                "'Apr','May','June',",
                "'July','Aug','Sept',",
                "'Oct','Nov','Dec']].plot.bar(stacked=True, figsize=(20,10), color=ASSIGN)",
                "plt.xlabel(\"Years\")",
                "plt.ylabel(\"Ridership\")",
                "plt.legend(loc=10)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = data.pivot_table(index='year', columns='month', values='day', aggfunc=len)",
                "ASSIGN = [\"#8B8B00\", \"#8B7E66\", \"#EE82EE\", \"#00C78C\",",
                "\"#00E5EE\", \"#FF6347\", \"#EED2EE\",",
                "\"#63B8FF\", \"#00FF7F\", \"#B9D3EE\",",
                "\"#836FFF\", \"#7D26CD\"]",
                "ASSIGN.loc[:,['Jan','Feb', 'Mar',",
                "'Apr','May','June',",
                "'July','Aug','Sept',",
                "'Oct','Nov','Dec']].plot.bar(stacked=True, figsize=(20,10), color=ASSIGN)",
                "plt.xlabel(\"Years\")",
                "plt.ylabel(\"Ridership\")",
                "plt.legend(loc=10)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1,2, figsize=(20,7))",
                "ASSIGN = ['",
                "ASSIGN = ax[0].ASSIGN(list(data['gender'].value_counts()),",
                "ASSIGN=list(data.gender.unique()),",
                "ASSIGN='%1.1f%%', shadow=True, startangle=90, colors=colors)",
                "ASSIGN = sns.countplot(x='usertype', data=data, ax=ax[1], color='g', alpha=0.75)",
                "ax[0].set_title(\"Gender Distribution in Ridership\")",
                "ax[1].set_xlabel(\"Type of Rider\")",
                "ax[1].set_ylabel(\"Ridership\")",
                "ax[1].set_title(\"Type of Customers\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(1,2, figsize=(20,7))",
                "ASSIGN = ['",
                "ASSIGN = ax[0].ASSIGN(list(data['gender'].value_counts()),",
                "ASSIGN=list(data.gender.unique()),",
                "ASSIGN='%1.1f%%', shadow=True, startangle=90, colors=colors)",
                "ASSIGN = sns.countplot(x='usertype', data=data, ax=ax[1], color='g', alpha=0.75)",
                "ax[0].set_title(\"Gender Distribution in Ridership\")",
                "ax[1].set_xlabel(\"Type of Rider\")",
                "ax[1].set_ylabel(\"Ridership\")",
                "ax[1].set_title(\"Type of Customers\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "data.usertype.value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "data.usertype.value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = data[['from_station_name','latitude_start','longitude_start']].drop_duplicates(subset='from_station_name')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = data[['from_station_name','latitude_start','longitude_start']].drop_duplicates(subset='from_station_name')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "station_info.sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "station_info.sample(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = list(station_info.latitude_start)",
                "ASSIGN = [str(i) for i in ASSIGN]",
                "ASSIGN = list(station_info.longitude_start)",
                "ASSIGN = [str(i) for i in ASSIGN]",
                "ASSIGN = list(station_info.from_station_name)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = list(station_info.latitude_start)",
                "ASSIGN = [str(i) for i in ASSIGN]",
                "ASSIGN = list(station_info.longitude_start)",
                "ASSIGN = [str(i) for i in ASSIGN]",
                "ASSIGN = list(station_info.from_station_name)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "display(HTML(\"\"\"",
                "<div>",
                "<a href=\"https:path~sominwpath?share_key=y6irxkKqSVolnuF0l4w420\" target=\"_blank\" title=\"Chicago Cycle Sharing Stations\" style=\"display: block; text-align: center;\"><img src=\"https:path~sominwpath?share_key=y6irxkKqSVolnuF0l4w420\" alt=\"Chicago Cycle Sharing Stations\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https:path';\" path><path>",
                "<script data-plotly=\"sominw:6\" sharekey-plotly=\"y6irxkKqSVolnuF0l4w420\" src=\"https:path\" async><path>",
                "<path>\"\"\"))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "display(HTML(\"\"\"",
                "<div>",
                "<a href=\"https:path~sominwpath?share_key=y6irxkKqSVolnuF0l4w420\" target=\"_blank\" title=\"Chicago Cycle Sharing Stations\" style=\"display: block; text-align: center;\"><img src=\"https:path~sominwpath?share_key=y6irxkKqSVolnuF0l4w420\" alt=\"Chicago Cycle Sharing Stations\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https:path';\" path><path>",
                "<script data-plotly=\"sominw:6\" sharekey-plotly=\"y6irxkKqSVolnuF0l4w420\" src=\"https:path\" async><path>",
                "<path>\"\"\"))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(TRAIN_NUMERIC, usecols=[ID_COLUMN, TARGET_COLUMN], nrows=NROWS)",
                "ASSIGN = pd.read_csv(TEST_NUMERIC, usecols=[ID_COLUMN], nrows=NROWS)",
                "ASSIGN = -1",
                "ASSIGN = -1",
                "ASSIGN = -1",
                "ASSIGN = -1"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(TRAIN_NUMERIC, usecols=[ID_COLUMN, TARGET_COLUMN], nrows=NROWS)",
                "ASSIGN = pd.read_csv(TEST_NUMERIC, usecols=[ID_COLUMN], nrows=NROWS)",
                "ASSIGN = -1",
                "ASSIGN = -1",
                "ASSIGN = -1",
                "ASSIGN = -1"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 0",
                "print ('ASSIGN',)",
                "ASSIGN = pd.read_csv(TRAIN_DATE, chunksize=CHUNKSIZE, iterator=True)",
                "ASSIGN = pd.read_csv(TEST_DATE, chunksize=CHUNKSIZE, iterator=True)",
                "for i in range(int(NROWSpath) + 1):",
                "ASSIGN = train_reader.get_chunk()",
                "ASSIGN = test_reader.get_chunk()",
                "ASSIGN = np.setdiff1d(tr.columns, [ID_COLUMN])",
                "ASSIGN = tr[feats].min(axis=1).values",
                "ASSIGN = te[feats].min(axis=1).values",
                "ASSIGN = tr[feats].max(axis=1).values",
                "ASSIGN = te[feats].max(axis=1).values",
                "train.loc[train.Id.isin(ASSIGN.Id), 'StartTime'] = ASSIGN",
                "test.loc[test.Id.isin(ASSIGN.Id), 'StartTime'] = ASSIGN",
                "train.loc[train.Id.isin(ASSIGN.Id), 'EndTime'] = ASSIGN",
                "test.loc[test.Id.isin(ASSIGN.Id), 'EndTime'] = ASSIGN",
                "ASSIGN += CHUNKSIZE",
                "print (ASSIGN,)",
                "if ASSIGN >= NROWS:",
                "break"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 0",
                "print ('ASSIGN',)",
                "ASSIGN = pd.read_csv(TRAIN_DATE, chunksize=CHUNKSIZE, iterator=True)",
                "ASSIGN = pd.read_csv(TEST_DATE, chunksize=CHUNKSIZE, iterator=True)",
                "for i in range(int(NROWSpath) + 1):",
                "ASSIGN = train_reader.get_chunk()",
                "ASSIGN = test_reader.get_chunk()",
                "ASSIGN = np.setdiff1d(tr.columns, [ID_COLUMN])",
                "ASSIGN = tr[feats].min(axis=1).values",
                "ASSIGN = te[feats].min(axis=1).values",
                "ASSIGN = tr[feats].max(axis=1).values",
                "ASSIGN = te[feats].max(axis=1).values",
                "train.loc[train.Id.isin(ASSIGN.Id), 'StartTime'] = ASSIGN",
                "test.loc[test.Id.isin(ASSIGN.Id), 'StartTime'] = ASSIGN",
                "train.loc[train.Id.isin(ASSIGN.Id), 'EndTime'] = ASSIGN",
                "test.loc[test.Id.isin(ASSIGN.Id), 'EndTime'] = ASSIGN",
                "ASSIGN += CHUNKSIZE",
                "print (ASSIGN,)",
                "if ASSIGN >= NROWS:",
                "break"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train.shape[0]",
                "ASSIGN = pd.concat((train, test)).reset_index(drop=True).reset_index(drop=False)",
                "ASSIGN['Duration'] = ASSIGN['EndTime'] - ASSIGN['StartTime']",
                "ASSIGN['magic1'] = ASSIGN[ID_COLUMN].diff().fillna(9999999).astype(int)",
                "ASSIGN['magic2'] = ASSIGN[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)",
                "ASSIGN = ASSIGN.sort_values(by=['StartTime', 'Id'], ascending=True)",
                "ASSIGN['magic3'] = ASSIGN[ID_COLUMN].diff().fillna(9999999).astype(int)",
                "ASSIGN['magic4'] = ASSIGN[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)",
                "ASSIGN = ASSIGN.sort_values(by=['index']).drop(['index'], axis=1)",
                "ASSIGN = train_test.iloc[:ntrain, :]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train.shape[0]",
                "ASSIGN = pd.concat((train, test)).reset_index(drop=True).reset_index(drop=False)",
                "ASSIGN['Duration'] = ASSIGN['EndTime'] - ASSIGN['StartTime']",
                "ASSIGN['magic1'] = ASSIGN[ID_COLUMN].diff().fillna(9999999).astype(int)",
                "ASSIGN['magic2'] = ASSIGN[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)",
                "ASSIGN = ASSIGN.sort_values(by=['StartTime', 'Id'], ascending=True)",
                "ASSIGN['magic3'] = ASSIGN[ID_COLUMN].diff().fillna(9999999).astype(int)",
                "ASSIGN['magic4'] = ASSIGN[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)",
                "ASSIGN = ASSIGN.sort_values(by=['index']).drop(['index'], axis=1)",
                "ASSIGN = train_test.iloc[:ntrain, :]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def twoplot(df, col, xaxis=None):",
                "''' scatter plot a feature split into response values as two subgraphs '''",
                "if col not in df.columns.values:",
                "print('ERROR: %s not a column' % col)",
                "ASSIGN = pd.DataFrame(index = df.index)",
                "ASSIGN = ASSIGN",
                "ASSIGN = ASSIGN if xaxis else df.index",
                "ASSIGN = ASSIGN",
                "ASSIGN = sns.FacetGrid(ndf, col=\"Response\", hue=\"Response\")",
                "ASSIGN.map(plt.scatter, xaxis, col, alpha=.7, s=1)",
                "ASSIGN.add_legend();",
                "del ndf"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def twoplot(df, col, xaxis=None):",
                "''' scatter plot a feature split into response values as two subgraphs '''",
                "if col not in df.columns.values:",
                "print('ERROR: %s not a column' % col)",
                "ASSIGN = pd.DataFrame(index = df.index)",
                "ASSIGN = ASSIGN",
                "ASSIGN = ASSIGN if xaxis else df.index",
                "ASSIGN = ASSIGN",
                "ASSIGN = sns.FacetGrid(ndf, col=\"Response\", hue=\"Response\")",
                "ASSIGN.map(plt.scatter, xaxis, col, alpha=.7, s=1)",
                "ASSIGN.add_legend();",
                "del ndf"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "twoplot(train, 'magic1')"
            ],
            "output_type": "display_data",
            "content_old": [
                "twoplot(train, 'magic1')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "twoplot(train, 'magic2')"
            ],
            "output_type": "display_data",
            "content_old": [
                "twoplot(train, 'magic2')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "twoplot(train, 'magic3')"
            ],
            "output_type": "display_data",
            "content_old": [
                "twoplot(train, 'magic3')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "twoplot(train, 'magic4')"
            ],
            "output_type": "display_data",
            "content_old": [
                "twoplot(train, 'magic4')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "twoplot(train, 'Duration')"
            ],
            "output_type": "display_data",
            "content_old": [
                "twoplot(train, 'Duration')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "twoplot(train, 'StartTime')"
            ],
            "output_type": "display_data",
            "content_old": [
                "twoplot(train, 'StartTime')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "twoplot(train, 'EndTime')"
            ],
            "output_type": "display_data",
            "content_old": [
                "twoplot(train, 'EndTime')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())",
                "print(os.listdir())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN= \"..path\"",
                "ASSIGN= \"..path\"",
                "ASSIGN=pd.read_csv(data_train_file)",
                "ASSIGN= pd.read_csv(data_test_file)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN= \"..path\"",
                "ASSIGN= \"..path\"",
                "ASSIGN=pd.read_csv(data_train_file)",
                "ASSIGN= pd.read_csv(data_test_file)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_train.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train.describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_train.describe()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "for i in range(5000,5005):",
                "ASSIGN =np.reshape(df_test[df_test.columns[1:]].iloc[i].valuespath,(28,28))",
                "plt.figure()",
                "plt.title(\"labelled cs {}\".format(df_test[\"0\"].iloc[i]))",
                "plt.imshow(ASSIGN,'gray')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "for i in range(5000,5005):",
                "ASSIGN =np.reshape(df_test[df_test.columns[1:]].iloc[i].valuespath,(28,28))",
                "plt.figure()",
                "plt.title(\"labelled cs {}\".format(df_test[\"0\"].iloc[i]))",
                "plt.imshow(ASSIGN,'gray')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "np.random.seed(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "np.random.seed(0)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(landslides['date'].head())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(landslides['date'].head())"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "landslides['date'].dtype"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "landslides['date'].dtype"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "earthquakes['Date'].dtype"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "earthquakes['Date'].dtype"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "landslides['date_parsed'] = pd.to_datetime(landslides['date'], format = \"%mpath%dpath%y\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "landslides['date_parsed'] = pd.to_datetime(landslides['date'], format = \"%mpath%dpath%y\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "landslides['date_parsed'].head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "landslides['date_parsed'].head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(.format(earthquakes['Date'].dtype))",
                "print(earthquakes['Date'].head())",
                "earthquakes['date_parsed']=pd.to_datetime(earthquakes['Date'], format = \"%mpath%dpath%Y\")",
                "earthquakes['date_parsed'].head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(.format(earthquakes['Date'].dtype))",
                "print(earthquakes['Date'].head())",
                "earthquakes['date_parsed']=pd.to_datetime(earthquakes['Date'], format = \"%mpath%dpath%Y\")",
                "earthquakes['date_parsed'].head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "earthquakes.iloc[3370:3390]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "earthquakes.iloc[3370:3390]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "earthquakes['date_parsed']=pd.to_datetime(earthquakes['Date'], infer_datetime_format=True)",
                "earthquakes['date_parsed'].head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "earthquakes['date_parsed']=pd.to_datetime(earthquakes['Date'], infer_datetime_format=True)",
                "earthquakes['date_parsed'].head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = landslides['date'].dt.day"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = landslides['date'].dt.day"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = landslides['date_parsed'].dt.day"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = landslides['date_parsed'].dt.day"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = earthquakes['date_parsed'].dt.day"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = earthquakes['date_parsed'].dt.day"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ASSIGN.dropna()",
                "sns.distplot(ASSIGN, kde=False, bins=31)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.dropna()",
                "sns.distplot(ASSIGN, kde=False, bins=31)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ASSIGN.dropna()",
                "sns.distplot(ASSIGN, kde=False, bins=31)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.dropna()",
                "sns.distplot(ASSIGN, kde=False, bins=31)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "volcanos['Last Known Eruption'].sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "volcanos['Last Known Eruption'].sample(5)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('path')",
                "print(f'Classifier output data shape: {ASSIGN.shape}')",
                "ASSIGN.head(10)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('path')",
                "print(f'Classifier output data shape: {ASSIGN.shape}')",
                "ASSIGN.head(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "classifier_output.dropna(inplace=True)",
                "print(f'Classifier output data shape without nans:  {classifier_output.shape}')"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "classifier_output.dropna(inplace=True)",
                "print(f'Classifier output data shape without nans:  {classifier_output.shape}')"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = []",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "ASSIGN.append(os.path.join(dirname, filename))",
                "ASSIGN = pd.concat([pd.read_csv(filepath) for filepath in metadata_files])",
                "print(f'Line data shape: {ASSIGN.shape}')",
                "ASSIGN.head(10)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = []",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "ASSIGN.append(os.path.join(dirname, filename))",
                "ASSIGN = pd.concat([pd.read_csv(filepath) for filepath in metadata_files])",
                "print(f'Line data shape: {ASSIGN.shape}')",
                "ASSIGN.head(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(f'Unique claims: {len(line_data[].unique())}')"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(f'Unique claims: {len(line_data[].unique())}')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = classifier_output.merge(line_data[['claim_id', 'make', 'model', 'year','poi']].drop_duplicates(subset=['claim_id'], keep='first'),",
                "ASSIGN='left', on='claim_id')",
                "print(f'Classifier outputs not associated with a claim: {ASSIGN[].isna().sum()}')",
                "ASSIGN.dropna(subset=['make'], inplace=True)",
                "ASSIGN = pd.merge(claim_merged, line_data[['claim_id', 'line_num', 'part', 'operation', 'part_price', 'labour_amt']],",
                "ASSIGN='left', on=['claim_id', 'part'])",
                "ASSIGN['operation'].fillna('undamaged', inplace=True)",
                "print(f'Merge ASSIGN shape: {ASSIGN.shape}')",
                "ASSIGN.head(10)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = classifier_output.merge(line_data[['claim_id', 'make', 'model', 'year','poi']].drop_duplicates(subset=['claim_id'], keep='first'),",
                "ASSIGN='left', on='claim_id')",
                "print(f'Classifier outputs not associated with a claim: {ASSIGN[].isna().sum()}')",
                "ASSIGN.dropna(subset=['make'], inplace=True)",
                "ASSIGN = pd.merge(claim_merged, line_data[['claim_id', 'line_num', 'part', 'operation', 'part_price', 'labour_amt']],",
                "ASSIGN='left', on=['claim_id', 'part'])",
                "ASSIGN['operation'].fillna('undamaged', inplace=True)",
                "print(f'Merge ASSIGN shape: {ASSIGN.shape}')",
                "ASSIGN.head(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "data['rounded_urr_score'] = data['urr_score'].apply(lambda x: round(x, 2))",
                "ASSIGN = (data[(data['set']==2)][['rounded_urr_score', 'operation', 'urr_score']]",
                ".groupby(['rounded_urr_score', 'operation'])",
                ".count()",
                ".reset_index()",
                ".rename(columns={'urr_score': 'count'})",
                ".set_index('rounded_urr_score')",
                ".pivot(columns='operation', values='count')",
                ".fillna(0)",
                ")",
                "ASSIGN = ASSIGN[['undamaged', 'repair', 'replace']]",
                "ASSIGN.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "data['rounded_urr_score'] = data['urr_score'].apply(lambda x: round(x, 2))",
                "ASSIGN = (data[(data['set']==2)][['rounded_urr_score', 'operation', 'urr_score']]",
                ".groupby(['rounded_urr_score', 'operation'])",
                ".count()",
                ".reset_index()",
                ".rename(columns={'urr_score': 'count'})",
                ".set_index('rounded_urr_score')",
                ".pivot(columns='operation', values='count')",
                ".fillna(0)",
                ")",
                "ASSIGN = ASSIGN[['undamaged', 'repair', 'replace']]",
                "ASSIGN.head(10)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "bucket_counts.sum(axis=1).plot.bar()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "bucket_counts.sum(axis=1).plot.bar()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = bucket_counts.divide(bucket_counts.sum(axis=1), axis=0)",
                "ASSIGN.plot.area()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = bucket_counts.divide(bucket_counts.sum(axis=1), axis=0)",
                "ASSIGN.plot.area()"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Data Validation Activtiy"
            ],
            "content": [
                "ASSIGN = {'undamaged': 0,",
                "'repair': 1,",
                "'replace': 2}",
                "data['operation_rank'] = data['operation'].apply(lambda x: ASSIGN[x])",
                "def mae_single_point(urr_score, operation_rank, repair_threshold, replace_threshold):",
                "ASSIGN = int(urr_score > repair_threshold) + int(urr_score > replace_threshold)",
                "return abs(ASSIGN - operation_rank)",
                "assert(mae_single_point(0.9, 0, 0.4, 0.7) == 2)",
                "assert(mae_single_point(0.5, 1, 0.4, 0.7) == 0)",
                "assert(mae_single_point(0.5, 2, 0.4, 0.7) == 1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {'undamaged': 0,",
                "'repair': 1,",
                "'replace': 2}",
                "data['operation_rank'] = data['operation'].apply(lambda x: ASSIGN[x])",
                "def mae_single_point(urr_score, operation_rank, repair_threshold, replace_threshold):",
                "ASSIGN = int(urr_score > repair_threshold) + int(urr_score > replace_threshold)",
                "return abs(ASSIGN - operation_rank)",
                "assert(mae_single_point(0.9, 0, 0.4, 0.7) == 2)",
                "assert(mae_single_point(0.5, 1, 0.4, 0.7) == 0)",
                "assert(mae_single_point(0.5, 2, 0.4, 0.7) == 1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def mae_dataset(data, repair_threshold, replace_threshold):",
                "ASSIGN =[]",
                "for i in range(2):",
                "ASSIGN = data[(data['operation_rank']==i)]",
                "ASSIGN = sum(class_data",
                ".apply(lambda row: mae_single_point(row['urr_score'], row['operation_rank'], repair_threshold, replace_threshold), axis=1))path(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = sum(class_maes)path",
                "return total_mae"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def mae_dataset(data, repair_threshold, replace_threshold):",
                "ASSIGN =[]",
                "for i in range(2):",
                "ASSIGN = data[(data['operation_rank']==i)]",
                "ASSIGN = sum(class_data",
                ".apply(lambda row: mae_single_point(row['urr_score'], row['operation_rank'], repair_threshold, replace_threshold), axis=1))path(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = sum(class_maes)path",
                "return total_mae"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = data[(data['set']==2)][['urr_score', 'operation_rank']]",
                "def mae(thresholds):",
                "return mae_dataset(ASSIGN, thresholds[0], thresholds[1])",
                "ASSIGN = gp_minimize(mae, dimensions=[(0.0, 1.0, 'uniform'), (0.0, 1.0, 'uniform')], n_calls=50, verbose=True)",
                "print(f'Best thresholds: {ASSIGN.x}')",
                "print(f'Best average mse: {ASSIGN.fun}')"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = data[(data['set']==2)][['urr_score', 'operation_rank']]",
                "def mae(thresholds):",
                "return mae_dataset(ASSIGN, thresholds[0], thresholds[1])",
                "ASSIGN = gp_minimize(mae, dimensions=[(0.0, 1.0, 'uniform'), (0.0, 1.0, 'uniform')], n_calls=50, verbose=True)",
                "print(f'Best thresholds: {ASSIGN.x}')",
                "print(f'Best average mse: {ASSIGN.fun}')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"..path\", index_col=0)",
                "pd.set_option(\"display.max_rows\", 5)",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"..path\", index_col=0)",
                "pd.set_option(\"display.max_rows\", 5)",
                "print()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "reviews.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "reviews.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "init_notebook_mode(connected=True)",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "init_notebook_mode(connected=True)",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN=pd.read_csv('path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=pd.read_csv('path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "corona_data.head(3)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "corona_data.head(3)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "corona_data.tail(2)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "corona_data.tail(2)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN=px.choropleth(corona_data,",
                "ASSIGN=\"Countrypath\",",
                "ASSIGN = \"country names\",",
                "ASSIGN=\"Confirmed\",",
                "ASSIGN=\"Countrypath\",",
                "ASSIGN=\"ObservationDate\"",
                ")",
                "ASSIGN.update_layout(",
                "ASSIGN = 'Global Spread of Coronavirus',",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN=px.choropleth(corona_data,",
                "ASSIGN=\"Countrypath\",",
                "ASSIGN = \"country names\",",
                "ASSIGN=\"Confirmed\",",
                "ASSIGN=\"Countrypath\",",
                "ASSIGN=\"ObservationDate\"",
                ")",
                "ASSIGN.update_layout(",
                "ASSIGN = 'Global Spread of Coronavirus',",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = px.pie(corona_data, values = 'Confirmed',names='Countrypath', height=600)",
                "ASSIGN.update_traces(textposition='inside', textinfo='percent+label')",
                "ASSIGN.update_layout(",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = px.pie(corona_data, values = 'Confirmed',names='Countrypath', height=600)",
                "ASSIGN.update_traces(textposition='inside', textinfo='percent+label')",
                "ASSIGN.update_layout(",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = corona_data.groupby(['Countrypath', 'ObservationDate']).sum().reset_index().sort_values('Confirmed', ascending=False)",
                "ASSIGN = ASSIGN.drop_duplicates(subset = ['Countrypath'])",
                "ASSIGN = ASSIGN.iloc[0:10]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = corona_data.groupby(['Countrypath', 'ObservationDate']).sum().reset_index().sort_values('Confirmed', ascending=False)",
                "ASSIGN = ASSIGN.drop_duplicates(subset = ['Countrypath'])",
                "ASSIGN = ASSIGN.iloc[0:10]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = px.pie(top10, values = 'Confirmed',names='Countrypath', height=600)",
                "ASSIGN.update_traces(textposition='inside', textinfo='percent+label')",
                "ASSIGN.update_layout(",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = px.pie(top10, values = 'Confirmed',names='Countrypath', height=600)",
                "ASSIGN.update_traces(textposition='inside', textinfo='percent+label')",
                "ASSIGN.update_layout(",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = corona_data.groupby(['Countrypath', 'ObservationDate']).sum().reset_index().sort_values('Confirmed', ascending=False)",
                "ASSIGN = ASSIGN.drop_duplicates(subset = ['Countrypath'])",
                "ASSIGN = ASSIGN.iloc[-20:-1]",
                "last20"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = corona_data.groupby(['Countrypath', 'ObservationDate']).sum().reset_index().sort_values('Confirmed', ascending=False)",
                "ASSIGN = ASSIGN.drop_duplicates(subset = ['Countrypath'])",
                "ASSIGN = ASSIGN.iloc[-20:-1]",
                "last20"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = px.pie(last20, values = 'Confirmed',names='Countrypath', height=600)",
                "ASSIGN.update_traces(textposition='inside', textinfo='percent+label')",
                "ASSIGN.update_layout(",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = px.pie(last20, values = 'Confirmed',names='Countrypath', height=600)",
                "ASSIGN.update_traces(textposition='inside', textinfo='percent+label')",
                "ASSIGN.update_layout(",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = corona_data.groupby(['Countrypath', 'ObservationDate'])['Confirmed', 'Deaths', 'Recovered'].sum().reset_index().sort_values('ObservationDate', ascending=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = corona_data.groupby(['Countrypath', 'ObservationDate'])['Confirmed', 'Deaths', 'Recovered'].sum().reset_index().sort_values('ObservationDate', ascending=True)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = px.bar(bar_data, x=\"ObservationDate\", y=\"Confirmed\", color='Countrypath', text = 'Confirmed', orientation='v', height=1300,width=1000,",
                "ASSIGN='Increase in COVID-19 Cases')",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = px.bar(bar_data, x=\"ObservationDate\", y=\"Confirmed\", color='Countrypath', text = 'Confirmed', orientation='v', height=1300,width=1000,",
                "ASSIGN='Increase in COVID-19 Cases')",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = px.bar(bar_data, x=\"ObservationDate\", y=\"Deaths\", color='Countrypath', text = 'Deaths', orientation='v', height=1000,width=900,",
                "ASSIGN='COVID-19 Deaths since February to April 11th')",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = px.bar(bar_data, x=\"ObservationDate\", y=\"Deaths\", color='Countrypath', text = 'Deaths', orientation='v', height=1000,width=900,",
                "ASSIGN='COVID-19 Deaths since February to April 11th')",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = px.bar(bar_data, x=\"ObservationDate\", y=\"Recovered\", color='Countrypath', text = 'Recovered', orientation='v', height=1000,width=900,",
                "ASSIGN='COVID-19 Recovered Cases since February to April 11th')",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = px.bar(bar_data, x=\"ObservationDate\", y=\"Recovered\", color='Countrypath', text = 'Recovered', orientation='v', height=1000,width=900,",
                "ASSIGN='COVID-19 Recovered Cases since February to April 11th')",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = corona_data.groupby('ObservationDate').sum().reset_index()",
                "ASSIGN = ASSIGN.melt(id_vars='ObservationDate',",
                "ASSIGN=['Confirmed',",
                "'Recovered',",
                "'Deaths'],",
                "ASSIGN='Ratio',",
                "ASSIGN='Value')",
                "ASSIGN = px.line(line_data, x=\"ObservationDate\", y=\"Value\", line_shape=\"spline\",color='Ratio',",
                "ASSIGN='Confirmed cases, Recovered cases, and Death Over Time')",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = corona_data.groupby('ObservationDate').sum().reset_index()",
                "ASSIGN = ASSIGN.melt(id_vars='ObservationDate',",
                "ASSIGN=['Confirmed',",
                "'Recovered',",
                "'Deaths'],",
                "ASSIGN='Ratio',",
                "ASSIGN='Value')",
                "ASSIGN = px.line(line_data, x=\"ObservationDate\", y=\"Value\", line_shape=\"spline\",color='Ratio',",
                "ASSIGN='Confirmed cases, Recovered cases, and Death Over Time')",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = '..path'",
                "ASSIGN = '..path'",
                "ASSIGN = 'submission.csv'",
                "ASSIGN = pd.read_csv(train_file_path)",
                "ASSIGN = pd.read_csv(test_file_path)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = '..path'",
                "ASSIGN = '..path'",
                "ASSIGN = 'submission.csv'",
                "ASSIGN = pd.read_csv(train_file_path)",
                "ASSIGN = pd.read_csv(test_file_path)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train.fillna(0)",
                "test.fillna(0)",
                "train.dtypes"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "train.fillna(0)",
                "test.fillna(0)",
                "train.dtypes"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare']",
                "ASSIGN = train['Survived']",
                "ASSIGN = train[data_predictors]",
                "ASSIGN = test[data_predictors]",
                "print(ASSIGN.head())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare']",
                "ASSIGN = train['Survived']",
                "ASSIGN = train[data_predictors]",
                "ASSIGN = test[data_predictors]",
                "print(ASSIGN.head())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.get_dummies(train_X)",
                "ASSIGN = pd.get_dummies(test_X)",
                "ASSIGN = ASSIGN.fillna(0)",
                "train_x"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.get_dummies(train_X)",
                "ASSIGN = pd.get_dummies(test_X)",
                "ASSIGN = ASSIGN.fillna(0)",
                "train_x"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = GradientBoostingRegressor()",
                "ASSIGN.fit(train_x, train_y)",
                "ASSIGN = plot_partial_dependence(plot_model,",
                "ASSIGN=[1, 3],",
                "X=train_x,",
                "ASSIGN=['Pclass', 'Age', 'SibSp', 'Fare'],",
                "ASSIGN=10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = GradientBoostingRegressor()",
                "ASSIGN.fit(train_x, train_y)",
                "ASSIGN = plot_partial_dependence(plot_model,",
                "ASSIGN=[1, 3],",
                "X=train_x,",
                "ASSIGN=['Pclass', 'Age', 'SibSp', 'Fare'],",
                "ASSIGN=10)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = make_pipeline(Imputer(), XGBRegressor())",
                "ASSIGN.fit(train_x, train_y)",
                "ASSIGN = cross_val_score(data_model, train_x, train_y, scoring='neg_mean_absolute_error')",
                "print(ASSIGN)",
                "print('Mean Absolute Error %2f' %(-1 * ASSIGN.mean()))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = make_pipeline(Imputer(), XGBRegressor())",
                "ASSIGN.fit(train_x, train_y)",
                "ASSIGN = cross_val_score(data_model, train_x, train_y, scoring='neg_mean_absolute_error')",
                "print(ASSIGN)",
                "print('Mean Absolute Error %2f' %(-1 * ASSIGN.mean()))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = data_model.predict(test_x)",
                "print('Estimated survivors: ' + str(ASSIGN.astype(int).sum()) + ' passengers')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = data_model.predict(test_x)",
                "print('Estimated survivors: ' + str(ASSIGN.astype(int).sum()) + ' passengers')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = test.assign(Survived=prediction.astype(int))",
                "ASSIGN.to_csv(submission_file_path,sep=',',columns=['PassengerId', 'Survived'], index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = test.assign(Survived=prediction.astype(int))",
                "ASSIGN.to_csv(submission_file_path,sep=',',columns=['PassengerId', 'Survived'], index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "filterwarnings('ignore')",
                "pd.set_option('display.max_columns', None)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "filterwarnings('ignore')",
                "pd.set_option('display.max_columns', None)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "def reduce_mem_usage2(df):",
                "\"\"\" iterate through all the columns of a dataframe and modify the data type",
                "to reduce memory usage.",
                "\"\"\"",
                "ASSIGN = df.memory_usage().sum() path**2",
                "print('Memory usage of dataframe is {:.2f} MB'.format(ASSIGN))",
                "for col in df.columns:",
                "ASSIGN = df[col].dtype",
                "if ASSIGN != object:",
                "ASSIGN = df[col].min()",
                "ASSIGN = df[col].max()",
                "if str(ASSIGN)[:3] == 'int':",
                "if ASSIGN > np.iinfo(np.int8).min and ASSIGN < np.iinfo(np.int8).max:",
                "ASSIGN = ASSIGN.astype(np.int8)",
                "elif ASSIGN > np.iinfo(np.int16).min and ASSIGN < np.iinfo(np.int16).max:",
                "ASSIGN = ASSIGN.astype(np.int16)",
                "elif ASSIGN > np.iinfo(np.int32).min and ASSIGN < np.iinfo(np.int32).max:",
                "ASSIGN = ASSIGN.astype(np.int32)",
                "elif ASSIGN > np.iinfo(np.int64).min and ASSIGN < np.iinfo(np.int64).max:",
                "ASSIGN = ASSIGN.astype(np.int64)",
                "else:",
                "if ASSIGN > np.finfo(np.float16).min and ASSIGN < np.finfo(np.float16).max:",
                "ASSIGN = ASSIGN.astype(np.float16)",
                "elif ASSIGN > np.finfo(np.float32).min and ASSIGN < np.finfo(np.float32).max:",
                "ASSIGN = ASSIGN.astype(np.float32)",
                "else:",
                "ASSIGN = ASSIGN.astype(np.float64)",
                "else:",
                "ASSIGN = ASSIGN.astype('category')",
                "ASSIGN = df.memory_usage().sum() path**2",
                "print('Memory usage after optimization is: {:.2f} MB'.format(ASSIGN))",
                "print('Decreased by {:.1f}%'.format(100 * (ASSIGN - ASSIGN) path))",
                "return df"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "def reduce_mem_usage2(df):",
                "\"\"\" iterate through all the columns of a dataframe and modify the data type",
                "to reduce memory usage.",
                "\"\"\"",
                "ASSIGN = df.memory_usage().sum() path**2",
                "print('Memory usage of dataframe is {:.2f} MB'.format(ASSIGN))",
                "for col in df.columns:",
                "ASSIGN = df[col].dtype",
                "if ASSIGN != object:",
                "ASSIGN = df[col].min()",
                "ASSIGN = df[col].max()",
                "if str(ASSIGN)[:3] == 'int':",
                "if ASSIGN > np.iinfo(np.int8).min and ASSIGN < np.iinfo(np.int8).max:",
                "ASSIGN = ASSIGN.astype(np.int8)",
                "elif ASSIGN > np.iinfo(np.int16).min and ASSIGN < np.iinfo(np.int16).max:",
                "ASSIGN = ASSIGN.astype(np.int16)",
                "elif ASSIGN > np.iinfo(np.int32).min and ASSIGN < np.iinfo(np.int32).max:",
                "ASSIGN = ASSIGN.astype(np.int32)",
                "elif ASSIGN > np.iinfo(np.int64).min and ASSIGN < np.iinfo(np.int64).max:",
                "ASSIGN = ASSIGN.astype(np.int64)",
                "else:",
                "if ASSIGN > np.finfo(np.float16).min and ASSIGN < np.finfo(np.float16).max:",
                "ASSIGN = ASSIGN.astype(np.float16)",
                "elif ASSIGN > np.finfo(np.float32).min and ASSIGN < np.finfo(np.float32).max:",
                "ASSIGN = ASSIGN.astype(np.float32)",
                "else:",
                "ASSIGN = ASSIGN.astype(np.float64)",
                "else:",
                "ASSIGN = ASSIGN.astype('category')",
                "ASSIGN = df.memory_usage().sum() path**2",
                "print('Memory usage after optimization is: {:.2f} MB'.format(ASSIGN))",
                "print('Decreased by {:.1f}%'.format(100 * (ASSIGN - ASSIGN) path))",
                "return df"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN=OrdinalEncoder()",
                "ASSIGN=KNN()",
                "def encode(data):",
                "'''function to encode non-null data and replace it in the original data'''",
                "ASSIGN = np.array(data.dropna())",
                "ASSIGN = nonulls.reshape(-1,1)",
                "ASSIGN = encoder.fit_transform(impute_reshape)",
                "data.loc[data.notnull()] = np.squeeze(ASSIGN)",
                "return data"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=OrdinalEncoder()",
                "ASSIGN=KNN()",
                "def encode(data):",
                "'''function to encode non-null data and replace it in the original data'''",
                "ASSIGN = np.array(data.dropna())",
                "ASSIGN = nonulls.reshape(-1,1)",
                "ASSIGN = encoder.fit_transform(impute_reshape)",
                "data.loc[data.notnull()] = np.squeeze(ASSIGN)",
                "return data"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN= pd.merge(Ktrain_transaction, Ktrain_identity, on='TransactionID', how='left', left_index=True, right_index=True)",
                "ASSIGN= pd.merge(Ktest_transaction, Ktest_identity, on='TransactionID', how='left', left_index=True, right_index=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN= pd.merge(Ktrain_transaction, Ktrain_identity, on='TransactionID', how='left', left_index=True, right_index=True)",
                "ASSIGN= pd.merge(Ktest_transaction, Ktest_identity, on='TransactionID', how='left', left_index=True, right_index=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=Ktrain.select_dtypes(include='object')",
                "ASSIGN =Ktest.select_dtypes(include='object')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=Ktrain.select_dtypes(include='object')",
                "ASSIGN =Ktest.select_dtypes(include='object')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "Ktrain_cat1=Ktrain_cat.drop(['P_emaildomain','R_emaildomain','id_30','id_31','id_33','DeviceInfo'], axis=1)",
                "Ktest_cat1=Ktest_cat.drop(['P_emaildomain','R_emaildomain','id-30','id-31','id-33','DeviceInfo'], axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "Ktrain_cat1=Ktrain_cat.drop(['P_emaildomain','R_emaildomain','id_30','id_31','id_33','DeviceInfo'], axis=1)",
                "Ktest_cat1=Ktest_cat.drop(['P_emaildomain','R_emaildomain','id-30','id-31','id-33','DeviceInfo'], axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for i in Ktrain_cat1:",
                "encode(Ktrain[i])",
                "for i in Ktest_cat1:",
                "encode(Ktest[i])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for i in Ktrain_cat1:",
                "encode(Ktrain[i])",
                "for i in Ktest_cat1:",
                "encode(Ktest[i])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "Ktrain_cat2=pd.concat([Ktrain['P_emaildomain'],Ktrain['R_emaildomain'],Ktrain['id_30'],Ktrain['id_31'],Ktrain['id_33'],Ktrain['DeviceInfo']], axis=1)",
                "Ktest_cat2=pd.concat([Ktest['P_emaildomain'],Ktest['R_emaildomain'],Ktest['id-30'],Ktest['id-31'],Ktest['id-33'],Ktest['DeviceInfo']], axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "Ktrain_cat2=pd.concat([Ktrain['P_emaildomain'],Ktrain['R_emaildomain'],Ktrain['id_30'],Ktrain['id_31'],Ktrain['id_33'],Ktrain['DeviceInfo']], axis=1)",
                "Ktest_cat2=pd.concat([Ktest['P_emaildomain'],Ktest['R_emaildomain'],Ktest['id-30'],Ktest['id-31'],Ktest['id-33'],Ktest['DeviceInfo']], axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for i in Ktrain_cat2:",
                "encode(Ktrain[i])",
                "for i in Ktest_cat2:",
                "encode(Ktest[i])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for i in Ktrain_cat2:",
                "encode(Ktrain[i])",
                "for i in Ktest_cat2:",
                "encode(Ktest[i])"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "del Ktest_identity",
                "del Ktest_transaction",
                "del Ktrain_identity",
                "del Ktrain_transaction",
                "del Ktrain_cat1",
                "del Ktest_cat1",
                "del Ktrain_cat2",
                "del Ktest_cat2",
                "gc.collect()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "del Ktest_identity",
                "del Ktest_transaction",
                "del Ktrain_identity",
                "del Ktrain_transaction",
                "del Ktrain_cat1",
                "del Ktest_cat1",
                "del Ktrain_cat2",
                "del Ktest_cat2",
                "gc.collect()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = reduce_mem_usage2(ASSIGN)",
                "ASSIGN = reduce_mem_usage2(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = reduce_mem_usage2(ASSIGN)",
                "ASSIGN = reduce_mem_usage2(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "Ktrain.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "Ktrain.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "Ktest.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "Ktest.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "Ktest.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Ktest.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN= Ktest.loc[:,'id-01':'id-38'].columns.str.replace('-','_')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN= Ktest.loc[:,'id-01':'id-38'].columns.str.replace('-','_')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=list(ASSIGN)",
                "z"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=list(ASSIGN)",
                "z"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for x,y in zip(Ktest.loc[:,'id-01':'id-38'].columns, z):",
                "SLICE=SLICE",
                "del Ktest[x]",
                "gc.collect()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "for x,y in zip(Ktest.loc[:,'id-01':'id-38'].columns, z):",
                "SLICE=SLICE",
                "del Ktest[x]",
                "gc.collect()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=Ktrain[\"isFraud\"]",
                "X=Ktrain.drop([\"isFraud\", \"TransactionID\"], axis=1).astype('float64')",
                "X= X.fillna(-999)",
                "ASSIGN = Ktest['TransactionID']",
                "ASSIGN = Ktest.drop(['TransactionID'], axis=1).astype('float64')",
                "ASSIGN = ASSIGN.fillna(-999)",
                "ASSIGN = ASSIGN[X.columns]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=Ktrain[\"isFraud\"]",
                "X=Ktrain.drop([\"isFraud\", \"TransactionID\"], axis=1).astype('float64')",
                "X= X.fillna(-999)",
                "ASSIGN = Ktest['TransactionID']",
                "ASSIGN = Ktest.drop(['TransactionID'], axis=1).astype('float64')",
                "ASSIGN = ASSIGN.fillna(-999)",
                "ASSIGN = ASSIGN[X.columns]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "'''",
                "ASSIGN=StandardScaler().fit_transform(X)",
                "ASSIGN=PCA().fit(X_fit)",
                "plt.plot(np.cumsum(ASSIGN.explained_variance_ratio_))",
                "plt.title('All columns included', color='gray')",
                "plt.xlabel(\"Number of Component\", color='green')",
                "plt.ylabel(\"Cumulative Variance Ratio\", color='green')",
                "plt.grid(color='gray', linestyle='-', linewidth=0.3)",
                "plt.show()",
                "ASSIGN=StandardScaler().fit_transform(X_Ktest)",
                "ASSIGN=PCA().fit(X_Ktest_fit)",
                "plt.plot(np.cumsum(ASSIGN.explained_variance_ratio_))",
                "plt.title('All columns included', color='gray')",
                "plt.xlabel(\"Number of Component\", color='green')",
                "plt.ylabel(\"Cumulative Variance Ratio\", color='green')",
                "plt.grid(color='gray', linestyle='-', linewidth=0.3)",
                "plt.show()",
                "'''"
            ],
            "output_type": "execute_result",
            "content_old": [
                "'''",
                "ASSIGN=StandardScaler().fit_transform(X)",
                "ASSIGN=PCA().fit(X_fit)",
                "plt.plot(np.cumsum(ASSIGN.explained_variance_ratio_))",
                "plt.title('All columns included', color='gray')",
                "plt.xlabel(\"Number of Component\", color='green')",
                "plt.ylabel(\"Cumulative Variance Ratio\", color='green')",
                "plt.grid(color='gray', linestyle='-', linewidth=0.3)",
                "plt.show()",
                "ASSIGN=StandardScaler().fit_transform(X_Ktest)",
                "ASSIGN=PCA().fit(X_Ktest_fit)",
                "plt.plot(np.cumsum(ASSIGN.explained_variance_ratio_))",
                "plt.title('All columns included', color='gray')",
                "plt.xlabel(\"Number of Component\", color='green')",
                "plt.ylabel(\"Cumulative Variance Ratio\", color='green')",
                "plt.grid(color='gray', linestyle='-', linewidth=0.3)",
                "plt.show()",
                "'''"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "\"\"\"",
                "ASSIGN = PCA(n_components=100).fit(X_fit)",
                "ASSIGN = X_pca.fit_transform(ASSIGN)",
                "ASSIGN.explained_variance_ratio_",
                "ASSIGN = PCA(n_components=100).fit(X_Ktest_fit)",
                "ASSIGN = X_Ktest_pca.fit_transform(ASSIGN)",
                "print(ASSIGN.explained_variance_ratio_.sum())",
                "print(ASSIGN.explained_variance_ratio_.sum())",
                "\"\"\""
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "\"\"\"",
                "ASSIGN = PCA(n_components=100).fit(X_fit)",
                "ASSIGN = X_pca.fit_transform(ASSIGN)",
                "ASSIGN.explained_variance_ratio_",
                "ASSIGN = PCA(n_components=100).fit(X_Ktest_fit)",
                "ASSIGN = X_Ktest_pca.fit_transform(ASSIGN)",
                "print(ASSIGN.explained_variance_ratio_.sum())",
                "print(ASSIGN.explained_variance_ratio_.sum())",
                "\"\"\""
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "'''",
                "ASSIGN=[]",
                "for i in range(1,101):",
                "ASSIGN.append(\"a\"+str(i))",
                "ASSIGN= pd.DataFrame(data=X_fit, columns= xlist)",
                "ASSIGN= pd.DataFrame(data=X_Ktest_fit, columns= xlist)",
                "ASSIGN.head()",
                "'''"
            ],
            "output_type": "execute_result",
            "content_old": [
                "'''",
                "ASSIGN=[]",
                "for i in range(1,101):",
                "ASSIGN.append(\"a\"+str(i))",
                "ASSIGN= pd.DataFrame(data=X_fit, columns= xlist)",
                "ASSIGN= pd.DataFrame(data=X_Ktest_fit, columns= xlist)",
                "ASSIGN.head()",
                "'''"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.25, random_state=42)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.25, random_state=42)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = reduce_mem_usage2(ASSIGN)",
                "ASSIGN = reduce_mem_usage2(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = reduce_mem_usage2(ASSIGN)",
                "ASSIGN = reduce_mem_usage2(ASSIGN)"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "gc.collect()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "gc.collect()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(Ktrain.shape)",
                "print(Ktest.shape)",
                "print(X.shape)",
                "print(X_Ktest.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(Ktrain.shape)",
                "print(Ktest.shape)",
                "print(X.shape)",
                "print(X_Ktest.shape)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "'''models = [LogisticRegression,",
                "KNeighborsClassifier,",
                "GaussianNB,",
                "SVC,",
                "DecisionTreeClassifier,",
                "RandomForestClassifier,",
                "GradientBoostingClassifier,",
                "LGBMClassifier,",
                "XGBClassifier",
                "]",
                "def compML (df, y, algorithm):",
                "ASSIGN=algorithm().fit(X_train, y_train)",
                "ASSIGN=model.predict(X_test)",
                "ASSIGN= accuracy_score(y_test, y_pred)",
                "ASSIGN= algorithm.__name__",
                "print(ASSIGN,,ASSIGN)",
                "for i in models:",
                "compML(X,\"isFraud\",i)",
                "'''"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "'''models = [LogisticRegression,",
                "KNeighborsClassifier,",
                "GaussianNB,",
                "SVC,",
                "DecisionTreeClassifier,",
                "RandomForestClassifier,",
                "GradientBoostingClassifier,",
                "LGBMClassifier,",
                "XGBClassifier",
                "]",
                "def compML (df, y, algorithm):",
                "ASSIGN=algorithm().fit(X_train, y_train)",
                "ASSIGN=model.predict(X_test)",
                "ASSIGN= accuracy_score(y_test, y_pred)",
                "ASSIGN= algorithm.__name__",
                "print(ASSIGN,,ASSIGN)",
                "for i in models:",
                "compML(X,\"isFraud\",i)",
                "'''"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN= LGBMClassifier().fit(X_train, y_train)",
                "ASSIGN=model.predict(X_test)",
                "accuracy_score(y_test,ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN= LGBMClassifier().fit(X_train, y_train)",
                "ASSIGN=model.predict(X_test)",
                "accuracy_score(y_test,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "model"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "model"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN=model.predict(X_Ktest)",
                "ASSIGN=pd.DataFrame({\"TransactionID\":Ktest_id, \"isFraud\":predictions})",
                "ASSIGN.to_csv('submission_model.csv', index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=model.predict(X_Ktest)",
                "ASSIGN=pd.DataFrame({\"TransactionID\":Ktest_id, \"isFraud\":predictions})",
                "ASSIGN.to_csv('submission_model.csv', index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\", index_col = 'Id')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\", index_col = 'Id')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "train"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = KNeighborsRegressor(38)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = KNeighborsRegressor(38)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = cross_val_score(knn, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = cross_val_score(knn, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "knn_score.mean()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "knn_score.mean()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = LassoCV(cv = 10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = LassoCV(cv = 10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = cross_val_score(lasso, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = cross_val_score(lasso, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "lasso_score.mean()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "lasso_score.mean()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = RidgeCV(cv = 10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = RidgeCV(cv = 10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = cross_val_score(ridge, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = cross_val_score(ridge, train.drop('median_house_value', axis = 1), train['median_house_value'], cv = 10, scoring = 'r2')"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ridge_score.mean()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ridge_score.mean()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = '..path'",
                "ASSIGN = pd.read_csv(iowa_file_path)",
                "ASSIGN = home_data.SalePrice",
                "ASSIGN = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']",
                "ASSIGN = home_data[features]",
                "train_X, val_X, train_y, val_y = train_test_split(ASSIGN, ASSIGN, random_state=1)",
                "ASSIGN = DecisionTreeRegressor(random_state=1)",
                "ASSIGN.fit(train_X, train_y)",
                "ASSIGN = iowa_model.predict(val_X)",
                "ASSIGN = mean_absolute_error(val_predictions, val_y)",
                "print(.format(ASSIGN))",
                "binder.bind(globals())",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = '..path'",
                "ASSIGN = pd.read_csv(iowa_file_path)",
                "ASSIGN = home_data.SalePrice",
                "ASSIGN = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']",
                "ASSIGN = home_data[features]",
                "train_X, val_X, train_y, val_y = train_test_split(ASSIGN, ASSIGN, random_state=1)",
                "ASSIGN = DecisionTreeRegressor(random_state=1)",
                "ASSIGN.fit(train_X, train_y)",
                "ASSIGN = iowa_model.predict(val_X)",
                "ASSIGN = mean_absolute_error(val_predictions, val_y)",
                "print(.format(ASSIGN))",
                "binder.bind(globals())",
                "print()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):",
                "ASSIGN = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)",
                "ASSIGN.fit(train_X, train_y)",
                "ASSIGN = model.predict(val_X)",
                "ASSIGN = mean_absolute_error(val_y, preds_val)",
                "return(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):",
                "ASSIGN = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)",
                "ASSIGN.fit(train_X, train_y)",
                "ASSIGN = model.predict(val_X)",
                "ASSIGN = mean_absolute_error(val_y, preds_val)",
                "return(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\", index_col = 'Id')",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\", index_col = 'Id')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "plt.figure(figsize=(15,10))",
                "(train[train['ham'] == True].mean() - train[train['ham'] == False].mean())[train.columns[:54]].plot(kind = 'bar')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.figure(figsize=(15,10))",
                "(train[train['ham'] == True].mean() - train[train['ham'] == False].mean())[train.columns[:54]].plot(kind = 'bar')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "(train[train['ham'] == True].mean() - train[train['ham'] == False].mean())[train.columns[54:57]].plot(kind = 'bar')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "(train[train['ham'] == True].mean() - train[train['ham'] == False].mean())[train.columns[54:57]].plot(kind = 'bar')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = train[train.columns[0:57]]",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train[train.columns[0:57]]",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = train['ham']",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train['ham']",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = GaussianNB()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = GaussianNB()"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = cross_val_score(NB, Xtrain,Ytrain, cv=10)",
                "scores"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = cross_val_score(NB, Xtrain,Ytrain, cv=10)",
                "scores"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path', index_col = 'Id')",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path', index_col = 'Id')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "NB.fit(Xtrain,Ytrain)",
                "ASSIGN = NB.predict(test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "NB.fit(Xtrain,Ytrain)",
                "ASSIGN = NB.predict(test)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(index = test.index)",
                "ASSIGN = Ytest",
                "ASSIGN.to_csv('submission.csv',index = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(index = test.index)",
                "ASSIGN = Ytest",
                "ASSIGN.to_csv('submission.csv',index = True)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(check_output([, ]).decode())"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(check_output([, ]).decode())"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df.drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin','Embarked'],axis='columns',inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin','Embarked'],axis='columns',inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df.drop('Survived',axis='columns')",
                "ASSIGN = df.Survived"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df.drop('Survived',axis='columns')",
                "ASSIGN = df.Survived"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "inputs.Sex = inputs.Sex.map({'male': 1, 'female': 2})"
            ],
            "output_type": "not_existent",
            "content_old": [
                "inputs.Sex = inputs.Sex.map({'male': 1, 'female': 2})"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "inputs.Age[:10]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "inputs.Age[:10]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "inputs.Age = inputs.Age.fillna(inputs.Age.mean())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "inputs.Age = inputs.Age.fillna(inputs.Age.mean())"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = LabelEncoder()",
                "ASSIGN = LabelEncoder()",
                "ASSIGN = LabelEncoder()",
                "ASSIGN=LabelEncoder()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = LabelEncoder()",
                "ASSIGN = LabelEncoder()",
                "ASSIGN = LabelEncoder()",
                "ASSIGN=LabelEncoder()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "inputs['Pclass_n'] = le_Pclass.fit_transform(inputs['Pclass'])",
                "inputs['Sex_n'] = le_Sex.fit_transform(inputs['Sex'])",
                "inputs['Age_n'] = le_Age.fit_transform(inputs['Age'])",
                "inputs['Fare_n'] = le_Fare.fit_transform(inputs['Fare'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "inputs['Pclass_n'] = le_Pclass.fit_transform(inputs['Pclass'])",
                "inputs['Sex_n'] = le_Sex.fit_transform(inputs['Sex'])",
                "inputs['Age_n'] = le_Age.fit_transform(inputs['Age'])",
                "inputs['Fare_n'] = le_Fare.fit_transform(inputs['Fare'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "inputs"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "inputs"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = inputs.drop(['Age','Sex','Fare','Pclass'],axis='columns')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = inputs.drop(['Age','Sex','Fare','Pclass'],axis='columns')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "inputs_n"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "inputs_n"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = tree.DecisionTreeClassifier()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = tree.DecisionTreeClassifier()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "model.fit(inputs_n,target)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.fit(inputs_n,target)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "model.score(inputs_n,target)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.score(inputs_n,target)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "model.predict([[0,30,2,80]])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.predict([[0,30,2,80]])"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(os.listdir('..path'))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(os.listdir('..path'))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'bank.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'bank.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df1.head(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df1.head(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotCorrelationMatrix(df1, 8)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plotCorrelationMatrix(df1, 8)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotScatterMatrix(df1, 20, 10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plotScatterMatrix(df1, 20, 10)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=pd.read_csv(\"path\")",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN=pd.read_csv(\"path\")",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=pd.read_csv(\"path\")",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN=pd.read_csv(\"path\")",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=trd.loc[trd.YrSold<2008][trd.SaleCondition=='Normal']",
                "ASSIGN= len(w)path(trd)",
                "print(,ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=trd.loc[trd.YrSold<2008][trd.SaleCondition=='Normal']",
                "ASSIGN= len(w)path(trd)",
                "print(,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=trd.loc[trd.LotArea<10000][trd.SaleCondition=='Normal']",
                "ASSIGN= len(x)path(trd)",
                "print(,ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=trd.loc[trd.LotArea<10000][trd.SaleCondition=='Normal']",
                "ASSIGN= len(x)path(trd)",
                "print(,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=trd.loc[trd.MSSubClass>60]",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=trd.loc[trd.MSSubClass>60]",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "\"\"\"author    s_agnik1511\"\"\"",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = trd.SalePrice",
                "ASSIGN = ['LotArea']",
                "ASSIGN = trd[predictor_cols]",
                "ASSIGN = RandomForestRegressor()",
                "ASSIGN.fit(ASSIGN, ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "\"\"\"author    s_agnik1511\"\"\"",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = trd.SalePrice",
                "ASSIGN = ['LotArea']",
                "ASSIGN = trd[predictor_cols]",
                "ASSIGN = RandomForestRegressor()",
                "ASSIGN.fit(ASSIGN, ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "trd.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "trd.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Post Development Phase"
            ],
            "content": [
                "SETUP",
                "\"\"\"author s_agnik1511\"\"\"",
                "ASSIGN = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})",
                "ASSIGN.to_csv('submission_sagnik.csv', index=False)"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "\"\"\"author s_agnik1511\"\"\"",
                "ASSIGN = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})",
                "ASSIGN.to_csv('submission_sagnik.csv', index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "SETUP",
                "ASSIGN=pd.read_csv(\"path\")",
                "k.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "SETUP",
                "ASSIGN=pd.read_csv(\"path\")",
                "k.shape"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Evaluation Activity",
                "Post Development Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN=tsd.predict(\"path\")",
                "SLICE=ASSIGN",
                "Submission.to_csv(\"submission_sagnik123\",index=False)"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "ASSIGN=tsd.predict(\"path\")",
                "SLICE=ASSIGN",
                "Submission.to_csv(\"submission_sagnik123\",index=False)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "\"\"\"author s_agnik1511\"\"\"",
                "ASSIGN=pd.read_csv('path')",
                "ASSIGN=test[predictor_cols]",
                "ASSIGN=my_model.predict(test_X)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "\"\"\"author s_agnik1511\"\"\"",
                "ASSIGN=pd.read_csv('path')",
                "ASSIGN=test[predictor_cols]",
                "ASSIGN=my_model.predict(test_X)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=LinearRegression()",
                "ASSIGN=pd.read_csv(\"path\")",
                "ASSIGN.fit(ASSIGN)",
                "ASSIGN.predict(ASSIGN)"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "ASSIGN=LinearRegression()",
                "ASSIGN=pd.read_csv(\"path\")",
                "ASSIGN.fit(ASSIGN)",
                "ASSIGN.predict(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")",
                "print(, train.shape) #  rows : 1459 columns : 81",
                "print(, test.shape)  # rows : 1459 columns : 80"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")",
                "print(, train.shape) #  rows : 1459 columns : 81",
                "print(, test.shape)  # rows : 1459 columns : 80"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head(20)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head(20)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test.head(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.concat((train, test))",
                "ASSIGN = df",
                "print(, ASSIGN.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.concat((train, test))",
                "ASSIGN = df",
                "print(, ASSIGN.shape)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "temp_df.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "temp_df.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "temp_df.tail()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "temp_df.tail()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "pd.set_option(\"display.max_columns\",2000)  # used for viewing all the columns at onces",
                "pd.set_option(\"display.max_rows\",85)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "pd.set_option(\"display.max_columns\",2000)  # used for viewing all the columns at onces",
                "pd.set_option(\"display.max_rows\",85)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "df.info()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.describe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df.select_dtypes(include=['int64', 'float64']).columns"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.select_dtypes(include=['int64', 'float64']).columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df.select_dtypes(include=['object']).columns"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.select_dtypes(include=['object']).columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.set_index(\"Id\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.set_index(\"Id\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,9))",
                "sns.heatmap(df.isnull())"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(16,9))",
                "sns.heatmap(df.isnull())"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df.isnull().sum()path[0]*100",
                "null_percent"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df.isnull().sum()path[0]*100",
                "null_percent"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = null_percent[null_percent > 20].keys()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = null_percent[null_percent > 20].keys()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.drop(col_for_drop, \"columns\")",
                "df.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.drop(col_for_drop, \"columns\")",
                "df.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df.isnull().sum()path[0]*100",
                "null_percent"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df.isnull().sum()path[0]*100",
                "null_percent"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for i in df.columns:",
                "print(i +  + str(len(df[i].unique())))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for i in df.columns:",
                "print(i +  + str(len(df[i].unique())))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for i in df.columns:",
                "print(.format(i, len(df[i].unique()), df[i].unique()))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for i in df.columns:",
                "print(.format(i, len(df[i].unique()), df[i].unique()))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[\"SalePrice\"].describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train[\"SalePrice\"].describe()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,8))",
                "ASSIGN = sns.distplot(train[\"SalePrice\"])"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(10,8))",
                "ASSIGN = sns.distplot(train[\"SalePrice\"])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(25,25))",
                "ASSIGN = sns.heatmap(train.corr(), cmap = \"coolwarm\", annot=True, linewidth=2)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(25,25))",
                "ASSIGN = sns.heatmap(train.corr(), cmap = \"coolwarm\", annot=True, linewidth=2)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = train.corr()",
                "ASSIGN = hig_corr.index[abs(hig_corr[\"SalePrice\"]) >= 0.5]",
                "hig_corr_features"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = train.corr()",
                "ASSIGN = hig_corr.index[abs(hig_corr[\"SalePrice\"]) >= 0.5]",
                "hig_corr_features"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,8))",
                "ASSIGN = sns.distplot(train[\"LotFrontage\"])"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(10,8))",
                "ASSIGN = sns.distplot(train[\"LotFrontage\"])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,8))",
                "ASSIGN = sns.distplot(train[\"MSSubClass\"])"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(10,8))",
                "ASSIGN = sns.distplot(train[\"MSSubClass\"])"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = np.load(DSPATH+\"olivetti_faces.npy\")",
                "ASSIGN = np.load(DSPATH+\"olivetti_faces_target.npy\")",
                "ThiefImage={}",
                "SLICE= image.imread(\"..path\")",
                "SLICE=image.imread(\"..path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = np.load(DSPATH+\"olivetti_faces.npy\")",
                "ASSIGN = np.load(DSPATH+\"olivetti_faces_target.npy\")",
                "ThiefImage={}",
                "SLICE= image.imread(\"..path\")",
                "SLICE=image.imread(\"..path\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ClASSES=np.unique(y)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ClASSES=np.unique(y)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "StratifiedSplit = StratifiedShuffleSplit( test_size=0.4, random_state=0)",
                "StratifiedSplit.get_n_splits(X, y)",
                "for train_index, test_index in StratifiedSplit.split(X, y):",
                "X_train, X_test, y_train, y_test= X[train_index], X[test_index], y[train_index], y[test_index]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "StratifiedSplit = StratifiedShuffleSplit( test_size=0.4, random_state=0)",
                "StratifiedSplit.get_n_splits(X, y)",
                "for train_index, test_index in StratifiedSplit.split(X, y):",
                "X_train, X_test, y_train, y_test= X[train_index], X[test_index], y[train_index], y[test_index]"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = sns.countplot(y_train)"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = sns.countplot(y_train)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=[]",
                "for i in range(len(X_train)):",
                "ASSIGN.append(X_train[y_train==i].mean(axis = 0))"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN=[]",
                "for i in range(len(X_train)):",
                "ASSIGN.append(X_train[y_train==i].mean(axis = 0))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def ShowTrainingData(showNclasses=5):",
                "if showNclasses>=40:",
                "ASSIGN=ClASSES",
                "ASSIGN=2,4",
                "for i in range(ASSIGN+1):",
                "ASSIGN = plt.subplots(rows,cols )",
                "ASSIGN=0",
                "for face in X_train[y_train==i]:",
                "ASSIGN+=1",
                "ASSIGN==cols:",
                "ASSIGN=5",
                "ASSIGN=plt.subplot(rows,cols,j)",
                "ASSIGN.imshow(face ,'gray' )",
                "ASSIGN = plt.subplot(1,cols,cols)",
                "ASSIGN.imshow( class_mean[i], 'gray' )",
                "plt.xlabel(\"Class \"+str(i)+\" mean \" )",
                "fig.tight_layout(pad=1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def ShowTrainingData(showNclasses=5):",
                "if showNclasses>=40:",
                "ASSIGN=ClASSES",
                "ASSIGN=2,4",
                "for i in range(ASSIGN+1):",
                "ASSIGN = plt.subplots(rows,cols )",
                "ASSIGN=0",
                "for face in X_train[y_train==i]:",
                "ASSIGN+=1",
                "ASSIGN==cols:",
                "ASSIGN=5",
                "ASSIGN=plt.subplot(rows,cols,j)",
                "ASSIGN.imshow(face ,'gray' )",
                "ASSIGN = plt.subplot(1,cols,cols)",
                "ASSIGN.imshow( class_mean[i], 'gray' )",
                "plt.xlabel(\"Class \"+str(i)+\" mean \" )",
                "fig.tight_layout(pad=1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def ShowTrainingData2(showNclasses):",
                "if showNclasses>=40:",
                "ASSIGN=ClASSES",
                "ASSIGN=2,4",
                "for i in range(ASSIGN+1):",
                "ASSIGN = plt.figure(figsize=(8, 4))",
                "ASSIGN=0",
                "for face in X_train[y_train==i]:",
                "ASSIGN+=1",
                "ASSIGN==cols:",
                "ASSIGN=5",
                "ASSIGN.add_subplot(rows, cols, ASSIGN)",
                "plt.imshow(face, cmap = plt.get_cmap('gray'))",
                "plt.axis('off')",
                "ASSIGN.add_subplot(1,cols,cols)",
                "plt.imshow(class_mean[i], cmap = plt.get_cmap('gray'))",
                "plt.title(\"class_mean {}\".format(i), fontsize=16)",
                "plt.axis('off')",
                "plt.suptitle(\"There are 6 image for class {}\".format(i), fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def ShowTrainingData2(showNclasses):",
                "if showNclasses>=40:",
                "ASSIGN=ClASSES",
                "ASSIGN=2,4",
                "for i in range(ASSIGN+1):",
                "ASSIGN = plt.figure(figsize=(8, 4))",
                "ASSIGN=0",
                "for face in X_train[y_train==i]:",
                "ASSIGN+=1",
                "ASSIGN==cols:",
                "ASSIGN=5",
                "ASSIGN.add_subplot(rows, cols, ASSIGN)",
                "plt.imshow(face, cmap = plt.get_cmap('gray'))",
                "plt.axis('off')",
                "ASSIGN.add_subplot(1,cols,cols)",
                "plt.imshow(class_mean[i], cmap = plt.get_cmap('gray'))",
                "plt.title(\"class_mean {}\".format(i), fontsize=16)",
                "plt.axis('off')",
                "plt.suptitle(\"There are 6 image for class {}\".format(i), fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def ShowPredictions(predic_Model,ShowNPredictions=5):",
                "if ShowNPredictions>=len(y_predictions):",
                "ShowNPredictions=len(y_predictions)",
                "ASSIGN=1,3",
                "for index, row in y_predictions.iterrows():",
                "if (index>ShowNPredictions):",
                "break",
                "ASSIGN=int(row[\"ASSIGN\"])",
                "ASSIGN=int(row[\"ASSIGN\"])",
                "ASSIGN=int(row[predic_Model+\"_predic\"])",
                "IsTrue=str(row[predic_Model+\"_True\"])",
                "ASSIGN = plt.subplots(rows,cols )",
                "ASSIGN=1",
                "ASSIGN=plt.subplot(rows,cols,j)",
                "ASSIGN.imshow(X_test[ASSIGN] ,'gray' )",
                "plt.xlabel(\"Test Number :\"+str(ASSIGN) )",
                "ASSIGN=2",
                "ASSIGN=plt.subplot(rows,cols,j)",
                "ASSIGN.imshow(class_mean[ASSIGN] ,'gray' )",
                "plt.xlabel(\"Class \"+str(ASSIGN)+\" mean \" )",
                "ASSIGN=3",
                "ASSIGN=plt.subplot(rows,cols,j)",
                "ASSIGN.imshow(ThiefImage[IsTrue] ,'gray' )",
                "plt.xlabel(\"Class \"+str(ASSIGN)+\" mean \" )",
                "fig.tight_layout(pad=2.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def ShowPredictions(predic_Model,ShowNPredictions=5):",
                "if ShowNPredictions>=len(y_predictions):",
                "ShowNPredictions=len(y_predictions)",
                "ASSIGN=1,3",
                "for index, row in y_predictions.iterrows():",
                "if (index>ShowNPredictions):",
                "break",
                "ASSIGN=int(row[\"ASSIGN\"])",
                "ASSIGN=int(row[\"ASSIGN\"])",
                "ASSIGN=int(row[predic_Model+\"_predic\"])",
                "IsTrue=str(row[predic_Model+\"_True\"])",
                "ASSIGN = plt.subplots(rows,cols )",
                "ASSIGN=1",
                "ASSIGN=plt.subplot(rows,cols,j)",
                "ASSIGN.imshow(X_test[ASSIGN] ,'gray' )",
                "plt.xlabel(\"Test Number :\"+str(ASSIGN) )",
                "ASSIGN=2",
                "ASSIGN=plt.subplot(rows,cols,j)",
                "ASSIGN.imshow(class_mean[ASSIGN] ,'gray' )",
                "plt.xlabel(\"Class \"+str(ASSIGN)+\" mean \" )",
                "ASSIGN=3",
                "ASSIGN=plt.subplot(rows,cols,j)",
                "ASSIGN.imshow(ThiefImage[IsTrue] ,'gray' )",
                "plt.xlabel(\"Class \"+str(ASSIGN)+\" mean \" )",
                "fig.tight_layout(pad=2.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ShowTrainingData2(5)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ShowTrainingData2(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=np.array([(i,y_test[i],c,distance.euclidean(X_test[i].flatten() , class_mean[c].flatten() )) for c in ClASSES for i in range(len(X_test))])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=np.array([(i,y_test[i],c,distance.euclidean(X_test[i].flatten() , class_mean[c].flatten() )) for c in ClASSES for i in range(len(X_test))])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "distanceTable"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "distanceTable"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN.T"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=ASSIGN.T"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = {'x': distanceTable[0], 'actually':distanceTable[1],'KNN_predic':distanceTable[2],'distance':distanceTable[3]}",
                "ASSIGN= pd.DataFrame(data=d)",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = {'x': distanceTable[0], 'actually':distanceTable[1],'KNN_predic':distanceTable[2],'distance':distanceTable[3]}",
                "ASSIGN= pd.DataFrame(data=d)",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df[df.x==0]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df[df.x==0]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=pd.merge(df ,df.groupby([\"x\",\"actually\"]).distance.min(), how = 'inner', on=[\"x\",\"actually\",\"distance\"])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=pd.merge(df ,df.groupby([\"x\",\"actually\"]).distance.min(), how = 'inner', on=[\"x\",\"actually\",\"distance\"])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "y_predictions[\"KNN_True\"]=y_predictions[\"KNN_predic\"]==y_predictions[\"actually\"]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "y_predictions[\"KNN_True\"]=y_predictions[\"KNN_predic\"]==y_predictions[\"actually\"]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.nonzero(y_predictions[\"KNN_True\"].values==1)[0]",
                "ASSIGN = np.nonzero(y_predictions[\"KNN_True\"].values==0)[0]",
                "print(len(ASSIGN),)",
                "print(len(ASSIGN),)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.nonzero(y_predictions[\"KNN_True\"].values==1)[0]",
                "ASSIGN = np.nonzero(y_predictions[\"KNN_True\"].values==0)[0]",
                "print(len(ASSIGN),)",
                "print(len(ASSIGN),)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print()",
                "print()",
                "ShowPredictions(\"KNN\",5)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print()",
                "print()",
                "ShowPredictions(\"KNN\",5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "print(,ASSIGN.shape,,y_train.shape)",
                "print(, ASSIGN.shape,,y_test.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "print(,ASSIGN.shape,,y_train.shape)",
                "print(, ASSIGN.shape,,y_test.shape)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(filters = 20, kernel_size = (5,5),padding = 'Same',",
                "ASSIGN ='relu', input_shape = (64,64,1)))",
                "ASSIGN.add(MaxPool2D(pool_size=(2,2)))",
                "ASSIGN.add(Dropout(0.25))",
                "ASSIGN.add(Conv2D(filters = 50, kernel_size = (6,6),padding = 'Same',",
                "ASSIGN ='relu'))",
                "ASSIGN.add(MaxPool2D(pool_size=(2,2)))",
                "ASSIGN.add(Dropout(0.25))",
                "ASSIGN.add(Conv2D(filters = 150, kernel_size = (5,5),padding = 'Same',",
                "ASSIGN ='relu', input_shape = (64,64,1)))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(256, ASSIGN = \"relu\"))",
                "ASSIGN.add(Dropout(0.5))",
                "ASSIGN.add(Dense(40, ASSIGN = \"softmax\"))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(filters = 20, kernel_size = (5,5),padding = 'Same',",
                "ASSIGN ='relu', input_shape = (64,64,1)))",
                "ASSIGN.add(MaxPool2D(pool_size=(2,2)))",
                "ASSIGN.add(Dropout(0.25))",
                "ASSIGN.add(Conv2D(filters = 50, kernel_size = (6,6),padding = 'Same',",
                "ASSIGN ='relu'))",
                "ASSIGN.add(MaxPool2D(pool_size=(2,2)))",
                "ASSIGN.add(Dropout(0.25))",
                "ASSIGN.add(Conv2D(filters = 150, kernel_size = (5,5),padding = 'Same',",
                "ASSIGN ='relu', input_shape = (64,64,1)))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(256, ASSIGN = \"relu\"))",
                "ASSIGN.add(Dropout(0.5))",
                "ASSIGN.add(Dense(40, ASSIGN = \"softmax\"))"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = ReduceLROnPlateau(monitor='val_acc',",
                "ASSIGN=3,",
                "ASSIGN=1,",
                "ASSIGN=0.7,",
                "ASSIGN=0.00000000001)",
                "ASSIGN = EarlyStopping(patience=2)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ReduceLROnPlateau(monitor='val_acc',",
                "ASSIGN=3,",
                "ASSIGN=1,",
                "ASSIGN=0.7,",
                "ASSIGN=0.00000000001)",
                "ASSIGN = EarlyStopping(patience=2)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "model.summary()"
            ],
            "output_type": "stream",
            "content_old": [
                "model.summary()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Post Development Phase"
            ],
            "content": [
                "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)",
                "model.compile(ASSIGN = ASSIGN , loss='sparse_categorical_crossentropy',",
                "ASSIGN=['sparse_categorical_accuracy'])",
                "ASSIGN = 37",
                "ASSIGN = 20",
                "ASSIGN = ImageDataGenerator(",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=5,",
                "ASSIGN = 0.05,",
                "ASSIGN=0,",
                "ASSIGN=0,",
                "ASSIGN=False,",
                "ASSIGN=False)",
                "ASSIGN.fit(X_train)",
                "ASSIGN = model.fit_generator(",
                "ASSIGN.flow(X_train,y_train, ASSIGN=ASSIGN),",
                "ASSIGN = epoch,",
                "ASSIGN = (X_test,y_test),",
                "ASSIGN = 2,",
                "ASSIGN=X_train.shape[0] path,",
                "ASSIGN=[learning_rate_reduction]",
                ")"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)",
                "model.compile(ASSIGN = ASSIGN , loss='sparse_categorical_crossentropy',",
                "ASSIGN=['sparse_categorical_accuracy'])",
                "ASSIGN = 37",
                "ASSIGN = 20",
                "ASSIGN = ImageDataGenerator(",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=5,",
                "ASSIGN = 0.05,",
                "ASSIGN=0,",
                "ASSIGN=0,",
                "ASSIGN=False,",
                "ASSIGN=False)",
                "ASSIGN.fit(X_train)",
                "ASSIGN = model.fit_generator(",
                "ASSIGN.flow(X_train,y_train, ASSIGN=ASSIGN),",
                "ASSIGN = epoch,",
                "ASSIGN = (X_test,y_test),",
                "ASSIGN = 2,",
                "ASSIGN=X_train.shape[0] path,",
                "ASSIGN=[learning_rate_reduction]",
                ")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print(history.history.keys())",
                "plt.plot(history.history['sparse_categorical_accuracy'])",
                "plt.plot(history.history['val_sparse_categorical_accuracy'])",
                "plt.title('model accuracy')",
                "plt.ylabel('accuracy')",
                "plt.xlabel('epoch')",
                "plt.legend(['train', 'test'], loc='upper left')",
                "plt.show()",
                "plt.plot(history.history['loss'])",
                "plt.plot(history.history['val_loss'])",
                "plt.title('model loss')",
                "plt.ylabel('loss')",
                "plt.xlabel('epoch')",
                "plt.legend(['train', 'test'], loc='upper left')",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(history.history.keys())",
                "plt.plot(history.history['sparse_categorical_accuracy'])",
                "plt.plot(history.history['val_sparse_categorical_accuracy'])",
                "plt.title('model accuracy')",
                "plt.ylabel('accuracy')",
                "plt.xlabel('epoch')",
                "plt.legend(['train', 'test'], loc='upper left')",
                "plt.show()",
                "plt.plot(history.history['loss'])",
                "plt.plot(history.history['val_loss'])",
                "plt.title('model loss')",
                "plt.ylabel('loss')",
                "plt.xlabel('epoch')",
                "plt.legend(['train', 'test'], loc='upper left')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print()",
                "print()",
                "ASSIGN = model.evaluate(X_test,y_test,batch_size=32)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print()",
                "print()",
                "ASSIGN = model.evaluate(X_test,y_test,batch_size=32)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN=model.predict_classes(X_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=model.predict_classes(X_test)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.reshape(-1,64,64)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.reshape(-1,64,64)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "del y_predictions",
                "ASSIGN=np.array([(i,y_test[i],CNN_predic[i] ) for i in range(len(X_test))])",
                "ASSIGN=ASSIGN.T",
                "ASSIGN = {'x': distanceTable[0], 'actually':distanceTable[1],'CNN_predic':distanceTable[2] }",
                "ASSIGN= pd.DataFrame(data=d)",
                "ASSIGN.head()",
                "ASSIGN[\"CNN_True\"]=ASSIGN[\"CNN_predic\"]==ASSIGN[\"actually\"]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "del y_predictions",
                "ASSIGN=np.array([(i,y_test[i],CNN_predic[i] ) for i in range(len(X_test))])",
                "ASSIGN=ASSIGN.T",
                "ASSIGN = {'x': distanceTable[0], 'actually':distanceTable[1],'CNN_predic':distanceTable[2] }",
                "ASSIGN= pd.DataFrame(data=d)",
                "ASSIGN.head()",
                "ASSIGN[\"CNN_True\"]=ASSIGN[\"CNN_predic\"]==ASSIGN[\"actually\"]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "y_predictions.head(100)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "y_predictions.head(100)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.nonzero(y_predictions[\"CNN_True\"].values==1)[0]",
                "ASSIGN = np.nonzero(y_predictions[\"CNN_True\"].values==0)[0]",
                "print(len(ASSIGN),)",
                "print(len(ASSIGN),)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.nonzero(y_predictions[\"CNN_True\"].values==1)[0]",
                "ASSIGN = np.nonzero(y_predictions[\"CNN_True\"].values==0)[0]",
                "print(len(ASSIGN),)",
                "print(len(ASSIGN),)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ShowPredictions(\"CNN\")"
            ],
            "output_type": "display_data",
            "content_old": [
                "ShowPredictions(\"CNN\")"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def display_all(df):",
                "'''",
                "input: dataframe",
                "description: it takes a dataframe and allows use to show a mentioned no. of rows and columns in the screen",
                "'''",
                "with pd.option_context(\"display.max_rows\",10,\"display.max_columns\",9):  #you might want to change these numbers.",
                "display(df)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def display_all(df):",
                "'''",
                "input: dataframe",
                "description: it takes a dataframe and allows use to show a mentioned no. of rows and columns in the screen",
                "'''",
                "with pd.option_context(\"display.max_rows\",10,\"display.max_columns\",9):  #you might want to change these numbers.",
                "display(df)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=pd.read_csv('..path')",
                "df.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=pd.read_csv('..path')",
                "df.shape"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "display_all(df)"
            ],
            "output_type": "display_data",
            "content_old": [
                "display_all(df)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def missing_values_table(df):",
                "ASSIGN = df.isnull().sum()",
                "ASSIGN = 100 * df.isnull().sum() path(df)",
                "ASSIGN = pd.concat([mis_val, mis_val_percent], axis=1)",
                "ASSIGN = mis_val_table.rename(",
                "ASSIGN = {0 : 'Missing Values', 1 : '% of Total Values'})",
                "ASSIGN = ASSIGN[",
                "ASSIGN.iloc[:,1] != 0].sort_values(",
                "'% of Total Values', ascending=False).round(1)",
                "print (\"Your selected dataframe has \" + str(df.shape[1]) + \" ASSIGN.\\n\"",
                "\"There are \" + str(ASSIGN.shape[0]) +",
                "\" ASSIGN that have missing values.\")",
                "return mis_val_table_ren_columns"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def missing_values_table(df):",
                "ASSIGN = df.isnull().sum()",
                "ASSIGN = 100 * df.isnull().sum() path(df)",
                "ASSIGN = pd.concat([mis_val, mis_val_percent], axis=1)",
                "ASSIGN = mis_val_table.rename(",
                "ASSIGN = {0 : 'Missing Values', 1 : '% of Total Values'})",
                "ASSIGN = ASSIGN[",
                "ASSIGN.iloc[:,1] != 0].sort_values(",
                "'% of Total Values', ascending=False).round(1)",
                "print (\"Your selected dataframe has \" + str(df.shape[1]) + \" ASSIGN.\\n\"",
                "\"There are \" + str(ASSIGN.shape[0]) +",
                "\" ASSIGN that have missing values.\")",
                "return mis_val_table_ren_columns"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "missing_values_table(df)"
            ],
            "output_type": "stream",
            "content_old": [
                "missing_values_table(df)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=['BMI','SkinThickness','BloodPressure','Insulin','Glucose']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=['BMI','SkinThickness','BloodPressure','Insulin','Glucose']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for i in features_with_missing_values:",
                "SLICE=SLICE.replace(0,np.median(SLICE.values))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for i in features_with_missing_values:",
                "SLICE=SLICE.replace(0,np.median(SLICE.values))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=df['Outcome'].values",
                "df.drop(['Outcome'],inplace=True,axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=df['Outcome'].values",
                "df.drop(['Outcome'],inplace=True,axis=1)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=StandardScaler()",
                "ASSIGN=sta.fit_transform(df)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN=StandardScaler()",
                "ASSIGN=sta.fit_transform(df)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "X_train,X_test,y_train,y_test=train_test_split(input,target,test_size=0.1,random_state=0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "X_train,X_test,y_train,y_test=train_test_split(input,target,test_size=0.1,random_state=0)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN=KNeighborsClassifier(n_neighbors=7)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=KNeighborsClassifier(n_neighbors=7)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "knn.fit(X_train,y_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "knn.fit(X_train,y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "knn.score(X_test,y_test)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "knn.score(X_test,y_test)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "sns.set_style(\"darkgrid\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "sns.set_style(\"darkgrid\")"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(12,8))",
                "sns.heatmap(jobs.isnull(), cmap=\"coolwarm\", yticklabels=False, cbar=False)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(12,8))",
                "sns.heatmap(jobs.isnull(), cmap=\"coolwarm\", yticklabels=False, cbar=False)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "jobs.drop(columns=[\"department\", \"salary_range\", \"benefits\"], inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "jobs.drop(columns=[\"department\", \"salary_range\", \"benefits\"], inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "jobs.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "jobs.info()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "jobs.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "jobs.describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "jobs.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "jobs.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = [\"company_profile\", \"description\", \"requirements\"]",
                "for col in ASSIGN:",
                "jobs.loc[(jobs[col].isnull()) & (jobs[\"fraudulent\"] == 0), col] = \"none\"",
                "jobs.loc[(jobs[col].isnull()) & (jobs[\"fraudulent\"] == 1), col] = \"missing\""
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = [\"company_profile\", \"description\", \"requirements\"]",
                "for col in ASSIGN:",
                "jobs.loc[(jobs[col].isnull()) & (jobs[\"fraudulent\"] == 0), col] = \"none\"",
                "jobs.loc[(jobs[col].isnull()) & (jobs[\"fraudulent\"] == 1), col] = \"missing\""
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for num,col in enumerate(feature_lst):",
                "jobs[str(num)] = jobs[col].apply(len)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for num,col in enumerate(feature_lst):",
                "jobs[str(num)] = jobs[col].apply(len)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.rename({\"0\": \"profile_length\", \"1\": \"description_length\", \"2\": \"requirements_length\"}, axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.rename({\"0\": \"profile_length\", \"1\": \"description_length\", \"2\": \"requirements_length\"}, axis=1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "jobs.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "jobs.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "jobs[\"fraudulent\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "jobs[\"fraudulent\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.pairplot(data=jobs[[\"fraudulent\", \"profile_length\", \"description_length\", \"requirements_length\"]],",
                "ASSIGN=\"fraudulent\", height=2, aspect=2);"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.pairplot(data=jobs[[\"fraudulent\", \"profile_length\", \"description_length\", \"requirements_length\"]],",
                "ASSIGN=\"fraudulent\", height=2, aspect=2);"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = sns.FacetGrid(jobs, col=\"fraudulent\", aspect=1.5, height=4, sharey=False)",
                "ASSIGN = ASSIGN.map(plt.hist, \"profile_length\", bins=40)",
                "ASSIGN = profile_grid.ASSIGN.flatten()",
                "ASSIGN[0].set_title(\"Non-Fraudulent (0)\", fontsize=14)",
                "ASSIGN[1].set_title(\"Fraudulent (1)\", fontsize=14)",
                "ASSIGN[0].set_ylabel(\"Count\", fontsize=14)",
                "for ax in ASSIGN:",
                "ax.set_xlabel(\"Profile Text Length\", fontsize=14)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = sns.FacetGrid(jobs, col=\"fraudulent\", aspect=1.5, height=4, sharey=False)",
                "ASSIGN = ASSIGN.map(plt.hist, \"profile_length\", bins=40)",
                "ASSIGN = profile_grid.ASSIGN.flatten()",
                "ASSIGN[0].set_title(\"Non-Fraudulent (0)\", fontsize=14)",
                "ASSIGN[1].set_title(\"Fraudulent (1)\", fontsize=14)",
                "ASSIGN[0].set_ylabel(\"Count\", fontsize=14)",
                "for ax in ASSIGN:",
                "ax.set_xlabel(\"Profile Text Length\", fontsize=14)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = sns.FacetGrid(jobs, col=\"fraudulent\", aspect=1.5, height=4, sharey=False)",
                "ASSIGN = ASSIGN.map(plt.hist, \"description_length\", bins=40)",
                "ASSIGN = description_grid.ASSIGN.flatten()",
                "ASSIGN[0].set_title(\"Non-Fraudulent (0)\", fontsize=14)",
                "ASSIGN[1].set_title(\"Fraudulent (1)\", fontsize=14)",
                "ASSIGN[0].set_ylabel(\"Count\", fontsize=14)",
                "for ax in ASSIGN:",
                "ax.set_xlabel(\"Description Text Length\", fontsize=14)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = sns.FacetGrid(jobs, col=\"fraudulent\", aspect=1.5, height=4, sharey=False)",
                "ASSIGN = ASSIGN.map(plt.hist, \"description_length\", bins=40)",
                "ASSIGN = description_grid.ASSIGN.flatten()",
                "ASSIGN[0].set_title(\"Non-Fraudulent (0)\", fontsize=14)",
                "ASSIGN[1].set_title(\"Fraudulent (1)\", fontsize=14)",
                "ASSIGN[0].set_ylabel(\"Count\", fontsize=14)",
                "for ax in ASSIGN:",
                "ax.set_xlabel(\"Description Text Length\", fontsize=14)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = sns.FacetGrid(jobs, col=\"fraudulent\", aspect=1.5, height=4, sharey=False)",
                "ASSIGN = ASSIGN.map(plt.hist, \"requirements_length\", bins=40)",
                "ASSIGN = requirements_grid.ASSIGN.flatten()",
                "ASSIGN[0].set_title(\"Non Fraudulent (0)\", fontsize=14)",
                "ASSIGN[1].set_title(\"Fraudulent (1)\", fontsize=14)",
                "ASSIGN[0].set_ylabel(\"Count\", fontsize=14)",
                "for ax in ASSIGN:",
                "ax.set_xlabel(\"Requirements Text Length\", fontsize=14)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = sns.FacetGrid(jobs, col=\"fraudulent\", aspect=1.5, height=4, sharey=False)",
                "ASSIGN = ASSIGN.map(plt.hist, \"requirements_length\", bins=40)",
                "ASSIGN = requirements_grid.ASSIGN.flatten()",
                "ASSIGN[0].set_title(\"Non Fraudulent (0)\", fontsize=14)",
                "ASSIGN[1].set_title(\"Fraudulent (1)\", fontsize=14)",
                "ASSIGN[0].set_ylabel(\"Count\", fontsize=14)",
                "for ax in ASSIGN:",
                "ax.set_xlabel(\"Requirements Text Length\", fontsize=14)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.catplot(x=\"has_company_logo\", hue=\"fraudulent\", data=jobs, kind=\"count\", aspect=2, height=4);",
                "plt.xlabel(\"Company Logo\", fontsize=14)",
                "plt.xticks([0, 1], (\"Has\", \"Doesn't have\"), fontsize=12)",
                "plt.ylabel(\"Count\", fontsize=14);"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.catplot(x=\"has_company_logo\", hue=\"fraudulent\", data=jobs, kind=\"count\", aspect=2, height=4);",
                "plt.xlabel(\"Company Logo\", fontsize=14)",
                "plt.xticks([0, 1], (\"Has\", \"Doesn't have\"), fontsize=12)",
                "plt.ylabel(\"Count\", fontsize=14);"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(1, 2, figsize=(18,8))",
                "ASSIGN = sns.countplot(x=jobs[\"employment_type\"].dropna(), hue=jobs[\"fraudulent\"], palette=\"Set1\", ax=axes[0])",
                "axes[0].set_xlabel(\"Employment Type\", fontsize=15)",
                "axes[0].set_ylabel(\"Count\", fontsize=15)",
                "axes[0].set_title(\"Employment Type Count\", fontsize=15)",
                "axes[0].legend(\"\")",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.0f}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 12),",
                "ASSIGN='offset points')",
                "ASSIGN = sns.countplot(x=jobs[\"employment_type\"].dropna(), hue=jobs[\"fraudulent\"], palette=\"Set1\", ax=axes[1])",
                "axes[1].set_xlabel(\"Employment Type\", fontsize=15)",
                "axes[1].set_ylim((0, 1500))",
                "axes[1].set_ylabel(\"\")",
                "axes[1].set_title(\"Employment Type Count Zoom\", fontsize=15)",
                "axes[1].legend(title=\"Fraudulent\", title_fontsize=14, fontsize=12, bbox_to_anchor=(1.2, 0.6));"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.subplots(1, 2, figsize=(18,8))",
                "ASSIGN = sns.countplot(x=jobs[\"employment_type\"].dropna(), hue=jobs[\"fraudulent\"], palette=\"Set1\", ax=axes[0])",
                "axes[0].set_xlabel(\"Employment Type\", fontsize=15)",
                "axes[0].set_ylabel(\"Count\", fontsize=15)",
                "axes[0].set_title(\"Employment Type Count\", fontsize=15)",
                "axes[0].legend(\"\")",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.0f}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 12),",
                "ASSIGN='offset points')",
                "ASSIGN = sns.countplot(x=jobs[\"employment_type\"].dropna(), hue=jobs[\"fraudulent\"], palette=\"Set1\", ax=axes[1])",
                "axes[1].set_xlabel(\"Employment Type\", fontsize=15)",
                "axes[1].set_ylim((0, 1500))",
                "axes[1].set_ylabel(\"\")",
                "axes[1].set_title(\"Employment Type Count Zoom\", fontsize=15)",
                "axes[1].legend(title=\"Fraudulent\", title_fontsize=14, fontsize=12, bbox_to_anchor=(1.2, 0.6));"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "jobs.columns"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "jobs.columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = jobs[\"company_profile\"]",
                "ASSIGN = jobs[\"fraudulent\"]",
                "X1_profile_train, X1_profile_test, y1_train, y1_test = train_test_split(ASSIGN, ASSIGN, test_size=0.2, random_state=42)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = jobs[\"company_profile\"]",
                "ASSIGN = jobs[\"fraudulent\"]",
                "X1_profile_train, X1_profile_test, y1_train, y1_test = train_test_split(ASSIGN, ASSIGN, test_size=0.2, random_state=42)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def text_process(text):",
                "ASSIGN = [char for char in text if char not in string.punctuation]",
                "ASSIGN = \"\".join(ASSIGN)",
                "return [word for word in ASSIGN.split() if word.lower() not in stopwords.words(\"english\")]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def text_process(text):",
                "ASSIGN = [char for char in text if char not in string.punctuation]",
                "ASSIGN = \"\".join(ASSIGN)",
                "return [word for word in ASSIGN.split() if word.lower() not in stopwords.words(\"english\")]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([(\"bow no func\", CountVectorizer()),",
                "(\"NB_classifier\", MultinomialNB())])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Pipeline([(\"bow no func\", CountVectorizer()),",
                "(\"NB_classifier\", MultinomialNB())])"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "NB_pipeline.fit(X1_profile_train, y1_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "NB_pipeline.fit(X1_profile_train, y1_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = NB_pipeline.predict(X1_profile_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = NB_pipeline.predict(X1_profile_test)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(classification_report(y1_test, NB_pred))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(classification_report(y1_test, NB_pred))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(confusion_matrix(y1_test, NB_pred))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(confusion_matrix(y1_test, NB_pred))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([(\"bow with func\", CountVectorizer(analyzer=text_process)),",
                "(\"NB_classifier\", MultinomialNB())])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Pipeline([(\"bow with func\", CountVectorizer(analyzer=text_process)),",
                "(\"NB_classifier\", MultinomialNB())])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = jobs[\"company_profile\"]",
                "ASSIGN = jobs[\"fraudulent\"]",
                "X2_profile_train, X2_profile_test, y2_train, y2_test = train_test_split(ASSIGN, ASSIGN, test_size=0.2, random_state=42)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = jobs[\"company_profile\"]",
                "ASSIGN = jobs[\"fraudulent\"]",
                "X2_profile_train, X2_profile_test, y2_train, y2_test = train_test_split(ASSIGN, ASSIGN, test_size=0.2, random_state=42)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "NB_func_pipeline.fit(X2_profile_train, y2_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "NB_func_pipeline.fit(X2_profile_train, y2_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = NB_func_pipeline.predict(X2_profile_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = NB_func_pipeline.predict(X2_profile_test)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(classification_report(y2_test, NB_func_pred))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(classification_report(y2_test, NB_func_pred))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(confusion_matrix(y2_test, NB_func_pred))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(confusion_matrix(y2_test, NB_func_pred))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([(\"bow no func\", CountVectorizer()),",
                "(\"tfidf\", TfidfTransformer()),",
                "(\"NB_classifier\", MultinomialNB())])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Pipeline([(\"bow no func\", CountVectorizer()),",
                "(\"tfidf\", TfidfTransformer()),",
                "(\"NB_classifier\", MultinomialNB())])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = jobs[\"company_profile\"]",
                "ASSIGN = jobs[\"fraudulent\"]",
                "X3_profile_train, X3_profile_test, y3_train, y3_test = train_test_split(ASSIGN, ASSIGN, test_size=0.2, random_state=42)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = jobs[\"company_profile\"]",
                "ASSIGN = jobs[\"fraudulent\"]",
                "X3_profile_train, X3_profile_test, y3_train, y3_test = train_test_split(ASSIGN, ASSIGN, test_size=0.2, random_state=42)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "NB_tfidf_pipeline.fit(X3_profile_train, y3_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "NB_tfidf_pipeline.fit(X3_profile_train, y3_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = NB_tfidf_pipeline.predict(X3_profile_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = NB_tfidf_pipeline.predict(X3_profile_test)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(classification_report(y3_test, NB_tfidf_pred))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(classification_report(y3_test, NB_tfidf_pred))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(confusion_matrix(y3_test, NB_tfidf_pred))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(confusion_matrix(y3_test, NB_tfidf_pred))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([(\"bow with func\", CountVectorizer(analyzer=text_process)),",
                "(\"tfidf\", TfidfTransformer()),",
                "(\"NB_classifier\", MultinomialNB())])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Pipeline([(\"bow with func\", CountVectorizer(analyzer=text_process)),",
                "(\"tfidf\", TfidfTransformer()),",
                "(\"NB_classifier\", MultinomialNB())])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = jobs[\"company_profile\"]",
                "ASSIGN = jobs[\"fraudulent\"]",
                "X4_profile_train, X4_profile_test, y4_train, y4_test = train_test_split(ASSIGN, ASSIGN, test_size=0.2, random_state=42)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = jobs[\"company_profile\"]",
                "ASSIGN = jobs[\"fraudulent\"]",
                "X4_profile_train, X4_profile_test, y4_train, y4_test = train_test_split(ASSIGN, ASSIGN, test_size=0.2, random_state=42)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "NB_func_tfidf_pipeline.fit(X4_profile_train, y4_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "NB_func_tfidf_pipeline.fit(X4_profile_train, y4_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = NB_func_tfidf_pipeline.predict(X4_profile_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = NB_func_tfidf_pipeline.predict(X4_profile_test)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(classification_report(y4_test, NB_func_tfidf_pred))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(classification_report(y4_test, NB_func_tfidf_pred))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(confusion_matrix(y4_test, NB_func_tfidf_pred))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(confusion_matrix(y4_test, NB_func_tfidf_pred))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "sns.set_style(\"whitegrid\")",
                "plt.style.use(\"fivethirtyeight\")",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))",
                "warnings.filterwarnings('ignore')"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "sns.set_style(\"whitegrid\")",
                "plt.style.use(\"fivethirtyeight\")",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"path\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df.columns"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df.columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df.drop(['RISK_MM'],axis=1,inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.drop(['RISK_MM'],axis=1,inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "df.info()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['Evaporation','Sunshine','Cloud9am','Cloud3pm','Date','Location']",
                "df.drop(columns=ASSIGN,inplace=True,axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['Evaporation','Sunshine','Cloud9am','Cloud3pm','Date','Location']",
                "df.drop(columns=ASSIGN,inplace=True,axis=1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "df.info()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.describe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df.describe(include='object')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.describe(include='object')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.describe(include='all')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.describe(include='all')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.isna().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.isna().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.skew()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.skew()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = [col for col in df.columns if df[col].dtype==\"float64\"]",
                "for col in ASSIGN:",
                "df[col].fillna(df[col].median(),inplace=True)",
                "ASSIGN = [col for col in df.columns if df[col].dtype==\"O\"]",
                "for col in ASSIGN:",
                "df[col].fillna(df[col].mode()[0],inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = [col for col in df.columns if df[col].dtype==\"float64\"]",
                "for col in ASSIGN:",
                "df[col].fillna(df[col].median(),inplace=True)",
                "ASSIGN = [col for col in df.columns if df[col].dtype==\"O\"]",
                "for col in ASSIGN:",
                "df[col].fillna(df[col].mode()[0],inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.isna().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.isna().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.corr().style.background_gradient(cmap=\"Reds\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.corr().style.background_gradient(cmap=\"Reds\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = plt.figure(figsize=(12,12))",
                "sns.heatmap(ASSIGN,annot=True,fmt=\".1f\",linewidths=\"0.1\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = plt.figure(figsize=(12,12))",
                "sns.heatmap(ASSIGN,annot=True,fmt=\".1f\",linewidths=\"0.1\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(.format(num))",
                "print(.format(len(num)))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(.format(num))",
                "print(.format(len(num)))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,15))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN=1",
                "ASSIGN = ['Red','Blue','Green','Cyan',",
                "'Red','Blue','Green','Cyan',",
                "'Red','Blue','Green','Cyan']",
                "ASSIGN=0",
                "for col in num:",
                "plt.subplot(3,4,ASSIGN)",
                "ASSIGN = sns.distplot(df[col],color=colors[j])",
                "ASSIGN+=1",
                "ASSIGN+=1"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,15))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN=1",
                "ASSIGN = ['Red','Blue','Green','Cyan',",
                "'Red','Blue','Green','Cyan',",
                "'Red','Blue','Green','Cyan']",
                "ASSIGN=0",
                "for col in num:",
                "plt.subplot(3,4,ASSIGN)",
                "ASSIGN = sns.distplot(df[col],color=colors[j])",
                "ASSIGN+=1",
                "ASSIGN+=1"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,30))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN=1",
                "for col in num:",
                "plt.subplot(6,2,ASSIGN)",
                "ASSIGN = sns.boxplot(data=df,x=\"RainTomorrow\",y=col)",
                "ASSIGN+=1"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,30))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN=1",
                "for col in num:",
                "plt.subplot(6,2,ASSIGN)",
                "ASSIGN = sns.boxplot(data=df,x=\"RainTomorrow\",y=col)",
                "ASSIGN+=1"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = ['Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm']",
                "for col in ASSIGN:",
                "Lower_Bound = df[col].quantile(0.25) - (IQR*3)",
                "Upper_Bound = df[col].quantile(0.75) + (IQR*3)",
                "print(.format(col,Lower_Bound,Upper_Bound))",
                "ASSIGN = df[col].min()",
                "ASSIGN = df[col].max()",
                "print(.format(col,ASSIGN,ASSIGN))",
                "if ASSIGN>Upper_Bound:",
                "print(.format(col,Upper_Bound))",
                "elif ASSIGN<Lower_Bound:",
                "print(.format(col,Lower_Bound))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = ['Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm']",
                "for col in ASSIGN:",
                "Lower_Bound = df[col].quantile(0.25) - (IQR*3)",
                "Upper_Bound = df[col].quantile(0.75) + (IQR*3)",
                "print(.format(col,Lower_Bound,Upper_Bound))",
                "ASSIGN = df[col].min()",
                "ASSIGN = df[col].max()",
                "print(.format(col,ASSIGN,ASSIGN))",
                "if ASSIGN>Upper_Bound:",
                "print(.format(col,Upper_Bound))",
                "elif ASSIGN<Lower_Bound:",
                "print(.format(col,Lower_Bound))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,30))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN=1",
                "for col in num:",
                "plt.subplot(6,2,ASSIGN)",
                "ASSIGN = sns.barplot(data=df,x=\"RainTomorrow\",y=col)",
                "ASSIGN+=1"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,30))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN=1",
                "for col in num:",
                "plt.subplot(6,2,ASSIGN)",
                "ASSIGN = sns.barplot(data=df,x=\"RainTomorrow\",y=col)",
                "ASSIGN+=1"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,5))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN=1",
                "ASSIGN = [\"MaxTemp\",\"Temp9am\",\"Temp3pm\"]",
                "for feature in ASSIGN:",
                "plt.subplot(1,3,ASSIGN)",
                "sns.scatterplot(data=df,x=\"MinTemp\",y=feature,hue=\"RainTomorrow\")",
                "ASSIGN+=1"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,5))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN=1",
                "ASSIGN = [\"MaxTemp\",\"Temp9am\",\"Temp3pm\"]",
                "for feature in ASSIGN:",
                "plt.subplot(1,3,ASSIGN)",
                "sns.scatterplot(data=df,x=\"MinTemp\",y=feature,hue=\"RainTomorrow\")",
                "ASSIGN+=1"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,8))",
                "plt.subplots_adjust(hspace=0.5)",
                "plt.subplot(3,2,1)",
                "sns.scatterplot(data=df,x=\"WindSpeed9am\",y=\"WindGustSpeed\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,2)",
                "sns.scatterplot(data=df,x=\"WindSpeed3pm\",y=\"WindGustSpeed\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,3)",
                "sns.scatterplot(data=df,x=\"Humidity9am\",y=\"Humidity3pm\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,4)",
                "sns.scatterplot(data=df,x=\"Temp9am\",y=\"Temp3pm\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,5)",
                "sns.scatterplot(data=df,x=\"MaxTemp\",y=\"Temp9am\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,6)",
                "sns.scatterplot(data=df,x=\"Humidity3pm\",y=\"Temp3pm\",hue=\"RainTomorrow\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(15,8))",
                "plt.subplots_adjust(hspace=0.5)",
                "plt.subplot(3,2,1)",
                "sns.scatterplot(data=df,x=\"WindSpeed9am\",y=\"WindGustSpeed\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,2)",
                "sns.scatterplot(data=df,x=\"WindSpeed3pm\",y=\"WindGustSpeed\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,3)",
                "sns.scatterplot(data=df,x=\"Humidity9am\",y=\"Humidity3pm\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,4)",
                "sns.scatterplot(data=df,x=\"Temp9am\",y=\"Temp3pm\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,5)",
                "sns.scatterplot(data=df,x=\"MaxTemp\",y=\"Temp9am\",hue=\"RainTomorrow\")",
                "plt.subplot(3,2,6)",
                "sns.scatterplot(data=df,x=\"Humidity3pm\",y=\"Temp3pm\",hue=\"RainTomorrow\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "cat"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "cat"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['WindGustDir'].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df['WindGustDir'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.figure(figsize=(15,5))",
                "sns.countplot(data=df,x=\"WindGustDir\",hue=\"RainTomorrow\");"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.figure(figsize=(15,5))",
                "sns.countplot(data=df,x=\"WindGustDir\",hue=\"RainTomorrow\");"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['WindDir9am'].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df['WindDir9am'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.figure(figsize=(15,5))",
                "sns.countplot(data=df,x=\"WindDir9am\",hue=\"RainTomorrow\");"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.figure(figsize=(15,5))",
                "sns.countplot(data=df,x=\"WindDir9am\",hue=\"RainTomorrow\");"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['WindDir3pm'].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df['WindDir3pm'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.figure(figsize=(15,5))",
                "sns.countplot(data=df,x=\"WindDir3pm\",hue=\"RainTomorrow\");"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.figure(figsize=(15,5))",
                "sns.countplot(data=df,x=\"WindDir3pm\",hue=\"RainTomorrow\");"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['RainTomorrow'].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df['RainTomorrow'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(data=df,x=\"RainTomorrow\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(data=df,x=\"RainTomorrow\")"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=df[['RainTomorrow']]",
                "X=df.drop(['RainTomorrow'],axis=1)",
                "X_train,X_test,y_train,y_test = tts(X,ASSIGN,test_size=0.3,random_state=0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN=df[['RainTomorrow']]",
                "X=df.drop(['RainTomorrow'],axis=1)",
                "X_train,X_test,y_train,y_test = tts(X,ASSIGN,test_size=0.3,random_state=0)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_train"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X_train"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_test"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X_test"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,30))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN = ['Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm']",
                "ASSIGN=1",
                "for col in ASSIGN:",
                "plt.subplot(6,2,ASSIGN)",
                "ASSIGN = df[col].hist(bins=10)",
                "ASSIGN.set_xlabel(col)",
                "ASSIGN.set_ylabel('RainTomorrow')",
                "ASSIGN+=1"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,30))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN = ['Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm']",
                "ASSIGN=1",
                "for col in ASSIGN:",
                "plt.subplot(6,2,ASSIGN)",
                "ASSIGN = df[col].hist(bins=10)",
                "ASSIGN.set_xlabel(col)",
                "ASSIGN.set_ylabel('RainTomorrow')",
                "ASSIGN+=1"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def remove_outliers(df,col,Lower_Bound,Upper_Bound):",
                "ASSIGN = df[col].min()",
                "ASSIGN = df[col].max()",
                "if ASSIGN>Upper_Bound:",
                "return np.where(df[col]>Upper_Bound,Upper_Bound,df[col])",
                "elif ASSIGN<Lower_Bound:",
                "return np.where(df[col]<Lower_Bound,Lower_Bound,df[col])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def remove_outliers(df,col,Lower_Bound,Upper_Bound):",
                "ASSIGN = df[col].min()",
                "ASSIGN = df[col].max()",
                "if ASSIGN>Upper_Bound:",
                "return np.where(df[col]>Upper_Bound,Upper_Bound,df[col])",
                "elif ASSIGN<Lower_Bound:",
                "return np.where(df[col]<Lower_Bound,Lower_Bound,df[col])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for df1 in [X_train,X_test]:",
                "df1['Rainfall'] = remove_outliers(df1,'Rainfall',-1.799,2.4)",
                "df1['WindGustSpeed'] = remove_outliers(df1,'WindGustSpeed',-14.0,91.0)",
                "df1['WindSpeed9am'] = remove_outliers(df1,'WindSpeed9am',-29.0,55.0)",
                "df1['WindSpeed3pm'] = remove_outliers(df1,'WindSpeed3pm',-20.0,57.0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for df1 in [X_train,X_test]:",
                "df1['Rainfall'] = remove_outliers(df1,'Rainfall',-1.799,2.4)",
                "df1['WindGustSpeed'] = remove_outliers(df1,'WindGustSpeed',-14.0,91.0)",
                "df1['WindSpeed9am'] = remove_outliers(df1,'WindSpeed9am',-29.0,55.0)",
                "df1['WindSpeed3pm'] = remove_outliers(df1,'WindSpeed3pm',-20.0,57.0)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,30))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN = ['Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm']",
                "ASSIGN=1",
                "for col in ASSIGN:",
                "plt.subplot(6,2,ASSIGN)",
                "ASSIGN = sns.boxplot(data=X_train,y=col)",
                "ASSIGN.set_xlabel(col)",
                "ASSIGN.set_ylabel('RainTomorrow')",
                "ASSIGN+=1"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(15,30))",
                "plt.subplots_adjust(hspace=0.5)",
                "ASSIGN = ['Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm']",
                "ASSIGN=1",
                "for col in ASSIGN:",
                "plt.subplot(6,2,ASSIGN)",
                "ASSIGN = sns.boxplot(data=X_train,y=col)",
                "ASSIGN.set_xlabel(col)",
                "ASSIGN.set_ylabel('RainTomorrow')",
                "ASSIGN+=1"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "X_train[features_to_examine].describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "X_train[features_to_examine].describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "X_test[features_to_examine].describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "X_test[features_to_examine].describe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for df2 in [y_train,y_test]:",
                "df2['RainTomorrow'] = df2['RainTomorrow'].replace({\"Yes\":1,",
                "\"No\":0})"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for df2 in [y_train,y_test]:",
                "df2['RainTomorrow'] = df2['RainTomorrow'].replace({\"Yes\":1,",
                "\"No\":0})"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = ce.BinaryEncoder(cols=['RainToday'])",
                "ASSIGN = encoder.fit_transform(ASSIGN)",
                "ASSIGN = encoder.transform(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = ce.BinaryEncoder(cols=['RainToday'])",
                "ASSIGN = encoder.fit_transform(ASSIGN)",
                "ASSIGN = encoder.transform(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.concat([ASSIGN[num],ASSIGN[['RainToday_0','RainToday_1']],",
                "pd.get_dummies(ASSIGN['WindGustDir']),",
                "pd.get_dummies(ASSIGN['WindDir9am']),",
                "pd.get_dummies(ASSIGN['WindDir3pm'])],axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.concat([ASSIGN[num],ASSIGN[['RainToday_0','RainToday_1']],",
                "pd.get_dummies(ASSIGN['WindGustDir']),",
                "pd.get_dummies(ASSIGN['WindDir9am']),",
                "pd.get_dummies(ASSIGN['WindDir3pm'])],axis=1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "X_train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "X_train.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.concat([ASSIGN[num],ASSIGN[['RainToday_0','RainToday_1']],",
                "pd.get_dummies(ASSIGN['WindGustDir']),",
                "pd.get_dummies(ASSIGN['WindDir9am']),",
                "pd.get_dummies(ASSIGN['WindDir3pm'])],axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.concat([ASSIGN[num],ASSIGN[['RainToday_0','RainToday_1']],",
                "pd.get_dummies(ASSIGN['WindGustDir']),",
                "pd.get_dummies(ASSIGN['WindDir9am']),",
                "pd.get_dummies(ASSIGN['WindDir3pm'])],axis=1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "X_test.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "X_test.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = X_train.columns",
                "ASSIGN = MinMaxScaler()",
                "ASSIGN = scaler.fit_transform(ASSIGN)",
                "ASSIGN = scaler.transform(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = X_train.columns",
                "ASSIGN = MinMaxScaler()",
                "ASSIGN = scaler.fit_transform(ASSIGN)",
                "ASSIGN = scaler.transform(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(ASSIGN,columns=cols)",
                "ASSIGN = pd.DataFrame(ASSIGN,columns=cols)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(ASSIGN,columns=cols)",
                "ASSIGN = pd.DataFrame(ASSIGN,columns=cols)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = LogisticRegression(solver='liblinear', random_state=0)",
                "ASSIGN.fit(X_train, y_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN = LogisticRegression(solver='liblinear', random_state=0)",
                "ASSIGN.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = logreg.predict(X_test)",
                "y_pred_test"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = logreg.predict(X_test)",
                "y_pred_test"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "logreg.predict_proba(X_test)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "logreg.predict_proba(X_test)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "logreg.predict_proba(X_test)[:,0]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "logreg.predict_proba(X_test)[:,0]"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "logreg.predict_proba(X_test)[:,1]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "logreg.predict_proba(X_test)[:,1]"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = accuracy_score(y_test,y_pred_test)",
                "print(.format(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = accuracy_score(y_test,y_pred_test)",
                "print(.format(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = ASSIGN(y_test, y_pred_test)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = ASSIGN(y_test, y_pred_test)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(classification_report(y_test, y_pred_test))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(classification_report(y_test, y_pred_test))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = logreg.predict(X_train)",
                "y_pred_train"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = logreg.predict(X_train)",
                "y_pred_train"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = accuracy_score(y_train,y_pred_train)",
                "print(.format(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = accuracy_score(y_train,y_pred_train)",
                "print(.format(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(.format(logreg.score(X_test,y_test)))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(.format(logreg.score(X_test,y_test)))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = LogisticRegression(solver='liblinear',C=100, random_state=0)",
                "ASSIGN.fit(X_train, y_train)",
                "ASSIGN = logreg100.predict(X_test)",
                "y_pred_test"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = LogisticRegression(solver='liblinear',C=100, random_state=0)",
                "ASSIGN.fit(X_train, y_train)",
                "ASSIGN = logreg100.predict(X_test)",
                "y_pred_test"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = accuracy_score(y_test,y_pred_test)",
                "print(.format(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = accuracy_score(y_test,y_pred_test)",
                "print(.format(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(.format(logreg100.score(X_test,y_test)))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(.format(logreg100.score(X_test,y_test)))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = ASSIGN(y_test, y_pred_test)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = ASSIGN(y_test, y_pred_test)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(classification_report(y_test, y_pred_test))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(classification_report(y_test, y_pred_test))"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = LogisticRegression(solver='liblinear',C=0.01, random_state=0)",
                "ASSIGN.fit(X_train, y_train)",
                "ASSIGN = logreg001.predict(X_test)",
                "y_pred_test"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = LogisticRegression(solver='liblinear',C=0.01, random_state=0)",
                "ASSIGN.fit(X_train, y_train)",
                "ASSIGN = logreg001.predict(X_test)",
                "y_pred_test"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = accuracy_score(y_test,y_pred_test)",
                "print(.format(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = accuracy_score(y_test,y_pred_test)",
                "print(.format(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(.format(logreg001.score(X_test,y_test)))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(.format(logreg001.score(X_test,y_test)))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = logreg100.predict_proba(X_test)[:, 1]",
                "ASSIGN = logreg100.predict_proba(X_test)[:, 0]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = logreg100.predict_proba(X_test)[:, 1]",
                "ASSIGN = logreg100.predict_proba(X_test)[:, 0]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.rcParams['font.size'] = 12",
                "plt.hist(y_pred1, bins = 10)",
                "plt.hist(y_pred0, bins = 10)",
                "plt.title('Histogram of predicted probabilities')",
                "plt.xlim(0,1)",
                "plt.legend('upper left' , labels = ['Rain','No Rain'])",
                "plt.xlabel('Predicted probabilities')",
                "plt.ylabel('Frequency')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.rcParams['font.size'] = 12",
                "plt.hist(y_pred1, bins = 10)",
                "plt.hist(y_pred0, bins = 10)",
                "plt.title('Histogram of predicted probabilities')",
                "plt.xlim(0,1)",
                "plt.legend('upper left' , labels = ['Rain','No Rain'])",
                "plt.xlabel('Predicted probabilities')",
                "plt.ylabel('Frequency')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")",
                "np.random.seed(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")",
                "np.random.seed(0)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.random.exponential(size = 1000)",
                "ASSIGN = minmax_scaling(original_data, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.random.exponential(size = 1000)",
                "ASSIGN = minmax_scaling(original_data, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = stats.boxcox(original_data)",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(original_data, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN[0], ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = stats.boxcox(original_data)",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(original_data, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN[0], ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = kickstarters_2017.usd_goal_real",
                "ASSIGN = minmax_scaling(usd_goal, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(kickstarters_2017.usd_goal_real, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = kickstarters_2017.usd_goal_real",
                "ASSIGN = minmax_scaling(usd_goal, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(kickstarters_2017.usd_goal_real, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = kickstarters_2017.ASSIGN",
                "ASSIGN = minmax_scaling(goal, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(kickstarters_2017.ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = kickstarters_2017.ASSIGN",
                "ASSIGN = minmax_scaling(goal, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(kickstarters_2017.ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = kickstarters_2017.usd_pledged_real > 0",
                "ASSIGN = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]",
                "ASSIGN = stats.boxcox(positive_pledges)[0]",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = kickstarters_2017.usd_pledged_real > 0",
                "ASSIGN = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]",
                "ASSIGN = stats.boxcox(positive_pledges)[0]",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = kickstarters_2017.pledged > 0",
                "ASSIGN = kickstarters_2017.pledged.loc[index_of_positive]",
                "ASSIGN = stats.boxcox(positive_pledges_x)[0]",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = kickstarters_2017.pledged > 0",
                "ASSIGN = kickstarters_2017.pledged.loc[index_of_positive]",
                "ASSIGN = stats.boxcox(positive_pledges_x)[0]",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = test_final"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = test_final"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def Filterdataset (dataset):",
                "ASSIGN = ASSIGN.copy()",
                "ASSIGN['has_alley'] = df['Alley'].fillna(0).apply(lambda _: 0 if _ == 0 else 1)",
                "ASSIGN = ASSIGN.fillna(value= {'Alley':'No alley access'})",
                "ASSIGN['has_BsmtQual'] = df['BsmtQual'].fillna(0).apply(lambda _: 0 if _ == 0 else 1)",
                "ASSIGN = ASSIGN.fillna(value= {'BsmtQual':'No Basement'})",
                "ASSIGN['has_BsmtCond'] = df['BsmtCond'].fillna(0).apply(lambda _: 0 if _ == 0 else 1)",
                "ASSIGN = ASSIGN.fillna(value= {'BsmtCond':'No Basement'})",
                "ASSIGN = ASSIGN - ASSIGN",
                "ASSIGN = ASSIGN - ASSIGN",
                "ASSIGN = (ASSIGN + ASSIGN + ASSIGN + ASSIGN).astype('float32')",
                "ASSIGN = SimpleImputer(missing_values=np.nan, strategy='most_frequent')",
                "ASSIGN = pd.get_dummies(ASSIGN, drop_first=True)",
                "ASSIGN = dataset",
                "ASSIGN = imp_mean.fit_transform(ASSIGN)",
                "ASSIGN = pd.DataFrame(data = ASSIGN, index = datasetc.index, columns = datasetc.columns)",
                "if 'Id' in ASSIGN.columns:",
                "ASSIGN = ASSIGN.drop(['Id'], axis=1)",
                "if 'SalePrice' in ASSIGN.columns:",
                "ASSIGN = ASSIGN.drop(['SalePrice'], axis=1)",
                "return dataset"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def Filterdataset (dataset):",
                "ASSIGN = ASSIGN.copy()",
                "ASSIGN['has_alley'] = df['Alley'].fillna(0).apply(lambda _: 0 if _ == 0 else 1)",
                "ASSIGN = ASSIGN.fillna(value= {'Alley':'No alley access'})",
                "ASSIGN['has_BsmtQual'] = df['BsmtQual'].fillna(0).apply(lambda _: 0 if _ == 0 else 1)",
                "ASSIGN = ASSIGN.fillna(value= {'BsmtQual':'No Basement'})",
                "ASSIGN['has_BsmtCond'] = df['BsmtCond'].fillna(0).apply(lambda _: 0 if _ == 0 else 1)",
                "ASSIGN = ASSIGN.fillna(value= {'BsmtCond':'No Basement'})",
                "ASSIGN = ASSIGN - ASSIGN",
                "ASSIGN = ASSIGN - ASSIGN",
                "ASSIGN = (ASSIGN + ASSIGN + ASSIGN + ASSIGN).astype('float32')",
                "ASSIGN = SimpleImputer(missing_values=np.nan, strategy='most_frequent')",
                "ASSIGN = pd.get_dummies(ASSIGN, drop_first=True)",
                "ASSIGN = dataset",
                "ASSIGN = imp_mean.fit_transform(ASSIGN)",
                "ASSIGN = pd.DataFrame(data = ASSIGN, index = datasetc.index, columns = datasetc.columns)",
                "if 'Id' in ASSIGN.columns:",
                "ASSIGN = ASSIGN.drop(['Id'], axis=1)",
                "if 'SalePrice' in ASSIGN.columns:",
                "ASSIGN = ASSIGN.drop(['SalePrice'], axis=1)",
                "return dataset"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df['SalePrice']",
                "ASSIGN = df.drop('SalePrice',axis=1)",
                "X_train, X_test, y_train, y_test = train_test_split( ASSIGN, ASSIGN, test_size=0.10, random_state=0)",
                "ASSIGN = Filterdataset(ASSIGN)",
                "ASSIGN = Filterdataset(ASSIGN)",
                "ASSIGN = Filterdataset(ASSIGN)",
                "ASSIGN = []",
                "for c in ASSIGN.ASSIGN:",
                "if c in ASSIGN.ASSIGN:",
                "if c in ASSIGN.ASSIGN:",
                "ASSIGN.append(c)",
                "ASSIGN = ASSIGN[columns]",
                "ASSIGN = ASSIGN[columns]",
                "ASSIGN = ASSIGN[columns]",
                "ASSIGN = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=100)",
                "ASSIGN.fit(ASSIGN, np.log(y_train))",
                "print(len(ASSIGN.ASSIGN), len(ASSIGN.ASSIGN), len(ASSIGN.ASSIGN))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df['SalePrice']",
                "ASSIGN = df.drop('SalePrice',axis=1)",
                "X_train, X_test, y_train, y_test = train_test_split( ASSIGN, ASSIGN, test_size=0.10, random_state=0)",
                "ASSIGN = Filterdataset(ASSIGN)",
                "ASSIGN = Filterdataset(ASSIGN)",
                "ASSIGN = Filterdataset(ASSIGN)",
                "ASSIGN = []",
                "for c in ASSIGN.ASSIGN:",
                "if c in ASSIGN.ASSIGN:",
                "if c in ASSIGN.ASSIGN:",
                "ASSIGN.append(c)",
                "ASSIGN = ASSIGN[columns]",
                "ASSIGN = ASSIGN[columns]",
                "ASSIGN = ASSIGN[columns]",
                "ASSIGN = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=100)",
                "ASSIGN.fit(ASSIGN, np.log(y_train))",
                "print(len(ASSIGN.ASSIGN), len(ASSIGN.ASSIGN), len(ASSIGN.ASSIGN))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = regr.predict(X_train)",
                "ASSIGN = regr.predict(X_test)",
                "ASSIGN = np.exp(regr.predict(test_final))",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = regr.predict(X_train)",
                "ASSIGN = regr.predict(X_test)",
                "ASSIGN = np.exp(regr.predict(test_final))",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "def Mrmse(y_true,y_pred):",
                "ASSIGN = np.log(ASSIGN)",
                "ASSIGN = math.sqrt(mean_squared_error(y_true, y_pred))",
                "return rmse"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def Mrmse(y_true,y_pred):",
                "ASSIGN = np.log(ASSIGN)",
                "ASSIGN = math.sqrt(mean_squared_error(y_true, y_pred))",
                "return rmse"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(Mrmse(y_train,y_pred_train))",
                "print(Mrmse(y_test,y_pred_test))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(Mrmse(y_train,y_pred_train))",
                "print(Mrmse(y_test,y_pred_test))"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({'Id': test_final_id['Id'], 'SalePrice': y_pred_final})",
                "ASSIGN.to_csv('submission.csv', index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame({'Id': test_final_id['Id'], 'SalePrice': y_pred_final})",
                "ASSIGN.to_csv('submission.csv', index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 0",
                "ASSIGN = 20",
                "ASSIGN = 0.2",
                "ASSIGN = transforms.ToTensor()",
                "ASSIGN = datasets.MNIST(root='data', train=True,",
                "ASSIGN=True, transform=transform)",
                "ASSIGN = datasets.MNIST(root='data', train=False,",
                "ASSIGN=True, transform=transform)",
                "ASSIGN = len(train_data)",
                "ASSIGN = list(range(num_train))",
                "np.random.shuffle(ASSIGN)",
                "ASSIGN = int(np.floor(valid_size * num_train))",
                "ASSIGN = indices[split:], indices[:split]",
                "ASSIGN = SubsetRandomSampler(train_idx)",
                "ASSIGN = SubsetRandomSampler(valid_idx)",
                "ASSIGN = torch.utils.data.DataLoader(train_data, batch_size=batch_size,",
                "ASSIGN=train_sampler, num_workers=num_workers)",
                "ASSIGN = torch.utils.data.DataLoader(train_data, batch_size=batch_size,",
                "ASSIGN=valid_sampler, num_workers=num_workers)",
                "ASSIGN = torch.utils.data.DataLoader(test_data, batch_size=batch_size,",
                "ASSIGN=ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 0",
                "ASSIGN = 20",
                "ASSIGN = 0.2",
                "ASSIGN = transforms.ToTensor()",
                "ASSIGN = datasets.MNIST(root='data', train=True,",
                "ASSIGN=True, transform=transform)",
                "ASSIGN = datasets.MNIST(root='data', train=False,",
                "ASSIGN=True, transform=transform)",
                "ASSIGN = len(train_data)",
                "ASSIGN = list(range(num_train))",
                "np.random.shuffle(ASSIGN)",
                "ASSIGN = int(np.floor(valid_size * num_train))",
                "ASSIGN = indices[split:], indices[:split]",
                "ASSIGN = SubsetRandomSampler(train_idx)",
                "ASSIGN = SubsetRandomSampler(valid_idx)",
                "ASSIGN = torch.utils.data.DataLoader(train_data, batch_size=batch_size,",
                "ASSIGN=train_sampler, num_workers=num_workers)",
                "ASSIGN = torch.utils.data.DataLoader(train_data, batch_size=batch_size,",
                "ASSIGN=valid_sampler, num_workers=num_workers)",
                "ASSIGN = torch.utils.data.DataLoader(test_data, batch_size=batch_size,",
                "ASSIGN=ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = iter(train_loader)",
                "ASSIGN = dataiter.next()",
                "ASSIGN = ASSIGN.numpy()",
                "ASSIGN = plt.figure(figsize=(25, 4))",
                "for idx in np.arange(20):",
                "ASSIGN = fig.add_subplot(2, 20path, idx+1, xticks=[], yticks=[])",
                "ASSIGN.imshow(np.squeeze(ASSIGN[idx]), cmap='gray')",
                "ASSIGN.set_title(str(labels[idx].item()))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = iter(train_loader)",
                "ASSIGN = dataiter.next()",
                "ASSIGN = ASSIGN.numpy()",
                "ASSIGN = plt.figure(figsize=(25, 4))",
                "for idx in np.arange(20):",
                "ASSIGN = fig.add_subplot(2, 20path, idx+1, xticks=[], yticks=[])",
                "ASSIGN.imshow(np.squeeze(ASSIGN[idx]), cmap='gray')",
                "ASSIGN.set_title(str(labels[idx].item()))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.squeeze(images[1])",
                "ASSIGN = plt.figure(figsize = (12,12))",
                "ASSIGN = fig.add_subplot(111)",
                "ASSIGN.imshow(ASSIGN, cmap='gray')",
                "ASSIGN = img.shape",
                "ASSIGN = img.max()path",
                "for x in range(width):",
                "for y in range(height):",
                "ASSIGN = round(img[x][y],2) if img[x][y] !=0 else 0",
                "ASSIGN.annotate(str(ASSIGN), xy=(y,x),",
                "ASSIGN='center',",
                "ASSIGN='center',",
                "ASSIGN='white' if img[x][y]<thresh else 'black')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.squeeze(images[1])",
                "ASSIGN = plt.figure(figsize = (12,12))",
                "ASSIGN = fig.add_subplot(111)",
                "ASSIGN.imshow(ASSIGN, cmap='gray')",
                "ASSIGN = img.shape",
                "ASSIGN = img.max()path",
                "for x in range(width):",
                "for y in range(height):",
                "ASSIGN = round(img[x][y],2) if img[x][y] !=0 else 0",
                "ASSIGN.annotate(str(ASSIGN), xy=(y,x),",
                "ASSIGN='center',",
                "ASSIGN='center',",
                "ASSIGN='white' if img[x][y]<thresh else 'black')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "class Net(nn.Module):",
                "def __init__(self):",
                "super(Net, self).__init__()",
                "ASSIGN = 512",
                "ASSIGN = 512",
                "self.fc1 = nn.Linear(28 * 28, ASSIGN)",
                "self.fc2 = nn.Linear(ASSIGN, ASSIGN)",
                "self.fc3 = nn.Linear(ASSIGN, 10)",
                "self.dropout = nn.Dropout(0.2)",
                "def forward(self, x):",
                "ASSIGN = ASSIGN.view(-1, 28 * 28)",
                "ASSIGN = F.relu(self.fc1(ASSIGN))",
                "ASSIGN = self.dropout(ASSIGN)",
                "ASSIGN = F.relu(self.fc2(ASSIGN))",
                "ASSIGN = self.dropout(ASSIGN)",
                "ASSIGN = self.fc3(ASSIGN)",
                "return x",
                "ASSIGN = Net()",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "class Net(nn.Module):",
                "def __init__(self):",
                "super(Net, self).__init__()",
                "ASSIGN = 512",
                "ASSIGN = 512",
                "self.fc1 = nn.Linear(28 * 28, ASSIGN)",
                "self.fc2 = nn.Linear(ASSIGN, ASSIGN)",
                "self.fc3 = nn.Linear(ASSIGN, 10)",
                "self.dropout = nn.Dropout(0.2)",
                "def forward(self, x):",
                "ASSIGN = ASSIGN.view(-1, 28 * 28)",
                "ASSIGN = F.relu(self.fc1(ASSIGN))",
                "ASSIGN = self.dropout(ASSIGN)",
                "ASSIGN = F.relu(self.fc2(ASSIGN))",
                "ASSIGN = self.dropout(ASSIGN)",
                "ASSIGN = self.fc3(ASSIGN)",
                "return x",
                "ASSIGN = Net()",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = nn.CrossEntropyLoss()",
                "ASSIGN = torch.optim.SGD(model.parameters(), lr=0.01)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = nn.CrossEntropyLoss()",
                "ASSIGN = torch.optim.SGD(model.parameters(), lr=0.01)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Post Development Phase",
                "Checkpoint Activity",
                "Model Training Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 50",
                "ASSIGN = np.Inf",
                "for epoch in range(ASSIGN):",
                "ASSIGN = 0.0",
                "ASSIGN = 0.0",
                "model.train()",
                "for data, target in train_loader:",
                "optimizer.zero_grad()",
                "ASSIGN = model(data)",
                "ASSIGN = criterion(output, target)",
                "ASSIGN.backward()",
                "optimizer.step()",
                "ASSIGN += ASSIGN.item()*data.size(0)",
                "model.eval()",
                "for data, target in valid_loader:",
                "ASSIGN = model(data)",
                "ASSIGN = criterion(output, target)",
                "ASSIGN += ASSIGN.item()*data.size(0)",
                "ASSIGN = train_losspath(train_loader.sampler)",
                "ASSIGN = valid_losspath(valid_loader.sampler)",
                "print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(",
                "epoch+1,",
                "ASSIGN,",
                "valid_loss",
                "))",
                "if ASSIGN <= ASSIGN:",
                "print('Validation ASSIGN decreased ({:.6f} --> {:.6f}). Saving model ...'.format(",
                "ASSIGN,",
                "ASSIGN))",
                "torch.save(model.state_dict(), 'model.pt')",
                "ASSIGN = valid_loss"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 50",
                "ASSIGN = np.Inf",
                "for epoch in range(ASSIGN):",
                "ASSIGN = 0.0",
                "ASSIGN = 0.0",
                "model.train()",
                "for data, target in train_loader:",
                "optimizer.zero_grad()",
                "ASSIGN = model(data)",
                "ASSIGN = criterion(output, target)",
                "ASSIGN.backward()",
                "optimizer.step()",
                "ASSIGN += ASSIGN.item()*data.size(0)",
                "model.eval()",
                "for data, target in valid_loader:",
                "ASSIGN = model(data)",
                "ASSIGN = criterion(output, target)",
                "ASSIGN += ASSIGN.item()*data.size(0)",
                "ASSIGN = train_losspath(train_loader.sampler)",
                "ASSIGN = valid_losspath(valid_loader.sampler)",
                "print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(",
                "epoch+1,",
                "ASSIGN,",
                "valid_loss",
                "))",
                "if ASSIGN <= ASSIGN:",
                "print('Validation ASSIGN decreased ({:.6f} --> {:.6f}). Saving model ...'.format(",
                "ASSIGN,",
                "ASSIGN))",
                "torch.save(model.state_dict(), 'model.pt')",
                "ASSIGN = valid_loss"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "model.load_state_dict(torch.load('model.pt'))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.load_state_dict(torch.load('model.pt'))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 0.0",
                "ASSIGN = list(0. for i in range(10))",
                "ASSIGN = list(0. for i in range(10))",
                "model.eval()",
                "for data, target in test_loader:",
                "ASSIGN = model(data)",
                "ASSIGN = criterion(output, target)",
                "ASSIGN += ASSIGN.item()*data.size(0)",
                "ASSIGN = torch.max(output, 1)",
                "ASSIGN = np.squeeze(pred.eq(target.data.view_as(pred)))",
                "for i in range(len(target)):",
                "ASSIGN = target.data[i]",
                "ASSIGN[ASSIGN] += ASSIGN[i].item()",
                "ASSIGN[ASSIGN] += 1",
                "ASSIGN = test_losspath(test_loader.sampler)",
                "print('Test Loss: {:.6f}\\n'.format(ASSIGN))",
                "for i in range(10):",
                "if ASSIGN[i] > 0:",
                "print('Test Accuracy of %5s: %2d%% (%2dpath%2d)' % (",
                "str(i), 100 * ASSIGN[i] path[i],",
                "np.sum(ASSIGN[i]), np.sum(ASSIGN[i])))",
                "else:",
                "print('Test Accuracy of %5s: Npath(no training examples)' % (classes[i]))",
                "print('\\nTest Accuracy (Overall): %2d%% (%2dpath%2d)' % (",
                "100. * np.sum(ASSIGN) path(ASSIGN),",
                "np.sum(ASSIGN), np.sum(ASSIGN)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 0.0",
                "ASSIGN = list(0. for i in range(10))",
                "ASSIGN = list(0. for i in range(10))",
                "model.eval()",
                "for data, target in test_loader:",
                "ASSIGN = model(data)",
                "ASSIGN = criterion(output, target)",
                "ASSIGN += ASSIGN.item()*data.size(0)",
                "ASSIGN = torch.max(output, 1)",
                "ASSIGN = np.squeeze(pred.eq(target.data.view_as(pred)))",
                "for i in range(len(target)):",
                "ASSIGN = target.data[i]",
                "ASSIGN[ASSIGN] += ASSIGN[i].item()",
                "ASSIGN[ASSIGN] += 1",
                "ASSIGN = test_losspath(test_loader.sampler)",
                "print('Test Loss: {:.6f}\\n'.format(ASSIGN))",
                "for i in range(10):",
                "if ASSIGN[i] > 0:",
                "print('Test Accuracy of %5s: %2d%% (%2dpath%2d)' % (",
                "str(i), 100 * ASSIGN[i] path[i],",
                "np.sum(ASSIGN[i]), np.sum(ASSIGN[i])))",
                "else:",
                "print('Test Accuracy of %5s: Npath(no training examples)' % (classes[i]))",
                "print('\\nTest Accuracy (Overall): %2d%% (%2dpath%2d)' % (",
                "100. * np.sum(ASSIGN) path(ASSIGN),",
                "np.sum(ASSIGN), np.sum(ASSIGN)))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = iter(test_loader)",
                "ASSIGN = dataiter.next()",
                "ASSIGN = model(images)",
                "ASSIGN = torch.max(output, 1)",
                "ASSIGN = ASSIGN.numpy()",
                "ASSIGN = plt.figure(figsize=(25, 4))",
                "for idx in np.arange(20):",
                "ASSIGN = fig.add_subplot(2, 20path, idx+1, xticks=[], yticks=[])",
                "ASSIGN.imshow(np.squeeze(ASSIGN[idx]), cmap='gray')",
                "ASSIGN.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),",
                "ASSIGN=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = iter(test_loader)",
                "ASSIGN = dataiter.next()",
                "ASSIGN = model(images)",
                "ASSIGN = torch.max(output, 1)",
                "ASSIGN = ASSIGN.numpy()",
                "ASSIGN = plt.figure(figsize=(25, 4))",
                "for idx in np.arange(20):",
                "ASSIGN = fig.add_subplot(2, 20path, idx+1, xticks=[], yticks=[])",
                "ASSIGN.imshow(np.squeeze(ASSIGN[idx]), cmap='gray')",
                "ASSIGN.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),",
                "ASSIGN=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "np.random.seed(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "np.random.seed(0)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "with open(\"..path(30-November-2017).csv\", 'rb') as rawdata:",
                "ASSIGN = chardet.detect(rawdata.read(100000))",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "with open(\"..path(30-November-2017).csv\", 'rb') as rawdata:",
                "ASSIGN = chardet.detect(rawdata.read(100000))",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path(30-November-2017).csv\",",
                "ASSIGN='Windows-1252')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path(30-November-2017).csv\",",
                "ASSIGN='Windows-1252')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "suicide_attacks.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "suicide_attacks.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "suicide_attacks['City'] = suicide_attacks['City'].str.lower()",
                "suicide_attacks['City'] = suicide_attacks['City'].str.strip()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "suicide_attacks['City'] = suicide_attacks['City'].str.lower()",
                "suicide_attacks['City'] = suicide_attacks['City'].str.strip()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['Province'].unique()",
                "ASSIGN.sort()",
                "provinces"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['Province'].unique()",
                "ASSIGN.sort()",
                "provinces"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "suicide_attacks['Province'] = suicide_attacks['Province'].str.lower()",
                "suicide_attacks['Province'] = suicide_attacks['Province'].str.strip()",
                "ASSIGN = suicide_attacks['Province'].unique()",
                "ASSIGN.sort()",
                "provinces"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "suicide_attacks['Province'] = suicide_attacks['Province'].str.lower()",
                "suicide_attacks['Province'] = suicide_attacks['Province'].str.strip()",
                "ASSIGN = suicide_attacks['Province'].unique()",
                "ASSIGN.sort()",
                "provinces"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = fuzzywuzzy.process.extract(\"d.i khan\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "matches"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = fuzzywuzzy.process.extract(\"d.i khan\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "matches"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):",
                "ASSIGN = df[column].unique()",
                "ASSIGN = fuzzywuzzy.process.extract(string_to_match, strings,",
                "ASSIGN=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "ASSIGN = [matches[0] for matches in matches if matches[1] >= min_ratio]",
                "ASSIGN = df[column].isin(close_matches)",
                "df.loc[ASSIGN, column] = string_to_match",
                "print()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):",
                "ASSIGN = df[column].unique()",
                "ASSIGN = fuzzywuzzy.process.extract(string_to_match, strings,",
                "ASSIGN=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "ASSIGN = [matches[0] for matches in matches if matches[1] >= min_ratio]",
                "ASSIGN = df[column].isin(close_matches)",
                "df.loc[ASSIGN, column] = string_to_match",
                "print()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"d.i khan\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"d.i khan\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = fuzzywuzzy.process.extract(\"kuram agency\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "matches"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = fuzzywuzzy.process.extract(\"kuram agency\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "matches"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"kuram agency\", min_ratio = 94)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"kuram agency\", min_ratio = 94)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path', index_col=\"ID\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('path', index_col=\"ID\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.dropna(axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.dropna(axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN = train.columns.to_list()",
                "ASSIGN = [x for x in column_list if x.find('_max') == -1 and x.find('_min') == -1 and x.find('_c') == -1]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN = train.columns.to_list()",
                "ASSIGN = [x for x in column_list if x.find('_max') == -1 and x.find('_min') == -1 and x.find('_c') == -1]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "non_redundant_cols"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "non_redundant_cols"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=train"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=train"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def ind_max(l):",
                "M=l[0]",
                "ASSIGN=0",
                "for i in range(1,len(l)):",
                "if l[i]>M:",
                "M=l[i]",
                "ASSIGN=i",
                "return ind"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def ind_max(l):",
                "M=l[0]",
                "ASSIGN=0",
                "for i in range(1,len(l)):",
                "if l[i]>M:",
                "M=l[i]",
                "ASSIGN=i",
                "return ind"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=[-5+ipath(21)]",
                "ASSIGN.remove(0.0)",
                "ASSIGN=[]",
                "for col in column_list:",
                "if col != 'MAC_CODE':",
                "ASSIGN=[]",
                "for p in ASSIGN:",
                "if (p%1==0 or not any(train[col]<0)) and (p>0 or not any(train[col]==0)):",
                "ASSIGN.append(abs(train_non_re['TARGET'].ASSIGN(train_non_re[col]**p)))",
                "else:",
                "ASSIGN.append(0)",
                "ASSIGN=pows[ind_max(corr)]",
                "ASSIGN.append(ASSIGN)",
                "train_non_re[col] = np.power(train_non_re[col], ASSIGN)",
                "res"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=[-5+ipath(21)]",
                "ASSIGN.remove(0.0)",
                "ASSIGN=[]",
                "for col in column_list:",
                "if col != 'MAC_CODE':",
                "ASSIGN=[]",
                "for p in ASSIGN:",
                "if (p%1==0 or not any(train[col]<0)) and (p>0 or not any(train[col]==0)):",
                "ASSIGN.append(abs(train_non_re['TARGET'].ASSIGN(train_non_re[col]**p)))",
                "else:",
                "ASSIGN.append(0)",
                "ASSIGN=pows[ind_max(corr)]",
                "ASSIGN.append(ASSIGN)",
                "train_non_re[col] = np.power(train_non_re[col], ASSIGN)",
                "res"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = ColumnTransformer([",
                "('MAC_CODE', OneHotEncoder(dtype='int'),['MAC_CODE'])],",
                "ASSIGN = StandardScaler())",
                "ASSIGN = RidgeCV(cv=5)",
                "ASSIGN = Pipeline([('col_transformer', col_transformer),('reg', reg)], verbose=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = ColumnTransformer([",
                "('MAC_CODE', OneHotEncoder(dtype='int'),['MAC_CODE'])],",
                "ASSIGN = StandardScaler())",
                "ASSIGN = RidgeCV(cv=5)",
                "ASSIGN = Pipeline([('col_transformer', col_transformer),('reg', reg)], verbose=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train_non_re"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "train_non_re"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "Xtr, Xte, ytr,  yte = train_test_split(train_non_re.drop('TARGET', axis=1), train_non_re['TARGET'], test_size=0.2)",
                "pipe.fit(Xtr,ytr)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "Xtr, Xte, ytr,  yte = train_test_split(train_non_re.drop('TARGET', axis=1), train_non_re['TARGET'], test_size=0.2)",
                "pipe.fit(Xtr,ytr)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "mean_absolute_error(yte, pipe.predict(Xte))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "mean_absolute_error(yte, pipe.predict(Xte))"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "pipe.fit(train_non_re.drop('TARGET', axis=1),train_non_re['TARGET'])"
            ],
            "output_type": "stream",
            "content_old": [
                "pipe.fit(train_non_re.drop('TARGET', axis=1),train_non_re['TARGET'])"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path', index_col=\"ID\")",
                "ASSIGN = ASSIGN[[x for x in column_list if x != 'TARGET']]",
                "for col in squared_cols:",
                "ASSIGN = np.power(ASSIGN,2)",
                "ASSIGN = pipe.ASSIGN(test)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = pd.read_csv('path', index_col=\"ID\")",
                "ASSIGN = ASSIGN[[x for x in column_list if x != 'TARGET']]",
                "for col in squared_cols:",
                "ASSIGN = np.power(ASSIGN,2)",
                "ASSIGN = pipe.ASSIGN(test)"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = predict",
                "test['TARGET'].to_csv(\"squared_ridge.csv\")"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = predict",
                "test['TARGET'].to_csv(\"squared_ridge.csv\")"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "sns.set_style(\"darkgrid\")",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "sns.set_style(\"darkgrid\")",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.head(8)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.head(8)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = app_df.drop(columns=['URL', 'Subtitle', 'Icon URL'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = app_df.drop(columns=['URL', 'Subtitle', 'Icon URL'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "app_df_cut.info()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.sort_values(by=\"User Rating Count\", ascending=False)",
                "ASSIGN.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = ASSIGN.sort_values(by=\"User Rating Count\", ascending=False)",
                "ASSIGN.head(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "app_df_cut.loc[(app_df_cut[\"User Rating Count\"].isnull()) | (app_df_cut[\"Average User Rating\"].isnull()),",
                "[\"Average User Rating\", \"User Rating Count\"]] = 0"
            ],
            "output_type": "not_existent",
            "content_old": [
                "app_df_cut.loc[(app_df_cut[\"User Rating Count\"].isnull()) | (app_df_cut[\"Average User Rating\"].isnull()),",
                "[\"Average User Rating\", \"User Rating Count\"]] = 0"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut.loc[(app_df_cut[\"User Rating Count\"].isnull()) | (app_df_cut[\"Average User Rating\"].isnull())]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "app_df_cut.loc[(app_df_cut[\"User Rating Count\"].isnull()) | (app_df_cut[\"Average User Rating\"].isnull())]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut.loc[app_df_cut[\"In-app Purchases\"].isnull(),",
                "\"In-app Purchases\"] = 0"
            ],
            "output_type": "not_existent",
            "content_old": [
                "app_df_cut.loc[app_df_cut[\"In-app Purchases\"].isnull(),",
                "\"In-app Purchases\"] = 0"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut.loc[app_df_cut[\"In-app Purchases\"].isnull()]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "app_df_cut.loc[app_df_cut[\"In-app Purchases\"].isnull()]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut.loc[(app_df_cut[\"ID\"] == 0) | (app_df_cut[\"ID\"].isnull()),",
                "\"ID\"]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "app_df_cut.loc[(app_df_cut[\"ID\"] == 0) | (app_df_cut[\"ID\"].isnull()),",
                "\"ID\"]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(app_df_cut[\"ID\"]) - len(app_df_cut[\"ID\"].unique())"
            ],
            "output_type": "execute_result",
            "content_old": [
                "len(app_df_cut[\"ID\"]) - len(app_df_cut[\"ID\"].unique())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "app_df_cut.drop_duplicates(subset=\"ID\", inplace=True)",
                "app_df_cut.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "app_df_cut.drop_duplicates(subset=\"ID\", inplace=True)",
                "app_df_cut.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut[(app_df_cut[\"Size\"].isnull()) | (app_df_cut['Size'] == 0)]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "app_df_cut[(app_df_cut[\"Size\"].isnull()) | (app_df_cut['Size'] == 0)]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "app_df_cut.drop([16782], axis=0, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "app_df_cut.drop([16782], axis=0, inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut[\"Size\"] = round(app_df_cut[\"Size\"]path)",
                "app_df_cut.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "app_df_cut[\"Size\"] = round(app_df_cut[\"Size\"]path)",
                "app_df_cut.head(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.drop(ASSIGN.loc[ASSIGN[\"Price\"].isnull()].index)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.drop(ASSIGN.loc[ASSIGN[\"Price\"].isnull()].index)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut.loc[app_df_cut[\"Price\"].isnull()]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "app_df_cut.loc[app_df_cut[\"Price\"].isnull()]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.drop(ASSIGN.loc[ASSIGN[\"Languages\"].isnull()].index)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.drop(ASSIGN.loc[ASSIGN[\"Languages\"].isnull()].index)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut.loc[app_df_cut[\"Languages\"].isnull()]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "app_df_cut.loc[app_df_cut[\"Languages\"].isnull()]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_cut.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "app_df_cut.info()"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "app_df_cut.to_csv(\"app_df_clean.csv\", index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "app_df_cut.to_csv(\"app_df_clean.csv\", index=False)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"ASSIGN.csv\")",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv(\"ASSIGN.csv\")",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "app_df_clean[\"Original Release Date\"] = pd.to_datetime(app_df_clean[\"Original Release Date\"])",
                "app_df_clean[\"Current Version Release Date\"] = pd.to_datetime(app_df_clean[\"Current Version Release Date\"])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "app_df_clean[\"Original Release Date\"] = pd.to_datetime(app_df_clean[\"Original Release Date\"])",
                "app_df_clean[\"Current Version Release Date\"] = pd.to_datetime(app_df_clean[\"Current Version Release Date\"])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "app_df_clean.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "app_df_clean.info()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = app_df_clean[\"Original Release Date\"].apply(lambda date: date.year)",
                "ASSIGN = app_df_clean[\"Size\"]",
                "ASSIGN = sns.color_palette(\"muted\")",
                "ASSIGN = sns.swarmplot(x=years, y=ASSIGN, palette=palette)",
                "ASSIGN.set_ylabel(\"Size (in MB)\", fontsize=16)",
                "ASSIGN.set_xlabel(\"Original Release Date\", fontsize=16)",
                "ASSIGN.set_title(\"Time Evolution of the Apps' Sizes\", fontsize=20)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = app_df_clean[\"Original Release Date\"].apply(lambda date: date.year)",
                "ASSIGN = app_df_clean[\"Size\"]",
                "ASSIGN = sns.color_palette(\"muted\")",
                "ASSIGN = sns.swarmplot(x=years, y=ASSIGN, palette=palette)",
                "ASSIGN.set_ylabel(\"Size (in MB)\", fontsize=16)",
                "ASSIGN.set_xlabel(\"Original Release Date\", fontsize=16)",
                "ASSIGN.set_title(\"Time Evolution of the Apps' Sizes\", fontsize=20)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = sns.color_palette(\"inferno_r\")",
                "ASSIGN = sns.countplot(x=years, data=app_df_clean, palette=palette1)",
                "ASSIGN.set_xlabel(\"Year of Release\", fontsize=16)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of Apps per Year\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path, p.get_height() + 40),",
                "ASSIGN=\"center\", ha=\"center\", fontsize=16)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = sns.color_palette(\"inferno_r\")",
                "ASSIGN = sns.countplot(x=years, data=app_df_clean, palette=palette1)",
                "ASSIGN.set_xlabel(\"Year of Release\", fontsize=16)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of Apps per Year\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path, p.get_height() + 40),",
                "ASSIGN=\"center\", ha=\"center\", fontsize=16)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = [year for year in range(2014,2019)]",
                "for year in ASSIGN:",
                "ASSIGN = app_df_clean[\"Original Release Date\"].apply(lambda date: (date.year == year) & (date.month >= 8)).sum()",
                "ASSIGN = app_df_clean[\"Original Release Date\"].apply(lambda date: date.year == year).sum()",
                "print(\"In {year}, {percentage}% games were produced from August to December.\"",
                ".format(year=year,",
                "ASSIGN=round((from_Augustpath)*100, 1)))"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = [year for year in range(2014,2019)]",
                "for year in ASSIGN:",
                "ASSIGN = app_df_clean[\"Original Release Date\"].apply(lambda date: (date.year == year) & (date.month >= 8)).sum()",
                "ASSIGN = app_df_clean[\"Original Release Date\"].apply(lambda date: date.year == year).sum()",
                "print(\"In {year}, {percentage}% games were produced from August to December.\"",
                ".format(year=year,",
                "ASSIGN=round((from_Augustpath)*100, 1)))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = app_df_clean[\"Price\"]",
                "ASSIGN = sns.light_palette(\"green\", reverse=True)",
                "ASSIGN = sns.countplot(x=price, palette=palette2)",
                "ASSIGN.set_xlabel(\"Price (in US dollars)\", fontsize=16)",
                "ASSIGN.set_xticklabels(ASSIGN.get_xticklabels(), fontsize=12, rotation=45)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of Each App per Price\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "price_vis.annotate(\"{:.0f}\".format(p.get_height()), # Text that will appear on the screen",
                "(p.get_x() + p.get_width() path+ 0.1, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 10),",
                "ASSIGN='offset points')"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = app_df_clean[\"Price\"]",
                "ASSIGN = sns.light_palette(\"green\", reverse=True)",
                "ASSIGN = sns.countplot(x=price, palette=palette2)",
                "ASSIGN.set_xlabel(\"Price (in US dollars)\", fontsize=16)",
                "ASSIGN.set_xticklabels(ASSIGN.get_xticklabels(), fontsize=12, rotation=45)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of Each App per Price\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "price_vis.annotate(\"{:.0f}\".format(p.get_height()), # Text that will appear on the screen",
                "(p.get_x() + p.get_width() path+ 0.1, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 10),",
                "ASSIGN='offset points')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = app_df_clean[\"In-app Purchases\"].str.split(\",\").apply(lambda lst: len(lst))",
                "ASSIGN = sns.color_palette(\"BuGn_r\", 23)",
                "ASSIGN = sns.stripplot(x=price, y=in_app_purchases, palette=palette3)",
                "ASSIGN.set_xlabel(\"Game Price (in US dollars)\", fontsize=16)",
                "ASSIGN.set_xticklabels(ASSIGN.get_xticklabels(), fontsize=12, rotation=45)",
                "ASSIGN.set_ylabel(\"In-app Purchases Available\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of In-app Purchases per Game Price\", fontsize=20)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = app_df_clean[\"In-app Purchases\"].str.split(\",\").apply(lambda lst: len(lst))",
                "ASSIGN = sns.color_palette(\"BuGn_r\", 23)",
                "ASSIGN = sns.stripplot(x=price, y=in_app_purchases, palette=palette3)",
                "ASSIGN.set_xlabel(\"Game Price (in US dollars)\", fontsize=16)",
                "ASSIGN.set_xticklabels(ASSIGN.get_xticklabels(), fontsize=12, rotation=45)",
                "ASSIGN.set_ylabel(\"In-app Purchases Available\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of In-app Purchases per Game Price\", fontsize=20)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = sns.color_palette(\"BuPu_r\")",
                "ASSIGN = sns.countplot(app_df_clean.iloc[:200][\"Price\"], palette=palette4)",
                "ASSIGN.set_xlabel(\"Price (in US dollars)\", fontsize=16)",
                "ASSIGN.set_xticklabels(ASSIGN.get_xticklabels(), fontsize=12)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of Each App per Price\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.0f}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 8),",
                "ASSIGN='offset points')"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = sns.color_palette(\"BuPu_r\")",
                "ASSIGN = sns.countplot(app_df_clean.iloc[:200][\"Price\"], palette=palette4)",
                "ASSIGN.set_xlabel(\"Price (in US dollars)\", fontsize=16)",
                "ASSIGN.set_xticklabels(ASSIGN.get_xticklabels(), fontsize=12)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of Each App per Price\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.0f}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 8),",
                "ASSIGN='offset points')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = app_df_clean[app_df_clean[\"Price\"] > 0]",
                "ASSIGN = len(paid)",
                "ASSIGN = app_df_clean[app_df_clean[\"Price\"] == 0]",
                "ASSIGN = len(free)",
                "ASSIGN = plt.subplots(1, 2, figsize=(16,10))",
                "ASSIGN = sns.countplot(x=\"Average User Rating\", data=free, ax=axes[0])",
                "ASSIGN.set_xlabel(\"Average User Rating\", fontsize=16)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Free Apps\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.1f}%\".format(100 * (p.get_height()path)),",
                "(p.get_x() + p.get_width() path+ 0.1, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 8),",
                "ASSIGN='offset points')",
                "ASSIGN = sns.countplot(x=\"Average User Rating\", data=paid, ax=axes[1])",
                "ASSIGN.set_xlabel(\"Average User Rating\", fontsize=16)",
                "ASSIGN.set_ylabel(\" \", fontsize=16)",
                "ASSIGN.set_title(\"Paid Apps\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.1f}%\".format(100 * (p.get_height()path)),",
                "(p.get_x() + p.get_width() path+ 0.1, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 8),",
                "ASSIGN='offset points')"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = app_df_clean[app_df_clean[\"Price\"] > 0]",
                "ASSIGN = len(paid)",
                "ASSIGN = app_df_clean[app_df_clean[\"Price\"] == 0]",
                "ASSIGN = len(free)",
                "ASSIGN = plt.subplots(1, 2, figsize=(16,10))",
                "ASSIGN = sns.countplot(x=\"Average User Rating\", data=free, ax=axes[0])",
                "ASSIGN.set_xlabel(\"Average User Rating\", fontsize=16)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Free Apps\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.1f}%\".format(100 * (p.get_height()path)),",
                "(p.get_x() + p.get_width() path+ 0.1, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 8),",
                "ASSIGN='offset points')",
                "ASSIGN = sns.countplot(x=\"Average User Rating\", data=paid, ax=axes[1])",
                "ASSIGN.set_xlabel(\"Average User Rating\", fontsize=16)",
                "ASSIGN.set_ylabel(\" \", fontsize=16)",
                "ASSIGN.set_title(\"Paid Apps\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.1f}%\".format(100 * (p.get_height()path)),",
                "(p.get_x() + p.get_width() path+ 0.1, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 8),",
                "ASSIGN='offset points')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = sns.color_palette(\"BuGn_r\")",
                "ASSIGN = sns.countplot(x=app_df_clean[\"Age Rating\"], order=[\"4+\", \"9+\", \"12+\", \"17+\"], palette=palette5)",
                "ASSIGN.set_xlabel(\"Age Rating\", fontsize=16)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Amount of Games per Age Restriction\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.0f}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 8),",
                "ASSIGN='offset points')"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = sns.color_palette(\"BuGn_r\")",
                "ASSIGN = sns.countplot(x=app_df_clean[\"Age Rating\"], order=[\"4+\", \"9+\", \"12+\", \"17+\"], palette=palette5)",
                "ASSIGN.set_xlabel(\"Age Rating\", fontsize=16)",
                "ASSIGN.set_ylabel(\"Amount\", fontsize=16)",
                "ASSIGN.set_title(\"Amount of Games per Age Restriction\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.0f}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=14, color='black', xytext=(0, 8),",
                "ASSIGN='offset points')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "app_df_clean[\"numLang\"] = app_df_clean[\"Languages\"].apply(lambda x: len(x.split(\",\")))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "app_df_clean[\"numLang\"] = app_df_clean[\"Languages\"].apply(lambda x: len(x.split(\",\")))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = app_df_clean.loc[app_df_clean[\"numLang\"] <= 25, \"numLang\"]",
                "ASSIGN = sns.color_palette(\"PuBuGn_r\")",
                "ASSIGN = sns.countplot(x=lang, data=app_df_clean, palette=palette6)",
                "ASSIGN.set_xlabel(\"Quantity of Languages\", fontsize=16)",
                "ASSIGN.set_ylabel(\"Amount of Games\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of Languages Available per Game\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.0f}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path+ .1, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=12, color='black', xytext=(0, 12),",
                "ASSIGN='offset points')"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(16,10))",
                "ASSIGN = app_df_clean.loc[app_df_clean[\"numLang\"] <= 25, \"numLang\"]",
                "ASSIGN = sns.color_palette(\"PuBuGn_r\")",
                "ASSIGN = sns.countplot(x=lang, data=app_df_clean, palette=palette6)",
                "ASSIGN.set_xlabel(\"Quantity of Languages\", fontsize=16)",
                "ASSIGN.set_ylabel(\"Amount of Games\", fontsize=16)",
                "ASSIGN.set_title(\"Quantity of Languages Available per Game\", fontsize=20)",
                "for p in ASSIGN.patches:",
                "ASSIGN.annotate(\"{:.0f}\".format(p.get_height()),",
                "(p.get_x() + p.get_width() path+ .1, p.get_height()),",
                "ASSIGN='center', va='center', fontsize=12, color='black', xytext=(0, 12),",
                "ASSIGN='offset points')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(app_df_clean[(app_df_clean[\"numLang\"] == 1) & (app_df_clean[\"Languages\"] == \"EN\")])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "len(app_df_clean[(app_df_clean[\"numLang\"] == 1) & (app_df_clean[\"Languages\"] == \"EN\")])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "len(app_df_clean[(app_df_clean[\"numLang\"] == 1) & (app_df_clean[\"Languages\"] != \"EN\")])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "len(app_df_clean[(app_df_clean[\"numLang\"] == 1) & (app_df_clean[\"Languages\"] != \"EN\")])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN=pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(df)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(df)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df.dtypes"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df.dtypes"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.astype('float64')",
                "ASSIGN = ASSIGN.astype('float64')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.astype('float64')",
                "ASSIGN = ASSIGN.astype('float64')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df.dtypes"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df.dtypes"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.isnull().any()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.isnull().any()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df.dropna(inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df.dropna(inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.isnull().any()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.isnull().any()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['CHAS'].value_counts(dropna=False)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df['CHAS'].value_counts(dropna=False)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df[['CRIM','ZN','INDUS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV','CHAS']]",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df[['CRIM','ZN','INDUS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV','CHAS']]",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.dropna()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.dropna()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df1.iloc[:, :-1].values",
                "ASSIGN = df1.iloc[:,13].values"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df1.iloc[:, :-1].values",
                "ASSIGN = df1.iloc[:,13].values"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df1.dtypes"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df1.dtypes"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y.shape"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size =0.2,random_state =0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size =0.2,random_state =0)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_train"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X_train"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y_train"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y_train"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = LinearRegression()",
                "ASSIGN.fit(X_train,y_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN = LinearRegression()",
                "ASSIGN.fit(X_train,y_train)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN =regressor.predict(X_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN =regressor.predict(X_test)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = np.append(arr=np.ones((394,1)).astype(int),values=ASSIGN,axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = np.append(arr=np.ones((394,1)).astype(int),values=ASSIGN,axis=1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(X)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(X)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = X[:,:13]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = X[:,:13]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN =X[:,[1,3,5,7,8,9,10,11,12]]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN =X[:,[1,3,5,7,8,9,10,11,12]]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN =X[:,[1,3,5,7,8,9,10,11]]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN =X[:,[1,3,5,7,8,9,10,11]]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN =X[:,[3,5,8,9,10,11]]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN =X[:,[3,5,8,9,10,11]]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN =X[:,[0,1,4,10,14]]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN =X[:,[0,1,4,10,14]]",
                "ASSIGN=sm.OLS(endog=y,exog=X_opt).fit()",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "binder.bind(globals())",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "binder.bind(globals())",
                "print()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = bigquery.Client()",
                "ASSIGN = client.dataset(\"chicago_crime\", project=\"bigquery-public-data\")",
                "ASSIGN = client.get_dataset(dataset_ref)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = bigquery.Client()",
                "ASSIGN = client.dataset(\"chicago_crime\", project=\"bigquery-public-data\")",
                "ASSIGN = client.get_dataset(dataset_ref)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = list(client.list_tables(dataset))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = list(client.list_tables(dataset))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=client.get_table(dataset_ref.ASSIGN(\"crime\"))",
                "table.schema"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=client.get_table(dataset_ref.ASSIGN(\"crime\"))",
                "table.schema"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "client.list_rows(table, max_results=5).to_dataframe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "client.list_rows(table, max_results=5).to_dataframe()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "X=pd.read_csv('path')",
                "ASSIGN=pd.read_csv('path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "X=pd.read_csv('path')",
                "ASSIGN=pd.read_csv('path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "X.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "X.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SLICE=np.nan",
                "ASSIGN=pd.concat([X,test])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SLICE=np.nan",
                "ASSIGN=pd.concat([X,test])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def data_inv(df):",
                "print('Number of Persons: ',df.shape[0])",
                "print('dataset variables: ',df.shape[1])",
                "print('-'*20)",
                "print('dateset columns: \\n')",
                "print(df.columns)",
                "print('-'*20)",
                "print('data-type of each column: \\n')",
                "print(df.dtypes)",
                "print('-'*20)",
                "print('missing rows in each column: \\n')",
                "ASSIGN=df.isnull().sum()",
                "print(ASSIGN[ASSIGN>0])",
                "print('-'*20)",
                "print('Missing vaules %age vise:\\n')",
                "print((100*(df.isnull().sum()path(df.index))))",
                "print('-'*20)",
                "print('Pictorial Representation:')",
                "plt.figure(figsize=(8,6))",
                "sns.heatmap(df.isnull(), yticklabels=False,cbar=False, cmap='viridis')",
                "plt.show()",
                "data_inv(full)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "def data_inv(df):",
                "print('Number of Persons: ',df.shape[0])",
                "print('dataset variables: ',df.shape[1])",
                "print('-'*20)",
                "print('dateset columns: \\n')",
                "print(df.columns)",
                "print('-'*20)",
                "print('data-type of each column: \\n')",
                "print(df.dtypes)",
                "print('-'*20)",
                "print('missing rows in each column: \\n')",
                "ASSIGN=df.isnull().sum()",
                "print(ASSIGN[ASSIGN>0])",
                "print('-'*20)",
                "print('Missing vaules %age vise:\\n')",
                "print((100*(df.isnull().sum()path(df.index))))",
                "print('-'*20)",
                "print('Pictorial Representation:')",
                "plt.figure(figsize=(8,6))",
                "sns.heatmap(df.isnull(), yticklabels=False,cbar=False, cmap='viridis')",
                "plt.show()",
                "data_inv(full)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.heatmap(full.corr(), annot = True)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.heatmap(full.corr(), annot = True)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "SLICE=SLICE.fillna(mode(SLICE))",
                "full['Fare'].fillna(full['Fare'].dropna().median(),inplace=True)",
                "ASSIGN = full.groupby(\"Pclass\")['Age'].transform(lambda x: x.fillna(x.median()))",
                "full.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "SLICE=SLICE.fillna(mode(SLICE))",
                "full['Fare'].fillna(full['Fare'].dropna().median(),inplace=True)",
                "ASSIGN = full.groupby(\"Pclass\")['Age'].transform(lambda x: x.fillna(x.median()))",
                "full.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SLICE=SLICE+SLICE"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SLICE=SLICE+SLICE"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=pd.get_dummies(data=ASSIGN,columns=['Sex','Embarked'],drop_first=True)",
                "ASSIGN.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN=pd.get_dummies(data=ASSIGN,columns=['Sex','Embarked'],drop_first=True)",
                "ASSIGN.info()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN.drop(['Cabin','Ticket','Name','Parch','SibSp'],axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=ASSIGN.drop(['Cabin','Ticket','Name','Parch','SibSp'],axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "preprocessing.StandardScaler().fit(full).transform(full.astype(float))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "preprocessing.StandardScaler().fit(full).transform(full.astype(float))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = full[full['Survived'].isna()].drop(['Survived'], axis = 1)",
                "ASSIGN = full[full['Survived'].notna()]",
                "ASSIGN.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = full[full['Survived'].isna()].drop(['Survived'], axis = 1)",
                "ASSIGN = full[full['Survived'].notna()]",
                "ASSIGN.info()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "X=train[['Age','Fare','Fam','Pclass','Sex_male','Embarked_Q' ,'Embarked_S']]",
                "ASSIGN=train[['Survived']].astype(np.int8)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "X=train[['Age','Fare','Fam','Pclass','Sex_male','Embarked_Q' ,'Embarked_S']]",
                "ASSIGN=train[['Survived']].astype(np.int8)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=[]",
                "ASSIGN=[]",
                "for cols in range(50,55):",
                "for rows in range(3,5):",
                "ASSIGN=(cols,rows)",
                "MLPClassifierModel = MLPClassifier(activation='logistic',",
                "ASSIGN='lbfgs',",
                "ASSIGN=0.1 ,hidden_layer_sizes=hidden_layer,random_state=33)",
                "MLPClassifierModel.fit(X_train, y_train)",
                "ASSIGN = MLPClassifierModel.predict(X_test)",
                "ASSIGN.append(MLPClassifierModel.score(X_test, y_test))",
                "ASSIGN.append(str(ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN=[]",
                "ASSIGN=[]",
                "for cols in range(50,55):",
                "for rows in range(3,5):",
                "ASSIGN=(cols,rows)",
                "MLPClassifierModel = MLPClassifier(activation='logistic',",
                "ASSIGN='lbfgs',",
                "ASSIGN=0.1 ,hidden_layer_sizes=hidden_layer,random_state=33)",
                "MLPClassifierModel.fit(X_train, y_train)",
                "ASSIGN = MLPClassifierModel.predict(X_test)",
                "ASSIGN.append(MLPClassifierModel.score(X_test, y_test))",
                "ASSIGN.append(str(ASSIGN))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({",
                "'hidden_layer': hidden_layer_sizes,",
                "'Score': Scores})",
                "ASSIGN.sort_values(by='Score', ascending=False )"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.DataFrame({",
                "'hidden_layer': hidden_layer_sizes,",
                "'Score': Scores})",
                "ASSIGN.sort_values(by='Score', ascending=False )"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.plot(hidden_layer_sizes,Scores)",
                "plt.ylabel('Accuracy ')",
                "plt.xlabel('hidden_layer_sizes ')",
                "plt.tight_layout()",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.plot(hidden_layer_sizes,Scores)",
                "plt.ylabel('Accuracy ')",
                "plt.xlabel('hidden_layer_sizes ')",
                "plt.tight_layout()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "MLPClassifierModel = MLPClassifier(activation='logistic',",
                "ASSIGN='lbfgs',",
                "ASSIGN='adaptive',",
                "ASSIGN= False,",
                "ASSIGN=0.1 ,hidden_layer_sizes=(52, 3),random_state=33)",
                "MLPClassifierModel.fit(X_train, y_train)",
                "ASSIGN = MLPClassifierModel.predict(X_test)",
                "MLPClassifierModel.fit(X, y)",
                "ASSIGN= MLPClassifierModel.predict(test[['Age','Fare','Fam','Pclass','Sex_male','Embarked_Q' ,'Embarked_S']])"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "MLPClassifierModel = MLPClassifier(activation='logistic',",
                "ASSIGN='lbfgs',",
                "ASSIGN='adaptive',",
                "ASSIGN= False,",
                "ASSIGN=0.1 ,hidden_layer_sizes=(52, 3),random_state=33)",
                "MLPClassifierModel.fit(X_train, y_train)",
                "ASSIGN = MLPClassifierModel.predict(X_test)",
                "MLPClassifierModel.fit(X, y)",
                "ASSIGN= MLPClassifierModel.predict(test[['Age','Fare','Fam','Pclass','Sex_male','Embarked_Q' ,'Embarked_S']])"
            ]
        },
        {
            "tags": [
                "Post Development Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN=test['PassengerId']",
                "ASSIGN=pd.DataFrame({'PassengerId':Id,'Survived':MLPClassifier_y_pred})",
                "ASSIGN.to_csv('submission.csv',index=False)",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN=test['PassengerId']",
                "ASSIGN=pd.DataFrame({'PassengerId':Id,'Survived':MLPClassifier_y_pred})",
                "ASSIGN.to_csv('submission.csv',index=False)",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Image(filename='path')",
                "display(ASSIGN)"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "ASSIGN = Image(filename='path')",
                "display(ASSIGN)"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "CHECKPOINT",
                "path"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "path"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "SETUP",
                "ASSIGN = next(os.walk(\"path\"))",
                "ASSIGN = len(files)",
                "file_count"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "SETUP",
                "ASSIGN = next(os.walk(\"path\"))",
                "ASSIGN = len(files)",
                "file_count"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for filename in glob.glob(os.path.join(directory_a, '*.png')):",
                "ASSIGN =cv2.imread(filename,0)",
                "print(ASSIGN.shape)"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "for filename in glob.glob(os.path.join(directory_a, '*.png')):",
                "ASSIGN =cv2.imread(filename,0)",
                "print(ASSIGN.shape)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "def giveMeFeatures(image):",
                "ASSIGN = hog(image, orientations=8, pixels_per_cell=(16,16),cells_per_block=(4, 4),block_norm= 'L2')",
                "return res"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "def giveMeFeatures(image):",
                "ASSIGN = hog(image, orientations=8, pixels_per_cell=(16,16),cells_per_block=(4, 4),block_norm= 'L2')",
                "return res"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "for filename in glob.glob(os.path.join(ASSIGN, '*.png')):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = giveMeFeatures(im1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(0)",
                "for filename in glob.glob(os.path.join(ASSIGN, '*.png')):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = giveMeFeatures(im1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(1)",
                "ASSIGN = np.array(np.float32(ASSIGN))",
                "ASSIGN = np.array(np.float32(ASSIGN))",
                "ASSIGN = np.random.RandomState(321)",
                "ASSIGN = rand.permutation(len(X))",
                "ASSIGN = ASSIGN[shuffle]",
                "ASSIGN = ASSIGN[shuffle]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "for filename in glob.glob(os.path.join(ASSIGN, '*.png')):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = giveMeFeatures(im1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(0)",
                "for filename in glob.glob(os.path.join(ASSIGN, '*.png')):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = giveMeFeatures(im1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(1)",
                "ASSIGN = np.array(np.float32(ASSIGN))",
                "ASSIGN = np.array(np.float32(ASSIGN))",
                "ASSIGN = np.random.RandomState(321)",
                "ASSIGN = rand.permutation(len(X))",
                "ASSIGN = ASSIGN[shuffle]",
                "ASSIGN = ASSIGN[shuffle]"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN=svm.SVC()",
                "ASSIGN = {'C': [2,3,4,5,6,7,8,9,10,11,12],",
                "'kernel': ['rbf']}",
                "ASSIGN = GridSearchCV(model, param_grid=params, n_jobs=-1)",
                "ASSIGN.fit(X_train,y_train)",
                "print(,ASSIGN.best_params_)",
                "ASSIGN=model1.predict(X_test)"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN=svm.SVC()",
                "ASSIGN = {'C': [2,3,4,5,6,7,8,9,10,11,12],",
                "'kernel': ['rbf']}",
                "ASSIGN = GridSearchCV(model, param_grid=params, n_jobs=-1)",
                "ASSIGN.fit(X_train,y_train)",
                "print(,ASSIGN.best_params_)",
                "ASSIGN=model1.predict(X_test)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "classification_report(y_test, prediction)"
            ],
            "output_type": "error",
            "content_old": [
                "SETUP",
                "classification_report(y_test, prediction)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(+str(accuracy_score(y_test, prediction)))"
            ],
            "output_type": "error",
            "content_old": [
                "CHECKPOINT",
                "print(+str(accuracy_score(y_test, prediction)))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def testModel(path):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN=[]",
                "ASSIGN.append(giveMeFeatures(ASSIGN))",
                "ASSIGN = np.array(np.float32(ASSIGN))",
                "ASSIGN =model1.predict(features)",
                "if(ASSIGN[0]==0):",
                "return 'fist'",
                "else:",
                "return 'palm'",
                "return"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def testModel(path):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN=[]",
                "ASSIGN.append(giveMeFeatures(ASSIGN))",
                "ASSIGN = np.array(np.float32(ASSIGN))",
                "ASSIGN =model1.predict(features)",
                "if(ASSIGN[0]==0):",
                "return 'fist'",
                "else:",
                "return 'palm'",
                "return"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "testModel('path')"
            ],
            "output_type": "error",
            "content_old": [
                "testModel('path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "testModel('path')"
            ],
            "output_type": "error",
            "content_old": [
                "testModel('path')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = models.Sequential()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = models.Sequential()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))",
                "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))",
                "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))",
                "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))",
                "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))",
                "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))",
                "model.add(Flatten())",
                "model.add(Dense(units = 512 , activation = 'relu'))",
                "model.add(Dropout(0.2))",
                "model.add(Dense(units = 2 , activation = 'softmax'))",
                "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])",
                "model.summary()"
            ],
            "output_type": "stream",
            "content_old": [
                "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))",
                "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))",
                "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))",
                "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))",
                "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))",
                "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))",
                "model.add(Flatten())",
                "model.add(Dense(units = 512 , activation = 'relu'))",
                "model.add(Dropout(0.2))",
                "model.add(Dense(units = 2 , activation = 'softmax'))",
                "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])",
                "model.summary()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = 0.001",
                "ASSIGN = \"sparse_categorical_crossentropy\"",
                "model.compile(Adam(lr=ASSIGN), ASSIGN=ASSIGN ,metrics=['accuracy'])",
                "model.summary()"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = 0.001",
                "ASSIGN = \"sparse_categorical_crossentropy\"",
                "model.compile(Adam(lr=ASSIGN), ASSIGN=ASSIGN ,metrics=['accuracy'])",
                "model.summary()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = ['*.png', '*.jpg']",
                "ASSIGN=0",
                "ASSIGN=0",
                "for typ in ASSIGN:",
                "for directory in ASSIGN:",
                "for filename in glob.glob(os.path.join(directory, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(28,28))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append([1,0])",
                "ASSIGN+=1",
                "for directory in ASSIGN:",
                "for filename in glob.glob(os.path.join(directory, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(28,28))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append([0,1])",
                "ASSIGN+=1",
                "print('A: ', ASSIGN)",
                "print('B: ', ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = ['*.png', '*.jpg']",
                "ASSIGN=0",
                "ASSIGN=0",
                "for typ in ASSIGN:",
                "for directory in ASSIGN:",
                "for filename in glob.glob(os.path.join(directory, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(28,28))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append([1,0])",
                "ASSIGN+=1",
                "for directory in ASSIGN:",
                "for filename in glob.glob(os.path.join(directory, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(28,28))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append([0,1])",
                "ASSIGN+=1",
                "print('A: ', ASSIGN)",
                "print('B: ', ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "X=Xpath"
            ],
            "output_type": "not_existent",
            "content_old": [
                "X=Xpath"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.reshape(4527, 28, 28,1)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = ASSIGN.reshape(4527, 28, 28,1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y[2].shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y[2].shape"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = LabelBinarizer()",
                "ASSIGN = label_binarizer.fit_transform(ASSIGN)",
                "ASSIGN = label_binarizer.fit_transform(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = LabelBinarizer()",
                "ASSIGN = label_binarizer.fit_transform(ASSIGN)",
                "ASSIGN = label_binarizer.fit_transform(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ImageDataGenerator(",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=10,",
                "ASSIGN = 0.1,",
                "ASSIGN=0.1,",
                "ASSIGN=0.1,",
                "ASSIGN=False,",
                "ASSIGN=False)",
                "ASSIGN.fit(X_train)"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = ImageDataGenerator(",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=10,",
                "ASSIGN = 0.1,",
                "ASSIGN=0.1,",
                "ASSIGN=0.1,",
                "ASSIGN=False,",
                "ASSIGN=False)",
                "ASSIGN.fit(X_train)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = 20",
                "ASSIGN = 256",
                "ASSIGN = model.fit(datagen.flow(X_train,y_train, batch_size = 128) ,epochs = 20 , validation_data = (X_test, y_test))"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = 20",
                "ASSIGN = 256",
                "ASSIGN = model.fit(datagen.flow(X_train,y_train, batch_size = 128) ,epochs = 20 , validation_data = (X_test, y_test))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.figure(figsize=(20,7))",
                "ASSIGN.add_subplot(121)",
                "plt.plot(history_1.epoch,history_1.history['accuracy'],label = \"accuracy\") # Accuracy curve for training set",
                "plt.plot(history_1.epoch,history_1.history['val_accuracy'],label = \"val_accuracy\") # Accuracy curve for validation set",
                "plt.title(\"Accuracy Curve\",fontsize=18)",
                "plt.xlabel(\"Epochs\",fontsize=15)",
                "plt.ylabel(\"Accuracy\",fontsize=15)",
                "plt.grid(alpha=0.3)",
                "plt.legend()",
                "ASSIGN.add_subplot(122)",
                "plt.plot(history_1.epoch,history_1.history['loss'],label=\"loss\") # Loss curve for training set",
                "plt.plot(history_1.epoch,history_1.history['val_loss'],label=\"val_loss\") # Loss curve for validation set",
                "plt.title(\"Loss Curve\",fontsize=18)",
                "plt.xlabel(\"Epochs\",fontsize=15)",
                "plt.ylabel(\"Loss\",fontsize=15)",
                "plt.grid(alpha=0.3)",
                "plt.legend()",
                "plt.show()"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = plt.figure(figsize=(20,7))",
                "ASSIGN.add_subplot(121)",
                "plt.plot(history_1.epoch,history_1.history['accuracy'],label = \"accuracy\") # Accuracy curve for training set",
                "plt.plot(history_1.epoch,history_1.history['val_accuracy'],label = \"val_accuracy\") # Accuracy curve for validation set",
                "plt.title(\"Accuracy Curve\",fontsize=18)",
                "plt.xlabel(\"Epochs\",fontsize=15)",
                "plt.ylabel(\"Accuracy\",fontsize=15)",
                "plt.grid(alpha=0.3)",
                "plt.legend()",
                "ASSIGN.add_subplot(122)",
                "plt.plot(history_1.epoch,history_1.history['loss'],label=\"loss\") # Loss curve for training set",
                "plt.plot(history_1.epoch,history_1.history['val_loss'],label=\"val_loss\") # Loss curve for validation set",
                "plt.title(\"Loss Curve\",fontsize=18)",
                "plt.xlabel(\"Epochs\",fontsize=15)",
                "plt.ylabel(\"Loss\",fontsize=15)",
                "plt.grid(alpha=0.3)",
                "plt.legend()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def testCNNModel(path,model):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(28,28))",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN.reshape(28,28))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = ASSIGN.reshape(1,28,28,1)",
                "ASSIGN =model.predict(t)",
                "return res",
                "return"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def testCNNModel(path,model):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(28,28))",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN.reshape(28,28))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = ASSIGN.reshape(1,28,28,1)",
                "ASSIGN =model.predict(t)",
                "return res",
                "return"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "testCNNModel('path',model)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "testCNNModel('path',model)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "label_binarizer.transform(np.asarray([0]))"
            ],
            "output_type": "execute_result",
            "content_old": [
                "label_binarizer.transform(np.asarray([0]))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = ['*.png', '*.jpg']",
                "for typ in ASSIGN:",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(0)",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(1)",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(2)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = ['*.png', '*.jpg']",
                "for typ in ASSIGN:",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(0)",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(1)",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(2)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "X.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "ASSIGN = Xpath",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(16, (2,2), input_shape=ASSIGN.shape[1:], activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))",
                "ASSIGN.add(Conv2D(32, (3,3), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(3, 3), strides=(3, 3), padding='same'))",
                "ASSIGN.add(Conv2D(64, (5,5), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Dense(3, activation='softmax'))",
                "ASSIGN = TensorBoard(log_dir=\"path{}\".format(NAME))",
                "ASSIGN.compile(loss='sparse_categorical_crossentropy',",
                "ASSIGN='adam',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(ASSIGN, y, batch_size=32, epochs=10, validation_split=0.2, callbacks=[ASSIGN])"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "SETUP",
                "ASSIGN = Xpath",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(16, (2,2), input_shape=ASSIGN.shape[1:], activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))",
                "ASSIGN.add(Conv2D(32, (3,3), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(3, 3), strides=(3, 3), padding='same'))",
                "ASSIGN.add(Conv2D(64, (5,5), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Dense(3, activation='softmax'))",
                "ASSIGN = TensorBoard(log_dir=\"path{}\".format(NAME))",
                "ASSIGN.compile(loss='sparse_categorical_crossentropy',",
                "ASSIGN='adam',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(ASSIGN, y, batch_size=32, epochs=10, validation_split=0.2, callbacks=[ASSIGN])"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def testCNNModel(path,model):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN.reshape(64,64))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = ASSIGN.reshape(1,64,64,1)",
                "ASSIGN =model.predict(t)",
                "return res",
                "return"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def testCNNModel(path,model):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN.reshape(64,64))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = ASSIGN.reshape(1,64,64,1)",
                "ASSIGN =model.predict(t)",
                "return res",
                "return"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "testCNNModel('path',model)"
            ],
            "output_type": "error",
            "content_old": [
                "testCNNModel('path',model)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = ['*.png', '*.jpg']",
                "for typ in ASSIGN:",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(0)",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(1)",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(2)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = ['*.png', '*.jpg']",
                "for typ in ASSIGN:",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(0)",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(1)",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(2)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "X.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "ASSIGN = Xpath",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(16, (2,2), input_shape=ASSIGN.shape[1:], activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))",
                "ASSIGN.add(Conv2D(32, (3,3), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(3, 3), strides=(3, 3), padding='same'))",
                "ASSIGN.add(Conv2D(64, (5,5), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Dense(3, activation='softmax'))",
                "ASSIGN = TensorBoard(log_dir=\"path{}\".format(NAME))",
                "ASSIGN.compile(loss='sparse_categorical_crossentropy',",
                "ASSIGN='adam',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(ASSIGN, y, batch_size=32, epochs=10, validation_split=0.2, callbacks=[ASSIGN])"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "SETUP",
                "ASSIGN = Xpath",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(16, (2,2), input_shape=ASSIGN.shape[1:], activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))",
                "ASSIGN.add(Conv2D(32, (3,3), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(3, 3), strides=(3, 3), padding='same'))",
                "ASSIGN.add(Conv2D(64, (5,5), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Dense(3, activation='softmax'))",
                "ASSIGN = TensorBoard(log_dir=\"path{}\".format(NAME))",
                "ASSIGN.compile(loss='sparse_categorical_crossentropy',",
                "ASSIGN='adam',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(ASSIGN, y, batch_size=32, epochs=10, validation_split=0.2, callbacks=[ASSIGN])"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def testCNNModel(path,model):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN.reshape(64,64))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = ASSIGN.reshape(1,64,64,1)",
                "ASSIGN =model.predict(t)",
                "return res",
                "return"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def testCNNModel(path,model):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN.reshape(64,64))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = ASSIGN.reshape(1,64,64,1)",
                "ASSIGN =model.predict(t)",
                "return res",
                "return"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "testCNNModel('path',model)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "testCNNModel('path',model)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print('asd')"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print('asd')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = ['*.png', '*.jpg']",
                "for typ in ASSIGN:",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(0)",
                "print('finished')",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(1)",
                "print('finished')",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(2)",
                "print('finished')",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(3)",
                "print('finished')"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = 'path'",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = ['*.png', '*.jpg']",
                "for typ in ASSIGN:",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(0)",
                "print('finished')",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(1)",
                "print('finished')",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(2)",
                "print('finished')",
                "for filename in glob.glob(os.path.join(ASSIGN, typ)):",
                "ASSIGN =cv2.imread(filename,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(3)",
                "print('finished')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "X.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.reshape(-1,64,64,1)",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "ASSIGN = Xpath",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(16, (2,2), input_shape=ASSIGN.shape[1:], activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))",
                "ASSIGN.add(Conv2D(32, (3,3), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(3, 3), strides=(3, 3), padding='same'))",
                "ASSIGN.add(Conv2D(64, (5,5), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Dense(4, activation='softmax'))",
                "ASSIGN = TensorBoard(log_dir=\"path{}\".format(NAME))",
                "ASSIGN.compile(loss='sparse_categorical_crossentropy',",
                "ASSIGN='adam',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(ASSIGN, y, batch_size=32, epochs=10, validation_split=0.2, callbacks=[ASSIGN])"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "SETUP",
                "ASSIGN = Xpath",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(16, (2,2), input_shape=ASSIGN.shape[1:], activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))",
                "ASSIGN.add(Conv2D(32, (3,3), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(3, 3), strides=(3, 3), padding='same'))",
                "ASSIGN.add(Conv2D(64, (5,5), activation='relu'))",
                "ASSIGN.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Dense(4, activation='softmax'))",
                "ASSIGN = TensorBoard(log_dir=\"path{}\".format(NAME))",
                "ASSIGN.compile(loss='sparse_categorical_crossentropy',",
                "ASSIGN='adam',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(ASSIGN, y, batch_size=32, epochs=10, validation_split=0.2, callbacks=[ASSIGN])"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def testCNNModel(path,model):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN.reshape(64,64))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = ASSIGN.reshape(1,64,64,1)",
                "ASSIGN =model.predict(t)",
                "return res",
                "return"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def testCNNModel(path,model):",
                "ASSIGN =cv2.imread(path,0)",
                "ASSIGN = cv2.resize(ASSIGN,(64,64))",
                "ASSIGN = []",
                "ASSIGN.append(ASSIGN.reshape(64,64))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = ASSIGN.reshape(1,64,64,1)",
                "ASSIGN =model.predict(t)",
                "return res",
                "return"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "testCNNModel('path',model)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "testCNNModel('path',model)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = [1, 2, 3, 4, 5, 6]",
                "for x in ASSIGN:",
                "print (x)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = [1, 2, 3, 4, 5, 6]",
                "for x in ASSIGN:",
                "print (x)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 0",
                "for x in mylist:",
                "ASSIGN=ASSIGN+x",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 0",
                "for x in mylist:",
                "ASSIGN=ASSIGN+x",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = \"This is a test string for HCDE 530\"",
                "ASSIGN=s.split()",
                "for x in ASSIGN:",
                "print (x)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = \"This is a test string for HCDE 530\"",
                "ASSIGN=s.split()",
                "for x in ASSIGN:",
                "print (x)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = [1, 2, 3, 4, 5, 6]",
                "ASSIGN[3]=\"four\"",
                "print (ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = [1, 2, 3, 4, 5, 6]",
                "ASSIGN[3]=\"four\"",
                "print (ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))",
                "ASSIGN = open('path', 'r')",
                "for f in ASSIGN:",
                "print (f.rstrip())",
                "ASSIGN.close()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))",
                "ASSIGN = open('path', 'r')",
                "for f in ASSIGN:",
                "print (f.rstrip())",
                "ASSIGN.close()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [\"Akita\",\"Alaskan Malamute\",\"Australian shepherd\",\"Basset hound\",\"Beagle\",\"Boston terrier\",\"Bulldog\",\"Chihuahua\",\"Cocker Spaniel\",\"Collie\",\"French Bulldog\",\"Golden Retriever\",\"Great Dane\",\"Poodle\",\"Russell Terrier\",\"Scottish Terrier\",\"Siberian Husky\",\"Skye terrier\",\"Smooth Fox terrier\",\"Terrier\",\"Whippet\"]",
                "for dogs in ASSIGN:",
                "if (dogs.find(\"Terrier\") != -1):",
                "print (dogs.find(\"Terrier\"))",
                "elif (dogs.find(\"terrier\") != -1):",
                "print(dogs.find())",
                "else:",
                "print(-1)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [\"Akita\",\"Alaskan Malamute\",\"Australian shepherd\",\"Basset hound\",\"Beagle\",\"Boston terrier\",\"Bulldog\",\"Chihuahua\",\"Cocker Spaniel\",\"Collie\",\"French Bulldog\",\"Golden Retriever\",\"Great Dane\",\"Poodle\",\"Russell Terrier\",\"Scottish Terrier\",\"Siberian Husky\",\"Skye terrier\",\"Smooth Fox terrier\",\"Terrier\",\"Whippet\"]",
                "for dogs in ASSIGN:",
                "if (dogs.find(\"Terrier\") != -1):",
                "print (dogs.find(\"Terrier\"))",
                "elif (dogs.find(\"terrier\") != -1):",
                "print(dogs.find())",
                "else:",
                "print(-1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [0,1,1,0,1,1,0]",
                "for num in ASSIGN:",
                "ASSIGN==1:",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [0,1,1,0,1,1,0]",
                "for num in ASSIGN:",
                "ASSIGN==1:",
                "print()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dogs in dogList:",
                "if (dogs.find(\"Bulldog\") != -1):",
                "print(dogs)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dogs in dogList:",
                "if (dogs.find(\"Bulldog\") != -1):",
                "print(dogs)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = open('path', 'r')",
                "for f in ASSIGN:",
                "ASSIGN=len(f)+ASSIGN",
                "ASSIGN=len(f[0])+ASSIGN",
                "ASSIGN=(len(f.split()))+ASSIGN",
                "print('%d characters'%ASSIGN)",
                "print('%d lines'%ASSIGN)",
                "print('%d words'%ASSIGN)",
                "ASSIGN.close()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = open('path', 'r')",
                "for f in ASSIGN:",
                "ASSIGN=len(f)+ASSIGN",
                "ASSIGN=len(f[0])+ASSIGN",
                "ASSIGN=(len(f.split()))+ASSIGN",
                "print('%d characters'%ASSIGN)",
                "print('%d lines'%ASSIGN)",
                "print('%d words'%ASSIGN)",
                "ASSIGN.close()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = open('path', 'r')",
                "for f in ASSIGN:",
                "ASSIGN=len(f)+ASSIGN",
                "ASSIGN=len(f[0])+ASSIGN",
                "ASSIGN=(len(f.split()))+ASSIGN",
                "print('%d characters'%ASSIGN)",
                "print('%d lines'%ASSIGN)",
                "print('%d words'%ASSIGN)",
                "ASSIGN.close()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = open('path', 'r')",
                "for f in ASSIGN:",
                "ASSIGN=len(f)+ASSIGN",
                "ASSIGN=len(f[0])+ASSIGN",
                "ASSIGN=(len(f.split()))+ASSIGN",
                "print('%d characters'%ASSIGN)",
                "print('%d lines'%ASSIGN)",
                "print('%d words'%ASSIGN)",
                "ASSIGN.close()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "class Student:",
                "def __init__(self, id, shyness, attitude, cap, usageRate, year):",
                "self.id = id",
                "self.shyness = shyness",
                "'''",
                "attitude towards drinking",
                "(normal distribution, mean is MeanAttitude and s.d 1)",
                "determines usagerate, whether student may drink alone and addiction",
                "'''",
                "self.attitude = attitude",
                "'''",
                "updated at the end of the school year",
                "if below a threshold, student can't continue next year (inSchool = 0)",
                "'''",
                "self.cap = cap",
                "self.usageRate = usageRate",
                "self.inSchool = True",
                "self.year = year",
                "self.friends = []",
                "self.host = []",
                "self.guestList = []",
                "self.whenAttend = []",
                "def host_party(self, student_list):",
                "ASSIGN = self.whenAttend",
                "ASSIGN = (0.2 * self.shyness**2) - (len(attending))path",
                "ASSIGN = rd.random()",
                "if ASSIGN <= ASSIGN:",
                "ASSIGN = ['Sun','Mon','Tue','Wed','Thu','Fri','Sat']",
                "for a in ASSIGN:",
                "if a in ASSIGN:",
                "ASSIGN.remove(a)",
                "ASSIGN = rd.choices(week, weights = [0.05,0.05,0.05,0.05,0.1,0.35,0.35])",
                "self.host.append(ASSIGN)",
                "for others in student_list:",
                "if others.id in self.friends:",
                "others.willAttend(ASSIGN)",
                "if ASSIGN in others.whenAttend:",
                "self.guestList.append(others.id)",
                "def willAttend(self, ASSIGN):",
                "if ASSIGN not in self.whenAttend:",
                "ASSIGN = rd.random()",
                "ASSIGN = ['Sun','Sat']",
                "if ASSIGN in ASSIGN:",
                "if ASSIGN <= 0.8:",
                "self.whenAttend.append(ASSIGN)",
                "else:",
                "if ASSIGN <= 0.4:",
                "self.whenAttend.append(ASSIGN)",
                "def partyDrink(self, peer_pressure):",
                "ASSIGN = (self.attitudepath) + (2*peer_pressure) - 0.1*(self.usageRatepath)",
                "ASSIGN = rd.random()",
                "if ASSIGN <= ASSIGN:",
                "self.usageRate += 1",
                "self.experience()",
                "return 1",
                "return 0",
                "def drinkAlone(self):",
                "if self.attitude > 3:",
                "ASSIGN = self.attitudepath",
                "ASSIGN = rd.random()",
                "if ASSIGN <= ASSIGN:",
                "self.usageRate += 1",
                "def experience(self):",
                "ASSIGN = rd.noramlvariate(meanExperience, stDevExperience)",
                "if ASSIGN < -6:",
                "ASSIGN = -6",
                "elif ASSIGN > 3:",
                "ASSIGN = 3",
                "ASSIGN = rd.random()",
                "if ASSIGN < probabilityofBust:",
                "ASSIGN -= 3",
                "self.attitude += ASSIGN*0.1",
                "def gradeExperience(self):",
                "if self.usageRate > usageRateGradeDrop:",
                "ASSIGN = -1*(self.usageRatepath)",
                "self.attitude += (ASSIGN * 0.2)",
                "def gradeUpdate(self):",
                "ASSIGN = 0.2path",
                "ASSIGN = rd.normalvariate(0.1,std_dev)",
                "if self.usageRate > usageRateGradeDrop:",
                "ASSIGN = self.usageRatepath(30*self.year)",
                "ASSIGN = 0.5path",
                "ASSIGN = rd.normalvariate(mean_drop,s_dev)",
                "ASSIGN += ASSIGN",
                "student.cap -= ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "class Student:",
                "def __init__(self, id, shyness, attitude, cap, usageRate, year):",
                "self.id = id",
                "self.shyness = shyness",
                "'''",
                "attitude towards drinking",
                "(normal distribution, mean is MeanAttitude and s.d 1)",
                "determines usagerate, whether student may drink alone and addiction",
                "'''",
                "self.attitude = attitude",
                "'''",
                "updated at the end of the school year",
                "if below a threshold, student can't continue next year (inSchool = 0)",
                "'''",
                "self.cap = cap",
                "self.usageRate = usageRate",
                "self.inSchool = True",
                "self.year = year",
                "self.friends = []",
                "self.host = []",
                "self.guestList = []",
                "self.whenAttend = []",
                "def host_party(self, student_list):",
                "ASSIGN = self.whenAttend",
                "ASSIGN = (0.2 * self.shyness**2) - (len(attending))path",
                "ASSIGN = rd.random()",
                "if ASSIGN <= ASSIGN:",
                "ASSIGN = ['Sun','Mon','Tue','Wed','Thu','Fri','Sat']",
                "for a in ASSIGN:",
                "if a in ASSIGN:",
                "ASSIGN.remove(a)",
                "ASSIGN = rd.choices(week, weights = [0.05,0.05,0.05,0.05,0.1,0.35,0.35])",
                "self.host.append(ASSIGN)",
                "for others in student_list:",
                "if others.id in self.friends:",
                "others.willAttend(ASSIGN)",
                "if ASSIGN in others.whenAttend:",
                "self.guestList.append(others.id)",
                "def willAttend(self, ASSIGN):",
                "if ASSIGN not in self.whenAttend:",
                "ASSIGN = rd.random()",
                "ASSIGN = ['Sun','Sat']",
                "if ASSIGN in ASSIGN:",
                "if ASSIGN <= 0.8:",
                "self.whenAttend.append(ASSIGN)",
                "else:",
                "if ASSIGN <= 0.4:",
                "self.whenAttend.append(ASSIGN)",
                "def partyDrink(self, peer_pressure):",
                "ASSIGN = (self.attitudepath) + (2*peer_pressure) - 0.1*(self.usageRatepath)",
                "ASSIGN = rd.random()",
                "if ASSIGN <= ASSIGN:",
                "self.usageRate += 1",
                "self.experience()",
                "return 1",
                "return 0",
                "def drinkAlone(self):",
                "if self.attitude > 3:",
                "ASSIGN = self.attitudepath",
                "ASSIGN = rd.random()",
                "if ASSIGN <= ASSIGN:",
                "self.usageRate += 1",
                "def experience(self):",
                "ASSIGN = rd.noramlvariate(meanExperience, stDevExperience)",
                "if ASSIGN < -6:",
                "ASSIGN = -6",
                "elif ASSIGN > 3:",
                "ASSIGN = 3",
                "ASSIGN = rd.random()",
                "if ASSIGN < probabilityofBust:",
                "ASSIGN -= 3",
                "self.attitude += ASSIGN*0.1",
                "def gradeExperience(self):",
                "if self.usageRate > usageRateGradeDrop:",
                "ASSIGN = -1*(self.usageRatepath)",
                "self.attitude += (ASSIGN * 0.2)",
                "def gradeUpdate(self):",
                "ASSIGN = 0.2path",
                "ASSIGN = rd.normalvariate(0.1,std_dev)",
                "if self.usageRate > usageRateGradeDrop:",
                "ASSIGN = self.usageRatepath(30*self.year)",
                "ASSIGN = 0.5path",
                "ASSIGN = rd.normalvariate(mean_drop,s_dev)",
                "ASSIGN += ASSIGN",
                "student.cap -= ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def make_friends(student1, student2):",
                "if student2.id not in student1.friends:",
                "shy1, shy2 = student1.shyness, student2.shyness",
                "fr1,fr2 = len(student1.friends), len(student2.friends)",
                "att1, att2 = student1.attitude, student2.attitude",
                "ASSIGN = ((wShy*(shy1 + shy2 + 4)) - (wFr*((fr1path(3+shy1)) + (fr2path(3+shy2)))) - (wAtt*(att1 - att2))) path(8*wShy)",
                "ASSIGN = rd.random()",
                "if ASSIGN <= ASSIGN:",
                "student1.friends.append(student2.id)",
                "student2.friends.append(student1.id)",
                "def party_friends(attendees):",
                "for guest in attendees:",
                "for others in attendees:",
                "if guest != others:",
                "make_friends(guest, others)",
                "def party_time(host, student_list, day):",
                "ASSIGN = host.guestList",
                "ASSIGN = [host]",
                "ASSIGN = 0",
                "for others in student_list:",
                "if others.id in ASSIGN:",
                "ASSIGN.append(others)",
                "party_friends(ASSIGN)",
                "for j in range(3):",
                "for member in ASSIGN:",
                "ASSIGN = member.partyDrink(peer_pressure)",
                "ASSIGN += (xpath(ASSIGN))",
                "host.guestList.remove(day)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def make_friends(student1, student2):",
                "if student2.id not in student1.friends:",
                "shy1, shy2 = student1.shyness, student2.shyness",
                "fr1,fr2 = len(student1.friends), len(student2.friends)",
                "att1, att2 = student1.attitude, student2.attitude",
                "ASSIGN = ((wShy*(shy1 + shy2 + 4)) - (wFr*((fr1path(3+shy1)) + (fr2path(3+shy2)))) - (wAtt*(att1 - att2))) path(8*wShy)",
                "ASSIGN = rd.random()",
                "if ASSIGN <= ASSIGN:",
                "student1.friends.append(student2.id)",
                "student2.friends.append(student1.id)",
                "def party_friends(attendees):",
                "for guest in attendees:",
                "for others in attendees:",
                "if guest != others:",
                "make_friends(guest, others)",
                "def party_time(host, student_list, day):",
                "ASSIGN = host.guestList",
                "ASSIGN = [host]",
                "ASSIGN = 0",
                "for others in student_list:",
                "if others.id in ASSIGN:",
                "ASSIGN.append(others)",
                "party_friends(ASSIGN)",
                "for j in range(3):",
                "for member in ASSIGN:",
                "ASSIGN = member.partyDrink(peer_pressure)",
                "ASSIGN += (xpath(ASSIGN))",
                "host.guestList.remove(day)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "MeanAttitude = 3",
                "NumberOfAgents = 1000",
                "ASSIGN = 0.8",
                "ASSIGN = 0.8",
                "ASSIGN = 0.5",
                "ASSIGN = 6",
                "ASSIGN = 1",
                "ASSIGN = 1.6",
                "ASSIGN = 1.6",
                "ASSIGN = 0.001",
                "ASSIGN = 3",
                "ASSIGN = 13"
            ],
            "output_type": "not_existent",
            "content_old": [
                "MeanAttitude = 3",
                "NumberOfAgents = 1000",
                "ASSIGN = 0.8",
                "ASSIGN = 0.8",
                "ASSIGN = 0.5",
                "ASSIGN = 6",
                "ASSIGN = 1",
                "ASSIGN = 1.6",
                "ASSIGN = 1.6",
                "ASSIGN = 0.001",
                "ASSIGN = 3",
                "ASSIGN = 13"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in range(NumberOfAgents):",
                "ASSIGN = rd.normalvariate(0,1)",
                "ASSIGN = rd.normalvariate(MeanAttitude,0.5)",
                "ASSIGN = rd.normalvariate(3.5, 0.5)",
                "if ASSIGN < 2:",
                "ASSIGN = 2",
                "elif ASSIGN > 5:",
                "ASSIGN = 5",
                "if ASSIGN < 0:",
                "ASSIGN = 0",
                "elif ASSIGN <= 5:",
                "ASSIGN = round(attitude_)",
                "else:",
                "ASSIGN = round(2*attitude_)",
                "ASSIGN = rd.choice([1,2,3,4])",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in range(NumberOfAgents):",
                "ASSIGN = rd.normalvariate(0,1)",
                "ASSIGN = rd.normalvariate(MeanAttitude,0.5)",
                "ASSIGN = rd.normalvariate(3.5, 0.5)",
                "if ASSIGN < 2:",
                "ASSIGN = 2",
                "elif ASSIGN > 5:",
                "ASSIGN = 5",
                "if ASSIGN < 0:",
                "ASSIGN = 0",
                "elif ASSIGN <= 5:",
                "ASSIGN = round(attitude_)",
                "else:",
                "ASSIGN = round(2*attitude_)",
                "ASSIGN = rd.choice([1,2,3,4])",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = rd.sample(range(1, 100000), NumberOfAgents)",
                "ASSIGN = pd.DataFrame({\"id\": id_list,",
                "\"shyness\": shyness_list,",
                "\"attitude\": attitude_list,",
                "\"cap\": cap_list,",
                "\"usage\": usagerate_list,",
                "\"year\": year_list,",
                "})",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN = rd.sample(range(1, 100000), NumberOfAgents)",
                "ASSIGN = pd.DataFrame({\"id\": id_list,",
                "\"shyness\": shyness_list,",
                "\"attitude\": attitude_list,",
                "\"cap\": cap_list,",
                "\"usage\": usagerate_list,",
                "\"year\": year_list,",
                "})",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = []",
                "for index, row in df.iterrows():",
                "ASSIGN = Student(row['id'],",
                "row['shyness'],",
                "row['attitude'],",
                "row['cap'],",
                "row['usage'],",
                "row['year'])",
                "ASSIGN.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "for index, row in df.iterrows():",
                "ASSIGN = Student(row['id'],",
                "row['shyness'],",
                "row['attitude'],",
                "row['cap'],",
                "row['usage'],",
                "row['year'])",
                "ASSIGN.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN.append(student.cap)",
                "ASSIGN += student.cap",
                "ASSIGN = total_start_cappath(student_list)",
                "print(ASSIGN)",
                "plt.hist(ASSIGN, color = 'purple')",
                "plt.title('Starting CAP')",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN.append(student.cap)",
                "ASSIGN += student.cap",
                "ASSIGN = total_start_cappath(student_list)",
                "print(ASSIGN)",
                "plt.hist(ASSIGN, color = 'purple')",
                "plt.title('Starting CAP')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = []",
                "for student in student_list:",
                "ASSIGN.append(student.attitude)",
                "plt.hist(ASSIGN)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = []",
                "for student in student_list:",
                "ASSIGN.append(student.attitude)",
                "plt.hist(ASSIGN)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = []",
                "for student in student_list:",
                "ASSIGN.append(student.usageRate)",
                "plt.hist(ASSIGN)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = []",
                "for student in student_list:",
                "ASSIGN.append(student.usageRate)",
                "plt.hist(ASSIGN)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {}",
                "ASSIGN = {}",
                "for week in range(13):",
                "for student in student_list:",
                "student.host_party(student_list)",
                "ASSIGN == 0:",
                "for student in student_list:",
                "if student.year == 1:",
                "for i in range(20):",
                "if student != student_list[i]:",
                "make_friends(student, student_list[i])",
                "else:",
                "for j in range(30):",
                "if student != student_list[j]:",
                "make_friends(student, student_list[j])",
                "elif week %3 == 0 and week != 12:",
                "for student in student_list:",
                "student.gradeExperience()",
                "ASSIGN == 12:",
                "for student in student_list:",
                "student.gradeUpdate()",
                "if student.cap < 2:",
                "student.inSchool = False",
                "student_list.remove(student)",
                "ASSIGN = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']",
                "for day in ASSIGN:",
                "for student in student_list:",
                "if day in student.host:",
                "party_time(student, student_list, day)",
                "else:",
                "for loners in student_list:",
                "loners.drinkAlone()",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.usageRate",
                "ASSIGN = total_usepath(student_list)",
                "ASSIGN[week] = ASSIGN",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.attitude",
                "ASSIGN = total_attpath(student_list)",
                "ASSIGN[week] = ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {}",
                "ASSIGN = {}",
                "for week in range(13):",
                "for student in student_list:",
                "student.host_party(student_list)",
                "ASSIGN == 0:",
                "for student in student_list:",
                "if student.year == 1:",
                "for i in range(20):",
                "if student != student_list[i]:",
                "make_friends(student, student_list[i])",
                "else:",
                "for j in range(30):",
                "if student != student_list[j]:",
                "make_friends(student, student_list[j])",
                "elif week %3 == 0 and week != 12:",
                "for student in student_list:",
                "student.gradeExperience()",
                "ASSIGN == 12:",
                "for student in student_list:",
                "student.gradeUpdate()",
                "if student.cap < 2:",
                "student.inSchool = False",
                "student_list.remove(student)",
                "ASSIGN = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']",
                "for day in ASSIGN:",
                "for student in student_list:",
                "if day in student.host:",
                "party_time(student, student_list, day)",
                "else:",
                "for loners in student_list:",
                "loners.drinkAlone()",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.usageRate",
                "ASSIGN = total_usepath(student_list)",
                "ASSIGN[week] = ASSIGN",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.attitude",
                "ASSIGN = total_attpath(student_list)",
                "ASSIGN[week] = ASSIGN"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "attitude_list"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "attitude_list"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in attitude_list.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "plt.plot(ASSIGN, ASSIGN)",
                "plt.title('Average attitude over the semester')",
                "plt.xlabel('Week')",
                "plt.ylabel('Average attitude')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in attitude_list.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "plt.plot(ASSIGN, ASSIGN)",
                "plt.title('Average attitude over the semester')",
                "plt.xlabel('Week')",
                "plt.ylabel('Average attitude')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN.append(student.cap)",
                "ASSIGN += student.cap",
                "ASSIGN = total_cappath(student_list)",
                "print(ASSIGN)",
                "print(max(start_cap))",
                "print(max(ASSIGN))",
                "plt.hist(start_cap, color = 'orange')",
                "plt.hist(ASSIGN, color = 'indigo')",
                "plt.legend(['Start', 'End'])",
                "plt.title('Average CAP Score')",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN.append(student.cap)",
                "ASSIGN += student.cap",
                "ASSIGN = total_cappath(student_list)",
                "print(ASSIGN)",
                "print(max(start_cap))",
                "print(max(ASSIGN))",
                "plt.hist(start_cap, color = 'orange')",
                "plt.hist(ASSIGN, color = 'indigo')",
                "plt.legend(['Start', 'End'])",
                "plt.title('Average CAP Score')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = []",
                "for student in student_list:",
                "ASSIGN.append(student.usageRate)",
                "plt.hist(start_usage, color = 'blue')",
                "plt.hist(ASSIGN, color = 'red')",
                "plt.title('Number of drinks taken over the semester')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = []",
                "for student in student_list:",
                "ASSIGN.append(student.usageRate)",
                "plt.hist(start_usage, color = 'blue')",
                "plt.hist(ASSIGN, color = 'red')",
                "plt.title('Number of drinks taken over the semester')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({'usage': end_usage, 'cap':end_cap})",
                "ASSIGN = end_test[end_test['usage'] < 8]",
                "ASSIGN = end_test[end_test['usage'] > 8]",
                "plt.hist(ASSIGN['cap'], color = 'blue')",
                "plt.hist(ASSIGN['cap'], color = 'orange')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.DataFrame({'usage': end_usage, 'cap':end_cap})",
                "ASSIGN = end_test[end_test['usage'] < 8]",
                "ASSIGN = end_test[end_test['usage'] > 8]",
                "plt.hist(ASSIGN['cap'], color = 'blue')",
                "plt.hist(ASSIGN['cap'], color = 'orange')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in range(NumberOfAgents):",
                "ASSIGN = rd.normalvariate(0,1)",
                "ASSIGN = rd.normalvariate(MeanAttitude,0.5)",
                "ASSIGN = rd.normalvariate(3.5, 0.5)",
                "if ASSIGN < 2:",
                "ASSIGN = 2",
                "elif ASSIGN > 5:",
                "ASSIGN = 5",
                "if ASSIGN < 0:",
                "ASSIGN = 0",
                "elif ASSIGN <= 5:",
                "ASSIGN = round(attitude_)",
                "else:",
                "ASSIGN = round(2*attitude_)",
                "ASSIGN = rd.choice([1,2,3,4])",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = rd.sample(range(1, 100000), NumberOfAgents)",
                "ASSIGN = pd.DataFrame({\"id\": id_list,",
                "\"shyness\": ASSIGN,",
                "\"attitude\": ASSIGN,",
                "\"cap\": ASSIGN,",
                "\"usage\": ASSIGN,",
                "\"year\": ASSIGN,",
                "})",
                "ASSIGN = []",
                "for index, row in ASSIGN.iterrows():",
                "ASSIGN = Student(row['id'],",
                "row['shyness'],",
                "row['attitude'],",
                "row['cap'],",
                "row['usage'],",
                "row['year'])",
                "ASSIGN.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in range(NumberOfAgents):",
                "ASSIGN = rd.normalvariate(0,1)",
                "ASSIGN = rd.normalvariate(MeanAttitude,0.5)",
                "ASSIGN = rd.normalvariate(3.5, 0.5)",
                "if ASSIGN < 2:",
                "ASSIGN = 2",
                "elif ASSIGN > 5:",
                "ASSIGN = 5",
                "if ASSIGN < 0:",
                "ASSIGN = 0",
                "elif ASSIGN <= 5:",
                "ASSIGN = round(attitude_)",
                "else:",
                "ASSIGN = round(2*attitude_)",
                "ASSIGN = rd.choice([1,2,3,4])",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = rd.sample(range(1, 100000), NumberOfAgents)",
                "ASSIGN = pd.DataFrame({\"id\": id_list,",
                "\"shyness\": ASSIGN,",
                "\"attitude\": ASSIGN,",
                "\"cap\": ASSIGN,",
                "\"usage\": ASSIGN,",
                "\"year\": ASSIGN,",
                "})",
                "ASSIGN = []",
                "for index, row in ASSIGN.iterrows():",
                "ASSIGN = Student(row['id'],",
                "row['shyness'],",
                "row['attitude'],",
                "row['cap'],",
                "row['usage'],",
                "row['year'])",
                "ASSIGN.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {}",
                "ASSIGN = {}",
                "for week in range(13):",
                "for student in student_list:",
                "student.host_party(student_list)",
                "ASSIGN == 0:",
                "for student in student_list:",
                "if student.year == 1:",
                "for i in range(20):",
                "if student != student_list[i]:",
                "make_friends(student, student_list[i])",
                "else:",
                "for j in range(30):",
                "if student != student_list[j]:",
                "make_friends(student, student_list[j])",
                "elif week %3 == 0 and week != 12:",
                "for student in student_list:",
                "student.gradeExperience()",
                "ASSIGN == 12:",
                "for student in student_list:",
                "student.gradeUpdate()",
                "if student.cap < 2:",
                "student.inSchool = False",
                "student_list.remove(student)",
                "ASSIGN = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']",
                "for day in ASSIGN:",
                "for student in student_list:",
                "if day in student.host:",
                "party_time(student, student_list, day)",
                "else:",
                "for loners in student_list:",
                "loners.drinkAlone()",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.usageRate",
                "ASSIGN = total_usepath(student_list)",
                "ASSIGN[week] = ASSIGN",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.attitude",
                "ASSIGN = total_attpath(student_list)",
                "ASSIGN[week] = ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {}",
                "ASSIGN = {}",
                "for week in range(13):",
                "for student in student_list:",
                "student.host_party(student_list)",
                "ASSIGN == 0:",
                "for student in student_list:",
                "if student.year == 1:",
                "for i in range(20):",
                "if student != student_list[i]:",
                "make_friends(student, student_list[i])",
                "else:",
                "for j in range(30):",
                "if student != student_list[j]:",
                "make_friends(student, student_list[j])",
                "elif week %3 == 0 and week != 12:",
                "for student in student_list:",
                "student.gradeExperience()",
                "ASSIGN == 12:",
                "for student in student_list:",
                "student.gradeUpdate()",
                "if student.cap < 2:",
                "student.inSchool = False",
                "student_list.remove(student)",
                "ASSIGN = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']",
                "for day in ASSIGN:",
                "for student in student_list:",
                "if day in student.host:",
                "party_time(student, student_list, day)",
                "else:",
                "for loners in student_list:",
                "loners.drinkAlone()",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.usageRate",
                "ASSIGN = total_usepath(student_list)",
                "ASSIGN[week] = ASSIGN",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.attitude",
                "ASSIGN = total_attpath(student_list)",
                "ASSIGN[week] = ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in range(NumberOfAgents):",
                "ASSIGN = rd.normalvariate(0,1)",
                "ASSIGN = rd.normalvariate(MeanAttitude,0.5)",
                "ASSIGN = rd.normalvariate(3.5, 0.5)",
                "if ASSIGN < 2:",
                "ASSIGN = 2",
                "elif ASSIGN > 5:",
                "ASSIGN = 5",
                "if ASSIGN < 0:",
                "ASSIGN = 0",
                "elif ASSIGN <= 5:",
                "ASSIGN = round(attitude_)",
                "else:",
                "ASSIGN = round(2*attitude_)",
                "ASSIGN = rd.choice([1,2,3,4])",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = rd.sample(range(1, 100000), NumberOfAgents)",
                "ASSIGN = pd.DataFrame({\"id\": id_list,",
                "\"shyness\": ASSIGN,",
                "\"attitude\": ASSIGN,",
                "\"cap\": ASSIGN,",
                "\"usage\": ASSIGN,",
                "\"year\": ASSIGN,",
                "})",
                "ASSIGN = []",
                "for index, row in ASSIGN.iterrows():",
                "ASSIGN = Student(row['id'],",
                "row['shyness'],",
                "row['attitude'],",
                "row['cap'],",
                "row['usage'],",
                "row['year'])",
                "ASSIGN.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in range(NumberOfAgents):",
                "ASSIGN = rd.normalvariate(0,1)",
                "ASSIGN = rd.normalvariate(MeanAttitude,0.5)",
                "ASSIGN = rd.normalvariate(3.5, 0.5)",
                "if ASSIGN < 2:",
                "ASSIGN = 2",
                "elif ASSIGN > 5:",
                "ASSIGN = 5",
                "if ASSIGN < 0:",
                "ASSIGN = 0",
                "elif ASSIGN <= 5:",
                "ASSIGN = round(attitude_)",
                "else:",
                "ASSIGN = round(2*attitude_)",
                "ASSIGN = rd.choice([1,2,3,4])",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = rd.sample(range(1, 100000), NumberOfAgents)",
                "ASSIGN = pd.DataFrame({\"id\": id_list,",
                "\"shyness\": ASSIGN,",
                "\"attitude\": ASSIGN,",
                "\"cap\": ASSIGN,",
                "\"usage\": ASSIGN,",
                "\"year\": ASSIGN,",
                "})",
                "ASSIGN = []",
                "for index, row in ASSIGN.iterrows():",
                "ASSIGN = Student(row['id'],",
                "row['shyness'],",
                "row['attitude'],",
                "row['cap'],",
                "row['usage'],",
                "row['year'])",
                "ASSIGN.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {}",
                "ASSIGN = {}",
                "for week in range(13):",
                "for student in student_list:",
                "student.host_party(student_list)",
                "ASSIGN == 0:",
                "for student in student_list:",
                "if student.year == 1:",
                "for i in range(20):",
                "if student != student_list[i]:",
                "make_friends(student, student_list[i])",
                "else:",
                "for j in range(30):",
                "if student != student_list[j]:",
                "make_friends(student, student_list[j])",
                "elif week %3 == 0 and week != 12:",
                "for student in student_list:",
                "student.gradeExperience()",
                "ASSIGN == 12:",
                "for student in student_list:",
                "student.gradeUpdate()",
                "if student.cap < 2:",
                "student.inSchool = False",
                "student_list.remove(student)",
                "ASSIGN = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']",
                "for day in ASSIGN:",
                "for student in student_list:",
                "if day in student.host:",
                "party_time(student, student_list, day)",
                "else:",
                "for loners in student_list:",
                "loners.drinkAlone()",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.usageRate",
                "ASSIGN = total_usepath(student_list)",
                "ASSIGN[week] = ASSIGN",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.attitude",
                "ASSIGN = total_attpath(student_list)",
                "ASSIGN[week] = ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {}",
                "ASSIGN = {}",
                "for week in range(13):",
                "for student in student_list:",
                "student.host_party(student_list)",
                "ASSIGN == 0:",
                "for student in student_list:",
                "if student.year == 1:",
                "for i in range(20):",
                "if student != student_list[i]:",
                "make_friends(student, student_list[i])",
                "else:",
                "for j in range(30):",
                "if student != student_list[j]:",
                "make_friends(student, student_list[j])",
                "elif week %3 == 0 and week != 12:",
                "for student in student_list:",
                "student.gradeExperience()",
                "ASSIGN == 12:",
                "for student in student_list:",
                "student.gradeUpdate()",
                "if student.cap < 2:",
                "student.inSchool = False",
                "student_list.remove(student)",
                "ASSIGN = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']",
                "for day in ASSIGN:",
                "for student in student_list:",
                "if day in student.host:",
                "party_time(student, student_list, day)",
                "else:",
                "for loners in student_list:",
                "loners.drinkAlone()",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.usageRate",
                "ASSIGN = total_usepath(student_list)",
                "ASSIGN[week] = ASSIGN",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.attitude",
                "ASSIGN = total_attpath(student_list)",
                "ASSIGN[week] = ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in range(NumberOfAgents):",
                "ASSIGN = rd.normalvariate(0,1)",
                "ASSIGN = rd.normalvariate(MeanAttitude,0.5)",
                "ASSIGN = rd.normalvariate(3.5, 0.5)",
                "if ASSIGN < 2:",
                "ASSIGN = 2",
                "elif ASSIGN > 5:",
                "ASSIGN = 5",
                "if ASSIGN < 0:",
                "ASSIGN = 0",
                "elif ASSIGN <= 5:",
                "ASSIGN = round(attitude_)",
                "else:",
                "ASSIGN = round(2*attitude_)",
                "ASSIGN = rd.choice([1,2,3,4])",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = rd.sample(range(1, 100000), NumberOfAgents)",
                "ASSIGN = pd.DataFrame({\"id\": id_list,",
                "\"shyness\": ASSIGN,",
                "\"attitude\": ASSIGN,",
                "\"cap\": ASSIGN,",
                "\"usage\": ASSIGN,",
                "\"year\": ASSIGN,",
                "})",
                "ASSIGN = []",
                "for index, row in ASSIGN.iterrows():",
                "ASSIGN = Student(row['id'],",
                "row['shyness'],",
                "row['attitude'],",
                "row['cap'],",
                "row['usage'],",
                "row['year'])",
                "ASSIGN.append(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in range(NumberOfAgents):",
                "ASSIGN = rd.normalvariate(0,1)",
                "ASSIGN = rd.normalvariate(MeanAttitude,0.5)",
                "ASSIGN = rd.normalvariate(3.5, 0.5)",
                "if ASSIGN < 2:",
                "ASSIGN = 2",
                "elif ASSIGN > 5:",
                "ASSIGN = 5",
                "if ASSIGN < 0:",
                "ASSIGN = 0",
                "elif ASSIGN <= 5:",
                "ASSIGN = round(attitude_)",
                "else:",
                "ASSIGN = round(2*attitude_)",
                "ASSIGN = rd.choice([1,2,3,4])",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = rd.sample(range(1, 100000), NumberOfAgents)",
                "ASSIGN = pd.DataFrame({\"id\": id_list,",
                "\"shyness\": ASSIGN,",
                "\"attitude\": ASSIGN,",
                "\"cap\": ASSIGN,",
                "\"usage\": ASSIGN,",
                "\"year\": ASSIGN,",
                "})",
                "ASSIGN = []",
                "for index, row in ASSIGN.iterrows():",
                "ASSIGN = Student(row['id'],",
                "row['shyness'],",
                "row['attitude'],",
                "row['cap'],",
                "row['usage'],",
                "row['year'])",
                "ASSIGN.append(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {}",
                "ASSIGN = {}",
                "for week in range(13):",
                "for student in student_list:",
                "student.host_party(student_list)",
                "ASSIGN == 0:",
                "for student in student_list:",
                "if student.year == 1:",
                "for i in range(20):",
                "if student != student_list[i]:",
                "make_friends(student, student_list[i])",
                "else:",
                "for j in range(30):",
                "if student != student_list[j]:",
                "make_friends(student, student_list[j])",
                "elif week %3 == 0 and week != 12:",
                "for student in student_list:",
                "student.gradeExperience()",
                "ASSIGN == 12:",
                "for student in student_list:",
                "student.gradeUpdate()",
                "if student.cap < 2:",
                "student.inSchool = False",
                "student_list.remove(student)",
                "ASSIGN = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']",
                "for day in ASSIGN:",
                "for student in student_list:",
                "if day in student.host:",
                "party_time(student, student_list, day)",
                "else:",
                "for loners in student_list:",
                "loners.drinkAlone()",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.usageRate",
                "ASSIGN = total_usepath(student_list)",
                "ASSIGN[week] = ASSIGN",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.attitude",
                "ASSIGN = total_attpath(student_list)",
                "ASSIGN[week] = ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {}",
                "ASSIGN = {}",
                "for week in range(13):",
                "for student in student_list:",
                "student.host_party(student_list)",
                "ASSIGN == 0:",
                "for student in student_list:",
                "if student.year == 1:",
                "for i in range(20):",
                "if student != student_list[i]:",
                "make_friends(student, student_list[i])",
                "else:",
                "for j in range(30):",
                "if student != student_list[j]:",
                "make_friends(student, student_list[j])",
                "elif week %3 == 0 and week != 12:",
                "for student in student_list:",
                "student.gradeExperience()",
                "ASSIGN == 12:",
                "for student in student_list:",
                "student.gradeUpdate()",
                "if student.cap < 2:",
                "student.inSchool = False",
                "student_list.remove(student)",
                "ASSIGN = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']",
                "for day in ASSIGN:",
                "for student in student_list:",
                "if day in student.host:",
                "party_time(student, student_list, day)",
                "else:",
                "for loners in student_list:",
                "loners.drinkAlone()",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.usageRate",
                "ASSIGN = total_usepath(student_list)",
                "ASSIGN[week] = ASSIGN",
                "ASSIGN = 0",
                "for student in student_list:",
                "ASSIGN += student.attitude",
                "ASSIGN = total_attpath(student_list)",
                "ASSIGN[week] = ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in usage_list_2.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in usage_list_3.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in usage_list_4.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 4')",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 3')",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 2')",
                "plt.title('Average usage over the sem')",
                "plt.xlabel('Week')",
                "plt.ylabel('Average usage rate')",
                "plt.legend()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in usage_list_2.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in usage_list_3.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in usage_list_4.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 4')",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 3')",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 2')",
                "plt.title('Average usage over the sem')",
                "plt.xlabel('Week')",
                "plt.ylabel('Average usage rate')",
                "plt.legend()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in attitude_list_2.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in attitude_list_3.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in attitude_list_4.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 4')",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 3')",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 2')",
                "plt.plot(weeks, att, label = 'sem 1')",
                "plt.title('Average attitude over the sem')",
                "plt.xlabel('Week')",
                "plt.ylabel('Average attitude level')",
                "plt.legend()",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in attitude_list_2.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in attitude_list_3.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "ASSIGN = []",
                "ASSIGN = []",
                "for key, value in attitude_list_4.items():",
                "ASSIGN.append(key)",
                "ASSIGN.append(value)",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 4')",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 3')",
                "plt.plot(ASSIGN, ASSIGN, label = 'sem 2')",
                "plt.plot(weeks, att, label = 'sem 1')",
                "plt.title('Average attitude over the sem')",
                "plt.xlabel('Week')",
                "plt.ylabel('Average attitude level')",
                "plt.legend()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in student_list:",
                "ASSIGN.append(len(student.friends))",
                "ASSIGN.append(student.shyness)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []",
                "for student in student_list:",
                "ASSIGN.append(len(student.friends))",
                "ASSIGN.append(student.shyness)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(shyness_score, friendship_len)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.scatter(shyness_score, friendship_len)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "np.random.seed(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "np.random.seed(0)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "with open(\"..path(30-November-2017).csv\", 'rb') as rawdata:",
                "ASSIGN = chardet.detect(rawdata.read(100000))",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "with open(\"..path(30-November-2017).csv\", 'rb') as rawdata:",
                "ASSIGN = chardet.detect(rawdata.read(100000))",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path(30-November-2017).csv\",",
                "ASSIGN='Windows-1252')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path(30-November-2017).csv\",",
                "ASSIGN='Windows-1252')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "suicide_attacks['City'] = suicide_attacks['City'].str.lower()",
                "suicide_attacks['City'] = suicide_attacks['City'].str.strip()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "suicide_attacks['City'] = suicide_attacks['City'].str.lower()",
                "suicide_attacks['City'] = suicide_attacks['City'].str.strip()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = suicide_attacks['Province'].unique()",
                "ASSIGN.sort()",
                "suicide_attacks['Province'] = suicide_attacks['Province'].str.lower()",
                "suicide_attacks['Province'] = suicide_attacks['Province'].str.strip()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = suicide_attacks['Province'].unique()",
                "ASSIGN.sort()",
                "suicide_attacks['Province'] = suicide_attacks['Province'].str.lower()",
                "suicide_attacks['Province'] = suicide_attacks['Province'].str.strip()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = fuzzywuzzy.process.extract(\"d.i khan\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "matches"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = fuzzywuzzy.process.extract(\"d.i khan\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "matches"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):",
                "ASSIGN = df[column].unique()",
                "ASSIGN = fuzzywuzzy.process.extract(string_to_match, strings,",
                "ASSIGN=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "ASSIGN = [matches[0] for matches in matches if matches[1] >= min_ratio]",
                "ASSIGN = df[column].isin(close_matches)",
                "df.loc[ASSIGN, column] = string_to_match",
                "print()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):",
                "ASSIGN = df[column].unique()",
                "ASSIGN = fuzzywuzzy.process.extract(string_to_match, strings,",
                "ASSIGN=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "ASSIGN = [matches[0] for matches in matches if matches[1] >= min_ratio]",
                "ASSIGN = df[column].isin(close_matches)",
                "df.loc[ASSIGN, column] = string_to_match",
                "print()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"d.i khan\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"d.i khan\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = suicide_attacks['City'].unique()",
                "ASSIGN.sort()",
                "cities"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = fuzzywuzzy.process.extract(\"kuram agency\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"kuram agency\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = fuzzywuzzy.process.extract(\"kuram agency\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)",
                "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"kuram agency\")"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = pd.read_csv('path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = pd.read_csv('path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train.Sequence.values[0].split(',')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train.Sequence.values[0].split(',')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "val"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "val"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = np.reshape(np.array(val),(7, 2))",
                "val_shaped",
                "ASSIGN = [int(i[0]) for i in val_shaped]",
                "ASSIGN = [int(i[1]) for i in val_shaped]",
                "ASSIGN = np.reshape(np.array(X),(7,1))",
                "ASSIGN = np.reshape(np.array(y),(7,1))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.reshape(np.array(val),(7, 2))",
                "val_shaped",
                "ASSIGN = [int(i[0]) for i in val_shaped]",
                "ASSIGN = [int(i[1]) for i in val_shaped]",
                "ASSIGN = np.reshape(np.array(X),(7,1))",
                "ASSIGN = np.reshape(np.array(y),(7,1))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_shaped"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X_shaped"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y_shaped"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y_shaped"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = PolynomialFeatures(len(X))",
                "ASSIGN = poly.fit_transform(X_shaped)",
                "ASSIGN = LinearRegression()",
                "ASSIGN.fit(ASSIGN, y_shaped)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN = PolynomialFeatures(len(X))",
                "ASSIGN = poly.fit_transform(X_shaped)",
                "ASSIGN = LinearRegression()",
                "ASSIGN.fit(ASSIGN, y_shaped)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = poly_model.predict(X_poly)",
                "predicted"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = poly_model.predict(X_poly)",
                "predicted"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y_shaped"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y_shaped"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "predicted"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "predicted"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "y_shaped[6][0] -predicted[6][0]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "y_shaped[6][0] -predicted[6][0]"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN = pd.read_csv(\"path\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [col for col in train_data.columns if train_data[col].isnull().any()]",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [col for col in train_data.columns if train_data[col].isnull().any()]",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [col for col in test_data.columns if test_data[col].isnull().any()]",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [col for col in test_data.columns if test_data[col].isnull().any()]",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = (train_data.dtypes == 'object')",
                "ASSIGN = list(s[s].index)",
                "print()",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = (train_data.dtypes == 'object')",
                "ASSIGN = list(s[s].index)",
                "print()",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']",
                "X=train_data[ASSIGN]",
                "ASSIGN=train_data[\"Survived\"]",
                "ASSIGN=test_data[feature_name]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']",
                "X=train_data[ASSIGN]",
                "ASSIGN=train_data[\"Survived\"]",
                "ASSIGN=test_data[feature_name]"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=SimpleImputer(strategy=\"most_frequent\")",
                "ASSIGN= pd.DataFrame(my_imputer.fit_transform(X_train))",
                "ASSIGN=pd.DataFrame(my_imputer.transform(X_test))",
                "ASSIGN=pd.DataFrame(my_imputer.transform(X_valid))",
                "ASSIGN.index = X_train.index",
                "ASSIGN.index = X_valid.index",
                "ASSIGN.index = X_test.index",
                "ASSIGN.columns=X_train.columns",
                "ASSIGN.columns=X_valid.columns",
                "ASSIGN.columns=X_test.columns"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN=SimpleImputer(strategy=\"most_frequent\")",
                "ASSIGN= pd.DataFrame(my_imputer.fit_transform(X_train))",
                "ASSIGN=pd.DataFrame(my_imputer.transform(X_test))",
                "ASSIGN=pd.DataFrame(my_imputer.transform(X_valid))",
                "ASSIGN.index = X_train.index",
                "ASSIGN.index = X_valid.index",
                "ASSIGN.index = X_test.index",
                "ASSIGN.columns=X_train.columns",
                "ASSIGN.columns=X_valid.columns",
                "ASSIGN.columns=X_test.columns"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "Col_with_missing_2 = [col for col in imputed_X_test.columns if imputed_X_test[col].isnull().any()]",
                "print(Col_with_missing_2)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "Col_with_missing_2 = [col for col in imputed_X_test.columns if imputed_X_test[col].isnull().any()]",
                "print(Col_with_missing_2)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = imputed_X_train['Sex'] + \"_\" + imputed_X_train['Embarked']",
                "ASSIGN = imputed_X_valid['Sex'] + \"_\" + imputed_X_valid['Embarked']",
                "ASSIGN = imputed_X_test['Sex'] + \"_\" + imputed_X_test['Embarked']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = imputed_X_train['Sex'] + \"_\" + imputed_X_train['Embarked']",
                "ASSIGN = imputed_X_valid['Sex'] + \"_\" + imputed_X_valid['Embarked']",
                "ASSIGN = imputed_X_test['Sex'] + \"_\" + imputed_X_test['Embarked']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "imputed_X_train[\"Sex_Embarked\"]=New_feature_train",
                "imputed_X_valid[\"Sex_Embarked\"]=New_feature_valid",
                "imputed_X_test[\"Sex_Embarked\"]=New_feature_test"
            ],
            "output_type": "not_existent",
            "content_old": [
                "imputed_X_train[\"Sex_Embarked\"]=New_feature_train",
                "imputed_X_valid[\"Sex_Embarked\"]=New_feature_valid",
                "imputed_X_test[\"Sex_Embarked\"]=New_feature_test"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "imputed_X_test.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "imputed_X_test.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=['Sex','Embarked','Sex_Embarked']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=['Sex','Embarked','Sex_Embarked']"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = OneHotEncoder(handle_unknown='ignore', sparse=False)",
                "ASSIGN = pd.DataFrame(OH_encoder.fit_transform(imputed_X_train[Cat_cols]))",
                "ASSIGN = pd.DataFrame(OH_encoder.transform(imputed_X_valid[Cat_cols]))",
                "ASSIGN = pd.DataFrame(OH_encoder.transform(imputed_X_test[Cat_cols]))",
                "ASSIGN.index = imputed_X_train.index",
                "ASSIGN.index = imputed_X_valid.index",
                "ASSIGN.index = imputed_X_test.index",
                "ASSIGN = imputed_X_train.drop(Cat_cols, axis =1)",
                "ASSIGN = imputed_X_valid.drop(Cat_cols, axis =1)",
                "ASSIGN = imputed_X_test.drop(Cat_cols, axis =1)",
                "ASSIGN = pd.concat([num_X_train, OH_cols_train], axis=1)",
                "ASSIGN = pd.concat([num_X_valid, OH_cols_valid], axis=1)",
                "ASSIGN = pd.concat([num_X_test, OH_cols_test], axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = OneHotEncoder(handle_unknown='ignore', sparse=False)",
                "ASSIGN = pd.DataFrame(OH_encoder.fit_transform(imputed_X_train[Cat_cols]))",
                "ASSIGN = pd.DataFrame(OH_encoder.transform(imputed_X_valid[Cat_cols]))",
                "ASSIGN = pd.DataFrame(OH_encoder.transform(imputed_X_test[Cat_cols]))",
                "ASSIGN.index = imputed_X_train.index",
                "ASSIGN.index = imputed_X_valid.index",
                "ASSIGN.index = imputed_X_test.index",
                "ASSIGN = imputed_X_train.drop(Cat_cols, axis =1)",
                "ASSIGN = imputed_X_valid.drop(Cat_cols, axis =1)",
                "ASSIGN = imputed_X_test.drop(Cat_cols, axis =1)",
                "ASSIGN = pd.concat([num_X_train, OH_cols_train], axis=1)",
                "ASSIGN = pd.concat([num_X_valid, OH_cols_valid], axis=1)",
                "ASSIGN = pd.concat([num_X_test, OH_cols_test], axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN=ASSIGN.rename(columns={0:\"Sex1\", 1:\"Sex2\"})",
                "ASSIGN=ASSIGN.rename(columns={2:\"C\", 3:\"Q\",4:\"S\"})",
                "ASSIGN=ASSIGN.rename(columns={0:\"Sex1\", 1:\"Sex2\"})",
                "ASSIGN=ASSIGN.rename(columns={2:\"C\", 3:\"Q\",4:\"S\"})",
                "ASSIGN=ASSIGN.rename(columns={0:\"Sex1\", 1:\"Sex2\"})",
                "ASSIGN=ASSIGN.rename(columns={2:\"C\", 3:\"Q\",4:\"S\"})"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN = ASSIGN.apply(pd.to_numeric)",
                "ASSIGN=ASSIGN.rename(columns={0:\"Sex1\", 1:\"Sex2\"})",
                "ASSIGN=ASSIGN.rename(columns={2:\"C\", 3:\"Q\",4:\"S\"})",
                "ASSIGN=ASSIGN.rename(columns={0:\"Sex1\", 1:\"Sex2\"})",
                "ASSIGN=ASSIGN.rename(columns={2:\"C\", 3:\"Q\",4:\"S\"})",
                "ASSIGN=ASSIGN.rename(columns={0:\"Sex1\", 1:\"Sex2\"})",
                "ASSIGN=ASSIGN.rename(columns={2:\"C\", 3:\"Q\",4:\"S\"})"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "OH_X_test.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "OH_X_test.head(10)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = XGBClassifier(n_estimators=1000, learning_rate=0.001)",
                "ASSIGN.fit(OH_X_train, y_train, early_stopping_rounds=50,",
                "ASSIGN=[(OH_X_valid, y_valid)], verbose=False)",
                "ASSIGN.fit(OH_X_train, y_train)",
                "ASSIGN = my_model.predict(OH_X_valid)",
                "print(,metrics.accuracy_score(y_valid, ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = XGBClassifier(n_estimators=1000, learning_rate=0.001)",
                "ASSIGN.fit(OH_X_train, y_train, early_stopping_rounds=50,",
                "ASSIGN=[(OH_X_valid, y_valid)], verbose=False)",
                "ASSIGN.fit(OH_X_train, y_train)",
                "ASSIGN = my_model.predict(OH_X_valid)",
                "print(,metrics.accuracy_score(y_valid, ASSIGN))"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Post Development Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = my_model.predict(OH_X_test)",
                "ASSIGN = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions2})",
                "ASSIGN.to_csv('my_submission_02_06.csv', index=False)",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = my_model.predict(OH_X_test)",
                "ASSIGN = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions2})",
                "ASSIGN.to_csv('my_submission_02_06.csv', index=False)",
                "print()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN = []"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN = []"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def generateCromosome():",
                "chromosome.clear()",
                "for i in range(4):",
                "ASSIGN = []",
                "for j in range(6):",
                "ASSIGN.append(random.randint(0,1))",
                "chromosome.append(ASSIGN)",
                "print (\"Generated chromosome = \",chromosome)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def generateCromosome():",
                "chromosome.clear()",
                "for i in range(4):",
                "ASSIGN = []",
                "for j in range(6):",
                "ASSIGN.append(random.randint(0,1))",
                "chromosome.append(ASSIGN)",
                "print (\"Generated chromosome = \",chromosome)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def evaluateSolution():",
                "fitval.clear()",
                "for i in range(4):",
                "ASSIGN = 0",
                "for j in range(1,6):",
                "ASSIGN += math.pow(2,5-j)*chromosome[i][j]",
                "if chromosome[i][0] == 1:",
                "ASSIGN = - ASSIGN",
                "fitval.append(ASSIGN)",
                "print (\"Fitval = \",fitval)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def evaluateSolution():",
                "fitval.clear()",
                "for i in range(4):",
                "ASSIGN = 0",
                "for j in range(1,6):",
                "ASSIGN += math.pow(2,5-j)*chromosome[i][j]",
                "if chromosome[i][0] == 1:",
                "ASSIGN = - ASSIGN",
                "fitval.append(ASSIGN)",
                "print (\"Fitval = \",fitval)"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "def func(x):",
                "return -(x*x)+5"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def func(x):",
                "return -(x*x)+5"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def selection():",
                "ASSIGN = [[0 for i in range(2)] for j in range(4)]",
                "print (ASSIGN)",
                "ASSIGN=-1",
                "ASSIGN=-1",
                "for i in range(4):",
                "ASSIGN[i][0]=func(fitval[i])",
                "ASSIGN[i][1]=i",
                "ASSIGN=sorted(ASSIGN,key=lambda l:l[0], reverse=True)",
                "ASSIGN=ftval2[0][1]",
                "ASSIGN=ftval2[1][1]",
                "ASSIGN = ftval2[0][0]",
                "print(,ASSIGN)",
                "return c1, c2, bstval"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def selection():",
                "ASSIGN = [[0 for i in range(2)] for j in range(4)]",
                "print (ASSIGN)",
                "ASSIGN=-1",
                "ASSIGN=-1",
                "for i in range(4):",
                "ASSIGN[i][0]=func(fitval[i])",
                "ASSIGN[i][1]=i",
                "ASSIGN=sorted(ASSIGN,key=lambda l:l[0], reverse=True)",
                "ASSIGN=ftval2[0][1]",
                "ASSIGN=ftval2[1][1]",
                "ASSIGN = ftval2[0][0]",
                "print(,ASSIGN)",
                "return c1, c2, bstval"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def crossover(s1,s2):",
                "ASSIGN = random.randint(0,5)",
                "for i in range(ASSIGN, 6):",
                "chromosome[s1][i],chromosome[s2][i] = chromosome[s2][i],chromosome[s1][i]",
                "print(,ASSIGN,,c1,c2,,chromosome)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def crossover(s1,s2):",
                "ASSIGN = random.randint(0,5)",
                "for i in range(ASSIGN, 6):",
                "chromosome[s1][i],chromosome[s2][i] = chromosome[s2][i],chromosome[s1][i]",
                "print(,ASSIGN,,c1,c2,,chromosome)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def mutation():",
                "ASSIGN = random.randint(1,50)",
                "ASSIGN == 30:",
                "ASSIGN = random.randint(0,3)",
                "ASSIGN = random.randint(0,5)",
                "chromosome[ASSIGN][ASSIGN] = 1 - chromosome[ASSIGN][ASSIGN]",
                "print(,ASSIGN,,ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def mutation():",
                "ASSIGN = random.randint(1,50)",
                "ASSIGN == 30:",
                "ASSIGN = random.randint(0,3)",
                "ASSIGN = random.randint(0,5)",
                "chromosome[ASSIGN][ASSIGN] = 1 - chromosome[ASSIGN][ASSIGN]",
                "print(,ASSIGN,,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "generateCromosome()",
                "for i in range(1000):",
                "print(,i+1)",
                "evaluateSolution()",
                "c1,c2,bstval=selection()",
                "ASSIGN==5.0:",
                "break",
                "crossover(c1,c2)",
                "mutation()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "generateCromosome()",
                "for i in range(1000):",
                "print(,i+1)",
                "evaluateSolution()",
                "c1,c2,bstval=selection()",
                "ASSIGN==5.0:",
                "break",
                "crossover(c1,c2)",
                "mutation()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",",
                "ASSIGN=\"github_repos\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",",
                "ASSIGN=\"github_repos\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = (\"\"\"",
                "-- Select all the columns we want in our joined table",
                "SELECT L.license, COUNT(sf.path) AS number_of_files",
                "FROM `bigquery-public-data.github_repos.sample_files` as sf",
                "-- Table to merge into sample_files",
                "INNER JOIN `bigquery-public-data.github_repos.licenses` as L",
                "ON sf.repo_name = L.repo_name -- what columns should we join on?",
                "GROUP BY L.license",
                "ORDER BY number_of_files DESC",
                "\"\"\")",
                "ASSIGN = github.query_to_pandas_safe(query, max_gb_scanned=6)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = (\"\"\"",
                "-- Select all the columns we want in our joined table",
                "SELECT L.license, COUNT(sf.path) AS number_of_files",
                "FROM `bigquery-public-data.github_repos.sample_files` as sf",
                "-- Table to merge into sample_files",
                "INNER JOIN `bigquery-public-data.github_repos.licenses` as L",
                "ON sf.repo_name = L.repo_name -- what columns should we join on?",
                "GROUP BY L.license",
                "ORDER BY number_of_files DESC",
                "\"\"\")",
                "ASSIGN = github.query_to_pandas_safe(query, max_gb_scanned=6)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(file_count_by_license)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(file_count_by_license)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "github.head(\"sample_commits\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "github.head(\"sample_commits\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = (\"\"\"",
                "WITH repolist AS",
                "(",
                "SELECT repo_name",
                "FROM `bigquery-public-data.github_repos.sample_files`",
                "WHERE path LIKE '%.py'",
                "GROUP BY repo_name",
                ")",
                "SELECT sf.repo_name, COUNT(sc.commit) AS number_of_commits",
                "FROM",
                "repolist as sf",
                "INNER JOIN `bigquery-public-data.github_repos.sample_commits` as sc",
                "ON sc.repo_name = sf.repo_name",
                "GROUP BY sf.repo_name",
                "ORDER BY number_of_commits DESC",
                "\"\"\")",
                "github.estimate_query_size(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = (\"\"\"",
                "WITH repolist AS",
                "(",
                "SELECT repo_name",
                "FROM `bigquery-public-data.github_repos.sample_files`",
                "WHERE path LIKE '%.py'",
                "GROUP BY repo_name",
                ")",
                "SELECT sf.repo_name, COUNT(sc.commit) AS number_of_commits",
                "FROM",
                "repolist as sf",
                "INNER JOIN `bigquery-public-data.github_repos.sample_commits` as sc",
                "ON sc.repo_name = sf.repo_name",
                "GROUP BY sf.repo_name",
                "ORDER BY number_of_commits DESC",
                "\"\"\")",
                "github.estimate_query_size(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = github.query_to_pandas_safe(query_commit, max_gb_scanned=6)",
                "python_commits"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = github.query_to_pandas_safe(query_commit, max_gb_scanned=6)",
                "python_commits"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "binder.bind(globals())",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "binder.bind(globals())",
                "print()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = bigquery.Client()",
                "ASSIGN = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")",
                "ASSIGN = client.get_dataset(dataset_ref)",
                "ASSIGN = dataset_ref.table(\"comments\")",
                "ASSIGN = client.get_table(table_ref)",
                "ASSIGN.list_rows(ASSIGN, max_results=5).to_dataframe()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = bigquery.Client()",
                "ASSIGN = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")",
                "ASSIGN = client.get_dataset(dataset_ref)",
                "ASSIGN = dataset_ref.table(\"comments\")",
                "ASSIGN = client.get_table(table_ref)",
                "ASSIGN.list_rows(ASSIGN, max_results=5).to_dataframe()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df['MSE']",
                "ASSIGN = df['ESE']",
                "sns.scatterplot(ASSIGN,ASSIGN)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df['MSE']",
                "ASSIGN = df['ESE']",
                "sns.scatterplot(ASSIGN,ASSIGN)"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = 0.01",
                "ASSIGN = 10000",
                "ASSIGN = float(len(x))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = 0.01",
                "ASSIGN = 10000",
                "ASSIGN = float(len(x))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for i in range(count):",
                "ASSIGN = b1*x + b0",
                "ASSIGN = ASSIGN - (alphapath)*sum(x*(y_bar-y))",
                "ASSIGN = ASSIGN - (alphapath)*sum(y_bar-y)",
                "print(ASSIGN,ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for i in range(count):",
                "ASSIGN = b1*x + b0",
                "ASSIGN = ASSIGN - (alphapath)*sum(x*(y_bar-y))",
                "ASSIGN = ASSIGN - (alphapath)*sum(y_bar-y)",
                "print(ASSIGN,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = b1*x + b0",
                "plt.scatter(x,y)",
                "plt.plot([min(x),max(x)],[min(ASSIGN),max(ASSIGN)],color='red')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = b1*x + b0",
                "plt.scatter(x,y)",
                "plt.plot([min(x),max(x)],[min(ASSIGN),max(ASSIGN)],color='red')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "SETUP",
                "CHECKPOINT",
                "def RSE(y_true,y_predict):",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = math.sqrt(RSSpath(len(y_true)-2))",
                "return rse",
                "ASSIGN = RSE(df['ESE'],y_bar)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "SETUP",
                "CHECKPOINT",
                "def RSE(y_true,y_predict):",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = math.sqrt(RSSpath(len(y_true)-2))",
                "return rse",
                "ASSIGN = RSE(df['ESE'],y_bar)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.array(df['MSE']).reshape(-1,1)",
                "ASSIGN = np.array(df['ESE']).reshape(-1,1)",
                "ASSIGN = LinearRegression()",
                "ASSIGN.fit(ASSIGN,ASSIGN)",
                "print(ASSIGN.coef_)",
                "print(ASSIGN.intercept_)",
                "ASSIGN = lr.predict(X)",
                "ASSIGN = RSE(Y,yp)",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.array(df['MSE']).reshape(-1,1)",
                "ASSIGN = np.array(df['ESE']).reshape(-1,1)",
                "ASSIGN = LinearRegression()",
                "ASSIGN.fit(ASSIGN,ASSIGN)",
                "print(ASSIGN.coef_)",
                "print(ASSIGN.intercept_)",
                "ASSIGN = lr.predict(X)",
                "ASSIGN = RSE(Y,yp)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "None"
            ],
            "content": [
                "ASSIGN=10000"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=10000"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {",
                "'x1': np.random.randint(0,3,sampleNumber) ,",
                "'x2': np.random.randint(0,3,sampleNumber) ,",
                "'x3': np.random.randint(0,2,sampleNumber) ,",
                "'x4': np.random.randint(0,3,sampleNumber) ,",
                "'x5': np.random.randint(0,2,sampleNumber) ,",
                "'x6': np.random.randint(0,2,sampleNumber) ,",
                "'y' : np.zeros(sampleNumber, dtype=bool)",
                "}",
                "ASSIGN = pd.DataFrame(ASSIGN=d)",
                "SLICE=(SLICE + SLICE + SLICE + SLICE + SLICE+ SLICE)>4",
                "X=ASSIGN[['x1','x2','x3','x4','x5','x6']]",
                "ASSIGN=data[[\"ASSIGN\"]]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {",
                "'x1': np.random.randint(0,3,sampleNumber) ,",
                "'x2': np.random.randint(0,3,sampleNumber) ,",
                "'x3': np.random.randint(0,2,sampleNumber) ,",
                "'x4': np.random.randint(0,3,sampleNumber) ,",
                "'x5': np.random.randint(0,2,sampleNumber) ,",
                "'x6': np.random.randint(0,2,sampleNumber) ,",
                "'y' : np.zeros(sampleNumber, dtype=bool)",
                "}",
                "ASSIGN = pd.DataFrame(ASSIGN=d)",
                "SLICE=(SLICE + SLICE + SLICE + SLICE + SLICE+ SLICE)>4",
                "X=ASSIGN[['x1','x2','x3','x4','x5','x6']]",
                "ASSIGN=data[[\"ASSIGN\"]]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "X_train, X_test, y_train, y_test = train_test_split(",
                "ASSIGN=.20, random_state=42)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "X_train, X_test, y_train, y_test = train_test_split(",
                "ASSIGN=.20, random_state=42)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=X_train",
                "ASSIGN[\"y\"]=y_train",
                "del X_train",
                "del y_train"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN=X_train",
                "ASSIGN[\"y\"]=y_train",
                "del X_train",
                "del y_train"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN= setup(data = train_Data, target = \"y\")"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN= setup(data = train_Data, target = \"y\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "compare_models()"
            ],
            "output_type": "display_data",
            "content_old": [
                "compare_models()"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = create_model('ASSIGN')"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = create_model('ASSIGN')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "plot_model(lr,\"confusion_matrix\")"
            ],
            "output_type": "display_data",
            "content_old": [
                "plot_model(lr,\"confusion_matrix\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "evaluate_model(lr)"
            ],
            "output_type": "display_data",
            "content_old": [
                "evaluate_model(lr)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = predict_model(lr, data = X_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = predict_model(lr, data = X_test)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "lr_pred"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "lr_pred"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "y_test.reset_index(drop=True, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "y_test.reset_index(drop=True, inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y_test"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y_test"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=ASSIGN.astype(\"int\").values.T"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=ASSIGN.astype(\"int\").values.T"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.nonzero(lr_pred[\"Label\"].values==y_test)[0]",
                "ASSIGN = np.nonzero(lr_pred[\"Label\"].values!=y_test)[0]",
                "print(len(ASSIGN),)",
                "print(len(ASSIGN),)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.nonzero(lr_pred[\"Label\"].values==y_test)[0]",
                "ASSIGN = np.nonzero(lr_pred[\"Label\"].values!=y_test)[0]",
                "print(len(ASSIGN),)",
                "print(len(ASSIGN),)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Data Ingestion Activity"
            ],
            "content": [
                "plt.figure(figsize=(20, 20))",
                "plt.title(\"Original\")",
                "plt.imshow(mpimg.imread('..path'))",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(20, 20))",
                "plt.title(\"Original\")",
                "plt.imshow(mpimg.imread('..path'))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = cv.imread('..path',0)",
                "ASSIGN =img[500:650, 500:600]",
                "plt.imshow(ASSIGN,cmap = 'gray')",
                "plt.title('ASSIGN'), plt.xticks([]), plt.yticks([])",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = cv.imread('..path',0)",
                "ASSIGN =img[500:650, 500:600]",
                "plt.imshow(ASSIGN,cmap = 'gray')",
                "plt.title('ASSIGN'), plt.xticks([]), plt.yticks([])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = img.copy()",
                "ASSIGN = template.shape[::-1]",
                "ASSIGN = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',",
                "'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']",
                "plt.figure(figsize=(20, 20))",
                "plt.imshow(mpimg.imread('..path'))",
                "plt.title('Detected Point')",
                "ASSIGN=[]",
                "for meth in ASSIGN:",
                "ASSIGN = img2.copy()",
                "ASSIGN = eval(meth)",
                "ASSIGN = cv.matchTemplate(img,template,method)",
                "ASSIGN = cv.minMaxLoc(res)",
                "if ASSIGN in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:",
                "ASSIGN = min_loc",
                "else:",
                "ASSIGN = max_loc",
                "ASSIGN+=[(meth,ASSIGN,ASSIGN)]",
                "ASSIGN = plt.gca()",
                "ASSIGN.add_patch( Rectangle(ASSIGN,",
                "ASSIGN,",
                "ASSIGN ='none',",
                "ASSIGN ='b',",
                "ASSIGN = 4) )",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = img.copy()",
                "ASSIGN = template.shape[::-1]",
                "ASSIGN = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',",
                "'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']",
                "plt.figure(figsize=(20, 20))",
                "plt.imshow(mpimg.imread('..path'))",
                "plt.title('Detected Point')",
                "ASSIGN=[]",
                "for meth in ASSIGN:",
                "ASSIGN = img2.copy()",
                "ASSIGN = eval(meth)",
                "ASSIGN = cv.matchTemplate(img,template,method)",
                "ASSIGN = cv.minMaxLoc(res)",
                "if ASSIGN in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:",
                "ASSIGN = min_loc",
                "else:",
                "ASSIGN = max_loc",
                "ASSIGN+=[(meth,ASSIGN,ASSIGN)]",
                "ASSIGN = plt.gca()",
                "ASSIGN.add_patch( Rectangle(ASSIGN,",
                "ASSIGN,",
                "ASSIGN ='none',",
                "ASSIGN ='b',",
                "ASSIGN = 4) )",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN=160",
                "plt.figure(figsize=(20, 20))",
                "for r in result:",
                "ASSIGN+=1",
                "plt.subplot(ASSIGN),plt.imshow(res,cmap = 'gray')",
                "ASSIGN =img[ r[1][1]:r[1][1]+r[3], r[1][0]: r[1][0]+r[2]]",
                "plt.imshow(ASSIGN,cmap = 'gray')",
                "plt.title(r[0]), plt.xticks([]), plt.yticks([])",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN=160",
                "plt.figure(figsize=(20, 20))",
                "for r in result:",
                "ASSIGN+=1",
                "plt.subplot(ASSIGN),plt.imshow(res,cmap = 'gray')",
                "ASSIGN =img[ r[1][1]:r[1][1]+r[3], r[1][0]: r[1][0]+r[2]]",
                "plt.imshow(ASSIGN,cmap = 'gray')",
                "plt.title(r[0]), plt.xticks([]), plt.yticks([])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Post Development Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],",
                "ASSIGN.loc[:,'MSSubClass':'SaleCondition']))",
                "ASSIGN = np.log1p(ASSIGN)",
                "ASSIGN = all_data.dtypes[all_data.dtypes != \"object\"].index",
                "ASSIGN = train[numeric_feats].apply(lambda x: skew(x.dropna()))",
                "ASSIGN = ASSIGN[ASSIGN > 0.75]",
                "ASSIGN = ASSIGN.index",
                "ASSIGN[ASSIGN] = np.log1p(ASSIGN[ASSIGN])",
                "ASSIGN = pd.get_dummies(ASSIGN)",
                "ASSIGN = ASSIGN.fillna(ASSIGN.mean())",
                "ASSIGN = all_data[:train.shape[0]]",
                "ASSIGN = all_data[train.shape[0]:]",
                "ASSIGN = train.SalePrice",
                "def rmse_cv(model):",
                "ASSIGN= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))",
                "return(ASSIGN)",
                "ASSIGN = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)",
                "rmse_cv(ASSIGN).mean()",
                "ASSIGN = pd.Series(model_lasso.coef_, index = X_train.columns)",
                "print( + str(sum(ASSIGN != 0)) + + str(sum(ASSIGN == 0)) + )",
                "ASSIGN = np.expm1(model_lasso.predict(X_test))",
                "ASSIGN = pd.DataFrame({\"id\":test.Id, \"SalePrice\":lasso_preds})",
                "ASSIGN.to_csv(\"ridge_sol.csv\", index = False)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],",
                "ASSIGN.loc[:,'MSSubClass':'SaleCondition']))",
                "ASSIGN = np.log1p(ASSIGN)",
                "ASSIGN = all_data.dtypes[all_data.dtypes != \"object\"].index",
                "ASSIGN = train[numeric_feats].apply(lambda x: skew(x.dropna()))",
                "ASSIGN = ASSIGN[ASSIGN > 0.75]",
                "ASSIGN = ASSIGN.index",
                "ASSIGN[ASSIGN] = np.log1p(ASSIGN[ASSIGN])",
                "ASSIGN = pd.get_dummies(ASSIGN)",
                "ASSIGN = ASSIGN.fillna(ASSIGN.mean())",
                "ASSIGN = all_data[:train.shape[0]]",
                "ASSIGN = all_data[train.shape[0]:]",
                "ASSIGN = train.SalePrice",
                "def rmse_cv(model):",
                "ASSIGN= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))",
                "return(ASSIGN)",
                "ASSIGN = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)",
                "rmse_cv(ASSIGN).mean()",
                "ASSIGN = pd.Series(model_lasso.coef_, index = X_train.columns)",
                "print( + str(sum(ASSIGN != 0)) + + str(sum(ASSIGN == 0)) + )",
                "ASSIGN = np.expm1(model_lasso.predict(X_test))",
                "ASSIGN = pd.DataFrame({\"id\":test.Id, \"SalePrice\":lasso_preds})",
                "ASSIGN.to_csv(\"ridge_sol.csv\", index = False)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "class SimpleLinearRegression:",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "def fit(self, x_train, y_train):",
                "ASSIGN = sum(x_train)",
                "ASSIGN = sum(y_train)",
                "ASSIGN = np.sum(np.square(x_train))",
                "ASSIGN = np.sum(np.square(y_train))",
                "ASSIGN = np.dot(x_train,y_train)",
                "ASSIGN = len(x_train)",
                "ASSIGN = sum_of_x2 - sum_of_x * sum_of_xpath",
                "ASSIGN = sum_of_y2 - sum_of_y * sum_of_ypath",
                "ASSIGN = length * dotproduct - sum_of_x * sum_of_y",
                "ASSIGN = (length * sum_of_x2 - sum_of_x * sum_of_x) * (length * sum_of_y2 - (sum_of_y * sum_of_y))",
                "ASSIGN = dotproduct - sum_of_x * sum_of_y path",
                "self.ASSIGN = np.square(ASSIGN path(ASSIGN))",
                "self.ASSIGN = ASSIGN path((ASSIGN path) * sum_of_xpath)",
                "self.ASSIGN = ASSIGN path",
                "def predict(self,x_test):",
                "return x_test * self.coef + self.intercept"
            ],
            "output_type": "not_existent",
            "content_old": [
                "class SimpleLinearRegression:",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "ASSIGN = 0",
                "def fit(self, x_train, y_train):",
                "ASSIGN = sum(x_train)",
                "ASSIGN = sum(y_train)",
                "ASSIGN = np.sum(np.square(x_train))",
                "ASSIGN = np.sum(np.square(y_train))",
                "ASSIGN = np.dot(x_train,y_train)",
                "ASSIGN = len(x_train)",
                "ASSIGN = sum_of_x2 - sum_of_x * sum_of_xpath",
                "ASSIGN = sum_of_y2 - sum_of_y * sum_of_ypath",
                "ASSIGN = length * dotproduct - sum_of_x * sum_of_y",
                "ASSIGN = (length * sum_of_x2 - sum_of_x * sum_of_x) * (length * sum_of_y2 - (sum_of_y * sum_of_y))",
                "ASSIGN = dotproduct - sum_of_x * sum_of_y path",
                "self.ASSIGN = np.square(ASSIGN path(ASSIGN))",
                "self.ASSIGN = ASSIGN path((ASSIGN path) * sum_of_xpath)",
                "self.ASSIGN = ASSIGN path",
                "def predict(self,x_test):",
                "return x_test * self.coef + self.intercept"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = np.array([ 1, 2, 3, 4])",
                "ASSIGN = np.array([ 2, 3, 4, 4])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.array([ 1, 2, 3, 4])",
                "ASSIGN = np.array([ 2, 3, 4, 4])"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = SimpleLinearRegression()",
                "ASSIGN.fit(x_train,y_train)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = SimpleLinearRegression()",
                "ASSIGN.fit(x_train,y_train)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(, slr.coef)",
                "print('Y-Intercept:',slr.intercept)",
                "print('R-Squared:',slr.rsquared)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(, slr.coef)",
                "print('Y-Intercept:',slr.intercept)",
                "print('R-Squared:',slr.rsquared)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = LinearRegression()",
                "ASSIGN.fit(x_train.reshape(-1,1), y_train.reshape(-1,1))",
                "print(ASSIGN.coef_)",
                "print(ASSIGN.intercept_)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = LinearRegression()",
                "ASSIGN.fit(x_train.reshape(-1,1), y_train.reshape(-1,1))",
                "print(ASSIGN.coef_)",
                "print(ASSIGN.intercept_)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(",
                "ASSIGN='..path',",
                "ASSIGN=None,",
                "ASSIGN=',')",
                "ASSIGN.columns=['A', 'B', 'C', 'D', 'class']",
                "ASSIGN.dropna(how=\"all\", inplace=True) # drops the empty line at file-end",
                "ASSIGN.tail()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(",
                "ASSIGN='..path',",
                "ASSIGN=None,",
                "ASSIGN=',')",
                "ASSIGN.columns=['A', 'B', 'C', 'D', 'class']",
                "ASSIGN.dropna(how=\"all\", inplace=True) # drops the empty line at file-end",
                "ASSIGN.tail()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df.ix[:,0:4].values",
                "ASSIGN = df.ix[:,4].values"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = df.ix[:,0:4].values",
                "ASSIGN = df.ix[:,4].values"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "y"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = {1: 'type0',",
                "2: 'type1',",
                "3: 'type2'}",
                "ASSIGN = {0: 'A',",
                "1: 'B',",
                "2: 'C',",
                "3: 'D'}",
                "with plt.style.context('seaborn-whitegrid'):",
                "plt.figure(figsize=(8, 6))",
                "for cnt in range(4):",
                "plt.subplot(2, 2, cnt+1)",
                "for lab in ('type0', 'type1', 'type2'):",
                "plt.hist(X[y==lab, cnt],",
                "ASSIGN=lab,",
                "ASSIGN=10,",
                "ASSIGN=0.3,)",
                "plt.xlabel(ASSIGN[cnt])",
                "plt.legend(loc='upper right', fancybox=True, fontsize=8)",
                "plt.tight_layout()",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = {1: 'type0',",
                "2: 'type1',",
                "3: 'type2'}",
                "ASSIGN = {0: 'A',",
                "1: 'B',",
                "2: 'C',",
                "3: 'D'}",
                "with plt.style.context('seaborn-whitegrid'):",
                "plt.figure(figsize=(8, 6))",
                "for cnt in range(4):",
                "plt.subplot(2, 2, cnt+1)",
                "for lab in ('type0', 'type1', 'type2'):",
                "plt.hist(X[y==lab, cnt],",
                "ASSIGN=lab,",
                "ASSIGN=10,",
                "ASSIGN=0.3,)",
                "plt.xlabel(ASSIGN[cnt])",
                "plt.legend(loc='upper right', fancybox=True, fontsize=8)",
                "plt.tight_layout()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = StandardScaler().fit_transform(X)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = StandardScaler().fit_transform(X)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X_std"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "X_std"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = np.mean(X_std, axis=0)",
                "ASSIGN = (X_std - mean_vec).T.dot((X_std - mean_vec)) path(X_std.shape[0]-1)",
                "print('Covariance matrix \\n%s' %ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = np.mean(X_std, axis=0)",
                "ASSIGN = (X_std - mean_vec).T.dot((X_std - mean_vec)) path(X_std.shape[0]-1)",
                "print('Covariance matrix \\n%s' %ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.cov(X_std.T)",
                "ASSIGN = np.linalg.eig(cov_mat)",
                "print('Eigenvectors \\n%s' %eig_vecs)",
                "print('\\nEigenvalues \\n%s' %eig_vals)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.cov(X_std.T)",
                "ASSIGN = np.linalg.eig(cov_mat)",
                "print('Eigenvectors \\n%s' %eig_vecs)",
                "print('\\nEigenvalues \\n%s' %eig_vals)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]",
                "ASSIGN.sort(key=lambda x: x[0], reverse=True)",
                "print('Eigenvalues in descending order:')",
                "for i in ASSIGN:",
                "print(i[0])"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]",
                "ASSIGN.sort(key=lambda x: x[0], reverse=True)",
                "print('Eigenvalues in descending order:')",
                "for i in ASSIGN:",
                "print(i[0])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = sum(eig_vals)",
                "ASSIGN = [(i path)*100 for i in sorted(eig_vals, reverse=True)]",
                "ASSIGN = np.cumsum(var_exp)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = sum(eig_vals)",
                "ASSIGN = [(i path)*100 for i in sorted(eig_vals, reverse=True)]",
                "ASSIGN = np.cumsum(var_exp)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "with plt.style.context('seaborn-whitegrid'):",
                "plt.figure(figsize=(6, 4))",
                "plt.bar(range(4), var_exp, alpha=0.5, align='center',",
                "ASSIGN='individual explained variance')",
                "plt.step(range(4), cum_var_exp, where='mid',",
                "ASSIGN='cumulative explained variance')",
                "plt.ylabel('Explained variance ratio')",
                "plt.xlabel('Principal components')",
                "plt.legend(loc='best')",
                "plt.tight_layout()"
            ],
            "output_type": "display_data",
            "content_old": [
                "with plt.style.context('seaborn-whitegrid'):",
                "plt.figure(figsize=(6, 4))",
                "plt.bar(range(4), var_exp, alpha=0.5, align='center',",
                "ASSIGN='individual explained variance')",
                "plt.step(range(4), cum_var_exp, where='mid',",
                "ASSIGN='cumulative explained variance')",
                "plt.ylabel('Explained variance ratio')",
                "plt.xlabel('Principal components')",
                "plt.legend(loc='best')",
                "plt.tight_layout()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.hstack((eig_pairs[0][1].reshape(4,1),",
                "eig_pairs[1][1].reshape(4,1)))",
                "print('Matrix W:\\n', ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.hstack((eig_pairs[0][1].reshape(4,1),",
                "eig_pairs[1][1].reshape(4,1)))",
                "print('Matrix W:\\n', ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = X_std.dot(matrix_w)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = X_std.dot(matrix_w)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "with plt.style.context('seaborn-whitegrid'):",
                "plt.figure(figsize=(6, 4))",
                "for lab, col in zip(('type0', 'type1', 'type2'),",
                "('blue', 'red', 'green')):",
                "plt.scatter(Y[y==lab, 0],",
                "Y[y==lab, 1],",
                "ASSIGN=lab,",
                "ASSIGN=col)",
                "plt.xlabel('Principal Component 1')",
                "plt.ylabel('Principal Component 2')",
                "plt.legend(loc='lower center')",
                "plt.tight_layout()",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "with plt.style.context('seaborn-whitegrid'):",
                "plt.figure(figsize=(6, 4))",
                "for lab, col in zip(('type0', 'type1', 'type2'),",
                "('blue', 'red', 'green')):",
                "plt.scatter(Y[y==lab, 0],",
                "Y[y==lab, 1],",
                "ASSIGN=lab,",
                "ASSIGN=col)",
                "plt.xlabel('Principal Component 1')",
                "plt.ylabel('Principal Component 2')",
                "plt.legend(loc='lower center')",
                "plt.tight_layout()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(discoveries.dtypes)",
                "ASSIGN = pd.to_datetime(ASSIGN)",
                "print(discoveries.dtypes)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(discoveries.dtypes)",
                "ASSIGN = pd.to_datetime(ASSIGN)",
                "print(discoveries.dtypes)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "discoveries.set_index('date', inplace = True)",
                "ASSIGN = discoveries.plot(color='blue')",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.set_ylabel('Number of great discoveries')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "discoveries.set_index('date', inplace = True)",
                "ASSIGN = discoveries.plot(color='blue')",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.set_ylabel('Number of great discoveries')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "plt.style.use('ggplot')",
                "ASSIGN = discoveries.plot()",
                "ASSIGN.set_title('ggplot Style')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "plt.style.use('ggplot')",
                "ASSIGN = discoveries.plot()",
                "ASSIGN.set_title('ggplot Style')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "plt.style.use('fivethirtyeight')",
                "ASSIGN = discoveries.plot()",
                "ASSIGN.set_title('FiveThirtyEight Style')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "plt.style.use('fivethirtyeight')",
                "ASSIGN = discoveries.plot()",
                "ASSIGN.set_title('FiveThirtyEight Style')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = discoveries.plot(color='blue',figsize =(8, 3), linewidth=2, fontsize=6)",
                "ASSIGN.set_title('Number of great inventions and scientific discoveries from 1860 to 1959', fontsize=8)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = discoveries.plot(color='blue',figsize =(8, 3), linewidth=2, fontsize=6)",
                "ASSIGN.set_title('Number of great inventions and scientific discoveries from 1860 to 1959', fontsize=8)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = discoveries ['1939-01-01': '1958-01-01']",
                "ASSIGN = discoveries_subset_2.plot(color='blue', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = discoveries ['1939-01-01': '1958-01-01']",
                "ASSIGN = discoveries_subset_2.plot(color='blue', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = discoveries.plot(color='blue', fontsize=6)",
                "ASSIGN.axvline('1939-01-01', color='red', linestyle='--')",
                "ASSIGN.axhline(4, color='green', linestyle='--')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = discoveries.plot(color='blue', fontsize=6)",
                "ASSIGN.axvline('1939-01-01', color='red', linestyle='--')",
                "ASSIGN.axhline(4, color='green', linestyle='--')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = discoveries.plot(color='blue', fontsize=6)",
                "ASSIGN.axvspan('1900-01-01', '1915-01-01', color='red', alpha=0.3)",
                "ASSIGN.axhspan(6, 8, color='green', alpha=0.3)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = discoveries.plot(color='blue', fontsize=6)",
                "ASSIGN.axvspan('1900-01-01', '1915-01-01', color='red', alpha=0.3)",
                "ASSIGN.axhspan(6, 8, color='green', alpha=0.3)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('path', parse_dates = ['datestamp'])",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('path', parse_dates = ['datestamp'])",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.set_index('datestamp')",
                "print(ASSIGN.isnull().sum())"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.set_index('datestamp')",
                "print(ASSIGN.isnull().sum())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.fillna(method='bfill')",
                "print(ASSIGN.isnull().sum())"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = ASSIGN.fillna(method='bfill')",
                "print(ASSIGN.isnull().sum())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = co2_levels.rolling(window=52).mean()",
                "ASSIGN = co2_levels.rolling(window=52).std()",
                "ASSIGN = ASSIGN + (ASSIGN * 2)",
                "ASSIGN = ASSIGN - (ASSIGN * 2)",
                "ASSIGN = ma.plot(linewidth=0.8, fontsize=6)",
                "ASSIGN.set_xlabel('Date', fontsize=10)",
                "ASSIGN.set_ylabel('CO2 levels in Mauai Hawaii', fontsize=10)",
                "ASSIGN.set_title('Rolling mean and variance of CO2 levels\\nin Mauai Hawaii from 1958 to 2001', fontsize=10)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = co2_levels.rolling(window=52).mean()",
                "ASSIGN = co2_levels.rolling(window=52).std()",
                "ASSIGN = ASSIGN + (ASSIGN * 2)",
                "ASSIGN = ASSIGN - (ASSIGN * 2)",
                "ASSIGN = ma.plot(linewidth=0.8, fontsize=6)",
                "ASSIGN.set_xlabel('Date', fontsize=10)",
                "ASSIGN.set_ylabel('CO2 levels in Mauai Hawaii', fontsize=10)",
                "ASSIGN.set_title('Rolling mean and variance of CO2 levels\\nin Mauai Hawaii from 1958 to 2001', fontsize=10)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = co2_levels.index.month",
                "ASSIGN = co2_levels.groupby(index_month).mean()",
                "ASSIGN.plot(fontsize = 6)",
                "plt.legend(fontsize=10)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = co2_levels.index.month",
                "ASSIGN = co2_levels.groupby(index_month).mean()",
                "ASSIGN.plot(fontsize = 6)",
                "plt.legend(fontsize=10)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(co2_levels.describe())",
                "print(co2_levels.co2.min())",
                "print(co2_levels.co2.max())"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(co2_levels.describe())",
                "print(co2_levels.co2.min())",
                "print(co2_levels.co2.max())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = co2_levels.plot(kind = 'hist', bins = 50, fontsize=6)",
                "ASSIGN.set_xlabel('CO2', fontsize=10)",
                "ASSIGN.set_ylabel('Histogram of CO2 levels in Maui Hawaii', fontsize=10)",
                "plt.legend(fontsize=10)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = co2_levels.plot(kind = 'hist', bins = 50, fontsize=6)",
                "ASSIGN.set_xlabel('CO2', fontsize=10)",
                "ASSIGN.set_ylabel('Histogram of CO2 levels in Maui Hawaii', fontsize=10)",
                "plt.legend(fontsize=10)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = co2_levels.plot(kind = 'density', linewidth = 4, fontsize=6)",
                "ASSIGN.set_xlabel('CO2', fontsize=10)",
                "ASSIGN.set_ylabel('Density plot of CO2 levels in Maui Hawaii', fontsize=10)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = co2_levels.plot(kind = 'density', linewidth = 4, fontsize=6)",
                "ASSIGN.set_xlabel('CO2', fontsize=10)",
                "ASSIGN.set_ylabel('Density plot of CO2 levels in Maui Hawaii', fontsize=10)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "plt.style.use('fivethirtyeight')",
                "ASSIGN = tsaplots.plot_acf(co2_levels['co2'], lags=24)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "plt.style.use('fivethirtyeight')",
                "ASSIGN = tsaplots.plot_acf(co2_levels['co2'], lags=24)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "plt.style.use('fivethirtyeight')",
                "ASSIGN = tsaplots.plot_pacf(co2_levels['co2'], lags=24)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "plt.style.use('fivethirtyeight')",
                "ASSIGN = tsaplots.plot_pacf(co2_levels['co2'], lags=24)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = sm.tsa.seasonal_decompose(co2_levels)",
                "print(ASSIGN.seasonal)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = sm.tsa.seasonal_decompose(co2_levels)",
                "print(ASSIGN.seasonal)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = decomposition.ASSIGN",
                "ASSIGN = trend.plot(figsize=(12, 6), fontsize=6)",
                "ASSIGN.set_xlabel('Date', fontsize=10)",
                "ASSIGN.set_title('Seasonal component the CO2 time-series', fontsize=10)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = decomposition.ASSIGN",
                "ASSIGN = trend.plot(figsize=(12, 6), fontsize=6)",
                "ASSIGN.set_xlabel('Date', fontsize=10)",
                "ASSIGN.set_title('Seasonal component the CO2 time-series', fontsize=10)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path', parse_dates = ['Month'], index_col = 'Month')",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv('path', parse_dates = ['Month'], index_col = 'Month')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = airline.plot(color = 'blue', fontsize=12)",
                "ASSIGN.axvline('1955-12-01', color='red', linestyle='--')",
                "ASSIGN.set_xlabel('Date', fontsize=12)",
                "ASSIGN.set_title('Number of Monthly Airline Passengers', fontsize=12)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = airline.plot(color = 'blue', fontsize=12)",
                "ASSIGN.axvline('1955-12-01', color='red', linestyle='--')",
                "ASSIGN.set_xlabel('Date', fontsize=12)",
                "ASSIGN.set_title('Number of Monthly Airline Passengers', fontsize=12)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(airline.isnull().sum())",
                "print(airline.describe())"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(airline.isnull().sum())",
                "print(airline.describe())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = airline.boxplot()",
                "ASSIGN.set_title('Boxplot of Monthly Airline\\nPassengers Count', fontsize=20)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = airline.boxplot()",
                "ASSIGN.set_title('Boxplot of Monthly Airline\\nPassengers Count', fontsize=20)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = airline.index.month",
                "ASSIGN = airline.groupby(index_month).mean()",
                "ASSIGN.plot()",
                "plt.legend(fontsize=20)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = airline.index.month",
                "ASSIGN = airline.groupby(index_month).mean()",
                "ASSIGN.plot()",
                "plt.legend(fontsize=20)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = sm.tsa.seasonal_decompose(airline)",
                "ASSIGN = decomposition.ASSIGN",
                "ASSIGN = decomposition.ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = sm.tsa.seasonal_decompose(airline)",
                "ASSIGN = decomposition.ASSIGN",
                "ASSIGN = decomposition.ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.concat([trend, seasonal], axis = 1)",
                "ASSIGN.columns = ['trend', 'seasonal']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.concat([trend, seasonal], axis = 1)",
                "ASSIGN.columns = ['trend', 'seasonal']"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print(airline_decomposed.head())",
                "ASSIGN = airline_decomposed.plot(figsize=(12, 6), fontsize=15)",
                "ASSIGN.set_xlabel('Date', fontsize=15)",
                "plt.legend(fontsize=15)",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(airline_decomposed.head())",
                "ASSIGN = airline_decomposed.plot(figsize=(12, 6), fontsize=15)",
                "ASSIGN.set_xlabel('Date', fontsize=15)",
                "plt.legend(fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Visualization Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path')",
                "display(ASSIGN.head(5))"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.read_csv('path')",
                "display(ASSIGN.head(5))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.to_datetime(ASSIGN )",
                "ASSIGN = ASSIGN.set_index('date')",
                "display(ASSIGN.describe())"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.to_datetime(ASSIGN )",
                "ASSIGN = ASSIGN.set_index('date')",
                "display(ASSIGN.describe())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = meat.plot(linewidth = 2, fontsize = 12)",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.legend(fontsize=15)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = meat.plot(linewidth = 2, fontsize = 12)",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.legend(fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = meat.plot.area(fontsize=12)",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.legend(fontsize=15)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = meat.plot.area(fontsize=12)",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.legend(fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = meat.plot(colormap='cubehelix', fontsize=15)",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.legend(fontsize=18)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = meat.plot(colormap='cubehelix', fontsize=15)",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.legend(fontsize=18)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = meat.plot(colormap = 'PuOr', fontsize=15)",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.legend(fontsize=18)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = meat.plot(colormap = 'PuOr', fontsize=15)",
                "ASSIGN.set_xlabel('Date')",
                "ASSIGN.legend(fontsize=18)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = meat.mean(axis = 0)",
                "ASSIGN = pd.DataFrame(ASSIGN).transpose()",
                "ASSIGN.index = ['mean']",
                "meat_mean"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = meat.mean(axis = 0)",
                "ASSIGN = pd.DataFrame(ASSIGN).transpose()",
                "ASSIGN.index = ['mean']",
                "meat_mean"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = meat.plot(fontsize=6, linewidth=1)",
                "ASSIGN.set_xlabel('Date', fontsize=6)",
                "ASSIGN.table(cellText=meat_mean.values,",
                "ASSIGN = [0.15]*len(meat_mean.columns),",
                "ASSIGN=meat_mean.index,",
                "ASSIGN=meat_mean.columns,",
                "ASSIGN='top')",
                "ASSIGN.legend(ASSIGN='upper center', bbox_to_anchor=(0.5, 0.95), ncol=3, fontsize=6)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = meat.plot(fontsize=6, linewidth=1)",
                "ASSIGN.set_xlabel('Date', fontsize=6)",
                "ASSIGN.table(cellText=meat_mean.values,",
                "ASSIGN = [0.15]*len(meat_mean.columns),",
                "ASSIGN=meat_mean.index,",
                "ASSIGN=meat_mean.columns,",
                "ASSIGN='top')",
                "ASSIGN.legend(ASSIGN='upper center', bbox_to_anchor=(0.5, 0.95), ncol=3, fontsize=6)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "meat.plot(subplots=True,",
                "ASSIGN=(2, 4),",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN='viridis',",
                "ASSIGN=2,",
                "ASSIGN=False,",
                "ASSIGN=0.2)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "meat.plot(subplots=True,",
                "ASSIGN=(2, 4),",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN='viridis',",
                "ASSIGN=2,",
                "ASSIGN=False,",
                "ASSIGN=0.2)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(meat[['beef', 'pork']].corr(method='spearman'))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(meat[['beef', 'pork']].corr(method='spearman'))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(meat[['pork', 'veal', 'turkey']].corr(method='pearson'))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(meat[['pork', 'veal', 'turkey']].corr(method='pearson'))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = meat.corr(method='spearman')",
                "sns.heatmap(ASSIGN,",
                "ASSIGN=True,",
                "ASSIGN=0.4,",
                "ASSIGN={\"size\": 10})",
                "plt.xticks(rotation=90)",
                "plt.yticks(rotation=0)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = meat.corr(method='spearman')",
                "sns.heatmap(ASSIGN,",
                "ASSIGN=True,",
                "ASSIGN=0.4,",
                "ASSIGN={\"size\": 10})",
                "plt.xticks(rotation=90)",
                "plt.yticks(rotation=0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = meat.corr(method = 'pearson')",
                "ASSIGN = sns.clustermap(corr_meat,",
                "ASSIGN=True,",
                "ASSIGN=True,",
                "ASSIGN=(10, 10))",
                "plt.setp(ASSIGN.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)",
                "plt.setp(ASSIGN.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = meat.corr(method = 'pearson')",
                "ASSIGN = sns.clustermap(corr_meat,",
                "ASSIGN=True,",
                "ASSIGN=True,",
                "ASSIGN=(10, 10))",
                "plt.setp(ASSIGN.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)",
                "plt.setp(ASSIGN.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('path', parse_dates = ['datestamp'])",
                "display(ASSIGN.head(5))",
                "print(ASSIGN.dtypes)",
                "ASSIGN = pd.to_datetime(ASSIGN)",
                "ASSIGN = ASSIGN.set_index('datestamp')",
                "display(ASSIGN.isnull().sum())"
            ],
            "output_type": "display_data",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('path', parse_dates = ['datestamp'])",
                "display(ASSIGN.head(5))",
                "print(ASSIGN.dtypes)",
                "ASSIGN = pd.to_datetime(ASSIGN)",
                "ASSIGN = ASSIGN.set_index('datestamp')",
                "display(ASSIGN.isnull().sum())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "jobs.boxplot(fontsize=6, vert=False)",
                "plt.show()",
                "display(jobs.describe())"
            ],
            "output_type": "display_data",
            "content_old": [
                "jobs.boxplot(fontsize=6, vert=False)",
                "plt.show()",
                "display(jobs.describe())"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = jobs[['Finance', 'Information', 'Manufacturing', 'Construction']]",
                "print(ASSIGN.head())",
                "ASSIGN = jobs_subset.plot(subplots=True,",
                "ASSIGN=(2,2),",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=0.7,",
                "ASSIGN=3,",
                "ASSIGN=False)",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = jobs[['Finance', 'Information', 'Manufacturing', 'Construction']]",
                "print(ASSIGN.head())",
                "ASSIGN = jobs_subset.plot(subplots=True,",
                "ASSIGN=(2,2),",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN=0.7,",
                "ASSIGN=3,",
                "ASSIGN=False)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = jobs.plot(colormap = 'Spectral', fontsize=6, linewidth=0.8)",
                "ASSIGN.set_xlabel('Date', fontsize=10)",
                "ASSIGN.set_ylabel('Unemployment Rate', fontsize=10)",
                "ASSIGN.set_title('Unemployment rate of U.S. workers by industry', fontsize=10)",
                "ASSIGN.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))",
                "ASSIGN.axvline('2001-07-01', color='blue', linestyle='--', linewidth=0.8)",
                "ASSIGN.axvline('2008-09-01', color='blue', linestyle='--', linewidth=0.8)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = jobs.plot(colormap = 'Spectral', fontsize=6, linewidth=0.8)",
                "ASSIGN.set_xlabel('Date', fontsize=10)",
                "ASSIGN.set_ylabel('Unemployment Rate', fontsize=10)",
                "ASSIGN.set_title('Unemployment rate of U.S. workers by industry', fontsize=10)",
                "ASSIGN.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))",
                "ASSIGN.axvline('2001-07-01', color='blue', linestyle='--', linewidth=0.8)",
                "ASSIGN.axvline('2008-09-01', color='blue', linestyle='--', linewidth=0.8)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = jobs.index.month",
                "ASSIGN = jobs.groupby(index_month).mean()",
                "ASSIGN = jobs_by_month.plot(fontsize=6, linewidth=1)",
                "ASSIGN.set_xlabel('Month', fontsize=10)",
                "ASSIGN.set_ylabel('Mean unemployment rate', fontsize=10)",
                "ASSIGN.legend(bbox_to_anchor=(0.8, 0.6), fontsize=10)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = jobs.index.month",
                "ASSIGN = jobs.groupby(index_month).mean()",
                "ASSIGN = jobs_by_month.plot(fontsize=6, linewidth=1)",
                "ASSIGN.set_xlabel('Month', fontsize=10)",
                "ASSIGN.set_ylabel('Mean unemployment rate', fontsize=10)",
                "ASSIGN.legend(bbox_to_anchor=(0.8, 0.6), fontsize=10)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = jobs.index.year",
                "ASSIGN = jobs.groupby(index_year).mean()",
                "ASSIGN = jobs_by_year.plot(fontsize=6, linewidth=1)",
                "ASSIGN.set_xlabel('Year', fontsize=10)",
                "ASSIGN.set_ylabel('Mean unemployment rate', fontsize=10)",
                "ASSIGN.legend(bbox_to_anchor=(0.1, 0.5), fontsize=10)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = jobs.index.year",
                "ASSIGN = jobs.groupby(index_year).mean()",
                "ASSIGN = jobs_by_year.plot(fontsize=6, linewidth=1)",
                "ASSIGN.set_xlabel('Year', fontsize=10)",
                "ASSIGN.set_ylabel('Mean unemployment rate', fontsize=10)",
                "ASSIGN.legend(bbox_to_anchor=(0.1, 0.5), fontsize=10)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = {}",
                "ASSIGN = jobs.columns",
                "for ts in ASSIGN:",
                "ASSIGN = sm.tsa.seasonal_decompose(jobs[ts])",
                "ASSIGN[ts] = ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {}",
                "ASSIGN = jobs.columns",
                "for ts in ASSIGN:",
                "ASSIGN = sm.tsa.seasonal_decompose(jobs[ts])",
                "ASSIGN[ts] = ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = {}",
                "for ts in jobs_names:",
                "ASSIGN[ts] = jobs_decomp[ts].seasonal",
                "ASSIGN = pd.DataFrame(jobs_seasonal)",
                "ASSIGN.index.name = None",
                "ASSIGN.plot(subplots=True,",
                "ASSIGN=(4, 4),",
                "ASSIGN=False,",
                "ASSIGN=2,",
                "ASSIGN=0.3,",
                "ASSIGN=False)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = {}",
                "for ts in jobs_names:",
                "ASSIGN[ts] = jobs_decomp[ts].seasonal",
                "ASSIGN = pd.DataFrame(jobs_seasonal)",
                "ASSIGN.index.name = None",
                "ASSIGN.plot(subplots=True,",
                "ASSIGN=(4, 4),",
                "ASSIGN=False,",
                "ASSIGN=2,",
                "ASSIGN=0.3,",
                "ASSIGN=False)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = seasonality_df.corr(method='spearman')",
                "ASSIGN = sns.clustermap(seasonality_corr, annot=True, annot_kws={\"size\": 4}, linewidths=.4, figsize=(15, 10))",
                "plt.setp(ASSIGN.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)",
                "plt.setp(ASSIGN.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = seasonality_df.corr(method='spearman')",
                "ASSIGN = sns.clustermap(seasonality_corr, annot=True, annot_kws={\"size\": 4}, linewidths=.4, figsize=(15, 10))",
                "plt.setp(ASSIGN.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)",
                "plt.setp(ASSIGN.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN=pd.read_csv('path')",
                "ASSIGN=pd.read_csv('path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=pd.read_csv('path')",
                "ASSIGN=pd.read_csv('path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train_data.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train_data.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [col for col in train_data.columns if train_data[col].isnull().any()]",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [col for col in train_data.columns if train_data[col].isnull().any()]",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = [col for col in test_data.columns if test_data[col].isnull().any()]",
                "print(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = [col for col in test_data.columns if test_data[col].isnull().any()]",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test_data.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "test_data.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train_data[\"label\"]",
                "ASSIGN = train_data.drop([\"label\"],axis = 1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train_data[\"label\"]",
                "ASSIGN = train_data.drop([\"label\"],axis = 1)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "Y_train.value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "Y_train.value_counts()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "sns.countplot(Y_train)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "sns.countplot(Y_train)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=28",
                "ASSIGN=28",
                "def data_prep_X(X):",
                "ASSIGN=len(X)",
                "ASSIGN=X.values.reshape(num_img,img_row,img_col,1)",
                "ASSIGN=x_as_arraypath",
                "return X_out"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=28",
                "ASSIGN=28",
                "def data_prep_X(X):",
                "ASSIGN=len(X)",
                "ASSIGN=X.values.reshape(num_img,img_row,img_col,1)",
                "ASSIGN=x_as_arraypath",
                "return X_out"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=10",
                "def data_prep_Y(Y):",
                "ASSIGN = to_categorical(Y, num_classes)",
                "return out_y"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN=10",
                "def data_prep_Y(Y):",
                "ASSIGN = to_categorical(Y, num_classes)",
                "return out_y"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = data_prep_X(ASSIGN)",
                "ASSIGN = data_prep_X(ASSIGN)",
                "ASSIGN = data_prep_Y(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = data_prep_X(ASSIGN)",
                "ASSIGN = data_prep_X(ASSIGN)",
                "ASSIGN = data_prep_Y(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = plt.imshow(X_train[0][:,:,0])"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = plt.imshow(X_train[0][:,:,0])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.imshow(X_train[1][:,:,0])"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = plt.imshow(X_train[1][:,:,0])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(20, kernel_size=(3, 3),",
                "ASSIGN='relu',",
                "ASSIGN=(img_row, img_col, 1)))",
                "ASSIGN.add(Conv2D(20, kernel_size=(3, 3), ASSIGN='relu'))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, ASSIGN='relu'))",
                "ASSIGN.add(Dense(num_classes, ASSIGN='softmax'))",
                "ASSIGN.compile(loss=keras.losses.categorical_crossentropy,",
                "ASSIGN='adam',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(X_train, Y_train,",
                "ASSIGN=128,",
                "ASSIGN=30,",
                "ASSIGN = 0.2)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(20, kernel_size=(3, 3),",
                "ASSIGN='relu',",
                "ASSIGN=(img_row, img_col, 1)))",
                "ASSIGN.add(Conv2D(20, kernel_size=(3, 3), ASSIGN='relu'))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, ASSIGN='relu'))",
                "ASSIGN.add(Dense(num_classes, ASSIGN='softmax'))",
                "ASSIGN.compile(loss=keras.losses.categorical_crossentropy,",
                "ASSIGN='adam',",
                "ASSIGN=['accuracy'])",
                "ASSIGN.fit(X_train, Y_train,",
                "ASSIGN=128,",
                "ASSIGN=30,",
                "ASSIGN = 0.2)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = model.predict(test_data)",
                "ASSIGN = np.argmax(ASSIGN,axis = 1)",
                "ASSIGN = pd.Series(ASSIGN,name=\"Label\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = model.predict(test_data)",
                "ASSIGN = np.argmax(ASSIGN,axis = 1)",
                "ASSIGN = pd.Series(ASSIGN,name=\"Label\")"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)",
                "ASSIGN.to_csv(\"mySubmission.csv\",index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)",
                "ASSIGN.to_csv(\"mySubmission.csv\",index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.head(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = df.iloc[:,1:40]",
                "ASSIGN.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df.iloc[:,1:40]",
                "ASSIGN.head(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = dataset.ASSIGN('pearson')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = dataset.ASSIGN('pearson')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.countplot(data = dataset,x='blueWins')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sns.countplot(data = dataset,x='blueWins')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "dataset.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "dataset.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = dataset.iloc[:,0:19]",
                "ASSIGN.drop(columns = ['blueDeaths'],inplace = True)",
                "ASSIGN.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = dataset.iloc[:,0:19]",
                "ASSIGN.drop(columns = ['blueDeaths'],inplace = True)",
                "ASSIGN.head(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = blue_df.ASSIGN('pearson')",
                "plt.figure(figsize = (10,10))",
                "sns.heatmap(ASSIGN,annot = True)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = blue_df.ASSIGN('pearson')",
                "plt.figure(figsize = (10,10))",
                "sns.heatmap(ASSIGN,annot = True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "corr['blueWins'].sort_values(ascending=False)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "corr['blueWins'].sort_values(ascending=False)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = blue_df.iloc[:,1:]",
                "ASSIGN = blue_df.iloc[:,1]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = blue_df.iloc[:,1:]",
                "ASSIGN = blue_df.iloc[:,1]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = StandardScaler()",
                "ASSIGN.fit(X)",
                "ASSIGN = pd.DataFrame(scaler.transform(ASSIGN),columns=ASSIGN.columns)",
                "ASSIGN.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = StandardScaler()",
                "ASSIGN.fit(X)",
                "ASSIGN = pd.DataFrame(scaler.transform(ASSIGN),columns=ASSIGN.columns)",
                "ASSIGN.head(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = blue_df['blueWins']",
                "ASSIGN = to_categorical(ASSIGN, 2)",
                "y"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = blue_df['blueWins']",
                "ASSIGN = to_categorical(ASSIGN, 2)",
                "y"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20,random_state=0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20,random_state=0)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Dense(units=18,activation='relu',input_dim=len(X.columns)))",
                "ASSIGN.add(Dense(36,activation = 'relu'))",
                "ASSIGN.add(Dense(72,activation = 'relu'))",
                "ASSIGN.add(Dense(units=2,activation='softmax'))",
                "ASSIGN.summary()"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = Sequential()",
                "ASSIGN.add(Dense(units=18,activation='relu',input_dim=len(X.columns)))",
                "ASSIGN.add(Dense(36,activation = 'relu'))",
                "ASSIGN.add(Dense(72,activation = 'relu'))",
                "ASSIGN.add(Dense(units=2,activation='softmax'))",
                "ASSIGN.summary()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = model.fit(X_train,y_train,",
                "ASSIGN=50,",
                "ASSIGN=(X_test,y_test))"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = model.fit(X_train,y_train,",
                "ASSIGN=50,",
                "ASSIGN=(X_test,y_test))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(8,8))",
                "plt.plot(history.history['val_accuracy'])",
                "plt.title('Accuracy curves')",
                "plt.xlabel('epochs')",
                "plt.ylabel('Accuracy')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(8,8))",
                "plt.plot(history.history['val_accuracy'])",
                "plt.title('Accuracy curves')",
                "plt.xlabel('epochs')",
                "plt.ylabel('Accuracy')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 7",
                "np.random.ASSIGN(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 7",
                "np.random.ASSIGN(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.load(\"..path\")",
                "ASSIGN = np.load(\"..path\")",
                "ASSIGN = np.load(\"..path\")",
                "ASSIGN = np.load(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "tlabel"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.load(\"..path\")",
                "ASSIGN = np.load(\"..path\")",
                "ASSIGN = np.load(\"..path\")",
                "ASSIGN = np.load(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "tlabel"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.subplot(221)",
                "plt.imshow(tpure[0], cmap=plt.get_cmap('gray'))",
                "plt.subplot(222)",
                "plt.imshow(tpure[1], cmap=plt.get_cmap('gray'))",
                "plt.subplot(223)",
                "plt.imshow(tpure[2], cmap=plt.get_cmap('gray'))",
                "plt.subplot(224)",
                "plt.imshow(tpure[3], cmap=plt.get_cmap('gray'))",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.subplot(221)",
                "plt.imshow(tpure[0], cmap=plt.get_cmap('gray'))",
                "plt.subplot(222)",
                "plt.imshow(tpure[1], cmap=plt.get_cmap('gray'))",
                "plt.subplot(223)",
                "plt.imshow(tpure[2], cmap=plt.get_cmap('gray'))",
                "plt.subplot(224)",
                "plt.imshow(tpure[3], cmap=plt.get_cmap('gray'))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.subplot(221)",
                "plt.imshow(tnoisy[0], cmap=plt.get_cmap('gray'))",
                "plt.subplot(222)",
                "plt.imshow(tnoisy[1], cmap=plt.get_cmap('gray'))",
                "plt.subplot(223)",
                "plt.imshow(tnoisy[2], cmap=plt.get_cmap('gray'))",
                "plt.subplot(224)",
                "plt.imshow(tnoisy[3], cmap=plt.get_cmap('gray'))",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.subplot(221)",
                "plt.imshow(tnoisy[0], cmap=plt.get_cmap('gray'))",
                "plt.subplot(222)",
                "plt.imshow(tnoisy[1], cmap=plt.get_cmap('gray'))",
                "plt.subplot(223)",
                "plt.imshow(tnoisy[2], cmap=plt.get_cmap('gray'))",
                "plt.subplot(224)",
                "plt.imshow(tnoisy[3], cmap=plt.get_cmap('gray'))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "for i in range(15,19):",
                "plt.subplot(221+(i%5))",
                "plt.imshow(trotated[i], cmap=plt.get_cmap('gray'))",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for i in range(15,19):",
                "plt.subplot(221+(i%5))",
                "plt.imshow(trotated[i], cmap=plt.get_cmap('gray'))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.subplot(221)",
                "plt.imshow(tboth[0], cmap=plt.get_cmap('gray'))",
                "plt.subplot(222)",
                "plt.imshow(tboth[1], cmap=plt.get_cmap('gray'))",
                "plt.subplot(223)",
                "plt.imshow(tboth[2], cmap=plt.get_cmap('gray'))",
                "plt.subplot(224)",
                "plt.imshow(tboth[3], cmap=plt.get_cmap('gray'))",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.subplot(221)",
                "plt.imshow(tboth[0], cmap=plt.get_cmap('gray'))",
                "plt.subplot(222)",
                "plt.imshow(tboth[1], cmap=plt.get_cmap('gray'))",
                "plt.subplot(223)",
                "plt.imshow(tboth[2], cmap=plt.get_cmap('gray'))",
                "plt.subplot(224)",
                "plt.imshow(tboth[3], cmap=plt.get_cmap('gray'))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "K.set_image_dim_ordering('th')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "K.set_image_dim_ordering('th')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def DataPrep(db):",
                "ASSIGN = ASSIGN.reshape(ASSIGN.shape[0], 1, 28, 28).astype('float32')",
                "ASSIGN = ASSIGN path",
                "ASSIGN = np_utils.to_categorical(ASSIGN)",
                "return db"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def DataPrep(db):",
                "ASSIGN = ASSIGN.reshape(ASSIGN.shape[0], 1, 28, 28).astype('float32')",
                "ASSIGN = ASSIGN path",
                "ASSIGN = np_utils.to_categorical(ASSIGN)",
                "return db"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = np_utils.to_categorical(ASSIGN['label'])",
                "ASSIGN = DataPrep(ASSIGN)",
                "ASSIGN = DataPrep(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np_utils.to_categorical(ASSIGN['label'])",
                "ASSIGN = DataPrep(ASSIGN)",
                "ASSIGN = DataPrep(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "def deepCNN():",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))",
                "ASSIGN.add(Conv2D(15, (3, 3), activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(50, activation='relu'))",
                "ASSIGN.add(Dense(tlabel.shape[1], activation='softmax'))",
                "ASSIGN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])",
                "return model"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def deepCNN():",
                "ASSIGN = Sequential()",
                "ASSIGN.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))",
                "ASSIGN.add(Conv2D(15, (3, 3), activation='relu'))",
                "ASSIGN.add(Dropout(0.2))",
                "ASSIGN.add(Flatten())",
                "ASSIGN.add(Dense(128, activation='relu'))",
                "ASSIGN.add(Dense(50, activation='relu'))",
                "ASSIGN.add(Dense(tlabel.shape[1], activation='softmax'))",
                "ASSIGN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])",
                "return model"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = deepCNN()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = deepCNN()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = [EarlyStopping(monitor = 'val_loss', patience = 2)]",
                "Xtrain,Xvalidation,Ytrain,Yvalidation = train_test_split(tpure,tlabel, test_size = 0.2)",
                "CNNmodel.fit(Xtrain, Ytrain, validation_data=(Xvalidation,Yvalidation), epochs=20,",
                "ASSIGN=200, verbose=1, callbacks = callbacks)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = [EarlyStopping(monitor = 'val_loss', patience = 2)]",
                "Xtrain,Xvalidation,Ytrain,Yvalidation = train_test_split(tpure,tlabel, test_size = 0.2)",
                "CNNmodel.fit(Xtrain, Ytrain, validation_data=(Xvalidation,Yvalidation), epochs=20,",
                "ASSIGN=200, verbose=1, callbacks = callbacks)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "binder.bind(globals())",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "binder.bind(globals())",
                "print()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = bigquery.Client()",
                "ASSIGN = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")",
                "ASSIGN = client.get_dataset(dataset_ref)",
                "ASSIGN = dataset_ref.table(\"posts_questions\")",
                "ASSIGN = client.get_table(table_ref)",
                "ASSIGN.list_rows(ASSIGN, max_results=5).to_dataframe()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = bigquery.Client()",
                "ASSIGN = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")",
                "ASSIGN = client.get_dataset(dataset_ref)",
                "ASSIGN = dataset_ref.table(\"posts_questions\")",
                "ASSIGN = client.get_table(table_ref)",
                "ASSIGN.list_rows(ASSIGN, max_results=5).to_dataframe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = dataset_ref.table(\"posts_answers\")",
                "ASSIGN = client.get_table(table_ref)",
                "client.list_rows(ASSIGN, max_results=5).to_dataframe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = dataset_ref.table(\"posts_answers\")",
                "ASSIGN = client.get_table(table_ref)",
                "client.list_rows(ASSIGN, max_results=5).to_dataframe()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = \"\"\"",
                "SELECT q.id AS q_id,",
                "MIN(TIMESTAMP_DIFF(a.creation_date, q.creation_date, SECOND)) as time_to_answer",
                "FROM `bigquery-public-data.stackoverflow.posts_questions` AS q",
                "INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a",
                "ON q.id = a.parent_id",
                "WHERE q.creation_date >= '2018-01-01' and q.creation_date < '2018-02-01'",
                "GROUP BY q_id",
                "ORDER BY time_to_answer",
                "\"\"\"",
                "ASSIGN = client.query(first_query).result().to_dataframe()",
                "print(\"Percentage of answered questions: %s%%\" % \\",
                "(sum(ASSIGN[\"time_to_answer\"].notnull()) path(ASSIGN) * 100))",
                "print(, len(ASSIGN))",
                "ASSIGN.head()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = \"\"\"",
                "SELECT q.id AS q_id,",
                "MIN(TIMESTAMP_DIFF(a.creation_date, q.creation_date, SECOND)) as time_to_answer",
                "FROM `bigquery-public-data.stackoverflow.posts_questions` AS q",
                "INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a",
                "ON q.id = a.parent_id",
                "WHERE q.creation_date >= '2018-01-01' and q.creation_date < '2018-02-01'",
                "GROUP BY q_id",
                "ORDER BY time_to_answer",
                "\"\"\"",
                "ASSIGN = client.query(first_query).result().to_dataframe()",
                "print(\"Percentage of answered questions: %s%%\" % \\",
                "(sum(ASSIGN[\"time_to_answer\"].notnull()) path(ASSIGN) * 100))",
                "print(, len(ASSIGN))",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def get_distance_matrix(str_list):",
                "\"\"\" Construct a levenshtein distance matrix for a list of strings\"\"\"",
                "ASSIGN = np.zeros(shape=(len(str_list), len(str_list)))",
                "print (\"Starting to build distance matrix. This will iterate from 0 till \", len(str_list) )",
                "for i in range(0, len(str_list)):",
                "print (i)",
                "for j in range(i+1, len(str_list)):",
                "ASSIGN[i][j] = distance(str_list[i], str_list[j])",
                "for i in range(0, len(str_list)):",
                "for j in range(0, len(str_list)):",
                "ASSIGN == j:",
                "ASSIGN[i][j] = 0",
                "elif i > j:",
                "ASSIGN[i][j] = ASSIGN[j][i]",
                "return dist_matrix"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def get_distance_matrix(str_list):",
                "\"\"\" Construct a levenshtein distance matrix for a list of strings\"\"\"",
                "ASSIGN = np.zeros(shape=(len(str_list), len(str_list)))",
                "print (\"Starting to build distance matrix. This will iterate from 0 till \", len(str_list) )",
                "for i in range(0, len(str_list)):",
                "print (i)",
                "for j in range(i+1, len(str_list)):",
                "ASSIGN[i][j] = distance(str_list[i], str_list[j])",
                "for i in range(0, len(str_list)):",
                "for j in range(0, len(str_list)):",
                "ASSIGN == j:",
                "ASSIGN[i][j] = 0",
                "elif i > j:",
                "ASSIGN[i][j] = ASSIGN[j][i]",
                "return dist_matrix"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = [",
                "\"part\", \"spartan\"",
                "]",
                "get_distance_matrix(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = [",
                "\"part\", \"spartan\"",
                "]",
                "get_distance_matrix(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "sns.set(rc={'figure.figsize':(20, 15)})"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "sns.set(rc={'figure.figsize':(20, 15)})"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Post Development Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "def save(model, cv_info, classification_report, name=\"model\", cv_scores=None):",
                "ASSIGN = {",
                "\"cv_info\": cv_info, \"classification_report\": classification_report, \"model\": model, \"cv_scores\": cv_scores",
                "}",
                "joblib.dump(ASSIGN, \"path\" + name + \".pkl\")",
                "def load(name=\"model\", verbose=True, with_metadata=False):",
                "ASSIGN = joblib.load(\"path\" + name + \".pkl\")",
                "if verbose:",
                "print()",
                "[print(.format(key=key, val=val)) for key, val in ASSIGN[].items()]",
                "print()",
                "print(ASSIGN[])",
                "if not with_metadata:",
                "return ASSIGN[\"model\"]",
                "else:",
                "return _model"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "def save(model, cv_info, classification_report, name=\"model\", cv_scores=None):",
                "ASSIGN = {",
                "\"cv_info\": cv_info, \"classification_report\": classification_report, \"model\": model, \"cv_scores\": cv_scores",
                "}",
                "joblib.dump(ASSIGN, \"path\" + name + \".pkl\")",
                "def load(name=\"model\", verbose=True, with_metadata=False):",
                "ASSIGN = joblib.load(\"path\" + name + \".pkl\")",
                "if verbose:",
                "print()",
                "[print(.format(key=key, val=val)) for key, val in ASSIGN[].items()]",
                "print()",
                "print(ASSIGN[])",
                "if not with_metadata:",
                "return ASSIGN[\"model\"]",
                "else:",
                "return _model"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('..path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('..path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.head(10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "train.info()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[\"Survived\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train[\"Survived\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[\"Sex\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train[\"Sex\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[\"Embarked\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train[\"Embarked\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[\"Pclass\"].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train[\"Pclass\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.describe()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "train.profile_report()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "train.profile_report()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "train.hist(figsize=(20, 15))",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "train.hist(figsize=(20, 15))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train.corr()",
                "ASSIGN[\"Survived\"]"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = train.corr()",
                "ASSIGN[\"Survived\"]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.violinplot(x=\"Sex\", y=\"Age\", hue=\"Survived\",",
                "ASSIGN=train, palette=\"muted\", split=True)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.violinplot(x=\"Sex\", y=\"Age\", hue=\"Survived\",",
                "ASSIGN=train, palette=\"muted\", split=True)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN path* 15",
                "train[[\"Age\", \"Survived\"]].groupby(['Age']).mean()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = ASSIGN path* 15",
                "train[[\"Age\", \"Survived\"]].groupby(['Age']).mean()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN + ASSIGN",
                "train[[\"RelativesOnboard\", \"Survived\"]].groupby([\"RelativesOnboard\"]).mean()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = ASSIGN + ASSIGN",
                "train[[\"RelativesOnboard\", \"Survived\"]].groupby([\"RelativesOnboard\"]).mean()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[[\"SibSp\", \"Survived\"]].groupby(['SibSp']).mean()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train[[\"SibSp\", \"Survived\"]].groupby(['SibSp']).mean()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[[\"Parch\", \"Survived\"]].groupby(['Parch']).mean()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train[[\"Parch\", \"Survived\"]].groupby(['Parch']).mean()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.corr()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.corr()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "class DataFrameSelector(BaseEstimator, TransformerMixin):",
                "def __init__(self, attribute_names):",
                "self.attribute_names = attribute_names",
                "def fit(self, X, y=None):",
                "return self",
                "def transform(self, X):",
                "return X[self.attribute_names]",
                "class MostFrequentImputer(BaseEstimator, TransformerMixin):",
                "def fit(self, X, y=None):",
                "self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],",
                "ASSIGN=X.columns)",
                "return self",
                "def transform(self, X, y=None):",
                "return X.fillna(self.most_frequent_)",
                "class AgeGrouper(BaseEstimator, TransformerMixin):",
                "def __init__(self, new_attribute=\"AgeGrp\", attribute_name=\"Age\", group_scale=15, del_originals=True):",
                "self.group_scale = group_scale",
                "self.attribute_name = attribute_name",
                "self.new_attribute = new_attribute",
                "self.del_originals = del_originals",
                "def fit(self, X, y=None):",
                "self.age_groups = X[self.attribute_name] path* self.group_scale",
                "return self",
                "def transform(self, X, y=None):",
                "X[self.new_attribute] = self.age_groups",
                "if self.del_originals:",
                "X.drop(columns=self.attribute_name, axis=1, inplace=True)",
                "return X",
                "class AtributesAdder(BaseEstimator, TransformerMixin):",
                "def __init__(self, new_attribute=\"RelativesOnboard\", attribute_names=[\"SibSp\", \"Parch\"], del_originals=True):",
                "self.attribute_names = attribute_names",
                "self.final_attr = 0",
                "self.new_attribute = new_attribute",
                "self.del_originals = del_originals",
                "def fit(self, X, y=None):",
                "for attr in self.attribute_names:",
                "self.final_attr += X[attr]",
                "return self",
                "def transform(self, X, y=None):",
                "X[self.new_attribute] = self.final_attr",
                "if self.del_originals:",
                "X.drop(columns=self.attribute_names, axis=1, inplace=True)",
                "return X"
            ],
            "output_type": "not_existent",
            "content_old": [
                "class DataFrameSelector(BaseEstimator, TransformerMixin):",
                "def __init__(self, attribute_names):",
                "self.attribute_names = attribute_names",
                "def fit(self, X, y=None):",
                "return self",
                "def transform(self, X):",
                "return X[self.attribute_names]",
                "class MostFrequentImputer(BaseEstimator, TransformerMixin):",
                "def fit(self, X, y=None):",
                "self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],",
                "ASSIGN=X.columns)",
                "return self",
                "def transform(self, X, y=None):",
                "return X.fillna(self.most_frequent_)",
                "class AgeGrouper(BaseEstimator, TransformerMixin):",
                "def __init__(self, new_attribute=\"AgeGrp\", attribute_name=\"Age\", group_scale=15, del_originals=True):",
                "self.group_scale = group_scale",
                "self.attribute_name = attribute_name",
                "self.new_attribute = new_attribute",
                "self.del_originals = del_originals",
                "def fit(self, X, y=None):",
                "self.age_groups = X[self.attribute_name] path* self.group_scale",
                "return self",
                "def transform(self, X, y=None):",
                "X[self.new_attribute] = self.age_groups",
                "if self.del_originals:",
                "X.drop(columns=self.attribute_name, axis=1, inplace=True)",
                "return X",
                "class AtributesAdder(BaseEstimator, TransformerMixin):",
                "def __init__(self, new_attribute=\"RelativesOnboard\", attribute_names=[\"SibSp\", \"Parch\"], del_originals=True):",
                "self.attribute_names = attribute_names",
                "self.final_attr = 0",
                "self.new_attribute = new_attribute",
                "self.del_originals = del_originals",
                "def fit(self, X, y=None):",
                "for attr in self.attribute_names:",
                "self.final_attr += X[attr]",
                "return self",
                "def transform(self, X, y=None):",
                "X[self.new_attribute] = self.final_attr",
                "if self.del_originals:",
                "X.drop(columns=self.attribute_names, axis=1, inplace=True)",
                "return X"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([",
                "(\"select_numeric\", DataFrameSelector([\"Age\", \"Fare\", \"SibSp\", \"Parch\"])),",
                "(\"age_grouper\", AgeGrouper(attribute_name=\"Age\", group_scale=15)),",
                "(\"total_relatives\", AtributesAdder(attribute_names=[\"SibSp\", \"Parch\"], del_originals=True)),",
                "(\"imputer\", SimpleImputer(strategy=\"median\")),",
                "])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Pipeline([",
                "(\"select_numeric\", DataFrameSelector([\"Age\", \"Fare\", \"SibSp\", \"Parch\"])),",
                "(\"age_grouper\", AgeGrouper(attribute_name=\"Age\", group_scale=15)),",
                "(\"total_relatives\", AtributesAdder(attribute_names=[\"SibSp\", \"Parch\"], del_originals=True)),",
                "(\"imputer\", SimpleImputer(strategy=\"median\")),",
                "])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = Pipeline([",
                "(\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),",
                "(\"imputer\", MostFrequentImputer()),",
                "(\"cat_encoder\", OneHotEncoder(sparse=False)),",
                "])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = Pipeline([",
                "(\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),",
                "(\"imputer\", MostFrequentImputer()),",
                "(\"cat_encoder\", OneHotEncoder(sparse=False)),",
                "])"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = FeatureUnion(transformer_list=[",
                "(\"num_pipeline\", num_pipeline),",
                "(\"cat_pipeline\", cat_pipeline),",
                "])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = FeatureUnion(transformer_list=[",
                "(\"num_pipeline\", num_pipeline),",
                "(\"cat_pipeline\", cat_pipeline),",
                "])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = preprocess_pipeline.fit_transform(train)",
                "ASSIGN = train[\"Survived\"]",
                "X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(",
                "ASSIGN=0.3, random_state=42)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = preprocess_pipeline.fit_transform(train)",
                "ASSIGN = train[\"Survived\"]",
                "X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(",
                "ASSIGN=0.3, random_state=42)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.zeros_like(corr_matrix)",
                "ASSIGN[np.triu_indices_from(ASSIGN)] = True",
                "with sns.axes_style(\"white\"):",
                "ASSIGN = plt.subplots(figsize=(7, 5))",
                "ASSIGN = sns.heatmap(corr_matrix, mask=mask, vmax=.3, square=True, cmap=\"YlGnBu\")"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = np.zeros_like(corr_matrix)",
                "ASSIGN[np.triu_indices_from(ASSIGN)] = True",
                "with sns.axes_style(\"white\"):",
                "ASSIGN = plt.subplots(figsize=(7, 5))",
                "ASSIGN = sns.heatmap(corr_matrix, mask=mask, vmax=.3, square=True, cmap=\"YlGnBu\")"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = {",
                "\"KNeighborsClassifier\": KNeighborsClassifier(),",
                "\"RandomForest\": RandomForestClassifier(),",
                "\"SVM\": SVC(),",
                "}",
                "ASSIGN = {",
                "\"KNeighborsClassifier\": {",
                "\"n_neighbors\": randint(low=1, high=30),",
                "},",
                "\"RandomForest\": {",
                "\"n_estimators\": randint(low=1, high=200),",
                "\"max_features\": randint(low=1, high=8),",
                "},",
                "\"SVM\": {",
                "\"kernel\": [\"linear\", \"rbf\"],",
                "\"C\": reciprocal(0.1, 200000),",
                "\"gamma\": expon(scale=1.0),",
                "}",
                "}"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {",
                "\"KNeighborsClassifier\": KNeighborsClassifier(),",
                "\"RandomForest\": RandomForestClassifier(),",
                "\"SVM\": SVC(),",
                "}",
                "ASSIGN = {",
                "\"KNeighborsClassifier\": {",
                "\"n_neighbors\": randint(low=1, high=30),",
                "},",
                "\"RandomForest\": {",
                "\"n_estimators\": randint(low=1, high=200),",
                "\"max_features\": randint(low=1, high=8),",
                "},",
                "\"SVM\": {",
                "\"kernel\": [\"linear\", \"rbf\"],",
                "\"C\": reciprocal(0.1, 200000),",
                "\"gamma\": expon(scale=1.0),",
                "}",
                "}"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = \"accuracy\"",
                "for model_name in models.keys():",
                "ASSIGN = RandomizedSearchCV(models[model_name], param_distributions=randomized_params[model_name], n_iter=100,",
                "ASSIGN=ASSIGN, cv=5, verbose=2, random_state=42, n_jobs=-1)",
                "ASSIGN.fit(X_train, y_train)",
                "ASSIGN = cross_val_score(grid.best_estimator_, X_train_val, y_train_val, cv=10,",
                "ASSIGN=ASSIGN, verbose=0, n_jobs=-1)",
                "ASSIGN = scores.mean()",
                "ASSIGN = scores.std()",
                "ASSIGN = grid.score(X_test_val, y_test_val)",
                "ASSIGN = {'Model_Name': model_name, 'Parameters': grid.best_params_, 'Test_Score': Test_scores,",
                "'CV Mean': ASSIGN, 'CV STDEV': ASSIGN}",
                "ASSIGN = grid.best_estimator_.fit(X_train_val, y_train_val)",
                "ASSIGN.score(X_test_val, y_test_val)",
                "ASSIGN = clf.predict(X_test_val)",
                "ASSIGN = classification_report(y_test_val, y_pred)",
                "save(ASSIGN, ASSIGN, ASSIGN, name=\"titanic_\"+model_name+\"_02\", cv_scores=ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = \"accuracy\"",
                "for model_name in models.keys():",
                "ASSIGN = RandomizedSearchCV(models[model_name], param_distributions=randomized_params[model_name], n_iter=100,",
                "ASSIGN=ASSIGN, cv=5, verbose=2, random_state=42, n_jobs=-1)",
                "ASSIGN.fit(X_train, y_train)",
                "ASSIGN = cross_val_score(grid.best_estimator_, X_train_val, y_train_val, cv=10,",
                "ASSIGN=ASSIGN, verbose=0, n_jobs=-1)",
                "ASSIGN = scores.mean()",
                "ASSIGN = scores.std()",
                "ASSIGN = grid.score(X_test_val, y_test_val)",
                "ASSIGN = {'Model_Name': model_name, 'Parameters': grid.best_params_, 'Test_Score': Test_scores,",
                "'CV Mean': ASSIGN, 'CV STDEV': ASSIGN}",
                "ASSIGN = grid.best_estimator_.fit(X_train_val, y_train_val)",
                "ASSIGN.score(X_test_val, y_test_val)",
                "ASSIGN = clf.predict(X_test_val)",
                "ASSIGN = classification_report(y_test_val, y_pred)",
                "save(ASSIGN, ASSIGN, ASSIGN, name=\"titanic_\"+model_name+\"_02\", cv_scores=ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = load(\"titanic_KNeighborsClassifier_02\", with_metadata=True)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = load(\"titanic_KNeighborsClassifier_02\", with_metadata=True)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = load(\"titanic_SVM_02\", with_metadata=True)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = load(\"titanic_SVM_02\", with_metadata=True)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = load(\"titanic_RandomForest_02\", with_metadata=True)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = load(\"titanic_RandomForest_02\", with_metadata=True)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(8, 4))",
                "plt.plot([1]*10, knn_grid[\"cv_scores\"], \".\")",
                "plt.plot([2]*10, svc_grid[\"cv_scores\"], \".\")",
                "plt.plot([3]*10, random_forest_grid[\"cv_scores\"], \".\")",
                "plt.boxplot([knn_grid[\"cv_scores\"], svc_grid[\"cv_scores\"], random_forest_grid[\"cv_scores\"]], labels=(\"KNN\", \"SVM\", \"Random Forest\"))",
                "plt.ylabel(\"Accuracy\", fontsize=14)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(8, 4))",
                "plt.plot([1]*10, knn_grid[\"cv_scores\"], \".\")",
                "plt.plot([2]*10, svc_grid[\"cv_scores\"], \".\")",
                "plt.plot([3]*10, random_forest_grid[\"cv_scores\"], \".\")",
                "plt.boxplot([knn_grid[\"cv_scores\"], svc_grid[\"cv_scores\"], random_forest_grid[\"cv_scores\"]], labels=(\"KNN\", \"SVM\", \"Random Forest\"))",
                "plt.ylabel(\"Accuracy\", fontsize=14)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = random_forest_grid[\"model\"].best_estimator_.fit(X_train, y_train)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = random_forest_grid[\"model\"].best_estimator_.fit(X_train, y_train)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = preprocess_pipeline.fit_transform(test)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = preprocess_pipeline.fit_transform(test)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = random_forest.predict(X_test)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = random_forest.predict(X_test)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(columns=['PassengerId', 'Survived'])",
                "ASSIGN['PassengerId'] = test['PassengerId']",
                "ASSIGN['Survived'] = y_pred"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(columns=['PassengerId', 'Survived'])",
                "ASSIGN['PassengerId'] = test['PassengerId']",
                "ASSIGN['Survived'] = y_pred"
            ]
        },
        {
            "tags": [
                "Post Development Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "submission_df.to_csv(\"path\", header=True, index=False)",
                "submission_df.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "submission_df.to_csv(\"path\", header=True, index=False)",
                "submission_df.head(10)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "breast_cancer.info()"
            ],
            "output_type": "stream",
            "content_old": [
                "breast_cancer.info()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "breast_cancer.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "breast_cancer.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "breast_cancer.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "breast_cancer.describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "breast_cancer.groupby('diagnosis').size()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "breast_cancer.groupby('diagnosis').size()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "breast_cancer.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "breast_cancer.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = breast_cancer.columns[2:-1]",
                "ASSIGN = breast_cancer[feature_names]",
                "ASSIGN = breast_cancer.diagnosis"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = breast_cancer.columns[2:-1]",
                "ASSIGN = breast_cancer[feature_names]",
                "ASSIGN = breast_cancer.diagnosis"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = LabelEncoder()",
                "ASSIGN = class_le.fit_transform(breast_cancer.diagnosis.values)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = LabelEncoder()",
                "ASSIGN = class_le.fit_transform(breast_cancer.diagnosis.values)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.heatmap(",
                "ASSIGN=x.corr(),",
                "ASSIGN=True,",
                "ASSIGN='.2f',",
                "ASSIGN='RdYlGn'",
                ")",
                "ASSIGN = plt.gcf()",
                "ASSIGN.set_size_inches(20, 16)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.heatmap(",
                "ASSIGN=x.corr(),",
                "ASSIGN=True,",
                "ASSIGN='.2f',",
                "ASSIGN='RdYlGn'",
                ")",
                "ASSIGN = plt.gcf()",
                "ASSIGN.set_size_inches(20, 16)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = train_test_split(",
                "x,",
                "y,",
                "ASSIGN=42,",
                "ASSIGN=0.32",
                ")",
                "print(x_train.shape, y_train.shape)",
                "print(x_test.shape, y_test.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = train_test_split(",
                "x,",
                "y,",
                "ASSIGN=42,",
                "ASSIGN=0.32",
                ")",
                "print(x_train.shape, y_train.shape)",
                "print(x_test.shape, y_test.shape)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 64",
                "ASSIGN = 2",
                "ASSIGN = 200",
                "ASSIGN = ASSIGN.astype('float32')",
                "ASSIGN = ASSIGN.astype('float32')",
                "ASSIGN = tf.keras.utils.to_categorical(ASSIGN, num_classes)",
                "ASSIGN = tf.keras.utils.to_categorical(ASSIGN, num_classes)",
                "ASSIGN = Sequential()",
                "ASSIGN.add(tf.keras.layers.Dense(100, input_dim=30, activation='sigmoid'))",
                "ASSIGN.add(tf.keras.layers.Dense(25, input_dim=30, activation='relu'))",
                "ASSIGN.add(tf.keras.layers.Dense(2, activation='softmax'))",
                "ASSIGN.summary()",
                "ASSIGN.compile(loss='categorical_crossentropy',",
                "ASSIGN=RMSprop(0.0001),",
                "ASSIGN=['accuracy'])",
                "ASSIGN = model.fit(x_train, y_train,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=1,",
                "ASSIGN=(x_test, y_test))",
                "ASSIGN = model.evaluate(x_test, y_test, verbose=1)",
                "print('Test loss:', ASSIGN[0])",
                "print('Test accuracy:', ASSIGN[1])",
                "plt.figure()",
                "plt.plot(np.arange(0,ASSIGN), ASSIGN.history[\"loss\"], label=\"train_loss\")",
                "plt.plot(np.arange(0,ASSIGN), ASSIGN.history[\"val_loss\"], label=\"val_loss\")",
                "plt.plot(np.arange(0,ASSIGN), ASSIGN.history[\"acc\"], label=\"train_acc\")",
                "plt.plot(np.arange(0,ASSIGN), ASSIGN.history[\"val_acc\"], label=\"val_acc\")",
                "plt.title(\"Acurácia\")",
                "plt.xlabel(\"Épocas #\")",
                "plt.ylabel(\"Losspath\")",
                "plt.legend()",
                "plt.show()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 64",
                "ASSIGN = 2",
                "ASSIGN = 200",
                "ASSIGN = ASSIGN.astype('float32')",
                "ASSIGN = ASSIGN.astype('float32')",
                "ASSIGN = tf.keras.utils.to_categorical(ASSIGN, num_classes)",
                "ASSIGN = tf.keras.utils.to_categorical(ASSIGN, num_classes)",
                "ASSIGN = Sequential()",
                "ASSIGN.add(tf.keras.layers.Dense(100, input_dim=30, activation='sigmoid'))",
                "ASSIGN.add(tf.keras.layers.Dense(25, input_dim=30, activation='relu'))",
                "ASSIGN.add(tf.keras.layers.Dense(2, activation='softmax'))",
                "ASSIGN.summary()",
                "ASSIGN.compile(loss='categorical_crossentropy',",
                "ASSIGN=RMSprop(0.0001),",
                "ASSIGN=['accuracy'])",
                "ASSIGN = model.fit(x_train, y_train,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=ASSIGN,",
                "ASSIGN=1,",
                "ASSIGN=(x_test, y_test))",
                "ASSIGN = model.evaluate(x_test, y_test, verbose=1)",
                "print('Test loss:', ASSIGN[0])",
                "print('Test accuracy:', ASSIGN[1])",
                "plt.figure()",
                "plt.plot(np.arange(0,ASSIGN), ASSIGN.history[\"loss\"], label=\"train_loss\")",
                "plt.plot(np.arange(0,ASSIGN), ASSIGN.history[\"val_loss\"], label=\"val_loss\")",
                "plt.plot(np.arange(0,ASSIGN), ASSIGN.history[\"acc\"], label=\"train_acc\")",
                "plt.plot(np.arange(0,ASSIGN), ASSIGN.history[\"val_acc\"], label=\"val_acc\")",
                "plt.title(\"Acurácia\")",
                "plt.xlabel(\"Épocas #\")",
                "plt.ylabel(\"Losspath\")",
                "plt.legend()",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(os.listdir('..path'))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(os.listdir('..path'))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\", index_col=\"ID\").drop(\"MAC_CODE\", axis = 1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\", index_col=\"ID\").drop(\"MAC_CODE\", axis = 1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.dropna(axis = 1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.dropna(axis = 1)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "SETUP",
                "ASSIGN= StandardScaler()",
                "ASSIGN.fit(train)",
                "ASSIGN = pd.DataFrame(scaler.transform(ASSIGN), columns = ASSIGN.columns, index = ASSIGN.index)",
                "train"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "SETUP",
                "ASSIGN= StandardScaler()",
                "ASSIGN.fit(train)",
                "ASSIGN = pd.DataFrame(scaler.transform(ASSIGN), columns = ASSIGN.columns, index = ASSIGN.index)",
                "train"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = linear_model.LassoCV(cv=5, random_state=0, max_iter=10000).fit(train.drop(\"TARGET\",axis=1), train[\"TARGET\"])",
                "print(ASSIGN.score(train.drop(,axis=1), train[]))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = linear_model.LassoCV(cv=5, random_state=0, max_iter=10000).fit(train.drop(\"TARGET\",axis=1), train[\"TARGET\"])",
                "print(ASSIGN.score(train.drop(,axis=1), train[]))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "plt.figure(figsize=(20,5))",
                "plt.xticks(rotation = 'vertical')",
                "plt.bar(train.drop(\"TARGET\", axis=1).columns, lasso_reg.coef_)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plt.figure(figsize=(20,5))",
                "plt.xticks(rotation = 'vertical')",
                "plt.bar(train.drop(\"TARGET\", axis=1).columns, lasso_reg.coef_)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN = train.columns.to_list()",
                "ASSIGN = [x for x in column_list if x.find('_max') == -1 and x.find('_min') == -1 and x.find('_c') == -1]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN = train.columns.to_list()",
                "ASSIGN = [x for x in column_list if x.find('_max') == -1 and x.find('_min') == -1 and x.find('_c') == -1]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = train[base_cols]",
                "train_base"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = train[base_cols]",
                "train_base"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = linear_model.LassoCV(cv=5, random_state=0, max_iter=20000, fit_intercept=True,normalize = True).fit(train_base.drop(\"TARGET\",axis=1), train_base[\"TARGET\"])",
                "print(ASSIGN.score(train_base.drop(,axis=1), train_base[]))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = linear_model.LassoCV(cv=5, random_state=0, max_iter=20000, fit_intercept=True,normalize = True).fit(train_base.drop(\"TARGET\",axis=1), train_base[\"TARGET\"])",
                "print(ASSIGN.score(train_base.drop(,axis=1), train_base[]))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "plt.figure(figsize=(20,5))",
                "plt.xticks(rotation = 'vertical')",
                "plt.bar(train_base.drop(\"TARGET\", axis=1).columns, lasso_reg_base.coef_)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "SETUP",
                "plt.figure(figsize=(20,5))",
                "plt.xticks(rotation = 'vertical')",
                "plt.bar(train_base.drop(\"TARGET\", axis=1).columns, lasso_reg_base.coef_)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\", index_col = \"ID\").drop(\"MAC_CODE\",axis=1)",
                "ASSIGN = np.ones(len(test.index))",
                "ASSIGN = pd.DataFrame(scaler.transform(ASSIGN[train.columns.to_list()]), index=ASSIGN.index, columns=train.columns)",
                "ASSIGN = lasso_reg.predict(test[train.columns.to_list()].drop(\"TARGET\", axis=1))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\", index_col = \"ID\").drop(\"MAC_CODE\",axis=1)",
                "ASSIGN = np.ones(len(test.index))",
                "ASSIGN = pd.DataFrame(scaler.transform(ASSIGN[train.columns.to_list()]), index=ASSIGN.index, columns=train.columns)",
                "ASSIGN = lasso_reg.predict(test[train.columns.to_list()].drop(\"TARGET\", axis=1))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = p1",
                "ASSIGN = pd.DataFrame(scaler.inverse_transform(test[train.columns.to_list()]), index=test.index, columns=test.columns)['TARGET']",
                "ASSIGN.to_csv('ASSIGN.csv')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = p1",
                "ASSIGN = pd.DataFrame(scaler.inverse_transform(test[train.columns.to_list()]), index=test.index, columns=test.columns)['TARGET']",
                "ASSIGN.to_csv('ASSIGN.csv')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = lasso_reg_base.predict(test[train_base.columns.to_list()].drop(\"TARGET\", axis=1))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = lasso_reg_base.predict(test[train_base.columns.to_list()].drop(\"TARGET\", axis=1))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = p2",
                "ASSIGN = pd.DataFrame(scaler.inverse_transform(test[train.columns.to_list()]), index=test.index, columns=test.columns)['TARGET']",
                "ASSIGN.to_csv('ASSIGN.csv')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = p2",
                "ASSIGN = pd.DataFrame(scaler.inverse_transform(test[train.columns.to_list()]), index=test.index, columns=test.columns)['TARGET']",
                "ASSIGN.to_csv('ASSIGN.csv')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "test.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[\"idhogar\"]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train[\"idhogar\"]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[\"parentesco1\"].value_counts()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train[\"parentesco1\"].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train.drop(train[train[\"parentesco1\"] == 0].index)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train.drop(train[train[\"parentesco1\"] == 0].index)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train_only_heads[\"parentesco1\"]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train_only_heads[\"parentesco1\"]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train_only_heads.dropna(thresh=len(train_only_heads[\"parentesco1\"])path, axis=\"columns\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train_only_heads.dropna(thresh=len(train_only_heads[\"parentesco1\"])path, axis=\"columns\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.dropna()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.dropna()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train_hna[(train_hna == 'yes') | (train_hna == 'no')].dropna(axis = 'columns', how='all')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train_hna[(train_hna == 'yes') | (train_hna == 'no')].dropna(axis = 'columns', how='all')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train_hna"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "train_hna"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train_hna.drop(['Target','Id','idhogar','dependency','edjefe','edjefa'] ,axis = 'columns')",
                "ASSIGN = train_hna.Target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train_hna.drop(['Target','Id','idhogar','dependency','edjefe','edjefa'] ,axis = 'columns')",
                "ASSIGN = train_hna.Target"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = KNeighborsClassifier(n_neighbors=10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = KNeighborsClassifier(n_neighbors=10)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = cross_val_score(knn, Xtrain_h, Ytrain_h, cv=10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = cross_val_score(knn, Xtrain_h, Ytrain_h, cv=10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "scores.mean()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "scores.mean()"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = []",
                "for i in range(50):",
                "ASSIGN = KNeighborsClassifier(n_neighbors=i+1)",
                "ASSIGN = cross_val_score(knn, Xtrain_h, Ytrain_h, cv=5)",
                "ASSIGN.append(ASSIGN.mean())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "for i in range(50):",
                "ASSIGN = KNeighborsClassifier(n_neighbors=i+1)",
                "ASSIGN = cross_val_score(knn, Xtrain_h, Ytrain_h, cv=5)",
                "ASSIGN.append(ASSIGN.mean())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.plot(score_array, 'ro')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.plot(score_array, 'ro')"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = KNeighborsClassifier(n_neighbors=33)",
                "ASSIGN.fit(Xtrain_h, Ytrain_h)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = KNeighborsClassifier(n_neighbors=33)",
                "ASSIGN.fit(Xtrain_h, Ytrain_h)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = test.drop(['Id','idhogar','dependency','edjefe','edjefa','rez_esc', 'v18q1', 'v2a1'] ,axis = 'columns')",
                "Xtest"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = test.drop(['Id','idhogar','dependency','edjefe','edjefa','rez_esc', 'v18q1', 'v2a1'] ,axis = 'columns')",
                "Xtest"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.fillna(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.fillna(0)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = knn.predict(Xtest)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = knn.predict(Xtest)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.DataFrame(test.Id)",
                "ASSIGN = pred",
                "prediction"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.DataFrame(test.Id)",
                "ASSIGN = pred",
                "prediction"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "prediction.to_csv(\"submition.csv\",index = False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "prediction.to_csv(\"submition.csv\",index = False)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(os.listdir('..path'))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(os.listdir('..path'))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'Mall_Customers.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'Mall_Customers.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df1.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df1.head(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotCorrelationMatrix(df1, 8)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotCorrelationMatrix(df1, 8)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotScatterMatrix(df1, 12, 10)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotScatterMatrix(df1, 12, 10)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "def calc_logloss(targets, outputs, eps=1e-6):",
                "ASSIGN = [log_loss(np.floor(targets[:,i]), np.clip(outputs[:,i], eps, 1-eps)) for i in range(6)]",
                "return np.average(ASSIGN, weights=[2,1,1,1,1,1])",
                "warnings.filterwarnings(\"ignore\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = ASSIGN.merge(dup, on = 'SOPInstanceUID', how = 'left')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "def calc_logloss(targets, outputs, eps=1e-6):",
                "ASSIGN = [log_loss(np.floor(targets[:,i]), np.clip(outputs[:,i], eps, 1-eps)) for i in range(6)]",
                "return np.average(ASSIGN, weights=[2,1,1,1,1,1])",
                "warnings.filterwarnings(\"ignore\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = ASSIGN.merge(dup, on = 'SOPInstanceUID', how = 'left')"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def get_split_result(filename, test, eps, rm_dup=False):",
                "ASSIGN = pd.read_csv(filename)",
                "ASSIGN['type'] = ASSIGN['ID'].apply(lambda x: x.split('_')[2])",
                "ASSIGN['name'] = ASSIGN['ID'].apply(lambda x: x.split('_')[1])",
                "ASSIGN = f1[['ASSIGN']]",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'epidural']",
                "ASSIGN.columns = ['ASSIGN','epidural']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'intraparenchymal']",
                "ASSIGN.columns = ['ASSIGN','intraparenchymal']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'intraventricular']",
                "ASSIGN.columns = ['ASSIGN','intraventricular']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'subarachnoid']",
                "ASSIGN.columns = ['ASSIGN','subarachnoid']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'subdural']",
                "ASSIGN.columns = ['ASSIGN','subdural']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'any']",
                "ASSIGN.columns = ['ASSIGN','any']",
                "ASSIGN = ASSIGN.merge(f1_any, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_epidural, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_intraparenchymal, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_intraventricular, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_subarachnoid, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_subdural, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.drop_duplicates()",
                "ASSIGN.rename(columns = {'ASSIGN': 'SOPInstanceUID'}, inplace=True)",
                "ASSIGN = 'ID_' + ASSIGN",
                "ASSIGN = ASSIGN.merge(test, on = 'SOPInstanceUID', how = 'left')",
                "if rm_dup:",
                "ASSIGN = name[name['dup'].isnull() == True]",
                "else:",
                "ASSIGN = name.copy()",
                "ASSIGN = name_use[['any_y',",
                "'epidural_y', 'subdural_y', 'subarachnoid_y', 'intraventricular_y',",
                "'intraparenchymal_y']].values",
                "ASSIGN = name_use[['any',",
                "'epidural', 'subdural', 'subarachnoid', 'intraventricular',",
                "'intraparenchymal']].values",
                "return calc_logloss(ASSIGN, ASSIGN, eps=eps)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def get_split_result(filename, test, eps, rm_dup=False):",
                "ASSIGN = pd.read_csv(filename)",
                "ASSIGN['type'] = ASSIGN['ID'].apply(lambda x: x.split('_')[2])",
                "ASSIGN['name'] = ASSIGN['ID'].apply(lambda x: x.split('_')[1])",
                "ASSIGN = f1[['ASSIGN']]",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'epidural']",
                "ASSIGN.columns = ['ASSIGN','epidural']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'intraparenchymal']",
                "ASSIGN.columns = ['ASSIGN','intraparenchymal']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'intraventricular']",
                "ASSIGN.columns = ['ASSIGN','intraventricular']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'subarachnoid']",
                "ASSIGN.columns = ['ASSIGN','subarachnoid']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'subdural']",
                "ASSIGN.columns = ['ASSIGN','subdural']",
                "ASSIGN = f1[['name','Label']][f1['type'] == 'any']",
                "ASSIGN.columns = ['ASSIGN','any']",
                "ASSIGN = ASSIGN.merge(f1_any, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_epidural, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_intraparenchymal, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_intraventricular, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_subarachnoid, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.merge(f1_subdural, on = 'ASSIGN', how = 'left')",
                "ASSIGN = ASSIGN.drop_duplicates()",
                "ASSIGN.rename(columns = {'ASSIGN': 'SOPInstanceUID'}, inplace=True)",
                "ASSIGN = 'ID_' + ASSIGN",
                "ASSIGN = ASSIGN.merge(test, on = 'SOPInstanceUID', how = 'left')",
                "if rm_dup:",
                "ASSIGN = name[name['dup'].isnull() == True]",
                "else:",
                "ASSIGN = name.copy()",
                "ASSIGN = name_use[['any_y',",
                "'epidural_y', 'subdural_y', 'subarachnoid_y', 'intraventricular_y',",
                "'intraparenchymal_y']].values",
                "ASSIGN = name_use[['any',",
                "'epidural', 'subdural', 'subarachnoid', 'intraventricular',",
                "'intraparenchymal']].values",
                "return calc_logloss(ASSIGN, ASSIGN, eps=eps)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "get_split_result(\"..path\", test, 1e-6)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "get_split_result(\"..path\", test, 1e-6)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "get_split_result(\"..path\", test, 1e-6, rm_dup=True)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "get_split_result(\"..path\", test, 1e-6, rm_dup=True)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN.head(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN.head(5)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(f)",
                "print(f)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(f)",
                "print(f)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.nunique()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train.nunique()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize = (8, 5))",
                "plt.title('Category Distribuition')",
                "sns.distplot(train['landmark_id'])",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.figure(figsize = (8, 5))",
                "plt.title('Category Distribuition')",
                "sns.distplot(train['landmark_id'])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(train['landmark_id'].value_counts().head(7))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(train['landmark_id'].value_counts().head(7))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(f)",
                "print(f)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(f)",
                "print(f)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train['landmark_id'].value_counts().describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train['landmark_id'].value_counts().describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "f\"Number of classes under 10 occurences : {(train['landmark_id'].value_counts() <= 10).sum()}path{len(train['landmark_id'].unique())}\""
            ],
            "output_type": "not_existent",
            "content_old": [
                "f\"Number of classes under 10 occurences : {(train['landmark_id'].value_counts() <= 10).sum()}path{len(train['landmark_id'].unique())}\""
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "def display_category(urls, category_name):",
                "ASSIGN = \"width: 180px; margin: 0px; float: left; border: 1px solid black;\"",
                "ASSIGN = ''.join([f\"<img style='{img_style}' src='{u}' path>\" for _, u in urls.head(12).iteritems()])",
                "display(HTML(ASSIGN))",
                "ASSIGN = train['landmark_id'].value_counts().keys()[0]",
                "ASSIGN = train[train['landmark_id'] == category]['url']",
                "display_category(ASSIGN, \"\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "def display_category(urls, category_name):",
                "ASSIGN = \"width: 180px; margin: 0px; float: left; border: 1px solid black;\"",
                "ASSIGN = ''.join([f\"<img style='{img_style}' src='{u}' path>\" for _, u in urls.head(12).iteritems()])",
                "display(HTML(ASSIGN))",
                "ASSIGN = train['landmark_id'].value_counts().keys()[0]",
                "ASSIGN = train[train['landmark_id'] == category]['url']",
                "display_category(ASSIGN, \"\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = train['landmark_id'].value_counts().keys()[1]",
                "ASSIGN = train[train['landmark_id'] == category]['url']",
                "display_category(ASSIGN, \"\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train['landmark_id'].value_counts().keys()[1]",
                "ASSIGN = train[train['landmark_id'] == category]['url']",
                "display_category(ASSIGN, \"\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = train['landmark_id'].value_counts().keys()[2]",
                "ASSIGN = train[train['landmark_id'] == category]['url']",
                "display_category(ASSIGN, \"\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train['landmark_id'].value_counts().keys()[2]",
                "ASSIGN = train[train['landmark_id'] == category]['url']",
                "display_category(ASSIGN, \"\")"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = {}",
                "ASSIGN = []",
                "ASSIGN['people'].append({",
                "'name': 'Scott',",
                "'website': 'stackabuse.com',",
                "'from': 'Nebraska'",
                "})",
                "ASSIGN['people'].append({",
                "'name': 'Larry',",
                "'website': 'google.com',",
                "'from': 'Michigan'",
                "})",
                "ASSIGN['people'].append({",
                "'name': 'Tim',",
                "'website': 'apple.com',",
                "'from': 'Alabama'",
                "})",
                "with open('ASSIGN.json', 'w') as outfile:",
                "json.dump(ASSIGN, outfile)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {}",
                "ASSIGN = []",
                "ASSIGN['people'].append({",
                "'name': 'Scott',",
                "'website': 'stackabuse.com',",
                "'from': 'Nebraska'",
                "})",
                "ASSIGN['people'].append({",
                "'name': 'Larry',",
                "'website': 'google.com',",
                "'from': 'Michigan'",
                "})",
                "ASSIGN['people'].append({",
                "'name': 'Tim',",
                "'website': 'apple.com',",
                "'from': 'Alabama'",
                "})",
                "with open('ASSIGN.json', 'w') as outfile:",
                "json.dump(ASSIGN, outfile)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN=\"people\""
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN=\"people\""
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "os.environ['KAGGLE_USERNAME'] = API[\"username\"]",
                "os.environ['KAGGLE_KEY'] = API[\"key\"]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "os.environ['KAGGLE_USERNAME'] = API[\"username\"]",
                "os.environ['KAGGLE_KEY'] = API[\"key\"]"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = {",
                "\"title\": dataset_name,",
                "\"id\": os.environ['KAGGLE_USERNAME']+\"path\"+dataset_name,",
                "\"licenses\": [",
                "{",
                "\"name\": \"CC0-1.0\"",
                "}",
                "]",
                "}",
                "with open('dataset-metadata.json', 'w') as outfile:",
                "json.dump(ASSIGN, outfile)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = {",
                "\"title\": dataset_name,",
                "\"id\": os.environ['KAGGLE_USERNAME']+\"path\"+dataset_name,",
                "\"licenses\": [",
                "{",
                "\"name\": \"CC0-1.0\"",
                "}",
                "]",
                "}",
                "with open('dataset-metadata.json', 'w') as outfile:",
                "json.dump(ASSIGN, outfile)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\")",
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "display(df_belem.shape, df_curitiba.shape)"
            ],
            "output_type": "display_data",
            "content_old": [
                "display(df_belem.shape, df_curitiba.shape)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "df_belem.set_index('YEAR',inplace=True)",
                "df_curitiba.set_index('YEAR',inplace=True)",
                "display(df_belem.head())",
                "display(df_curitiba.head())"
            ],
            "output_type": "display_data",
            "content_old": [
                "df_belem.set_index('YEAR',inplace=True)",
                "df_curitiba.set_index('YEAR',inplace=True)",
                "display(df_belem.head())",
                "display(df_curitiba.head())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(25,25))",
                "df_belem.hist()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(25,25))",
                "df_belem.hist()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "display(df_belem['JAN'].value_counts())",
                "display(df_curitiba['JAN'].value_counts())"
            ],
            "output_type": "display_data",
            "content_old": [
                "display(df_belem['JAN'].value_counts())",
                "display(df_curitiba['JAN'].value_counts())"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_belem.replace(999.90,np.nan)",
                "ASSIGN = ASSIGN.fillna(ASSIGN.mean())",
                "display(ASSIGN)",
                "ASSIGN = df_curitiba.replace(999.90,np.nan)",
                "ASSIGN = ASSIGN.fillna(ASSIGN.mean())",
                "display(ASSIGN)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_belem.replace(999.90,np.nan)",
                "ASSIGN = ASSIGN.fillna(ASSIGN.mean())",
                "display(ASSIGN)",
                "ASSIGN = df_curitiba.replace(999.90,np.nan)",
                "ASSIGN = ASSIGN.fillna(ASSIGN.mean())",
                "display(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,10))",
                "ASSIGN=plt.figure()",
                "ASSIGN=fig.add_axes([0,0,1,1])",
                "ASSIGN.scatter(df_curitiba_t.index, df_curitiba_t.JUL, color='r')",
                "ASSIGN.scatter(df_belem_t.index, df_belem_t.JUL, color='b')",
                "ASSIGN.set_xlabel('Ano')",
                "ASSIGN.set_ylabel('Temperatura (ºC)')",
                "ASSIGN.legend([\"Curitiba - Julho\", \"Belém - Julho\"])",
                "ASSIGN.set_title('scatter plot')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "plt.figure(figsize=(10,10))",
                "ASSIGN=plt.figure()",
                "ASSIGN=fig.add_axes([0,0,1,1])",
                "ASSIGN.scatter(df_curitiba_t.index, df_curitiba_t.JUL, color='r')",
                "ASSIGN.scatter(df_belem_t.index, df_belem_t.JUL, color='b')",
                "ASSIGN.set_xlabel('Ano')",
                "ASSIGN.set_ylabel('Temperatura (ºC)')",
                "ASSIGN.legend([\"Curitiba - Julho\", \"Belém - Julho\"])",
                "ASSIGN.set_title('scatter plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "display(df_curitiba_t['JUL'].describe())",
                "display(df_belem_t['JUL'].describe())",
                "stats.f_oneway(df_belem_t['JUL'], df_curitiba_t['JUL'])"
            ],
            "output_type": "display_data",
            "content_old": [
                "display(df_curitiba_t['JUL'].describe())",
                "display(df_belem_t['JUL'].describe())",
                "stats.f_oneway(df_belem_t['JUL'], df_curitiba_t['JUL'])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(df_curitiba_t['JAN'],columns=['JAN'])",
                "ASSIGN['A1'] = ASSIGN['JAN'].shift(1)",
                "ASSIGN['A2'] = ASSIGN['JAN'].shift(2)",
                "ASSIGN['A3'] = ASSIGN['JAN'].shift(3)",
                "ASSIGN = ASSIGN.dropna()",
                "display(ASSIGN.head())",
                "X_train, X_test, y_train, y_test = model_selection.train_test_split(ASSIGN.drop(columns=['JAN']),ASSIGN['JAN'],test_size=0.25, random_state=33)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.DataFrame(df_curitiba_t['JAN'],columns=['JAN'])",
                "ASSIGN['A1'] = ASSIGN['JAN'].shift(1)",
                "ASSIGN['A2'] = ASSIGN['JAN'].shift(2)",
                "ASSIGN['A3'] = ASSIGN['JAN'].shift(3)",
                "ASSIGN = ASSIGN.dropna()",
                "display(ASSIGN.head())",
                "X_train, X_test, y_train, y_test = model_selection.train_test_split(ASSIGN.drop(columns=['JAN']),ASSIGN['JAN'],test_size=0.25, random_state=33)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = xgb.XGBRegressor()",
                "ASSIGN.fit(X_train,y_train)",
                "ASSIGN = model.predict(data=X_train)",
                "ASSIGN = model.predict(data=X_test)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = xgb.XGBRegressor()",
                "ASSIGN.fit(X_train,y_train)",
                "ASSIGN = model.predict(data=X_train)",
                "ASSIGN = model.predict(data=X_test)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = math.sqrt(mean_squared_error(p_train, y_train))",
                "print('Pontuação para o treinamento: %.2f RMSE' % (ASSIGN))",
                "ASSIGN = math.sqrt(mean_squared_error(p_test, y_test))",
                "print('Pontuação para o teste: %.2f RMSE' % (ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = math.sqrt(mean_squared_error(p_train, y_train))",
                "print('Pontuação para o treinamento: %.2f RMSE' % (ASSIGN))",
                "ASSIGN = math.sqrt(mean_squared_error(p_test, y_test))",
                "print('Pontuação para o teste: %.2f RMSE' % (ASSIGN))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({'YEAR': X_test.index, 'PRED': p_test, 'REAL': y_test}).reset_index(drop=True)",
                "display(ASSIGN.sort_values(['YEAR']).set_index('YEAR'))",
                "plt.figure(figsize=(10,10))",
                "ASSIGN=plt.figure()",
                "ASSIGN=fig.add_axes([0,0,1,1])",
                "ASSIGN.scatter(ASSIGN['YEAR'],ASSIGN['PRED'] , color='r')",
                "ASSIGN.scatter(ASSIGN['YEAR'],ASSIGN['REAL'] , color='b')",
                "ASSIGN.set_xlabel('Ano')",
                "ASSIGN.set_ylabel('Temperatura (ºC)')",
                "ASSIGN.legend([\"Curitiba - Janeiro - Previsto\", \"Curitiba - Janeiro - Real\"])",
                "ASSIGN.set_title('scatter plot')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pd.DataFrame({'YEAR': X_test.index, 'PRED': p_test, 'REAL': y_test}).reset_index(drop=True)",
                "display(ASSIGN.sort_values(['YEAR']).set_index('YEAR'))",
                "plt.figure(figsize=(10,10))",
                "ASSIGN=plt.figure()",
                "ASSIGN=fig.add_axes([0,0,1,1])",
                "ASSIGN.scatter(ASSIGN['YEAR'],ASSIGN['PRED'] , color='r')",
                "ASSIGN.scatter(ASSIGN['YEAR'],ASSIGN['REAL'] , color='b')",
                "ASSIGN.set_xlabel('Ano')",
                "ASSIGN.set_ylabel('Temperatura (ºC)')",
                "ASSIGN.legend([\"Curitiba - Janeiro - Previsto\", \"Curitiba - Janeiro - Real\"])",
                "ASSIGN.set_title('scatter plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "sales_data.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sales_data.head()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "itemcategories_data.info()",
                "itemcategories_data.head()"
            ],
            "output_type": "stream",
            "content_old": [
                "itemcategories_data.info()",
                "itemcategories_data.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "items_data.info()",
                "items_data.head()"
            ],
            "output_type": "stream",
            "content_old": [
                "items_data.info()",
                "items_data.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "shops_data.info()",
                "shops_data.head()"
            ],
            "output_type": "stream",
            "content_old": [
                "shops_data.info()",
                "shops_data.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "test_data.info()",
                "test_data.head()"
            ],
            "output_type": "stream",
            "content_old": [
                "test_data.info()",
                "test_data.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "shops_data.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "shops_data.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "sales_data.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "sales_data.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,4))",
                "sns.scatterplot(x=sales_data.item_cnt_day, y=sales_data.item_price, data=sales_data)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(10,4))",
                "sns.scatterplot(x=sales_data.item_cnt_day, y=sales_data.item_price, data=sales_data)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN[ASSIGN.item_price<45000]",
                "ASSIGN = ASSIGN[ASSIGN.item_cnt_day<600]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN[ASSIGN.item_price<45000]",
                "ASSIGN = ASSIGN[ASSIGN.item_cnt_day<600]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,4))",
                "sns.scatterplot(x=sales_data.item_cnt_day, y=sales_data.item_price, data=sales_data)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(10,4))",
                "sns.scatterplot(x=sales_data.item_cnt_day, y=sales_data.item_price, data=sales_data)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = sales_data",
                "ASSIGN['month'] = pd.DatetimeIndex(ASSIGN['date']).month",
                "ASSIGN['year'] = pd.DatetimeIndex(ASSIGN['date']).year",
                "ASSIGN.head(10)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = sales_data",
                "ASSIGN['month'] = pd.DatetimeIndex(ASSIGN['date']).month",
                "ASSIGN['year'] = pd.DatetimeIndex(ASSIGN['date']).year",
                "ASSIGN.head(10)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "satıs_grup = sales_train_sub.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\"item_cnt_day\"].agg('sum').reset_index()",
                "ASSIGN=satıs_grup.iloc[:,:-1]",
                "ASSIGN=satıs_grup.iloc[:,-1:]",
                "ASSIGN = train_test_split(x,y,test_size=0.25, random_state=0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "satıs_grup = sales_train_sub.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\"item_cnt_day\"].agg('sum').reset_index()",
                "ASSIGN=satıs_grup.iloc[:,:-1]",
                "ASSIGN=satıs_grup.iloc[:,-1:]",
                "ASSIGN = train_test_split(x,y,test_size=0.25, random_state=0)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "x"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "x"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = ExtraTreesRegressor(n_estimators=25,random_state=16)",
                "ASSIGN.fit(x_train,y_train.values.ravel())",
                "ASSIGN = etr.predict(x_test)",
                "print(,r2_score(y_test,ASSIGN))",
                "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, ASSIGN))",
                "print('Root Mean Squared Error:', metrics.mean_squared_error(y_test, ASSIGN, squared=False))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = ExtraTreesRegressor(n_estimators=25,random_state=16)",
                "ASSIGN.fit(x_train,y_train.values.ravel())",
                "ASSIGN = etr.predict(x_test)",
                "print(,r2_score(y_test,ASSIGN))",
                "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, ASSIGN))",
                "print('Root Mean Squared Error:', metrics.mean_squared_error(y_test, ASSIGN, squared=False))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(os.listdir())"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "forest_data.head(20)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "forest_data.head(20)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "forest_data.info()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "forest_data.info()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(\"..path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "happiness_data.info()",
                "happiness_data.head(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "happiness_data.info()",
                "happiness_data.head(5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.concat([forest_data.iloc[:,:1],forest_data.iloc[:,-1]],axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.concat([forest_data.iloc[:,:1],forest_data.iloc[:,-1]],axis=1)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = happiness_data.merge(new_forest_data, left_on='Country',right_on='CountryName')",
                "ASSIGN.rename(columns={'2015': 'ForestRatio'}, inplace=True)",
                "ASSIGN.drop([\"CountryName\"], axis= 1, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = happiness_data.merge(new_forest_data, left_on='Country',right_on='CountryName')",
                "ASSIGN.rename(columns={'2015': 'ForestRatio'}, inplace=True)",
                "ASSIGN.drop([\"CountryName\"], axis= 1, inplace=True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "result.head(20)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "result.head(20)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = result[pd.notnull(result.ForestRatio) & result.ForestRatio > 0]",
                "ASSIGN.columns = [each.replace(\" \",\"\").replace(\"(\",\"_\").replace(\")\",\"\") for each in ASSIGN.columns]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = result[pd.notnull(result.ForestRatio) & result.ForestRatio > 0]",
                "ASSIGN.columns = [each.replace(\" \",\"\").replace(\"(\",\"_\").replace(\")\",\"\") for each in ASSIGN.columns]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "main_data.corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "main_data.corr()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(x = main_data.HappinessScore, y = main_data.ForestRatio)",
                "plt.xlabel(\"Happiness Score\")",
                "plt.ylabel(\"Forest Ratio\")",
                "plt.title(\"Happiness Score vs Forest Ratio\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.scatter(x = main_data.HappinessScore, y = main_data.ForestRatio)",
                "plt.xlabel(\"Happiness Score\")",
                "plt.ylabel(\"Forest Ratio\")",
                "plt.title(\"Happiness Score vs Forest Ratio\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = main_data.groupby([\"Region\"]).mean()",
                "ASSIGN.corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = main_data.groupby([\"Region\"]).mean()",
                "ASSIGN.corr()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "new_data"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "new_data"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(x = new_data.ForestRatio, y = new_data.Freedom)",
                "plt.xlabel(\"Forest Ratio\")",
                "plt.ylabel(\"Freedom\")",
                "plt.title(\"Forest Ratio vs Freedom\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.scatter(x = new_data.ForestRatio, y = new_data.Freedom)",
                "plt.xlabel(\"Forest Ratio\")",
                "plt.ylabel(\"Freedom\")",
                "plt.title(\"Forest Ratio vs Freedom\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "happiness_data.columns = [ each.replace(\" \",\"\").replace(\"(\",\"_\").replace(\")\",\"\") for each in happiness_data.columns ]",
                "happiness_data.columns"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "happiness_data.columns = [ each.replace(\" \",\"\").replace(\"(\",\"_\").replace(\")\",\"\") for each in happiness_data.columns ]",
                "happiness_data.columns"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "happiness_data.corr()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "happiness_data.corr()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(figsize=(15, 15))",
                "sns.heatmap(happiness_data.corr(), annot=True, linewidths=.5, fmt= '.2f',ax=ax)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(figsize=(15, 15))",
                "sns.heatmap(happiness_data.corr(), annot=True, linewidths=.5, fmt= '.2f',ax=ax)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "happiness_data.Family.plot(color = 'r',label = 'Family',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.Economy_GDPperCapita.plot(color = 'orange',label = 'Economy_GDPperCapita',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.Health_LifeExpectancy.plot(color = 'yellow',label = 'Health (Life Expectancy)',linewidth=1, alpha = 1.0,grid = True)",
                "happiness_data.Freedom.plot(color = 'g',label = 'Freedom',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.Trust_GovernmentCorruption.plot(color = 'black',label = 'Trust (Government Corruption)',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.Generosity.plot(color = 'b',label = 'Generosity',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.DystopiaResidual.plot(color = 'gray',label = 'Dystopia Residual',linewidth=1, alpha = 0.9,grid = True)",
                "plt.legend()",
                "plt.xlabel('Happiness Rank')",
                "plt.ylabel('Score')",
                "plt.title('Happiness Factors Line Plot Graph')",
                "ASSIGN = plt.gcf()",
                "ASSIGN.set_size_inches(18.5, 10.5, forward=True)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "happiness_data.Family.plot(color = 'r',label = 'Family',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.Economy_GDPperCapita.plot(color = 'orange',label = 'Economy_GDPperCapita',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.Health_LifeExpectancy.plot(color = 'yellow',label = 'Health (Life Expectancy)',linewidth=1, alpha = 1.0,grid = True)",
                "happiness_data.Freedom.plot(color = 'g',label = 'Freedom',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.Trust_GovernmentCorruption.plot(color = 'black',label = 'Trust (Government Corruption)',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.Generosity.plot(color = 'b',label = 'Generosity',linewidth=1, alpha = 0.9,grid = True)",
                "happiness_data.DystopiaResidual.plot(color = 'gray',label = 'Dystopia Residual',linewidth=1, alpha = 0.9,grid = True)",
                "plt.legend()",
                "plt.xlabel('Happiness Rank')",
                "plt.ylabel('Score')",
                "plt.title('Happiness Factors Line Plot Graph')",
                "ASSIGN = plt.gcf()",
                "ASSIGN.set_size_inches(18.5, 10.5, forward=True)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(nrows = 2, ncols = 4, figsize=(30, 15))",
                "happiness_data.plot(kind = \"scatter\", x= \"Family\", y = \"HappinessScore\", ax = axes[0][0])",
                "happiness_data.plot(kind = \"scatter\", x= \"Economy_GDPperCapita\", y = \"HappinessScore\", ax = axes[0][1])",
                "happiness_data.plot(kind = \"scatter\", x= \"Health_LifeExpectancy\", y = \"HappinessScore\", ax = axes[0][2])",
                "happiness_data.plot(kind = \"scatter\", x= \"Freedom\", y = \"HappinessScore\", ax = axes[0][3])",
                "happiness_data.plot(kind = \"scatter\", x= \"Trust_GovernmentCorruption\", y = \"HappinessScore\", ax = axes[1][0])",
                "happiness_data.plot(kind = \"scatter\", x= \"Generosity\", y = \"HappinessScore\", ax = axes[1][1])",
                "happiness_data.plot(kind = \"scatter\", x= \"DystopiaResidual\", y = \"HappinessScore\", ax = axes[1][2])",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(nrows = 2, ncols = 4, figsize=(30, 15))",
                "happiness_data.plot(kind = \"scatter\", x= \"Family\", y = \"HappinessScore\", ax = axes[0][0])",
                "happiness_data.plot(kind = \"scatter\", x= \"Economy_GDPperCapita\", y = \"HappinessScore\", ax = axes[0][1])",
                "happiness_data.plot(kind = \"scatter\", x= \"Health_LifeExpectancy\", y = \"HappinessScore\", ax = axes[0][2])",
                "happiness_data.plot(kind = \"scatter\", x= \"Freedom\", y = \"HappinessScore\", ax = axes[0][3])",
                "happiness_data.plot(kind = \"scatter\", x= \"Trust_GovernmentCorruption\", y = \"HappinessScore\", ax = axes[1][0])",
                "happiness_data.plot(kind = \"scatter\", x= \"Generosity\", y = \"HappinessScore\", ax = axes[1][1])",
                "happiness_data.plot(kind = \"scatter\", x= \"DystopiaResidual\", y = \"HappinessScore\", ax = axes[1][2])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(nrows = 2, ncols = 4, figsize=(30, 15))",
                "happiness_data.Family.plot(kind = 'hist',bins = 50, ax = axes[0][0])",
                "happiness_data.Economy_GDPperCapita.plot(kind = \"hist\", ax = axes[0][1])",
                "happiness_data.Health_LifeExpectancy.plot(kind = \"hist\", ax = axes[0][2])",
                "happiness_data.Freedom.plot(kind = \"hist\", ax = axes[0][3])",
                "happiness_data.Trust_GovernmentCorruption.plot(kind = \"hist\", ax = axes[1][0])",
                "happiness_data.Generosity.plot(kind = \"hist\", ax = axes[1][1])",
                "happiness_data.DystopiaResidual.plot(kind = \"hist\", ax = axes[1][2])",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = plt.subplots(nrows = 2, ncols = 4, figsize=(30, 15))",
                "happiness_data.Family.plot(kind = 'hist',bins = 50, ax = axes[0][0])",
                "happiness_data.Economy_GDPperCapita.plot(kind = \"hist\", ax = axes[0][1])",
                "happiness_data.Health_LifeExpectancy.plot(kind = \"hist\", ax = axes[0][2])",
                "happiness_data.Freedom.plot(kind = \"hist\", ax = axes[0][3])",
                "happiness_data.Trust_GovernmentCorruption.plot(kind = \"hist\", ax = axes[1][0])",
                "happiness_data.Generosity.plot(kind = \"hist\", ax = axes[1][1])",
                "happiness_data.DystopiaResidual.plot(kind = \"hist\", ax = axes[1][2])",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "happiness_data.boxplot(column='HappinessScore',by = 'Region', figsize=(30, 15))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "happiness_data.boxplot(column='HappinessScore',by = 'Region', figsize=(30, 15))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "happiness_data[\"HappinessDegree\"] = ['Happy' if each > 6 else 'Normal' if each > 5 else 'Unhappy' for each in happiness_data.HappinessScore ]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "happiness_data[\"HappinessDegree\"] = ['Happy' if each > 6 else 'Normal' if each > 5 else 'Unhappy' for each in happiness_data.HappinessScore ]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = happiness_data.pivot_table( index=['Region'], columns = \"HappinessDegree\", values = \"HappinessRank\",aggfunc='count')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = happiness_data.pivot_table( index=['Region'], columns = \"HappinessDegree\", values = \"HappinessRank\",aggfunc='count')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "pivot_data"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "pivot_data"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"path\", na_values = \"?\")",
                "adult_train.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"path\", na_values = \"?\")",
                "adult_train.shape"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"path\", na_values = \"?\")",
                "adult_test.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"path\", na_values = \"?\")",
                "adult_test.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "adult_train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "adult_train.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "adult_train.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "adult_train.describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "adult_train.describe(exclude = [np.number])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "adult_train.describe(exclude = [np.number])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = adult_train.dropna()",
                "n_adult.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = adult_train.dropna()",
                "n_adult.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = adult_train.describe(exclude = [np.number]).columns",
                "ASSIGN = adult_train[cat].apply(pd.Categorical)",
                "for col in ASSIGN:",
                "adult_train[col + \"_cat\"] = ASSIGN[col].ASSIGN.codes",
                "ASSIGN = adult_test[cat[:-1]].apply(pd.Categorical)",
                "for col in ASSIGN[:-1]:",
                "adult_test[col + \"_cat\"] = ASSIGN[col].ASSIGN.codes"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = adult_train.describe(exclude = [np.number]).columns",
                "ASSIGN = adult_train[cat].apply(pd.Categorical)",
                "for col in ASSIGN:",
                "adult_train[col + \"_cat\"] = ASSIGN[col].ASSIGN.codes",
                "ASSIGN = adult_test[cat[:-1]].apply(pd.Categorical)",
                "for col in ASSIGN[:-1]:",
                "adult_test[col + \"_cat\"] = ASSIGN[col].ASSIGN.codes"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "adult_train.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "adult_train.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "sns.pairplot(adult_train, vars=[\"age\", \"fnlwgt\", \"education.num\", \"capital.gain\", \"capital.loss\",",
                "\"hours.per.week\"], hue=\"income\", diag_kws={'bw':\"1.0\"}, corner=True)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "sns.pairplot(adult_train, vars=[\"age\", \"fnlwgt\", \"education.num\", \"capital.gain\", \"capital.loss\",",
                "\"hours.per.week\"], hue=\"income\", diag_kws={'bw':\"1.0\"}, corner=True)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "adult_train[\"native.country\"].value_counts().plot(kind=\"pie\", figsize = (8,8))",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "adult_train[\"native.country\"].value_counts().plot(kind=\"pie\", figsize = (8,8))",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = adult_train.copy()",
                "ASSIGN = LabelEncoder()",
                "ASSIGN[\"income\"] = ASSIGN.fit_transform(ASSIGN['income'])",
                "plt.figure(figsize=(10,10))",
                "ASSIGN = np.zeros_like(adult_copy.corr(), dtype=np.bool)",
                "ASSIGN[np.triu_indices_from(ASSIGN)] = True",
                "sns.heatmap(ASSIGN.corr(), square=True, vmin=-1, vmax=1, annot = True, linewidths=.5, ASSIGN=ASSIGN)",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = adult_train.copy()",
                "ASSIGN = LabelEncoder()",
                "ASSIGN[\"income\"] = ASSIGN.fit_transform(ASSIGN['income'])",
                "plt.figure(figsize=(10,10))",
                "ASSIGN = np.zeros_like(adult_copy.corr(), dtype=np.bool)",
                "ASSIGN[np.triu_indices_from(ASSIGN)] = True",
                "sns.heatmap(ASSIGN.corr(), square=True, vmin=-1, vmax=1, annot = True, linewidths=.5, ASSIGN=ASSIGN)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = plt.subplots(nrows = 2, ncols = 2)",
                "plt.tight_layout(pad = .4, w_pad = .5, h_pad = 1.)",
                "adult_train.groupby(['sex', 'income']).size().unstack().plot(kind = 'bar', stacked = True, ax = axes[0, 0], figsize = (20, 15))",
                "ASSIGN = adult_train.groupby(['ASSIGN', 'income']).size().unstack()",
                "ASSIGN = adult_train.groupby('relationship').size()",
                "ASSIGN = ASSIGN.sort_values('sum', ascending = False)[['<=50K', '>50K']]",
                "ASSIGN.plot(kind = 'bar', stacked = True, ax = axes[0, 1])",
                "ASSIGN = adult_train.groupby(['ASSIGN', 'income']).size().unstack()",
                "ASSIGN = adult_train.groupby('education').size()",
                "ASSIGN = ASSIGN.sort_values('sum', ascending = False)[['<=50K', '>50K']]",
                "ASSIGN.plot(kind = 'bar', stacked = True, ax = axes[1, 0])",
                "ASSIGN = adult_train.groupby(['ASSIGN', 'income']).size().unstack()",
                "ASSIGN = adult_train.groupby('occupation').size()",
                "ASSIGN = ASSIGN.sort_values('sum', ascending = False)[['<=50K', '>50K']]",
                "ASSIGN.plot(kind = 'bar', stacked = True, ax = axes[1, 1])"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = plt.subplots(nrows = 2, ncols = 2)",
                "plt.tight_layout(pad = .4, w_pad = .5, h_pad = 1.)",
                "adult_train.groupby(['sex', 'income']).size().unstack().plot(kind = 'bar', stacked = True, ax = axes[0, 0], figsize = (20, 15))",
                "ASSIGN = adult_train.groupby(['ASSIGN', 'income']).size().unstack()",
                "ASSIGN = adult_train.groupby('relationship').size()",
                "ASSIGN = ASSIGN.sort_values('sum', ascending = False)[['<=50K', '>50K']]",
                "ASSIGN.plot(kind = 'bar', stacked = True, ax = axes[0, 1])",
                "ASSIGN = adult_train.groupby(['ASSIGN', 'income']).size().unstack()",
                "ASSIGN = adult_train.groupby('education').size()",
                "ASSIGN = ASSIGN.sort_values('sum', ascending = False)[['<=50K', '>50K']]",
                "ASSIGN.plot(kind = 'bar', stacked = True, ax = axes[1, 0])",
                "ASSIGN = adult_train.groupby(['ASSIGN', 'income']).size().unstack()",
                "ASSIGN = adult_train.groupby('occupation').size()",
                "ASSIGN = ASSIGN.sort_values('sum', ascending = False)[['<=50K', '>50K']]",
                "ASSIGN.plot(kind = 'bar', stacked = True, ax = axes[1, 1])"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN= ['age', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']",
                "ASSIGN= ['occupation', 'relationship', 'sex','education']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN= ['age', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']",
                "ASSIGN= ['occupation', 'relationship', 'sex','education']"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = adult_train[princ_num_colum + princ_cat_colum]",
                "ASSIGN = adult_train[princ_num_colum + list(map(lambda x: x + \"_cat\", princ_cat_colum))]",
                "ASSIGN = adult_test[princ_num_colum + princ_cat_colum]",
                "ASSIGN = adult_test[princ_num_colum + list(map(lambda x: x + \"_cat\", princ_cat_colum))]",
                "ASSIGN = adult_train.income"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = adult_train[princ_num_colum + princ_cat_colum]",
                "ASSIGN = adult_train[princ_num_colum + list(map(lambda x: x + \"_cat\", princ_cat_colum))]",
                "ASSIGN = adult_test[princ_num_colum + princ_cat_colum]",
                "ASSIGN = adult_test[princ_num_colum + list(map(lambda x: x + \"_cat\", princ_cat_colum))]",
                "ASSIGN = adult_train.income"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = {}",
                "ASSIGN = 0.0",
                "for k in range(30, 35):",
                "ASSIGN = KNeighborsClassifier(k, metric = 'manhattan')",
                "ASSIGN = np.mean(cross_val_score(knn, numX_train, Yadult, cv = 10))",
                "if ASSIGN > ASSIGN:",
                "ASSIGN = k",
                "ASSIGN = score",
                "ASSIGN = knn",
                "ASSIGN['KNN'].fit(numX_train, Yadult)",
                "print(.format(ASSIGN, ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = {}",
                "ASSIGN = 0.0",
                "for k in range(30, 35):",
                "ASSIGN = KNeighborsClassifier(k, metric = 'manhattan')",
                "ASSIGN = np.mean(cross_val_score(knn, numX_train, Yadult, cv = 10))",
                "if ASSIGN > ASSIGN:",
                "ASSIGN = k",
                "ASSIGN = score",
                "ASSIGN = knn",
                "ASSIGN['KNN'].fit(numX_train, Yadult)",
                "print(.format(ASSIGN, ASSIGN))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = classifiers['KNN'].predict(numXadul_test)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = classifiers['KNN'].predict(numXadul_test)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame({'Id' : list(range(len(predictions)))})",
                "ASSIGN = pd.DataFrame({'ASSIGN' : predictions})",
                "ASSIGN = income"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame({'Id' : list(range(len(predictions)))})",
                "ASSIGN = pd.DataFrame({'ASSIGN' : predictions})",
                "ASSIGN = income"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "result.to_csv(\"submission.csv\", index = True, index_label = 'Id')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "result.to_csv(\"submission.csv\", index = True, index_label = 'Id')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "binder.bind(globals())",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "binder.bind(globals())",
                "print()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "museum_data.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "museum_data.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "museum_data.tail()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "museum_data.tail()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "list(museum_data.columns)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "list(museum_data.columns)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = '",
                "ASSIGN = '",
                "ASSIGN = '",
                "ASSIGN = '",
                "register_matplotlib_converters()",
                "warnings.filterwarnings('ignore')",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = '",
                "ASSIGN = '",
                "ASSIGN = '",
                "ASSIGN = '",
                "register_matplotlib_converters()",
                "warnings.filterwarnings('ignore')",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('path',parse_dates=['Date'], dayfirst=True)",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = pd.read_excel('path',sheet_name='India', parse_dates=['Date'])",
                "ASSIGN = pd.read_excel('path',sheet_name='Italy', parse_dates=['Date'])",
                "ASSIGN = pd.read_excel('path',sheet_name='Korea', parse_dates=['Date'])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('path',parse_dates=['Date'], dayfirst=True)",
                "ASSIGN = pd.read_csv('path')",
                "ASSIGN = pd.read_excel('path',sheet_name='India', parse_dates=['Date'])",
                "ASSIGN = pd.read_excel('path',sheet_name='Italy', parse_dates=['Date'])",
                "ASSIGN = pd.read_excel('path',sheet_name='Korea', parse_dates=['Date'])"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_india.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_india.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "df_coordinates.dropna(axis = 1, inplace = True)",
                "df_coordinates.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_coordinates.dropna(axis = 1, inplace = True)",
                "df_coordinates.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "df_coordinates.rename(columns = {'Name of State path':'Statepath'}, inplace = True)",
                "df_coordinates.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_coordinates.rename(columns = {'Name of State path':'Statepath'}, inplace = True)",
                "df_coordinates.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_india.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df_india.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_india.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_india.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_india.dropna(axis = 0, inplace = True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_india.dropna(axis = 0, inplace = True)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_india.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_india.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_india[\"Statepath\"].replace({'Chattisgarh': 'Chhattisgarh ',",
                "'Chhattisgarh' :'Chhattisgarh ',",
                "'Puducherry' : 'Pondicherry',",
                "'Himachal Pradesh' : 'Himachal Pradesh ',",
                "'Madhya Pradesh' : 'Madhya Pradesh ',",
                "'Bihar':'Bihar ',",
                "'Himachal Pradesh':'Himachal Pradesh ',",
                "'Manipur':'Manipur ',",
                "'West Bengal':'West Bengal ',",
                "'Goa' : 'Goa '}, inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_india[\"Statepath\"].replace({'Chattisgarh': 'Chhattisgarh ',",
                "'Chhattisgarh' :'Chhattisgarh ',",
                "'Puducherry' : 'Pondicherry',",
                "'Himachal Pradesh' : 'Himachal Pradesh ',",
                "'Madhya Pradesh' : 'Madhya Pradesh ',",
                "'Bihar':'Bihar ',",
                "'Himachal Pradesh':'Himachal Pradesh ',",
                "'Manipur':'Manipur ',",
                "'West Bengal':'West Bengal ',",
                "'Goa' : 'Goa '}, inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.merge(ASSIGN, df_coordinates, how='left', on='Statepath')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.merge(ASSIGN, df_coordinates, how='left', on='Statepath')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_india.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_india.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "df_india[['Latitude','Longitude']] = df_india[['Latitude','Longitude']].fillna(0)",
                "df_india.isnull().sum()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_india[['Latitude','Longitude']] = df_india[['Latitude','Longitude']].fillna(0)",
                "df_india.isnull().sum()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.drop('Sno', axis = 1)",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = ASSIGN.drop('Sno', axis = 1)",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "df_india.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "df_india.shape"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "df_india.to_csv('Processed_data.csv')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_india.to_csv('Processed_data.csv')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN[['Date', 'Statepath', 'Latitude', 'Longitude','ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths']]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN[['Date', 'Statepath', 'Latitude', 'Longitude','ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths']]"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths','Active']",
                "df_india['Active'] = (df_india['ConfirmedIndianNational'] + df_india['ConfirmedForeignNational']) - df_india['Deaths'] - df_india['Cured']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths','Active']",
                "df_india['Active'] = (df_india['ConfirmedIndianNational'] + df_india['ConfirmedForeignNational']) - df_india['Deaths'] - df_india['Cured']"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_india.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df_india.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_india[Total_cases] = df_india[Total_cases].fillna(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_india[Total_cases] = df_india[Total_cases].fillna(0)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = df_india[df_india['Statepath'].str.contains('Maharashtra')]",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df_india[df_india['Statepath'].str.contains('Maharashtra')]",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = df_india[df_india['Statepath'].str.contains('Kerala')]",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df_india[df_india['Statepath'].str.contains('Kerala')]",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df_india.groupby('Date')['ConfirmedIndianNational','ConfirmedForeignNational','Deaths', 'Cured', 'Active'].sum().reset_index()",
                "ASSIGN.style.background_gradient(cmap='Reds')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df_india.groupby('Date')['ConfirmedIndianNational','ConfirmedForeignNational','Deaths', 'Cured', 'Active'].sum().reset_index()",
                "ASSIGN.style.background_gradient(cmap='Reds')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "Indian_National = df_india['ConfirmedIndianNational'].sum()",
                "ASSIGN = df_india['ConfirmedForeignNational'].sum()",
                "ASSIGN ={\"Indian\": Indian_National,\"Foriengners\":Foreigners}",
                "ASSIGN=['orange','blue']",
                "plt.figure(figsize = (10,10))",
                "plt.pie(ASSIGN.values(),labels=ASSIGN.keys(),ASSIGN=ASSIGN,shadow=True,explode=(0.1, 0.1), autopct='%1.2f%%')",
                "plt.axis('equal')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "Indian_National = df_india['ConfirmedIndianNational'].sum()",
                "ASSIGN = df_india['ConfirmedForeignNational'].sum()",
                "ASSIGN ={\"Indian\": Indian_National,\"Foriengners\":Foreigners}",
                "ASSIGN=['orange','blue']",
                "plt.figure(figsize = (10,10))",
                "plt.pie(ASSIGN.values(),labels=ASSIGN.keys(),ASSIGN=ASSIGN,shadow=True,explode=(0.1, 0.1), autopct='%1.2f%%')",
                "plt.axis('equal')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df_india_latest[df_india_latest['Date']==max(df_india_latest['Date'])].reset_index(drop=True)",
                "ASSIGN.style.background_gradient(cmap='copper')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df_india_latest[df_india_latest['Date']==max(df_india_latest['Date'])].reset_index(drop=True)",
                "ASSIGN.style.background_gradient(cmap='copper')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = slate.melt(id_vars=\"Date\", value_vars=['Active','Cured','Deaths'])",
                "plot"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = slate.melt(id_vars=\"Date\", value_vars=['Active','Cured','Deaths'])",
                "plot"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ex.treemap(plot, path=['variable'], values=\"value\", height=500, width=800,",
                "ASSIGN=[acti,cure,deth])",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = ex.treemap(plot, path=['variable'], values=\"value\", height=500, width=800,",
                "ASSIGN=[acti,cure,deth])",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df_india[df_india['Date']==max(df_india['Date'])].reset_index()",
                "ASSIGN = india_latest.groupby('Statepath')['ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths','Active'].sum().reset_index()",
                "ASSIGN.style.background_gradient(cmap='OrRd')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df_india[df_india['Date']==max(df_india['Date'])].reset_index()",
                "ASSIGN = india_latest.groupby('Statepath')['ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths','Active'].sum().reset_index()",
                "ASSIGN.style.background_gradient(cmap='OrRd')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = india_latest_groupby.sort_values(by='ConfirmedIndianNational', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.style.background_gradient(cmap='OrRd')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = india_latest_groupby.sort_values(by='ConfirmedIndianNational', ascending=False)",
                "ASSIGN = ASSIGN.reset_index(drop=True)",
                "ASSIGN.style.background_gradient(cmap='OrRd')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = state_confirmed[state_confirmed['Deaths']>0][['Statepath','Deaths']]",
                "ASSIGN.sort_values('Deaths',ascending=False).reset_index(drop=True).style.background_gradient(cmap='OrRd')"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = state_confirmed[state_confirmed['Deaths']>0][['Statepath','Deaths']]",
                "ASSIGN.sort_values('Deaths',ascending=False).reset_index(drop=True).style.background_gradient(cmap='OrRd')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = state_confirmed[state_confirmed['ConfirmedIndianNational']+ state_confirmed['ConfirmedForeignNational'] ==",
                "state_confirmed['Deaths']+ state_confirmed['Cured']]",
                "ASSIGN = ASSIGN[['Statepath','ConfirmedIndianNational','ConfirmedForeignNational','Deaths','Cured']]",
                "ASSIGN = ASSIGN.sort_values('ConfirmedIndianNational', ascending=False)",
                "ASSIGN['Cured'].count()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = state_confirmed[state_confirmed['ConfirmedIndianNational']+ state_confirmed['ConfirmedForeignNational'] ==",
                "state_confirmed['Deaths']+ state_confirmed['Cured']]",
                "ASSIGN = ASSIGN[['Statepath','ConfirmedIndianNational','ConfirmedForeignNational','Deaths','Cured']]",
                "ASSIGN = ASSIGN.sort_values('ConfirmedIndianNational', ascending=False)",
                "ASSIGN['Cured'].count()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = folium.Map(location=[20.5937,78.9629], tiles='cartodbpositron', min_zoom=4, max_zoom=10, zoom_start=4)",
                "for i in range(0, len(df_india)):",
                "folium.Circle(",
                "ASSIGN=[df_india.iloc[i]['Latitude'],df_india.iloc[i]['Longitude']],",
                "ASSIGN='crimson',",
                "ASSIGN = '<li><bold>Statepath: '+str(df_india.iloc[i]['Statepath'])+",
                "'<li><bold>ConfirmedIndianNational : '+str(df_india.iloc[i]['ConfirmedIndianNational'])+",
                "'<li><bold>ConfirmedForeignNational : '+str(df_india.iloc[i]['ConfirmedForeignNational'])+",
                "'<li><bold>Deaths : '+str(df_india.iloc[i]['Deaths'])+",
                "'<li><bold>Cured : '+str(df_india.iloc[i]['Cured']),",
                "ASSIGN=int(df_india.iloc[i]['ConfirmedIndianNational'])**1.1).add_to(India)",
                "India"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = folium.Map(location=[20.5937,78.9629], tiles='cartodbpositron', min_zoom=4, max_zoom=10, zoom_start=4)",
                "for i in range(0, len(df_india)):",
                "folium.Circle(",
                "ASSIGN=[df_india.iloc[i]['Latitude'],df_india.iloc[i]['Longitude']],",
                "ASSIGN='crimson',",
                "ASSIGN = '<li><bold>Statepath: '+str(df_india.iloc[i]['Statepath'])+",
                "'<li><bold>ConfirmedIndianNational : '+str(df_india.iloc[i]['ConfirmedIndianNational'])+",
                "'<li><bold>ConfirmedForeignNational : '+str(df_india.iloc[i]['ConfirmedForeignNational'])+",
                "'<li><bold>Deaths : '+str(df_india.iloc[i]['Deaths'])+",
                "'<li><bold>Cured : '+str(df_india.iloc[i]['Cured']),",
                "ASSIGN=int(df_india.iloc[i]['ConfirmedIndianNational'])**1.1).add_to(India)",
                "India"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_india.groupby('Date')['Cured', 'Deaths', 'Active'].sum().reset_index()",
                "ASSIGN = ASSIGN.melt(id_vars='Date', value_vars=['Cured', 'Deaths', 'Active'],",
                "ASSIGN='Case', value_name='Count')",
                "ASSIGN.head()",
                "ASSIGN=ex.area(graph, x='Date', y='Count', color='Case',",
                "ASSIGN = 'Cases over time', color_discrete_sequence=[cure, deth, acti])",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_india.groupby('Date')['Cured', 'Deaths', 'Active'].sum().reset_index()",
                "ASSIGN = ASSIGN.melt(id_vars='Date', value_vars=['Cured', 'Deaths', 'Active'],",
                "ASSIGN='Case', value_name='Count')",
                "ASSIGN.head()",
                "ASSIGN=ex.area(graph, x='Date', y='Count', color='Case',",
                "ASSIGN = 'Cases over time', color_discrete_sequence=[cure, deth, acti])",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "Cure_over_Death = df_india.groupby('Date').sum().reset_index()",
                "Cure_over_Death['No. of Deaths to 100 Confirmed Cases'] = round(Cure_over_Death['Deaths']path(Cure_over_Death['ConfirmedIndianNational']+Cure_over_Death['ConfirmedForeignNational']),3)*100",
                "Cure_over_Death['No. of Recovered to 100 Confirmed Cases'] = round(Cure_over_Death['Cured']path(Cure_over_Death['ConfirmedIndianNational']+Cure_over_Death['ConfirmedForeignNational']),3)*100",
                "Cure_over_Death = Cure_over_Death.melt(id_vars ='Date',",
                "ASSIGN=['No. of Deaths to 100 Confirmed Cases','No. of Recovered to 100 Confirmed Cases'],",
                "ASSIGN='Ratio',",
                "ASSIGN='Value')",
                "ASSIGN = ex.line(Cure_over_Death, x='Date', y='Value', color='Ratio', log_y=True,",
                "ASSIGN='Cure_over_Death', color_discrete_sequence=[deth,cure])",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "Cure_over_Death = df_india.groupby('Date').sum().reset_index()",
                "Cure_over_Death['No. of Deaths to 100 Confirmed Cases'] = round(Cure_over_Death['Deaths']path(Cure_over_Death['ConfirmedIndianNational']+Cure_over_Death['ConfirmedForeignNational']),3)*100",
                "Cure_over_Death['No. of Recovered to 100 Confirmed Cases'] = round(Cure_over_Death['Cured']path(Cure_over_Death['ConfirmedIndianNational']+Cure_over_Death['ConfirmedForeignNational']),3)*100",
                "Cure_over_Death = Cure_over_Death.melt(id_vars ='Date',",
                "ASSIGN=['No. of Deaths to 100 Confirmed Cases','No. of Recovered to 100 Confirmed Cases'],",
                "ASSIGN='Ratio',",
                "ASSIGN='Value')",
                "ASSIGN = ex.line(Cure_over_Death, x='Date', y='Value', color='Ratio', log_y=True,",
                "ASSIGN='Cure_over_Death', color_discrete_sequence=[deth,cure])",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = df_india.drop(['Latitude', 'Longitude'], axis=1)",
                "ASSIGN['TotalConfirmed'] = ASSIGN['ConfirmedIndianNational'] + ASSIGN['ConfirmedForeignNational']",
                "ASSIGN = ASSIGN[['Date', 'Statepath','TotalConfirmed','ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths','Active']]",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = df_india.drop(['Latitude', 'Longitude'], axis=1)",
                "ASSIGN['TotalConfirmed'] = ASSIGN['ConfirmedIndianNational'] + ASSIGN['ConfirmedForeignNational']",
                "ASSIGN = ASSIGN[['Date', 'Statepath','TotalConfirmed','ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths','Active']]",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_india_data[df_india_data['TotalConfirmed']!=0].groupby('Date')['Statepath'].unique().apply(len)",
                "ASSIGN = pd.DataFrame(ASSIGN).reset_index()",
                "ASSIGN = ex.line(spread, x='Date', y='Statepath', text='Statepath',",
                "ASSIGN='Number of Statepath',",
                "ASSIGN=[conf,deth, cure])",
                "ASSIGN.update_traces(textposition='top center')",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_india_data[df_india_data['TotalConfirmed']!=0].groupby('Date')['Statepath'].unique().apply(len)",
                "ASSIGN = pd.DataFrame(ASSIGN).reset_index()",
                "ASSIGN = ex.line(spread, x='Date', y='Statepath', text='Statepath',",
                "ASSIGN='Number of Statepath',",
                "ASSIGN=[conf,deth, cure])",
                "ASSIGN.update_traces(textposition='top center')",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_india_data.groupby(['Date', 'Statepath'])['TotalConfirmed'].sum().reset_index().sort_values('TotalConfirmed', ascending=False)",
                "ex.line(ASSIGN, x=\"Date\", y=\"TotalConfirmed\", color='Statepath', title='ASSIGN over time', height=600)"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_india_data.groupby(['Date', 'Statepath'])['TotalConfirmed'].sum().reset_index().sort_values('TotalConfirmed', ascending=False)",
                "ex.line(ASSIGN, x=\"Date\", y=\"TotalConfirmed\", color='Statepath', title='ASSIGN over time', height=600)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = india_latest_groupby",
                "ASSIGN['TotalConfirmed'] = ASSIGN['ConfirmedIndianNational'] + ASSIGN['ConfirmedForeignNational']",
                "ASSIGN = ASSIGN[['Statepath','TotalConfirmed','ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths','Active']]",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = india_latest_groupby",
                "ASSIGN['TotalConfirmed'] = ASSIGN['ConfirmedIndianNational'] + ASSIGN['ConfirmedForeignNational']",
                "ASSIGN = ASSIGN[['Statepath','TotalConfirmed','ConfirmedIndianNational','ConfirmedForeignNational','Cured','Deaths','Active']]",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ex.bar(latest_date.sort_values('TotalConfirmed', ascending=False).head(30).sort_values('TotalConfirmed', ascending=True),",
                "ASSIGN=\"TotalConfirmed\", y=\"Statepath\", title='Confirmed Cases', text='TotalConfirmed', orientation='h',",
                "ASSIGN=900, height=700, range_x = [0, max(latest_date['TotalConfirmed'])+15])",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = ex.bar(latest_date.sort_values('TotalConfirmed', ascending=False).head(30).sort_values('TotalConfirmed', ascending=True),",
                "ASSIGN=\"TotalConfirmed\", y=\"Statepath\", title='Confirmed Cases', text='TotalConfirmed', orientation='h',",
                "ASSIGN=900, height=700, range_x = [0, max(latest_date['TotalConfirmed'])+15])",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ex.bar(latest_date.sort_values('Deaths', ascending=False).head(30).sort_values('Deaths', ascending=True),",
                "ASSIGN=\"Deaths\", y=\"Statepath\", title='Death in each state', text='Deaths', orientation='h',",
                "ASSIGN=800, height=700, range_x = [0, max(latest_date['Deaths'])+0.5])",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = ex.bar(latest_date.sort_values('Deaths', ascending=False).head(30).sort_values('Deaths', ascending=True),",
                "ASSIGN=\"Deaths\", y=\"Statepath\", title='Death in each state', text='Deaths', orientation='h',",
                "ASSIGN=800, height=700, range_x = [0, max(latest_date['Deaths'])+0.5])",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ex.bar(latest_date.sort_values('Cured', ascending=False).head(30).sort_values('Cured', ascending=True),",
                "ASSIGN=\"Cured\", y=\"Statepath\", title='Cured cases', text='Cured', orientation='h',",
                "ASSIGN=800, height=700, range_x = [0, max(latest_date['Cured'])+4])",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = ex.bar(latest_date.sort_values('Cured', ascending=False).head(30).sort_values('Cured', ascending=True),",
                "ASSIGN=\"Cured\", y=\"Statepath\", title='Cured cases', text='Cured', orientation='h',",
                "ASSIGN=800, height=700, range_x = [0, max(latest_date['Cured'])+4])",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ex.bar(latest_date.sort_values('Active', ascending=False).head(30).sort_values('Active', ascending=True),",
                "ASSIGN=\"Active\", y=\"Statepath\", title='Active cases', text='Active', orientation='h',",
                "ASSIGN=800, height=700, range_x = [0, max(latest_date['Active'])+10])",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = ex.bar(latest_date.sort_values('Active', ascending=False).head(30).sort_values('Active', ascending=True),",
                "ASSIGN=\"Active\", y=\"Statepath\", title='Active cases', text='Active', orientation='h',",
                "ASSIGN=800, height=700, range_x = [0, max(latest_date['Active'])+10])",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "latest_date['Death Rate'] = round((latest_date['Deaths']path['TotalConfirmed'])*20,2)",
                "Top_50 = latest_date[latest_date['TotalConfirmed']>20]",
                "Top_50 = Top_50.sort_values('Death Rate', ascending=False)",
                "ASSIGN = ex.bar(Top_50.sort_values('Death Rate', ascending=False).head(20).sort_values('Death Rate', ascending=True),",
                "ASSIGN=\"Death Rate\", y=\"Statepath\", text='Death Rate', orientation='h',",
                "ASSIGN=500, height=500, range_x = [0, 2], title='No. of Deaths Per 20 Confirmed Case')",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "latest_date['Death Rate'] = round((latest_date['Deaths']path['TotalConfirmed'])*20,2)",
                "Top_50 = latest_date[latest_date['TotalConfirmed']>20]",
                "Top_50 = Top_50.sort_values('Death Rate', ascending=False)",
                "ASSIGN = ex.bar(Top_50.sort_values('Death Rate', ascending=False).head(20).sort_values('Death Rate', ascending=True),",
                "ASSIGN=\"Death Rate\", y=\"Statepath\", text='Death Rate', orientation='h',",
                "ASSIGN=500, height=500, range_x = [0, 2], title='No. of Deaths Per 20 Confirmed Case')",
                "ASSIGN.update_traces(marker_color='",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_india_data.groupby(['Statepath', 'Date'])['TotalConfirmed', 'Deaths', 'Cured'].sum()",
                "ASSIGN = ASSIGN.reset_index()",
                "ASSIGN = ex.bar(Date_vs_confirmed, x=\"Date\", y=\"TotalConfirmed\", color='Statepath', orientation='v', height=600,",
                "ASSIGN='Date vs Confirmed', color_discrete_sequence = ex.colors.cyclical.mygbm)",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_india_data.groupby(['Statepath', 'Date'])['TotalConfirmed', 'Deaths', 'Cured'].sum()",
                "ASSIGN = ASSIGN.reset_index()",
                "ASSIGN = ex.bar(Date_vs_confirmed, x=\"Date\", y=\"TotalConfirmed\", color='Statepath', orientation='v', height=600,",
                "ASSIGN='Date vs Confirmed', color_discrete_sequence = ex.colors.cyclical.mygbm)",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_india_data.groupby(['Statepath', 'Date'])['TotalConfirmed', 'Deaths', 'Cured'].sum()",
                "ASSIGN = ASSIGN.reset_index()",
                "ASSIGN = ex.bar(Date_vs_cured, x=\"Date\", y=\"Cured\", color='Statepath', orientation='v', height=600,",
                "ASSIGN='Date vs Cured', color_discrete_sequence = ex.colors.cyclical.mygbm)",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_india_data.groupby(['Statepath', 'Date'])['TotalConfirmed', 'Deaths', 'Cured'].sum()",
                "ASSIGN = ASSIGN.reset_index()",
                "ASSIGN = ex.bar(Date_vs_cured, x=\"Date\", y=\"Cured\", color='Statepath', orientation='v', height=600,",
                "ASSIGN='Date vs Cured', color_discrete_sequence = ex.colors.cyclical.mygbm)",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "Date_vs_Deaths = df_india_data.groupby(['Statepath', 'Date'])['TotalConfirmed', 'Deaths', 'Cured'].sum()",
                "Date_vs_Deaths = Date_vs_Deaths.reset_index()",
                "Date_vs_Deaths_fig = ex.bar(Date_vs_Deaths, x=\"Date\", y=\"Deaths\", color='Statepath', orientation='v', height=600,",
                "ASSIGN='Date vs Active', color_discrete_sequence = ex.colors.cyclical.mygbm)",
                "Date_vs_Deaths_fig.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "Date_vs_Deaths = df_india_data.groupby(['Statepath', 'Date'])['TotalConfirmed', 'Deaths', 'Cured'].sum()",
                "Date_vs_Deaths = Date_vs_Deaths.reset_index()",
                "Date_vs_Deaths_fig = ex.bar(Date_vs_Deaths, x=\"Date\", y=\"Deaths\", color='Statepath', orientation='v', height=600,",
                "ASSIGN='Date vs Active', color_discrete_sequence = ex.colors.cyclical.mygbm)",
                "Date_vs_Deaths_fig.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_india_data.groupby(['Statepath', 'Date', ])['TotalConfirmed', 'Deaths', 'Cured']",
                "ASSIGN = ASSIGN.sum().diff().reset_index()",
                "ASSIGN = new_cases['Statepath'] != new_cases['Statepath'].shift(1)",
                "ASSIGN.loc[ASSIGN, 'TotalConfirmed'] = np.nan",
                "ASSIGN.loc[ASSIGN, 'Deaths'] = np.nan",
                "ASSIGN.loc[ASSIGN, 'Cured'] = np.nan",
                "ASSIGN = ex.bar(new_cases, x=\"Date\", y=\"TotalConfirmed\", color='Statepath',title='New cases')",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_india_data.groupby(['Statepath', 'Date', ])['TotalConfirmed', 'Deaths', 'Cured']",
                "ASSIGN = ASSIGN.sum().diff().reset_index()",
                "ASSIGN = new_cases['Statepath'] != new_cases['Statepath'].shift(1)",
                "ASSIGN.loc[ASSIGN, 'TotalConfirmed'] = np.nan",
                "ASSIGN.loc[ASSIGN, 'Deaths'] = np.nan",
                "ASSIGN.loc[ASSIGN, 'Cured'] = np.nan",
                "ASSIGN = ex.bar(new_cases, x=\"Date\", y=\"TotalConfirmed\", color='Statepath',title='New cases')",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "Death_vs_Conf = latest_date.sort_values('Deaths', ascending=False).iloc[:15, :]",
                "Death_vs_Conf_plot = ex.scatter(Death_vs_Conf,",
                "ASSIGN='TotalConfirmed', y='Deaths', color='Statepath',",
                "ASSIGN='Statepath', log_x=True, log_y=True, title='Deaths vs Confirmed')",
                "Death_vs_Conf_plot.update_traces(textposition='top center')",
                "Death_vs_Conf_plot.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "Death_vs_Conf = latest_date.sort_values('Deaths', ascending=False).iloc[:15, :]",
                "Death_vs_Conf_plot = ex.scatter(Death_vs_Conf,",
                "ASSIGN='TotalConfirmed', y='Deaths', color='Statepath',",
                "ASSIGN='Statepath', log_x=True, log_y=True, title='Deaths vs Confirmed')",
                "Death_vs_Conf_plot.update_traces(textposition='top center')",
                "Death_vs_Conf_plot.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "Cured_vs_Conf = latest_date.sort_values('Cured', ascending=False).iloc[:15, :]",
                "Cured_vs_Conf_plot = ex.scatter(Death_vs_Conf,",
                "ASSIGN='TotalConfirmed', y='Cured', color='Statepath',",
                "ASSIGN='Statepath', log_x=True, log_y=True, title='Cured vs Confirmed')",
                "Cured_vs_Conf_plot.update_traces(textposition='top center')",
                "Cured_vs_Conf_plot.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "Cured_vs_Conf = latest_date.sort_values('Cured', ascending=False).iloc[:15, :]",
                "Cured_vs_Conf_plot = ex.scatter(Death_vs_Conf,",
                "ASSIGN='TotalConfirmed', y='Cured', color='Statepath',",
                "ASSIGN='Statepath', log_x=True, log_y=True, title='Cured vs Confirmed')",
                "Cured_vs_Conf_plot.update_traces(textposition='top center')",
                "Cured_vs_Conf_plot.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "\"\"\"",
                "df_India_perday",
                "df_Italy_perday",
                "df_Korea_perday",
                "\"\"\"",
                "ASSIGN = make_subplots(",
                "ASSIGN=2, cols=2,",
                "ASSIGN=[[{}, {}],",
                "[{\"colspan\": 2}, None]],",
                "ASSIGN=(\"S.Korea\",\"Italy\", \"India\"))",
                "ASSIGN.add_trace(gp.Bar(x=df_Korea_perday['Date'], y=df_Korea_perday['Total Cases'],",
                "ASSIGN= dict(color=df_Korea_perday['Total Cases'], coloraxis=\"coloraxis\")),",
                "1, 1)",
                "ASSIGN.add_trace(gp.Bar(x=df_Italy_perday['Date'], y=df_Italy_perday['Total Cases'],",
                "ASSIGN= dict(color=df_Italy_perday['Total Cases'], coloraxis=\"coloraxis\")),",
                "1, 2)",
                "ASSIGN.add_trace(gp.Bar(x=df_india_data['Date'], y=df_india_data['TotalConfirmed'],",
                "ASSIGN= dict(color=df_india_data['TotalConfirmed'], coloraxis=\"coloraxis\")),",
                "2, 1)",
                "ASSIGN.update_layout(coloraxis=dict(colorscale='RdBu'), showlegend=False,title_text=\"Total Confirmed cases(Cumulative)\")",
                "ASSIGN.update_layout(plot_bgcolor='rgb(250, 242, 242)')",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "\"\"\"",
                "df_India_perday",
                "df_Italy_perday",
                "df_Korea_perday",
                "\"\"\"",
                "ASSIGN = make_subplots(",
                "ASSIGN=2, cols=2,",
                "ASSIGN=[[{}, {}],",
                "[{\"colspan\": 2}, None]],",
                "ASSIGN=(\"S.Korea\",\"Italy\", \"India\"))",
                "ASSIGN.add_trace(gp.Bar(x=df_Korea_perday['Date'], y=df_Korea_perday['Total Cases'],",
                "ASSIGN= dict(color=df_Korea_perday['Total Cases'], coloraxis=\"coloraxis\")),",
                "1, 1)",
                "ASSIGN.add_trace(gp.Bar(x=df_Italy_perday['Date'], y=df_Italy_perday['Total Cases'],",
                "ASSIGN= dict(color=df_Italy_perday['Total Cases'], coloraxis=\"coloraxis\")),",
                "1, 2)",
                "ASSIGN.add_trace(gp.Bar(x=df_india_data['Date'], y=df_india_data['TotalConfirmed'],",
                "ASSIGN= dict(color=df_india_data['TotalConfirmed'], coloraxis=\"coloraxis\")),",
                "2, 1)",
                "ASSIGN.update_layout(coloraxis=dict(colorscale='RdBu'), showlegend=False,title_text=\"Total Confirmed cases(Cumulative)\")",
                "ASSIGN.update_layout(plot_bgcolor='rgb(250, 242, 242)')",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_india_data['TotalConfirmed'].sum()",
                "ASSIGN = df_Italy_perday['Total Cases'].sum()",
                "South_Korea = df_Korea_perday['Total Cases'].sum()",
                "ASSIGN ={\"India\": India,\"Italy\":Italy, 'South Korea':South_Korea}",
                "ASSIGN=['red','blue', 'yellow']",
                "plt.figure(figsize = (10,10))",
                "plt.pie(ASSIGN.values(),labels=ASSIGN.keys(),ASSIGN=ASSIGN,shadow=True,explode=(0.1, 0.1, 0.1), autopct='%1.2f%%')",
                "plt.axis('equal')",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = df_india_data['TotalConfirmed'].sum()",
                "ASSIGN = df_Italy_perday['Total Cases'].sum()",
                "South_Korea = df_Korea_perday['Total Cases'].sum()",
                "ASSIGN ={\"India\": India,\"Italy\":Italy, 'South Korea':South_Korea}",
                "ASSIGN=['red','blue', 'yellow']",
                "plt.figure(figsize = (10,10))",
                "plt.pie(ASSIGN.values(),labels=ASSIGN.keys(),ASSIGN=ASSIGN,shadow=True,explode=(0.1, 0.1, 0.1), autopct='%1.2f%%')",
                "plt.axis('equal')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(check_output([, ]).decode())"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(check_output([, ]).decode())"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN=pd.read_csv(\"..path\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=pd.read_csv(\"..path\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "pd.options.display.max_rows = 999",
                "pd.options.display.max_columns=999",
                "train.describe()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "pd.options.display.max_rows = 999",
                "pd.options.display.max_columns=999",
                "train.describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.count()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.count()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train.shape"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "train.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train.columns"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "train.columns"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train.dtypes"
            ],
            "output_type": "execute_result",
            "content_old": [
                "CHECKPOINT",
                "train.dtypes"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.corr()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.corr()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pl.figure()",
                "ASSIGN = fig.add_subplot(111)",
                "ASSIGN = cm.get_cmap('jet', 80)",
                "ASSIGN = ax1.imshow(train.corr(), interpolation=\"nearest\", cmap=cmap)",
                "ASSIGN.grid(True)",
                "pl.title('Abalone Feature Correlation')",
                "ASSIGN.colorbar(ASSIGN, ticks=[.75,.8,.85,.90,.95,1])",
                "pl.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = pl.figure()",
                "ASSIGN = fig.add_subplot(111)",
                "ASSIGN = cm.get_cmap('jet', 80)",
                "ASSIGN = ax1.imshow(train.corr(), interpolation=\"nearest\", cmap=cmap)",
                "ASSIGN.grid(True)",
                "pl.title('Abalone Feature Correlation')",
                "ASSIGN.colorbar(ASSIGN, ticks=[.75,.8,.85,.90,.95,1])",
                "pl.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "pl.plot(train[\"YearBuilt\"], train[\"GarageYrBlt\"], \"o\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "pl.plot(train[\"YearBuilt\"], train[\"GarageYrBlt\"], \"o\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "pl.plot(train[\"TotalBsmtSF\"], train[\"1stFlrSF\"], \"o\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "pl.plot(train[\"TotalBsmtSF\"], train[\"1stFlrSF\"], \"o\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "pl.plot(train[\"GarageCars\"], train[\"GarageArea\"], \"o\")"
            ],
            "output_type": "execute_result",
            "content_old": [
                "pl.plot(train[\"GarageCars\"], train[\"GarageArea\"], \"o\")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Phase",
                "Checkpoint Activity"
            ],
            "content": [
                "pl.plot(train[\"SalePrice\"], train[\"MiscVal\"], \"o\")",
                "ASSIGN=train[[\"SalePrice\",\"MiscVal\"]]",
                "ASSIGN.corr()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "pl.plot(train[\"SalePrice\"], train[\"MiscVal\"], \"o\")",
                "ASSIGN=train[[\"SalePrice\",\"MiscVal\"]]",
                "ASSIGN.corr()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "Alley2=train['Alley'].fillna('NoAlley')",
                "train[\"Alley2\"]=Alley2"
            ],
            "output_type": "not_existent",
            "content_old": [
                "Alley2=train['Alley'].fillna('NoAlley')",
                "train[\"Alley2\"]=Alley2"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.count()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train.count()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "py.init_notebook_mode(connected=True)"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "py.init_notebook_mode(connected=True)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(train.shape)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(train.shape)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train['label']",
                "ASSIGN = ASSIGN.drop(\"label\",axis=1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train['label']",
                "ASSIGN = ASSIGN.drop(\"label\",axis=1)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = train.values",
                "ASSIGN = StandardScaler().fit_transform(X)",
                "ASSIGN = np.mean(X_std, axis=0)",
                "ASSIGN = np.cov(X_std.T)",
                "ASSIGN = np.linalg.eig(cov_mat)",
                "ASSIGN = [ (np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))]",
                "ASSIGN.sort(key = lambda x: x[0], reverse= True)",
                "ASSIGN = sum(eig_vals)",
                "ASSIGN = [(ipath)*100 for i in sorted(eig_vals, reverse=True)]",
                "ASSIGN = np.cumsum(var_exp)"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "ASSIGN = train.values",
                "ASSIGN = StandardScaler().fit_transform(X)",
                "ASSIGN = np.mean(X_std, axis=0)",
                "ASSIGN = np.cov(X_std.T)",
                "ASSIGN = np.linalg.eig(cov_mat)",
                "ASSIGN = [ (np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))]",
                "ASSIGN.sort(key = lambda x: x[0], reverse= True)",
                "ASSIGN = sum(eig_vals)",
                "ASSIGN = [(ipath)*100 for i in sorted(eig_vals, reverse=True)]",
                "ASSIGN = np.cumsum(var_exp)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = go.Scatter(",
                "ASSIGN=list(range(784)),",
                "ASSIGN= cum_var_exp,",
                "ASSIGN='lines+markers',",
                "ASSIGN=\"'Cumulative Explained Variance'\",",
                "ASSIGN=dict(",
                "ASSIGN='spline',",
                "ASSIGN = 'goldenrod'",
                ")",
                ")",
                "ASSIGN = go.Scatter(",
                "ASSIGN=list(range(784)),",
                "ASSIGN= var_exp,",
                "ASSIGN='lines+markers',",
                "ASSIGN=\"'Individual Explained Variance'\",",
                "ASSIGN=dict(",
                "ASSIGN='linear',",
                "ASSIGN = 'black'",
                ")",
                ")",
                "ASSIGN = tls.make_subplots(insets=[{'cell': (1,1), 'l': 0.7, 'b': 0.5}],",
                "ASSIGN=True)",
                "ASSIGN.append_trace(ASSIGN, 1, 1)",
                "ASSIGN.append_trace(ASSIGN,1,1)",
                "ASSIGN.layout.title = 'Explained Variance plots - Full and Zoomed-in'",
                "ASSIGN.layout.xaxis = dict(range=[0, 80], title = 'Feature columns')",
                "ASSIGN.layout.yaxis = dict(range=[0, 60], title = 'Explained Variance')"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = go.Scatter(",
                "ASSIGN=list(range(784)),",
                "ASSIGN= cum_var_exp,",
                "ASSIGN='lines+markers',",
                "ASSIGN=\"'Cumulative Explained Variance'\",",
                "ASSIGN=dict(",
                "ASSIGN='spline',",
                "ASSIGN = 'goldenrod'",
                ")",
                ")",
                "ASSIGN = go.Scatter(",
                "ASSIGN=list(range(784)),",
                "ASSIGN= var_exp,",
                "ASSIGN='lines+markers',",
                "ASSIGN=\"'Individual Explained Variance'\",",
                "ASSIGN=dict(",
                "ASSIGN='linear',",
                "ASSIGN = 'black'",
                ")",
                ")",
                "ASSIGN = tls.make_subplots(insets=[{'cell': (1,1), 'l': 0.7, 'b': 0.5}],",
                "ASSIGN=True)",
                "ASSIGN.append_trace(ASSIGN, 1, 1)",
                "ASSIGN.append_trace(ASSIGN,1,1)",
                "ASSIGN.layout.title = 'Explained Variance plots - Full and Zoomed-in'",
                "ASSIGN.layout.xaxis = dict(range=[0, 80], title = 'Feature columns')",
                "ASSIGN.layout.yaxis = dict(range=[0, 60], title = 'Explained Variance')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = 30",
                "ASSIGN = PCA(n_components=n_components).fit(train.values)",
                "ASSIGN = pca.components_.reshape(n_components, 28, 28)",
                "ASSIGN = pca.components_"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = 30",
                "ASSIGN = PCA(n_components=n_components).fit(train.values)",
                "ASSIGN = pca.components_.reshape(n_components, 28, 28)",
                "ASSIGN = pca.components_"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = 4",
                "ASSIGN = 7",
                "plt.figure(figsize=(13,12))",
                "for i in list(range(ASSIGN * ASSIGN)):",
                "ASSIGN =0",
                "plt.subplot(ASSIGN, ASSIGN, i + 1)",
                "plt.imshow(eigenvalues[i].reshape(28,28), cmap='jet')",
                "ASSIGN = 'Eigenvalue ' + str(i + 1)",
                "plt.title(ASSIGN, size=6.5)",
                "plt.xticks(())",
                "plt.yticks(())",
                "plt.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = 4",
                "ASSIGN = 7",
                "plt.figure(figsize=(13,12))",
                "for i in list(range(ASSIGN * ASSIGN)):",
                "ASSIGN =0",
                "plt.subplot(ASSIGN, ASSIGN, i + 1)",
                "plt.imshow(eigenvalues[i].reshape(28,28), cmap='jet')",
                "ASSIGN = 'Eigenvalue ' + str(i + 1)",
                "plt.title(ASSIGN, size=6.5)",
                "plt.xticks(())",
                "plt.yticks(())",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(14,12))",
                "for digit_num in range(0,70):",
                "plt.subplot(7,10,digit_num+1)",
                "ASSIGN = train.iloc[digit_num].as_matrix().reshape(28,28)",
                "plt.imshow(ASSIGN, interpolation = \"none\", cmap = \"afmhot\")",
                "plt.xticks([])",
                "plt.yticks([])",
                "plt.tight_layout()"
            ],
            "output_type": "stream",
            "content_old": [
                "plt.figure(figsize=(14,12))",
                "for digit_num in range(0,70):",
                "plt.subplot(7,10,digit_num+1)",
                "ASSIGN = train.iloc[digit_num].as_matrix().reshape(28,28)",
                "plt.imshow(ASSIGN, interpolation = \"none\", cmap = \"afmhot\")",
                "plt.xticks([])",
                "plt.yticks([])",
                "plt.tight_layout()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "del X",
                "X= train[:6000].values",
                "del train",
                "ASSIGN = StandardScaler().fit_transform(X)",
                "ASSIGN = PCA(n_components=5)",
                "ASSIGN.fit(ASSIGN)",
                "ASSIGN = pca.transform(X_std)",
                "ASSIGN = target[:6000]"
            ],
            "output_type": "stream",
            "content_old": [
                "del X",
                "X= train[:6000].values",
                "del train",
                "ASSIGN = StandardScaler().fit_transform(X)",
                "ASSIGN = PCA(n_components=5)",
                "ASSIGN.fit(ASSIGN)",
                "ASSIGN = pca.transform(X_std)",
                "ASSIGN = target[:6000]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = go.Scatter(",
                "ASSIGN = X_5d[:,0],",
                "ASSIGN = X_5d[:,1],",
                "ASSIGN = 'markers',",
                "ASSIGN = Target,",
                "ASSIGN = False,",
                "ASSIGN = dict(",
                "ASSIGN = 8,",
                "ASSIGN = Target,",
                "ASSIGN ='Jet',",
                "ASSIGN = False,",
                "ASSIGN = dict(",
                "ASSIGN = 2,",
                "ASSIGN = 'rgb(255, 255, 255)'",
                "),",
                "ASSIGN = 0.8",
                ")",
                ")",
                "ASSIGN = [trace0]",
                "ASSIGN = go.Layout(",
                "ASSIGN= 'Principal Component Analysis (PCA)',",
                "ASSIGN= 'closest',",
                "ASSIGN= dict(",
                "ASSIGN= 'First Principal Component',",
                "ASSIGN= 5,",
                "ASSIGN= False,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN=dict(",
                "ASSIGN= 'Second Principal Component',",
                "ASSIGN= 5,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN= True",
                ")",
                "ASSIGN = dict(data=data, layout=layout)",
                "py.iplot(ASSIGN, filename='styled-scatter')"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = go.Scatter(",
                "ASSIGN = X_5d[:,0],",
                "ASSIGN = X_5d[:,1],",
                "ASSIGN = 'markers',",
                "ASSIGN = Target,",
                "ASSIGN = False,",
                "ASSIGN = dict(",
                "ASSIGN = 8,",
                "ASSIGN = Target,",
                "ASSIGN ='Jet',",
                "ASSIGN = False,",
                "ASSIGN = dict(",
                "ASSIGN = 2,",
                "ASSIGN = 'rgb(255, 255, 255)'",
                "),",
                "ASSIGN = 0.8",
                ")",
                ")",
                "ASSIGN = [trace0]",
                "ASSIGN = go.Layout(",
                "ASSIGN= 'Principal Component Analysis (PCA)',",
                "ASSIGN= 'closest',",
                "ASSIGN= dict(",
                "ASSIGN= 'First Principal Component',",
                "ASSIGN= 5,",
                "ASSIGN= False,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN=dict(",
                "ASSIGN= 'Second Principal Component',",
                "ASSIGN= 5,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN= True",
                ")",
                "ASSIGN = dict(data=data, layout=layout)",
                "py.iplot(ASSIGN, filename='styled-scatter')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Training Activity",
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = KMeans(n_clusters=9)",
                "ASSIGN = kmeans.fit_predict(X_5d)",
                "ASSIGN = go.Scatter(x=X_5d[:, 0], y= X_5d[:, 1], mode=\"markers\",",
                "ASSIGN=False,",
                "ASSIGN=dict(",
                "ASSIGN=8,",
                "ASSIGN = X_clustered,",
                "ASSIGN = 'Portland',",
                "ASSIGN=False,",
                "ASSIGN = dict(",
                "ASSIGN = 2,",
                "ASSIGN = 'rgb(255, 255, 255)'",
                ")",
                "))",
                "ASSIGN = go.Layout(",
                "ASSIGN= 'KMeans Clustering',",
                "ASSIGN= 'closest',",
                "ASSIGN= dict(",
                "ASSIGN= 'First Principal Component',",
                "ASSIGN= 5,",
                "ASSIGN= False,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN=dict(",
                "ASSIGN= 'Second Principal Component',",
                "ASSIGN= 5,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN= True",
                ")",
                "ASSIGN = [trace_Kmeans]",
                "ASSIGN = dict(data=data, layout= layout)",
                "py.iplot(ASSIGN, filename=\"svm\")"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = KMeans(n_clusters=9)",
                "ASSIGN = kmeans.fit_predict(X_5d)",
                "ASSIGN = go.Scatter(x=X_5d[:, 0], y= X_5d[:, 1], mode=\"markers\",",
                "ASSIGN=False,",
                "ASSIGN=dict(",
                "ASSIGN=8,",
                "ASSIGN = X_clustered,",
                "ASSIGN = 'Portland',",
                "ASSIGN=False,",
                "ASSIGN = dict(",
                "ASSIGN = 2,",
                "ASSIGN = 'rgb(255, 255, 255)'",
                ")",
                "))",
                "ASSIGN = go.Layout(",
                "ASSIGN= 'KMeans Clustering',",
                "ASSIGN= 'closest',",
                "ASSIGN= dict(",
                "ASSIGN= 'First Principal Component',",
                "ASSIGN= 5,",
                "ASSIGN= False,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN=dict(",
                "ASSIGN= 'Second Principal Component',",
                "ASSIGN= 5,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN= True",
                ")",
                "ASSIGN = [trace_Kmeans]",
                "ASSIGN = dict(data=data, layout= layout)",
                "py.iplot(ASSIGN, filename=\"svm\")"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = LDA(n_components=5)",
                "ASSIGN = lda.fit_transform(X_std, Target.values )"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = LDA(n_components=5)",
                "ASSIGN = lda.fit_transform(X_std, Target.values )"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "8",
                "ASSIGN = go.Scatter(",
                "ASSIGN = X_LDA_2D[:,0],",
                "ASSIGN = X_LDA_2D[:,1],",
                "ASSIGN = 'markers',",
                "ASSIGN = Target,",
                "ASSIGN = True,",
                "ASSIGN = dict(",
                "ASSIGN = 8,",
                "ASSIGN = Target,",
                "ASSIGN ='Jet',",
                "ASSIGN = False,",
                "ASSIGN = dict(",
                "ASSIGN = 2,",
                "ASSIGN = 'rgb(255, 255, 255)'",
                "),",
                "ASSIGN = 0.8",
                ")",
                ")",
                "ASSIGN = [traceLDA]",
                "ASSIGN = go.Layout(",
                "ASSIGN= 'Linear Discriminant Analysis (LDA)',",
                "ASSIGN= 'closest',",
                "ASSIGN= dict(",
                "ASSIGN= 'First Linear Discriminant',",
                "ASSIGN= 5,",
                "ASSIGN= False,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN=dict(",
                "ASSIGN= 'Second Linear Discriminant',",
                "ASSIGN= 5,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN= False",
                ")",
                "ASSIGN = dict(data=data, layout=layout)",
                "py.iplot(ASSIGN, filename='styled-scatter')"
            ],
            "output_type": "display_data",
            "content_old": [
                "8",
                "ASSIGN = go.Scatter(",
                "ASSIGN = X_LDA_2D[:,0],",
                "ASSIGN = X_LDA_2D[:,1],",
                "ASSIGN = 'markers',",
                "ASSIGN = Target,",
                "ASSIGN = True,",
                "ASSIGN = dict(",
                "ASSIGN = 8,",
                "ASSIGN = Target,",
                "ASSIGN ='Jet',",
                "ASSIGN = False,",
                "ASSIGN = dict(",
                "ASSIGN = 2,",
                "ASSIGN = 'rgb(255, 255, 255)'",
                "),",
                "ASSIGN = 0.8",
                ")",
                ")",
                "ASSIGN = [traceLDA]",
                "ASSIGN = go.Layout(",
                "ASSIGN= 'Linear Discriminant Analysis (LDA)',",
                "ASSIGN= 'closest',",
                "ASSIGN= dict(",
                "ASSIGN= 'First Linear Discriminant',",
                "ASSIGN= 5,",
                "ASSIGN= False,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN=dict(",
                "ASSIGN= 'Second Linear Discriminant',",
                "ASSIGN= 5,",
                "ASSIGN= 2,",
                "),",
                "ASSIGN= False",
                ")",
                "ASSIGN = dict(data=data, layout=layout)",
                "py.iplot(ASSIGN, filename='styled-scatter')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = TSNE(n_components=2)",
                "ASSIGN = tsne.fit_transform(X_std)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = TSNE(n_components=2)",
                "ASSIGN = tsne.fit_transform(X_std)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = go.Scatter(",
                "ASSIGN = tsne_results[:,0],",
                "ASSIGN = tsne_results[:,1],",
                "ASSIGN = Target,",
                "ASSIGN = Target,",
                "ASSIGN = 'markers',",
                "ASSIGN = Target,",
                "ASSIGN = True,",
                "ASSIGN = dict(",
                "ASSIGN = 8,",
                "ASSIGN = Target,",
                "ASSIGN ='Jet',",
                "ASSIGN = False,",
                "ASSIGN = dict(",
                "ASSIGN = 2,",
                "ASSIGN = 'rgb(255, 255, 255)'",
                "),",
                "ASSIGN = 0.8",
                ")",
                ")",
                "ASSIGN = [traceTSNE]",
                "ASSIGN = dict(title = 'TSNE (T-Distributed Stochastic Neighbour Embedding)',",
                "ASSIGN= 'closest',",
                "ASSIGN = dict(zeroline = False),",
                "ASSIGN = dict(zeroline = False),",
                "ASSIGN= False,",
                ")",
                "ASSIGN = dict(data=data, layout=layout)",
                "py.iplot(ASSIGN, filename='styled-scatter')"
            ],
            "output_type": "error",
            "content_old": [
                "ASSIGN = go.Scatter(",
                "ASSIGN = tsne_results[:,0],",
                "ASSIGN = tsne_results[:,1],",
                "ASSIGN = Target,",
                "ASSIGN = Target,",
                "ASSIGN = 'markers',",
                "ASSIGN = Target,",
                "ASSIGN = True,",
                "ASSIGN = dict(",
                "ASSIGN = 8,",
                "ASSIGN = Target,",
                "ASSIGN ='Jet',",
                "ASSIGN = False,",
                "ASSIGN = dict(",
                "ASSIGN = 2,",
                "ASSIGN = 'rgb(255, 255, 255)'",
                "),",
                "ASSIGN = 0.8",
                ")",
                ")",
                "ASSIGN = [traceTSNE]",
                "ASSIGN = dict(title = 'TSNE (T-Distributed Stochastic Neighbour Embedding)',",
                "ASSIGN= 'closest',",
                "ASSIGN = dict(zeroline = False),",
                "ASSIGN = dict(zeroline = False),",
                "ASSIGN= False,",
                ")",
                "ASSIGN = dict(data=data, layout=layout)",
                "py.iplot(ASSIGN, filename='styled-scatter')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = range(1000)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = 2",
                "ASSIGN = 500",
                "def line_function(ASSIGN):",
                "ASSIGN = w1 * X + b",
                "return y",
                "ASSIGN = line_function(X)",
                "plt.plot(ASSIGN,ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = range(1000)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = 2",
                "ASSIGN = 500",
                "def line_function(ASSIGN):",
                "ASSIGN = w1 * X + b",
                "return y",
                "ASSIGN = line_function(X)",
                "plt.plot(ASSIGN,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = range(1000)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = 9path",
                "ASSIGN = 32",
                "ASSIGN = line_function(C)",
                "ASSIGN = plt.figure(figsize=(4,3))",
                "ASSIGN = fig.add_subplot(111)",
                "ASSIGN.set_title('change of ASSIGN with respect to ASSIGN')",
                "plt.plot(ASSIGN,ASSIGN)",
                "ASSIGN.set_xlabel('Celsius (ASSIGN)')",
                "ASSIGN.set_ylabel('Fahrenheit (ASSIGN)')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = range(1000)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = 9path",
                "ASSIGN = 32",
                "ASSIGN = line_function(C)",
                "ASSIGN = plt.figure(figsize=(4,3))",
                "ASSIGN = fig.add_subplot(111)",
                "ASSIGN.set_title('change of ASSIGN with respect to ASSIGN')",
                "plt.plot(ASSIGN,ASSIGN)",
                "ASSIGN.set_xlabel('Celsius (ASSIGN)')",
                "ASSIGN.set_ylabel('Fahrenheit (ASSIGN)')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = range(1000)",
                "ASSIGN = range(1000)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = 8",
                "ASSIGN = 6",
                "ASSIGN = [w1,w2]",
                "ASSIGN = 500",
                "def hyperplane(Xs):",
                "ASSIGN=b",
                "for (w,x) in zip(ASSIGN,Xs):",
                "ASSIGN+=w*x",
                "return y",
                "ASSIGN = plt.axes(projection='3d')",
                "ASSIGN = np.meshgrid(X1, X2)",
                "ASSIGN = [xv, yv]",
                "ASSIGN = hyperplane(Xs)",
                "ASSIGN.plot_surface(ASSIGN,ASSIGN);"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = range(1000)",
                "ASSIGN = range(1000)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = 8",
                "ASSIGN = 6",
                "ASSIGN = [w1,w2]",
                "ASSIGN = 500",
                "def hyperplane(Xs):",
                "ASSIGN=b",
                "for (w,x) in zip(ASSIGN,Xs):",
                "ASSIGN+=w*x",
                "return y",
                "ASSIGN = plt.axes(projection='3d')",
                "ASSIGN = np.meshgrid(X1, X2)",
                "ASSIGN = [xv, yv]",
                "ASSIGN = hyperplane(Xs)",
                "ASSIGN.plot_surface(ASSIGN,ASSIGN);"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv('..path')",
                "plt.scatter(ASSIGN.x,ASSIGN.y,s = 4)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv('..path')",
                "plt.scatter(ASSIGN.x,ASSIGN.y,s = 4)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv('..path')",
                "plt.scatter(ASSIGN.x,ASSIGN.y,s = 4)",
                "X= range(100)",
                "Y= X",
                "plt.plot(X,Y,c='red')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv('..path')",
                "plt.scatter(ASSIGN.x,ASSIGN.y,s = 4)",
                "X= range(100)",
                "Y= X",
                "plt.plot(X,Y,c='red')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.scatter(df.x,df.y,s = 4)",
                "X= np.asarray((range(100)))",
                "Y= -X",
                "plt.plot(X,Y,c='red')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.scatter(df.x,df.y,s = 4)",
                "X= np.asarray((range(100)))",
                "Y= -X",
                "plt.plot(X,Y,c='red')"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = ASSIGN.dropna()",
                "plt.scatter(ASSIGN.x,ASSIGN.y,s = 4)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = ASSIGN.dropna()",
                "plt.scatter(ASSIGN.x,ASSIGN.y,s = 4)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def getXYfromDF(df):",
                "ASSIGN = []",
                "for i in list(df.x):",
                "if(type(i)!=list):",
                "ASSIGN = [ASSIGN]",
                "ASSIGN.append(1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(df.ASSIGN)",
                "return X,y",
                "def randomWeights(m):",
                "ASSIGN= []",
                "for ASSIGN in range(m):",
                "ASSIGN.append(random.randint(1,9))",
                "ASSIGN = np.asarray(ASSIGN)",
                "return w",
                "ASSIGN = getXYfromDF(df)",
                "ASSIGN = X.shape[0]",
                "ASSIGN = X.shape[1]",
                "ASSIGN = randomWeights(m)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def getXYfromDF(df):",
                "ASSIGN = []",
                "for i in list(df.x):",
                "if(type(i)!=list):",
                "ASSIGN = [ASSIGN]",
                "ASSIGN.append(1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(df.ASSIGN)",
                "return X,y",
                "def randomWeights(m):",
                "ASSIGN= []",
                "for ASSIGN in range(m):",
                "ASSIGN.append(random.randint(1,9))",
                "ASSIGN = np.asarray(ASSIGN)",
                "return w",
                "ASSIGN = getXYfromDF(df)",
                "ASSIGN = X.shape[0]",
                "ASSIGN = X.shape[1]",
                "ASSIGN = randomWeights(m)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = np.dot(np.dot(np.linalg.inv(np.dot((X.T),X)),(X.T)),y)",
                "w"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = np.dot(np.dot(np.linalg.inv(np.dot((X.T),X)),(X.T)),y)",
                "w"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotTheLineWithData(X,w):",
                "plt.scatter(df.x,df.y,s = 4)",
                "X=[]",
                "for i in range(100):",
                "X.append([i,1])",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.dot(X,w)",
                "plt.plot(ASSIGN[:,0],ASSIGN,c='red')",
                "plotTheLineWithData(ASSIGN,w)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotTheLineWithData(X,w):",
                "plt.scatter(df.x,df.y,s = 4)",
                "X=[]",
                "for i in range(100):",
                "X.append([i,1])",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.dot(X,w)",
                "plt.plot(ASSIGN[:,0],ASSIGN,c='red')",
                "plotTheLineWithData(ASSIGN,w)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = getXYfromDF(df)",
                "ASSIGN = randomWeights(m)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = getXYfromDF(df)",
                "ASSIGN = randomWeights(m)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity"
            ],
            "content": [
                "def MSE(y,y_predicted):",
                "return ((y- y_predicted)**2).mean()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def MSE(y,y_predicted):",
                "return ((y- y_predicted)**2).mean()"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "def gradient_descent(X,y,w,max_iteration=1000,lr=0.00001):",
                "ASSIGN = []",
                "ASSIGN = []",
                "for iteration in range(max_iteration):",
                "ASSIGN = np.dot(X,w)",
                "ASSIGN = MSE(y,predicted_y)",
                "ASSIGN = round(ASSIGN,9)",
                "ASSIGN.append(w)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = -(2path[0])* X.dot(loss).sum()",
                "ASSIGN = ASSIGN + lr * derivative",
                "return w_history,loss_hostory"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def gradient_descent(X,y,w,max_iteration=1000,lr=0.00001):",
                "ASSIGN = []",
                "ASSIGN = []",
                "for iteration in range(max_iteration):",
                "ASSIGN = np.dot(X,w)",
                "ASSIGN = MSE(y,predicted_y)",
                "ASSIGN = round(ASSIGN,9)",
                "ASSIGN.append(w)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = -(2path[0])* X.dot(loss).sum()",
                "ASSIGN = ASSIGN + lr * derivative",
                "return w_history,loss_hostory"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = gradient_descent(X,y,w,lr = 0.0000001)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = gradient_descent(X,y,w,lr = 0.0000001)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = loss_hostory.index(min(loss_hostory))",
                "ASSIGN = w_history[perfect_i]",
                "ASSIGN= perfect_w"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = loss_hostory.index(min(loss_hostory))",
                "ASSIGN = w_history[perfect_i]",
                "ASSIGN= perfect_w"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotTheLineWithData(X,w)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plotTheLineWithData(X,w)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "plt.scatter(ASSIGN.X1,ASSIGN.X2,c= ASSIGN.Y)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "plt.scatter(ASSIGN.X1,ASSIGN.X2,c= ASSIGN.Y)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "plt.scatter(ASSIGN.X1,ASSIGN.X2,c= ASSIGN.Y)",
                "ASSIGN = range(1000)",
                "ASSIGN= X",
                "plt.plot(ASSIGN,ASSIGN,c='red')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "plt.scatter(ASSIGN.X1,ASSIGN.X2,c= ASSIGN.Y)",
                "ASSIGN = range(1000)",
                "ASSIGN= X",
                "plt.plot(ASSIGN,ASSIGN,c='red')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.asarray(range(1000))",
                "ASSIGN = -(2path)*X",
                "plt.plot(ASSIGN,ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.asarray(range(1000))",
                "ASSIGN = -(2path)*X",
                "plt.plot(ASSIGN,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.asarray(range(1000))",
                "ASSIGN = -(2path)*X",
                "plt.plot(ASSIGN,ASSIGN)",
                "plt.plot(800,-400,'+',c='green')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.asarray(range(1000))",
                "ASSIGN = -(2path)*X",
                "plt.plot(ASSIGN,ASSIGN)",
                "plt.plot(800,-400,'+',c='green')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.asarray(range(1000))",
                "ASSIGN = -(2path)*X",
                "plt.plot(ASSIGN,ASSIGN)",
                "plt.plot(400,-500,'_',c='red')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.asarray(range(1000))",
                "ASSIGN = -(2path)*X",
                "plt.plot(ASSIGN,ASSIGN)",
                "plt.plot(400,-500,'_',c='red')"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def getXYfromDF(df):",
                "ASSIGN = []",
                "for i in df[['X1','X2']].values.tolist():",
                "if(type(i)!=list):",
                "ASSIGN = [ASSIGN]",
                "ASSIGN.append(1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(df.Y)",
                "return X,y",
                "def randomWeights(m):",
                "ASSIGN= []",
                "for ASSIGN in range(m):",
                "ASSIGN.append(random.randint(1,9)path)",
                "ASSIGN = np.asarray(ASSIGN)",
                "return w"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def getXYfromDF(df):",
                "ASSIGN = []",
                "for i in df[['X1','X2']].values.tolist():",
                "if(type(i)!=list):",
                "ASSIGN = [ASSIGN]",
                "ASSIGN.append(1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(df.Y)",
                "return X,y",
                "def randomWeights(m):",
                "ASSIGN= []",
                "for ASSIGN in range(m):",
                "ASSIGN.append(random.randint(1,9)path)",
                "ASSIGN = np.asarray(ASSIGN)",
                "return w"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = getXYfromDF(df)",
                "ASSIGN= randomWeights(3)",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = getXYfromDF(df)",
                "ASSIGN= randomWeights(3)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "plt.scatter(df.X1,df.X2,c=df.Y)",
                "ASSIGN = np.column_stack((range(1000),np.ones(1000)))",
                "print(ASSIGN.shape)",
                "print(w[1:2].shape)",
                "ASSIGN = -np.divide(np.dot(X12,w[1:3]),w[0])",
                "ASSIGN = [sub[0] for sub in X12]",
                "ASSIGN = res",
                "plt.plot(ASSIGN,ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "plt.scatter(df.X1,df.X2,c=df.Y)",
                "ASSIGN = np.column_stack((range(1000),np.ones(1000)))",
                "print(ASSIGN.shape)",
                "print(w[1:2].shape)",
                "ASSIGN = -np.divide(np.dot(X12,w[1:3]),w[0])",
                "ASSIGN = [sub[0] for sub in X12]",
                "ASSIGN = res",
                "plt.plot(ASSIGN,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Model Training Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def equales(list1,list2):",
                "if(len(list1)!=len(list2)):",
                "return False",
                "else:",
                "for i in range(len(list1)):",
                "if(list1[i]!=list2[i]):",
                "return False",
                "return True",
                "def perceptron(X,y,w,learning_rate = 0.0001,max_iterations= 1000):",
                "for iteration in range(max_iterations):",
                "ASSIGN = w",
                "for i in range(w.shape[0]):",
                "if(np.dot(np.dot(X[i],w),y[i]) < 0 and y[i]<0):",
                "ASSIGN=ASSIGN- learning_rate * X[i]",
                "elif(np.dot(np.dot(X[i],ASSIGN),y[i]) < 0 and y[i]>0):",
                "ASSIGN=ASSIGN+ learning_rate * X[i]",
                "if(equales(ASSIGN,ASSIGN)):",
                "print('ASSIGN == ASSIGN in ',iteration)",
                "break",
                "return w"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def equales(list1,list2):",
                "if(len(list1)!=len(list2)):",
                "return False",
                "else:",
                "for i in range(len(list1)):",
                "if(list1[i]!=list2[i]):",
                "return False",
                "return True",
                "def perceptron(X,y,w,learning_rate = 0.0001,max_iterations= 1000):",
                "for iteration in range(max_iterations):",
                "ASSIGN = w",
                "for i in range(w.shape[0]):",
                "if(np.dot(np.dot(X[i],w),y[i]) < 0 and y[i]<0):",
                "ASSIGN=ASSIGN- learning_rate * X[i]",
                "elif(np.dot(np.dot(X[i],ASSIGN),y[i]) < 0 and y[i]>0):",
                "ASSIGN=ASSIGN+ learning_rate * X[i]",
                "if(equales(ASSIGN,ASSIGN)):",
                "print('ASSIGN == ASSIGN in ',iteration)",
                "break",
                "return w"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = perceptron(X,y,w,learning_rate=0.000001,max_iterations= 100000)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = perceptron(X,y,w,learning_rate=0.000001,max_iterations= 100000)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN= new_w"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN= new_w"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "plt.scatter(df.X1,df.X2,c=df.Y)",
                "ASSIGN = np.column_stack((range(1000),np.ones(1000)))",
                "print(ASSIGN.shape)",
                "print(w[1:2].shape)",
                "ASSIGN = -np.divide(np.dot(X12,w[1:3]),w[0])",
                "ASSIGN = [sub[0] for sub in X12]",
                "ASSIGN = res",
                "plt.plot(ASSIGN,ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "plt.scatter(df.X1,df.X2,c=df.Y)",
                "ASSIGN = np.column_stack((range(1000),np.ones(1000)))",
                "print(ASSIGN.shape)",
                "print(w[1:2].shape)",
                "ASSIGN = -np.divide(np.dot(X12,w[1:3]),w[0])",
                "ASSIGN = [sub[0] for sub in X12]",
                "ASSIGN = res",
                "plt.plot(ASSIGN,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def softmax(z):",
                "ASSIGN = np.exp(z)",
                "return ASSIGN path()",
                "ASSIGN = (3,12,-5,0,10)",
                "np.round(softmax(ASSIGN),1)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def softmax(z):",
                "ASSIGN = np.exp(z)",
                "return ASSIGN path()",
                "ASSIGN = (3,12,-5,0,10)",
                "np.round(softmax(ASSIGN),1)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def getOneHot(y):",
                "ASSIGN = []",
                "for i in range(y.shape[0]):",
                "if(y[i]==-1):",
                "ASSIGN.append([1,0])",
                "else:",
                "ASSIGN.append([0,1])",
                "return np.asarray(ASSIGN)",
                "def getXYfromDF(df):",
                "ASSIGN = []",
                "for i in df[['X1','X2']].values.tolist():",
                "if(type(i)!=list):",
                "ASSIGN = [ASSIGN]",
                "ASSIGN.append(1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(df.Y)",
                "return X,y",
                "def randomWeights(m,k):",
                "ASSIGN= []",
                "for ASSIGN in range(m):",
                "ASSIGN = []",
                "for j in range(k):",
                "ASSIGN.append(random.randint(1,9))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "return w",
                "ASSIGN = getXYfromDF(df)",
                "ASSIGN = getOneHot(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def getOneHot(y):",
                "ASSIGN = []",
                "for i in range(y.shape[0]):",
                "if(y[i]==-1):",
                "ASSIGN.append([1,0])",
                "else:",
                "ASSIGN.append([0,1])",
                "return np.asarray(ASSIGN)",
                "def getXYfromDF(df):",
                "ASSIGN = []",
                "for i in df[['X1','X2']].values.tolist():",
                "if(type(i)!=list):",
                "ASSIGN = [ASSIGN]",
                "ASSIGN.append(1)",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN = np.asarray(df.Y)",
                "return X,y",
                "def randomWeights(m,k):",
                "ASSIGN= []",
                "for ASSIGN in range(m):",
                "ASSIGN = []",
                "for j in range(k):",
                "ASSIGN.append(random.randint(1,9))",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN = np.asarray(ASSIGN)",
                "return w",
                "ASSIGN = getXYfromDF(df)",
                "ASSIGN = getOneHot(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "y.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "y.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = X.shape[0]",
                "ASSIGN = X.shape[1]",
                "ASSIGN = 2",
                "ASSIGN = randomWeights(m,k)",
                "ASSIGN=np.asarray(ASSIGN,'float64')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = X.shape[0]",
                "ASSIGN = X.shape[1]",
                "ASSIGN = 2",
                "ASSIGN = randomWeights(m,k)",
                "ASSIGN=np.asarray(ASSIGN,'float64')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "w.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "w.shape"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "CHECKPOINT",
                "plt.scatter(df.X1,df.X2,c=df.Y)",
                "ASSIGN = np.column_stack((range(1000),np.ones(1000)))",
                "ASSIGN = -np.divide(np.dot(X12,w[1:3]),w[0])",
                "ASSIGN = [sub[0] for sub in X12]",
                "ASSIGN = np.asarray(res)",
                "print(ASSIGN.shape)",
                "print(ASSIGN.shape)",
                "plt.plot(ASSIGN,ASSIGN[:,0],c='blue')",
                "plt.plot(ASSIGN,ASSIGN[:,1],c='red')",
                "plt.show"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "CHECKPOINT",
                "plt.scatter(df.X1,df.X2,c=df.Y)",
                "ASSIGN = np.column_stack((range(1000),np.ones(1000)))",
                "ASSIGN = -np.divide(np.dot(X12,w[1:3]),w[0])",
                "ASSIGN = [sub[0] for sub in X12]",
                "ASSIGN = np.asarray(res)",
                "print(ASSIGN.shape)",
                "print(ASSIGN.shape)",
                "plt.plot(ASSIGN,ASSIGN[:,0],c='blue')",
                "plt.plot(ASSIGN,ASSIGN[:,1],c='red')",
                "plt.show"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def softmax(x):",
                "ASSIGN = np.exp(x - np.max(x))",
                "return ASSIGN path(axis=0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def softmax(x):",
                "ASSIGN = np.exp(x - np.max(x))",
                "return ASSIGN path(axis=0)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "def cross_entropy(y, y_hat):",
                "ASSIGN = np.clip(ASSIGN, EPS, 1-EPS)",
                "return -np.sum(y * np.log(ASSIGN)path)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "def cross_entropy(y, y_hat):",
                "ASSIGN = np.clip(ASSIGN, EPS, 1-EPS)",
                "return -np.sum(y * np.log(ASSIGN)path)"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = []",
                "ASSIGN =1000",
                "ASSIGN = 0.1",
                "for _ in range(ASSIGN):",
                "ASSIGN = np.dot(X,w)",
                "ASSIGN = []",
                "for i in range(n):",
                "ASSIGN.append(softmax(ASSIGN[i]))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN.append(cross_entropy(y,ASSIGN))",
                "for j in range(k):",
                "ASSIGN=0",
                "for i in range(n):",
                "ASSIGN += np.dot(X.T,(y-ASSIGN))",
                "ASSIGN = - deltaTemppath",
                "ASSIGN = np.asarray(ASSIGN)",
                "w-=ASSIGN*ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "ASSIGN =1000",
                "ASSIGN = 0.1",
                "for _ in range(ASSIGN):",
                "ASSIGN = np.dot(X,w)",
                "ASSIGN = []",
                "for i in range(n):",
                "ASSIGN.append(softmax(ASSIGN[i]))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN.append(cross_entropy(y,ASSIGN))",
                "for j in range(k):",
                "ASSIGN=0",
                "for i in range(n):",
                "ASSIGN += np.dot(X.T,(y-ASSIGN))",
                "ASSIGN = - deltaTemppath",
                "ASSIGN = np.asarray(ASSIGN)",
                "w-=ASSIGN*ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.plot(history)",
                "plt.title('the change of loss with iterations')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.plot(history)",
                "plt.title('the change of loss with iterations')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "plt.scatter(df.X1,df.X2,c=df.Y)",
                "ASSIGN = np.column_stack((range(1000),np.ones(1000)))",
                "print(ASSIGN.shape)",
                "print(w[1:2].shape)",
                "ASSIGN = -np.divide(np.dot(X12,w[1:3]),w[0])",
                "ASSIGN = [sub[0] for sub in X12]",
                "ASSIGN = res",
                "plt.plot(ASSIGN,ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "plt.scatter(df.X1,df.X2,c=df.Y)",
                "ASSIGN = np.column_stack((range(1000),np.ones(1000)))",
                "print(ASSIGN.shape)",
                "print(w[1:2].shape)",
                "ASSIGN = -np.divide(np.dot(X12,w[1:3]),w[0])",
                "ASSIGN = [sub[0] for sub in X12]",
                "ASSIGN = res",
                "plt.plot(ASSIGN,ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = load_digits()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = load_digits()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = digits.data",
                "ASSIGN = digits.target"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = digits.data",
                "ASSIGN = digits.target"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = plt.subplots(2, 3, sharex='col', sharey='row')",
                "ASSIGN = 0",
                "for i in range(2):",
                "for j in range(3):",
                "ASSIGN = X[currNum,0:64]",
                "ASSIGN += 1",
                "ASSIGN = np.array(ASSIGN, dtype='float')",
                "ASSIGN = img.reshape((8, 8))",
                "ax[i, j].imshow(ASSIGN, cmap='gray')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = plt.subplots(2, 3, sharex='col', sharey='row')",
                "ASSIGN = 0",
                "for i in range(2):",
                "for j in range(3):",
                "ASSIGN = X[currNum,0:64]",
                "ASSIGN += 1",
                "ASSIGN = np.array(ASSIGN, dtype='float')",
                "ASSIGN = img.reshape((8, 8))",
                "ax[i, j].imshow(ASSIGN, cmap='gray')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def add_bias(X):",
                "ASSIGN = []",
                "for i in range(X.shape[0]):",
                "ASSIGN.append(np.append(X[i],1))",
                "return np.asarray(ASSIGN)",
                "ASSIGN = add_bias(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def add_bias(X):",
                "ASSIGN = []",
                "for i in range(X.shape[0]):",
                "ASSIGN.append(np.append(X[i],1))",
                "return np.asarray(ASSIGN)",
                "ASSIGN = add_bias(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "X.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "X.shape"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN=[0,1,2,3,4,5,6,7,8,9]",
                "def oneHot(y,ASSIGN):",
                "ASSIGN = []",
                "for i in range(y.shape[0]):",
                "ASSIGN = []",
                "for j in ASSIGN:",
                "if(y[i]==ASSIGN[j]):",
                "ASSIGN.append(1)",
                "else:",
                "ASSIGN.append(0)",
                "ASSIGN.append(ASSIGN)",
                "return np.asarray(ASSIGN)",
                "ASSIGN = oneHot(ASSIGN,targets)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=[0,1,2,3,4,5,6,7,8,9]",
                "def oneHot(y,ASSIGN):",
                "ASSIGN = []",
                "for i in range(y.shape[0]):",
                "ASSIGN = []",
                "for j in ASSIGN:",
                "if(y[i]==ASSIGN[j]):",
                "ASSIGN.append(1)",
                "else:",
                "ASSIGN.append(0)",
                "ASSIGN.append(ASSIGN)",
                "return np.asarray(ASSIGN)",
                "ASSIGN = oneHot(ASSIGN,targets)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = X.shape[0]",
                "ASSIGN = X.shape[1]",
                "ASSIGN = 10",
                "ASSIGN = randomWeights(m,k)",
                "ASSIGN=np.asarray(ASSIGN,'float64')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = X.shape[0]",
                "ASSIGN = X.shape[1]",
                "ASSIGN = 10",
                "ASSIGN = randomWeights(m,k)",
                "ASSIGN=np.asarray(ASSIGN,'float64')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "w.shape"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "w.shape"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = 20",
                "for iteration in range(ASSIGN):",
                "print('iteration: ',iteration)",
                "ASSIGN = np.dot(X,w)",
                "ASSIGN = []",
                "for i in range(n):",
                "ASSIGN.append(softmax(ASSIGN[i]))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN.append(cross_entropy(y,ASSIGN))",
                "for j in range(k):",
                "ASSIGN=0",
                "for i in range(n):",
                "ASSIGN += np.dot(X.T,(y-ASSIGN))",
                "ASSIGN = - deltaTemppath",
                "ASSIGN = np.asarray(ASSIGN)",
                "w-=0.1*ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = []",
                "ASSIGN = 20",
                "for iteration in range(ASSIGN):",
                "print('iteration: ',iteration)",
                "ASSIGN = np.dot(X,w)",
                "ASSIGN = []",
                "for i in range(n):",
                "ASSIGN.append(softmax(ASSIGN[i]))",
                "ASSIGN = np.asarray(ASSIGN)",
                "ASSIGN.append(cross_entropy(y,ASSIGN))",
                "for j in range(k):",
                "ASSIGN=0",
                "for i in range(n):",
                "ASSIGN += np.dot(X.T,(y-ASSIGN))",
                "ASSIGN = - deltaTemppath",
                "ASSIGN = np.asarray(ASSIGN)",
                "w-=0.1*ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.plot(history)",
                "plt.title('the change of loss with iterations')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.plot(history)",
                "plt.title('the change of loss with iterations')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "def giveMeValueFromOneHot(y_hat):",
                "return np.where(y_hat == 1)[0][0]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def giveMeValueFromOneHot(y_hat):",
                "return np.where(y_hat == 1)[0][0]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase",
                "Model Evaluation Activity"
            ],
            "content": [
                "def predictDis(x):",
                "ASSIGN = np.array(x, dtype='float')",
                "ASSIGN = x[0:64].reshape((8, 8))",
                "plt.imshow(ASSIGN, cmap='gray')",
                "ASSIGN = np.dot(x,w)",
                "print (\"the class of this Image is: \",giveMeValueFromOneHot(softmax(ASSIGN)))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def predictDis(x):",
                "ASSIGN = np.array(x, dtype='float')",
                "ASSIGN = x[0:64].reshape((8, 8))",
                "plt.imshow(ASSIGN, cmap='gray')",
                "ASSIGN = np.dot(x,w)",
                "print (\"the class of this Image is: \",giveMeValueFromOneHot(softmax(ASSIGN)))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = X[0]",
                "predictDis(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = X[0]",
                "predictDis(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = X[1]",
                "predictDis(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = X[1]",
                "predictDis(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "ASSIGN = X[3]",
                "predictDis(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = X[3]",
                "predictDis(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity",
                "Data Ingestion Activity",
                "Post Development Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN=\".path\"",
                "os.mkdir(ASSIGN)",
                "for dirname, _, filenames in os.walk('..path'):",
                "for filename in filenames:",
                "ASSIGN = \"..path\"+filename",
                "ASSIGN = test_set+os.path.splitext(filename)[0]+\".wav\"",
                "ASSIGN = AudioSegment.from_mp3(src)",
                "ASSIGN = ASSIGN.set_frame_rate(8000)",
                "ASSIGN.export(ASSIGN, format=\"wav\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN=\".path\"",
                "os.mkdir(ASSIGN)",
                "for dirname, _, filenames in os.walk('..path'):",
                "for filename in filenames:",
                "ASSIGN = \"..path\"+filename",
                "ASSIGN = test_set+os.path.splitext(filename)[0]+\".wav\"",
                "ASSIGN = AudioSegment.from_mp3(src)",
                "ASSIGN = ASSIGN.set_frame_rate(8000)",
                "ASSIGN.export(ASSIGN, format=\"wav\")"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def getpatterns(symbol):",
                "return \"$$$.{6}|.{3}$$$.{3}|.{6}$$$|$.{2}$.{2}$.{2}|.$.{2}$.{2}$.|.{2}$.{2}$.{2}$|$.{3}$.{3}$|.{2}$.$.$.{2}\".replace(\"$\",symbol)",
                "def checkPatterns(pattern,TicTecBoard):",
                "return len(re.findall(pattern,\"\".join(TicTecBoard)))",
                "def printTicTecBoard(TicTecBoard):",
                "print()",
                "ASSIGN=\"\"",
                "ASSIGN=\"\"",
                "for i in range(0,9):",
                "ASSIGN+= 3*\" \" + str(i+1) + \" \"*3+\"|\"",
                "ASSIGN+= 3*\" \" + TicTecBoard[i] + \" \"*3+\"|\"",
                "if (i+1)%3==0:",
                "ASSIGN=ASSIGN[0:-1]+\" \"*25+strTicTecBoard[0:-1] +\"\\n\"+\"_\"*25+\" \"*25+\"_\"*20+\"\\n\"",
                "ASSIGN=\"\"",
                "print(ASSIGN[0:-75],)",
                "def getValidPlace(TicTecBoard):",
                "return [str(i+1) for i,x in enumerate(TicTecBoard) if x==\"-\"]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def getpatterns(symbol):",
                "return \"$$$.{6}|.{3}$$$.{3}|.{6}$$$|$.{2}$.{2}$.{2}|.$.{2}$.{2}$.|.{2}$.{2}$.{2}$|$.{3}$.{3}$|.{2}$.$.$.{2}\".replace(\"$\",symbol)",
                "def checkPatterns(pattern,TicTecBoard):",
                "return len(re.findall(pattern,\"\".join(TicTecBoard)))",
                "def printTicTecBoard(TicTecBoard):",
                "print()",
                "ASSIGN=\"\"",
                "ASSIGN=\"\"",
                "for i in range(0,9):",
                "ASSIGN+= 3*\" \" + str(i+1) + \" \"*3+\"|\"",
                "ASSIGN+= 3*\" \" + TicTecBoard[i] + \" \"*3+\"|\"",
                "if (i+1)%3==0:",
                "ASSIGN=ASSIGN[0:-1]+\" \"*25+strTicTecBoard[0:-1] +\"\\n\"+\"_\"*25+\" \"*25+\"_\"*20+\"\\n\"",
                "ASSIGN=\"\"",
                "print(ASSIGN[0:-75],)",
                "def getValidPlace(TicTecBoard):",
                "return [str(i+1) for i,x in enumerate(TicTecBoard) if x==\"-\"]"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN=getpatterns(\"O\")",
                "ASSIGN=getpatterns(\"X\")",
                "TicTecBoard=[\"-\" for i in range(9)]",
                "ASSIGN=\"O\"",
                "try:",
                "while True:",
                "ValidIndexList=getValidPlace(TicTecBoard)",
                "ASSIGN==\"O\":",
                "while True:",
                "printTicTecBoard(TicTecBoard)",
                "ASSIGN=input(\" \\n Enter Cell Number from Valid Index List \"+str(ValidIndexList )+\" : \\n\")",
                "if ASSIGN in ValidIndexList:",
                "ASSIGN=int(ASSIGN)-1",
                "break",
                "else:",
                "print()",
                "else:",
                "ASSIGN=0",
                "for place in ValidIndexList:",
                "ASSIGN=list(TicTecBoard)",
                "ASSIGN=int(place)-1",
                "SLICE=ASSIGN",
                "if checkPatterns(ASSIGN,ASSIGN)>0:",
                "ASSIGN=testIndex",
                "ASSIGN=1",
                "ASSIGN==0:",
                "for place in ValidIndexList:",
                "ASSIGN=list(TicTecBoard)",
                "ASSIGN=int(place)-1",
                "SLICE=\"O\"",
                "if checkPatterns(ASSIGN,ASSIGN)>0:",
                "ASSIGN=testIndex",
                "ASSIGN=-1",
                "ASSIGN==0:",
                "ASSIGN=4 if \"5\" in ValidIndexList else int(random.choice(ValidIndexList))-1",
                "SLICE=ASSIGN",
                "if checkPatterns(getpatterns(ASSIGN),TicTecBoard)>0:",
                "printTicTecBoard(TicTecBoard)",
                "print('\\x1b[6;30;42m' +ASSIGN++ '\\x1b[0m')",
                "break",
                "elif checkPatterns(\"-\",TicTecBoard)==0:",
                "printTicTecBoard(TicTecBoard)",
                "print()",
                "break",
                "else:",
                "ASSIGN=\"X\" if ASSIGN==\"O\" else \"O\"",
                "except:",
                "print()"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN=getpatterns(\"O\")",
                "ASSIGN=getpatterns(\"X\")",
                "TicTecBoard=[\"-\" for i in range(9)]",
                "ASSIGN=\"O\"",
                "try:",
                "while True:",
                "ValidIndexList=getValidPlace(TicTecBoard)",
                "ASSIGN==\"O\":",
                "while True:",
                "printTicTecBoard(TicTecBoard)",
                "ASSIGN=input(\" \\n Enter Cell Number from Valid Index List \"+str(ValidIndexList )+\" : \\n\")",
                "if ASSIGN in ValidIndexList:",
                "ASSIGN=int(ASSIGN)-1",
                "break",
                "else:",
                "print()",
                "else:",
                "ASSIGN=0",
                "for place in ValidIndexList:",
                "ASSIGN=list(TicTecBoard)",
                "ASSIGN=int(place)-1",
                "SLICE=ASSIGN",
                "if checkPatterns(ASSIGN,ASSIGN)>0:",
                "ASSIGN=testIndex",
                "ASSIGN=1",
                "ASSIGN==0:",
                "for place in ValidIndexList:",
                "ASSIGN=list(TicTecBoard)",
                "ASSIGN=int(place)-1",
                "SLICE=\"O\"",
                "if checkPatterns(ASSIGN,ASSIGN)>0:",
                "ASSIGN=testIndex",
                "ASSIGN=-1",
                "ASSIGN==0:",
                "ASSIGN=4 if \"5\" in ValidIndexList else int(random.choice(ValidIndexList))-1",
                "SLICE=ASSIGN",
                "if checkPatterns(getpatterns(ASSIGN),TicTecBoard)>0:",
                "printTicTecBoard(TicTecBoard)",
                "print('\\x1b[6;30;42m' +ASSIGN++ '\\x1b[0m')",
                "break",
                "elif checkPatterns(\"-\",TicTecBoard)==0:",
                "printTicTecBoard(TicTecBoard)",
                "print()",
                "break",
                "else:",
                "ASSIGN=\"X\" if ASSIGN==\"O\" else \"O\"",
                "except:",
                "print()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")",
                "np.random.seed(0)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv(\"..path\")",
                "np.random.seed(0)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = np.random.exponential(size = 1000)",
                "ASSIGN = minmax_scaling(original_data, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = np.random.exponential(size = 1000)",
                "ASSIGN = minmax_scaling(original_data, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = stats.boxcox(original_data)",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(original_data, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN[0], ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = stats.boxcox(original_data)",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(original_data, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN[0], ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "kickstarters_2017.sample(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "kickstarters_2017.sample(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = kickstarters_2017.usd_goal_real",
                "ASSIGN = minmax_scaling(usd_goal, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(kickstarters_2017.usd_goal_real, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = kickstarters_2017.usd_goal_real",
                "ASSIGN = minmax_scaling(usd_goal, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(kickstarters_2017.usd_goal_real, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = kickstarters_2017.ASSIGN",
                "ASSIGN = minmax_scaling(goal, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(kickstarters_2017.ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = kickstarters_2017.ASSIGN",
                "ASSIGN = minmax_scaling(goal, columns = [0])",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(kickstarters_2017.ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Scaled data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = kickstarters_2017.usd_pledged_real > 0",
                "ASSIGN = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]",
                "ASSIGN = stats.boxcox(positive_pledges)[0]",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = kickstarters_2017.usd_pledged_real > 0",
                "ASSIGN = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]",
                "ASSIGN = stats.boxcox(positive_pledges)[0]",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = kickstarters_2017.pledged > 0",
                "ASSIGN = kickstarters_2017.pledged.loc[index_of_positive_pledges]",
                "ASSIGN = stats.boxcox(positive_pledged)[0]",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = kickstarters_2017.pledged > 0",
                "ASSIGN = kickstarters_2017.pledged.loc[index_of_positive_pledges]",
                "ASSIGN = stats.boxcox(positive_pledged)[0]",
                "ASSIGN=plt.subplots(1,2)",
                "sns.distplot(ASSIGN, ax=ax[0])",
                "ax[0].set_title(\"Original Data\")",
                "sns.distplot(ASSIGN, ax=ax[1])",
                "ax[1].set_title(\"Normalized data\")"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "init_notebook_mode(connected=True)",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.head()",
                "ASSIGN = ASSIGN.rename(columns={'Countrypath':'Country'})",
                "ASSIGN = ASSIGN.rename(columns={'ObservationDate':'Date'})",
                "ASSIGN = df.groupby(['Country', 'Date']).sum().reset_index().sort_values('Date', ascending=False)",
                "ASSIGN = ASSIGN.drop_duplicates(subset = ['Country'])",
                "ASSIGN = ASSIGN[ASSIGN['Confirmed']>0]",
                "ASSIGN = df[df['Confirmed']>0]",
                "ASSIGN = ASSIGN.groupby(['Date','Country']).sum().reset_index()",
                "df_countrydate",
                "ASSIGN = px.choropleth(df_countrydate,",
                "ASSIGN=\"Country\",",
                "ASSIGN = \"country names\",",
                "ASSIGN=\"Confirmed\",",
                "ASSIGN=\"Country\",",
                "ASSIGN=\"Date\"",
                ")",
                "ASSIGN.update_layout(",
                "ASSIGN = 'Global Spread of Coronavirus',",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "init_notebook_mode(connected=True)",
                "ASSIGN = pd.read_csv(\"path\")",
                "ASSIGN.head()",
                "ASSIGN = ASSIGN.rename(columns={'Countrypath':'Country'})",
                "ASSIGN = ASSIGN.rename(columns={'ObservationDate':'Date'})",
                "ASSIGN = df.groupby(['Country', 'Date']).sum().reset_index().sort_values('Date', ascending=False)",
                "ASSIGN = ASSIGN.drop_duplicates(subset = ['Country'])",
                "ASSIGN = ASSIGN[ASSIGN['Confirmed']>0]",
                "ASSIGN = df[df['Confirmed']>0]",
                "ASSIGN = ASSIGN.groupby(['Date','Country']).sum().reset_index()",
                "df_countrydate",
                "ASSIGN = px.choropleth(df_countrydate,",
                "ASSIGN=\"Country\",",
                "ASSIGN = \"country names\",",
                "ASSIGN=\"Confirmed\",",
                "ASSIGN=\"Country\",",
                "ASSIGN=\"Date\"",
                ")",
                "ASSIGN.update_layout(",
                "ASSIGN = 'Global Spread of Coronavirus',",
                "ASSIGN = 0.5,",
                "ASSIGN=dict(",
                "ASSIGN = False,",
                "ASSIGN = False,",
                "))",
                "ASSIGN.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.read_csv('..path', dtype=np.object)",
                "ASSIGN = multiple.iloc[0,:]",
                "ASSIGN = multiple.iloc[1:,:]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.read_csv('..path', dtype=np.object)",
                "ASSIGN = multiple.iloc[0,:]",
                "ASSIGN = multiple.iloc[1:,:]"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = mulcA[round(mulcA.iloc[:,0].astype(int) path) <= 3].index",
                "ASSIGN = ASSIGN.drop(fast, axis=0)",
                "ASSIGN = mulcA.Q5",
                "ASSIGN.value_counts(normalize=True).plot(kind='bar')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = mulcA[round(mulcA.iloc[:,0].astype(int) path) <= 3].index",
                "ASSIGN = ASSIGN.drop(fast, axis=0)",
                "ASSIGN = mulcA.Q5",
                "ASSIGN.value_counts(normalize=True).plot(kind='bar')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = mulcA.Q9",
                "ASSIGN.value_counts().plot(kind='bar')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = mulcA.Q9",
                "ASSIGN.value_counts().plot(kind='bar')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "mulcA.replace({'Q9':{'0-10,000':1,'10-20,000':2,'20-30,000':3,'30-40,000':4,'40-50,000':5,'50-60,000':6,",
                "'60-70,000':7,'70-80,000':8,'80-90,000':9,'90-100,000':10,'100-125,000':11,'125-150,000':12,",
                "'150-200,000':13,'200-250,000':14,'250-300,000':15,'300-400,000':16,'400-500,000':17,",
                "'500,000+':18}},inplace = True)",
                "mulcA.replace({'Q3':{'United Kingdom of Great Britain and Northern Ireland':'Great B.','Iran, Islamic Republic of...':'Iran',",
                "'United States of America':'USA','Hong Kong (S.A.R.)':'Hong Kong','Republic of Korea':'R. Korea',",
                "'Czech Republic':'Czech R.'}},inplace = True)",
                "ASSIGN = multiple.filter(regex=\"(Q{t}$|Q{t}_)\".format(t = 16))[1:]",
                "ASSIGN = {'Q16_Part_1':'Python','Q16_Part_2':'R','Q16_Part_3':'SQL','Q16_Part_4': 'Bash','Q16_Part_5':'Java',",
                "'Q16_Part_6':'Javascript','Q16_Part_7':'VBA','Q16_Part_8':'Cpath++','Q16_Part_9':'MATLAB',",
                "'Q16_Part_10':'Scala','Q16_Part_11':'Julia','Q16_Part_12':'Go','Q16_Part_13':'C",
                "'Q16_Part_15':'Ruby','Q16_Part_16':'SASpath'}",
                "ASSIGN= q16.rename(columns=q16_col).fillna(0).replace('[^\\\\d]',1, regex=True)",
                "ASSIGN.pop('Q16_Part_17')",
                "ASSIGN.pop('Q16_Part_18')",
                "ASSIGN.pop('Q16_OTHER_TEXT')",
                "ASSIGN = list(q16_lim.iloc[:0])",
                "for i in ASSIGN:",
                "SLICE= ASSIGN['{}'.format(i)]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Computer science (software engineering, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Engineering (non-computer focused)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Mathematics or statistics') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'A business discipline (accounting, economics, finance, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Physics or astronomy') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Information technology, networking, or system administration') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Medical or life sciences (biology, chemistry, medicine, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Social sciences (anthropology, psychology, sociology, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Humanities (history, literature, philosophy, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Environmental science or geology') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Fine arts or performing arts') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = [com_sci.Q9.mean(),eng_nco.Q9.mean(),mat_sta.Q9.mean(),biu_dis.Q9.mean(),phy_ast.Q9.mean(),inf_tec.Q9.mean(),med_sci.Q9.mean(),",
                "ASSIGN.Q9.mean(),ASSIGN.Q9.mean(),ASSIGN.Q9.mean(),ASSIGN.Q9.mean()]",
                "plt.figure(figsize=(20,10))",
                "plt.bar(np.arange(11),ASSIGN,color=['dodgerblue','c','tomato','silver','midnightblue','tan'])",
                "plt.xticks(np.arange(11), ('Com. Science', 'Engieneering', 'Mathematics', 'Economics', 'Physics','Inf. Tecnologist','Medics','Social sciences','Humanities',",
                "'Env. Sciense','Arts'))",
                "plt.yticks(np.arange(10),('$10000','$20000','$30000','$40000','$50000','$60000','$70000','$80000','$90000','$100000'))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "mulcA.replace({'Q9':{'0-10,000':1,'10-20,000':2,'20-30,000':3,'30-40,000':4,'40-50,000':5,'50-60,000':6,",
                "'60-70,000':7,'70-80,000':8,'80-90,000':9,'90-100,000':10,'100-125,000':11,'125-150,000':12,",
                "'150-200,000':13,'200-250,000':14,'250-300,000':15,'300-400,000':16,'400-500,000':17,",
                "'500,000+':18}},inplace = True)",
                "mulcA.replace({'Q3':{'United Kingdom of Great Britain and Northern Ireland':'Great B.','Iran, Islamic Republic of...':'Iran',",
                "'United States of America':'USA','Hong Kong (S.A.R.)':'Hong Kong','Republic of Korea':'R. Korea',",
                "'Czech Republic':'Czech R.'}},inplace = True)",
                "ASSIGN = multiple.filter(regex=\"(Q{t}$|Q{t}_)\".format(t = 16))[1:]",
                "ASSIGN = {'Q16_Part_1':'Python','Q16_Part_2':'R','Q16_Part_3':'SQL','Q16_Part_4': 'Bash','Q16_Part_5':'Java',",
                "'Q16_Part_6':'Javascript','Q16_Part_7':'VBA','Q16_Part_8':'Cpath++','Q16_Part_9':'MATLAB',",
                "'Q16_Part_10':'Scala','Q16_Part_11':'Julia','Q16_Part_12':'Go','Q16_Part_13':'C",
                "'Q16_Part_15':'Ruby','Q16_Part_16':'SASpath'}",
                "ASSIGN= q16.rename(columns=q16_col).fillna(0).replace('[^\\\\d]',1, regex=True)",
                "ASSIGN.pop('Q16_Part_17')",
                "ASSIGN.pop('Q16_Part_18')",
                "ASSIGN.pop('Q16_OTHER_TEXT')",
                "ASSIGN = list(q16_lim.iloc[:0])",
                "for i in ASSIGN:",
                "SLICE= ASSIGN['{}'.format(i)]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Computer science (software engineering, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Engineering (non-computer focused)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Mathematics or statistics') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'A business discipline (accounting, economics, finance, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Physics or astronomy') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Information technology, networking, or system administration') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Medical or life sciences (biology, chemistry, medicine, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Social sciences (anthropology, psychology, sociology, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Humanities (history, literature, philosophy, etc.)') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Environmental science or geology') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = mulcA[(mulcA.Q5 == 'Fine arts or performing arts') & (mulcA.Q9 != 'I do not wish to disclose my approximate yearly compensation')]",
                "ASSIGN = [com_sci.Q9.mean(),eng_nco.Q9.mean(),mat_sta.Q9.mean(),biu_dis.Q9.mean(),phy_ast.Q9.mean(),inf_tec.Q9.mean(),med_sci.Q9.mean(),",
                "ASSIGN.Q9.mean(),ASSIGN.Q9.mean(),ASSIGN.Q9.mean(),ASSIGN.Q9.mean()]",
                "plt.figure(figsize=(20,10))",
                "plt.bar(np.arange(11),ASSIGN,color=['dodgerblue','c','tomato','silver','midnightblue','tan'])",
                "plt.xticks(np.arange(11), ('Com. Science', 'Engieneering', 'Mathematics', 'Economics', 'Physics','Inf. Tecnologist','Medics','Social sciences','Humanities',",
                "'Env. Sciense','Arts'))",
                "plt.yticks(np.arange(10),('$10000','$20000','$30000','$40000','$50000','$60000','$70000','$80000','$90000','$100000'))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '18-21')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '22-24')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '25-29')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '30-34')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '35-39')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '40-44')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '45-49')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '50-54')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '55-59')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '60-69')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '70-79')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '80+')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = pd.DataFrame([age_18_21.value_counts(normalize=True),age_22_24.value_counts(normalize=True),age_25_29.value_counts(normalize=True),age_30_34.value_counts(normalize=True),",
                "ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True)",
                ",ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True)],",
                "ASSIGN=['age18-21','age22-24','age25-29','age30-34','age35-39','age40-44','age45-49','age50-54','age55-59'",
                ",'age60-69','age70-79','age80+']).T",
                "ASSIGN = df_arol.plot.barh(rot=0, subplots=True,figsize=(15,35))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '18-21')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '22-24')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '25-29')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '30-34')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '35-39')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '40-44')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '45-49')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '50-54')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '55-59')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '60-69')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '70-79')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = mulcA.Q5[(mulcA.Q2 == '80+')&(mulcA.Q5 != 'Other')&(mulcA.Q5 != 'I never declared a major')]",
                "ASSIGN = pd.DataFrame([age_18_21.value_counts(normalize=True),age_22_24.value_counts(normalize=True),age_25_29.value_counts(normalize=True),age_30_34.value_counts(normalize=True),",
                "ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True)",
                ",ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True),ASSIGN.value_counts(normalize=True)],",
                "ASSIGN=['age18-21','age22-24','age25-29','age30-34','age35-39','age40-44','age45-49','age50-54','age55-59'",
                ",'age60-69','age70-79','age80+']).T",
                "ASSIGN = df_arol.plot.barh(rot=0, subplots=True,figsize=(15,35))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(15,3))",
                "ASSIGN = ['Comp. Science','Engeneering','Mathematics','Inf. Technology','Business','Physics','Medical','Soc. Science']",
                "ASSIGN = pd.DataFrame([com_sci.Q3.value_counts(),eng_nco.Q3.value_counts(),mat_sta.Q3.value_counts(),inf_tec.Q3.value_counts()",
                ",biu_dis.Q3.value_counts(),phy_ast.Q3.value_counts(),med_sci.Q3.value_counts(),soc_sci.Q3.value_counts()]",
                ",index=[names])",
                "ASSIGN= ASSIGN.drop(['Other'],axis=1).T",
                "ASSIGN = plt.subplots(4, 2, sharey=True,figsize=(15,20))",
                "axes[0, 0].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Comp. Science'].values[:10])),color='cadetblue')",
                "axes[0, 0].set_title('Comp. Science')",
                "axes[0, 1].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Engeneering'].values[:10])),color='slategray')",
                "axes[0, 1].set_title('Engeneering')",
                "axes[1, 0].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Mathematics'].values[:10])),color='seagreen')",
                "axes[1, 0].set_title('Mathematics')",
                "axes[1, 1].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Inf. Technology'].values[:10])),color='palevioletred')",
                "axes[1, 1].set_title('Inf. Technology')",
                "axes[2, 0].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Business'].values[:10])),color='darkblue')",
                "axes[2, 0].set_title('Business')",
                "axes[2, 1].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Physics'].values[:10])),color='khaki')",
                "axes[2, 1].set_title('Physics')",
                "axes[3, 0].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Medical'].values[:10])),color='k')",
                "axes[3, 0].set_title('Medical')",
                "axes[3, 1].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Soc. Science'].values[:10])),color='firebrick')",
                "axes[3, 1].set_title('Soc. Science')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.figure(figsize=(15,3))",
                "ASSIGN = ['Comp. Science','Engeneering','Mathematics','Inf. Technology','Business','Physics','Medical','Soc. Science']",
                "ASSIGN = pd.DataFrame([com_sci.Q3.value_counts(),eng_nco.Q3.value_counts(),mat_sta.Q3.value_counts(),inf_tec.Q3.value_counts()",
                ",biu_dis.Q3.value_counts(),phy_ast.Q3.value_counts(),med_sci.Q3.value_counts(),soc_sci.Q3.value_counts()]",
                ",index=[names])",
                "ASSIGN= ASSIGN.drop(['Other'],axis=1).T",
                "ASSIGN = plt.subplots(4, 2, sharey=True,figsize=(15,20))",
                "axes[0, 0].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Comp. Science'].values[:10])),color='cadetblue')",
                "axes[0, 0].set_title('Comp. Science')",
                "axes[0, 1].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Engeneering'].values[:10])),color='slategray')",
                "axes[0, 1].set_title('Engeneering')",
                "axes[1, 0].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Mathematics'].values[:10])),color='seagreen')",
                "axes[1, 0].set_title('Mathematics')",
                "axes[1, 1].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Inf. Technology'].values[:10])),color='palevioletred')",
                "axes[1, 1].set_title('Inf. Technology')",
                "axes[2, 0].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Business'].values[:10])),color='darkblue')",
                "axes[2, 0].set_title('Business')",
                "axes[2, 1].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Physics'].values[:10])),color='khaki')",
                "axes[2, 1].set_title('Physics')",
                "axes[3, 0].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Medical'].values[:10])),color='k')",
                "axes[3, 0].set_title('Medical')",
                "axes[3, 1].barh(ASSIGN.index[:10],list(map(int,ASSIGN['Soc. Science'].values[:10])),color='firebrick')",
                "axes[3, 1].set_title('Soc. Science')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = pd.DataFrame([mulcA['Python'].sum(),mulcA['R'].sum(),mulcA['SQL'].sum(),mulcA['Bash'].sum(),mulcA['Java'].sum(),",
                "mulcA['Javascript'].sum(),mulcA['VBA'].sum(),mulcA['Cpath++'].sum(),mulcA['MATLAB'].sum(),",
                "mulcA['Scala'].sum(),mulcA['Julia'].sum(),mulcA['Go'].sum(),mulcA['C",
                "mulcA['PHP'].sum(),mulcA['Ruby'].sum(),mulcA['SASpath'].sum()],index=lab)",
                "ASSIGN.plot(kind='bar',color='brown')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame([mulcA['Python'].sum(),mulcA['R'].sum(),mulcA['SQL'].sum(),mulcA['Bash'].sum(),mulcA['Java'].sum(),",
                "mulcA['Javascript'].sum(),mulcA['VBA'].sum(),mulcA['Cpath++'].sum(),mulcA['MATLAB'].sum(),",
                "mulcA['Scala'].sum(),mulcA['Julia'].sum(),mulcA['Go'].sum(),mulcA['C",
                "mulcA['PHP'].sum(),mulcA['Ruby'].sum(),mulcA['SASpath'].sum()],index=lab)",
                "ASSIGN.plot(kind='bar',color='brown')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN=[mulcA[i][mulcA.Q5=='Computer science (software engineering, etc.)'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Engineering (non-computer focused)'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Mathematics or statistics'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='A business discipline (accounting, economics, finance, etc.)'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Physics or astronomy'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Information technology, networking, or system administration'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Medical or life sciences (biology, chemistry, medicine, etc.)'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Social sciences (anthropology, psychology, sociology, etc.)'].sum() for i in lab ]",
                "ASSIGN = plt.subplots(4, 2, sharey=True,figsize=(15,20))",
                "axes[0, 0].barh(lab,ASSIGN,color='c')",
                "axes[0, 0].set_title('Comp. Science')",
                "axes[0, 1].barh(lab,ASSIGN,color='r')",
                "axes[0, 1].set_title('Engeneering')",
                "axes[1, 0].barh(lab,ASSIGN,color='k')",
                "axes[1, 0].set_title('Mathematics')",
                "axes[1, 1].barh(lab,ASSIGN)",
                "axes[1, 1].set_title('Inf. Technology')",
                "axes[2, 0].barh(lab,ASSIGN,color = 'tomato')",
                "axes[2, 0].set_title('Business')",
                "axes[2, 1].barh(lab,ASSIGN,color='b')",
                "axes[2, 1].set_title('Physics')",
                "axes[3, 0].barh(lab,ASSIGN,color='y')",
                "axes[3, 0].set_title('Medical')",
                "axes[3, 1].barh(lab,ASSIGN,color='g')",
                "axes[3, 1].set_title('Soc. Science')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN=[mulcA[i][mulcA.Q5=='Computer science (software engineering, etc.)'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Engineering (non-computer focused)'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Mathematics or statistics'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='A business discipline (accounting, economics, finance, etc.)'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Physics or astronomy'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Information technology, networking, or system administration'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Medical or life sciences (biology, chemistry, medicine, etc.)'].sum() for i in lab ]",
                "ASSIGN=[mulcA[i][mulcA.Q5=='Social sciences (anthropology, psychology, sociology, etc.)'].sum() for i in lab ]",
                "ASSIGN = plt.subplots(4, 2, sharey=True,figsize=(15,20))",
                "axes[0, 0].barh(lab,ASSIGN,color='c')",
                "axes[0, 0].set_title('Comp. Science')",
                "axes[0, 1].barh(lab,ASSIGN,color='r')",
                "axes[0, 1].set_title('Engeneering')",
                "axes[1, 0].barh(lab,ASSIGN,color='k')",
                "axes[1, 0].set_title('Mathematics')",
                "axes[1, 1].barh(lab,ASSIGN)",
                "axes[1, 1].set_title('Inf. Technology')",
                "axes[2, 0].barh(lab,ASSIGN,color = 'tomato')",
                "axes[2, 0].set_title('Business')",
                "axes[2, 1].barh(lab,ASSIGN,color='b')",
                "axes[2, 1].set_title('Physics')",
                "axes[3, 0].barh(lab,ASSIGN,color='y')",
                "axes[3, 0].set_title('Medical')",
                "axes[3, 1].barh(lab,ASSIGN,color='g')",
                "axes[3, 1].set_title('Soc. Science')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = mulcA.Q5[mulcA.Q1 == \"Female\"]",
                "ASSIGN = mulcA.Q5[mulcA.Q1 == \"Male\"]",
                "ASSIGN = pd.DataFrame([fem_oc.value_counts(normalize=True),mal_oc.value_counts(normalize=True)],index=['Female','Male']).T",
                "ASSIGN = df_gen.plot.barh(rot=0, subplots=True,figsize=(15,15))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = mulcA.Q5[mulcA.Q1 == \"Female\"]",
                "ASSIGN = mulcA.Q5[mulcA.Q1 == \"Male\"]",
                "ASSIGN = pd.DataFrame([fem_oc.value_counts(normalize=True),mal_oc.value_counts(normalize=True)],index=['Female','Male']).T",
                "ASSIGN = df_gen.plot.barh(rot=0, subplots=True,figsize=(15,15))"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('path(6).csv', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'owid-covid-data (6).csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('path(6).csv', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'owid-covid-data (6).csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df1.head(5)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df1.head(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotCorrelationMatrix(df1, 8)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotCorrelationMatrix(df1, 8)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotScatterMatrix(df1, 20, 10)"
            ],
            "output_type": "display_data",
            "content_old": [
                "plotScatterMatrix(df1, 20, 10)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "print(check_output([, ]).decode())"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "print(check_output([, ]).decode())"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(os.listdir('..path'))",
                "print(os.listdir('..path'))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print(os.listdir('..path'))",
                "print(os.listdir('..path'))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'IDAData.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'IDAData.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df1.head(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df1.head(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plotPerColumnDistribution(df1, 10, 5)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'IDACountry.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'IDACountry.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df2.head(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df2.head(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotPerColumnDistribution(df2, 10, 5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plotPerColumnDistribution(df2, 10, 5)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'IDASeries.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = 1000",
                "ASSIGN = pd.read_csv('..path', delimiter=',', nrows = nRowsRead)",
                "ASSIGN.dataframeName = 'IDASeries.csv'",
                "nRow, nCol = ASSIGN.shape",
                "print(f'There are {nRow} rows and {nCol} columns')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df3.head(5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df3.head(5)"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plotPerColumnDistribution(df3, 10, 5)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plotPerColumnDistribution(df3, 10, 5)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "def count_unique_values(df) :",
                "ASSIGN = list(df.columns)",
                "print('Count unique values :')",
                "for i in ASSIGN :",
                "ASSIGN = len(df[i].unique())",
                "print(i,':',ASSIGN)",
                "def check_missing_values(df) :",
                "ASSIGN = len(df)",
                "ASSIGN = list(df.columns)",
                "ASSIGN = []",
                "ASSIGN = []",
                "print('Variable with missing values :')",
                "for i in ASSIGN :",
                "ASSIGN = np.sum(df[i].isna())",
                "ASSIGN = round(count*100path, 2)",
                "if ASSIGN > 0 :",
                "print(i,':',ASSIGN,'path',ASSIGN,'%')",
                "ASSIGN.append(i)",
                "ASSIGN.append(ASSIGN)",
                "return missing_var, missing_count",
                "def stepwise_selection(X, y,",
                "ASSIGN=[],",
                "ASSIGN=0.01,",
                "ASSIGN = 0.05,",
                "ASSIGN=True):",
                "ASSIGN = list(initial_list)",
                "while True:",
                "ASSIGN=False",
                "ASSIGN = list(set(X.columns)-set(included))",
                "ASSIGN = pd.Series(index=excluded)",
                "for new_column in ASSIGN:",
                "ASSIGN = sm.genmod.GLM(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))",
                ",family=sm.genmod.families.Gamma(link=sm.genmod.families.links.log)).fit()",
                "ASSIGN[new_column] = ASSIGN.pvalues[new_column]",
                "ASSIGN = new_pval.min()",
                "if ASSIGN < ASSIGN:",
                "ASSIGN = new_pval.argmin()",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN=True",
                "if ASSIGN:",
                "print('Add {:30} with p-value {:.6}'.format(ASSIGN, ASSIGN))",
                "ASSIGN = sm.genmod.GLM(y, sm.add_constant(pd.DataFrame(X[included]))",
                ",family=sm.genmod.families.Gamma(link=sm.genmod.families.links.log)).fit()",
                "ASSIGN = model.ASSIGN.iloc[1:]",
                "ASSIGN = pvalues.max()",
                "if ASSIGN > ASSIGN:",
                "ASSIGN=True",
                "ASSIGN = pvalues.argmax()",
                "ASSIGN.remove(ASSIGN)",
                "if ASSIGN:",
                "print('Drop {:30} with p-value {:.6}'.format(ASSIGN, ASSIGN))",
                "if not ASSIGN:",
                "break",
                "return included",
                "def dataset_ready(x_train, y_train) :",
                "ASSIGN = pd.get_dummies(x_train)",
                "ASSIGN = [1]*len(X)",
                "ASSIGN['gdp_pop'] = np.log(ASSIGN['gdp_per_capita']*ASSIGN['population'])",
                "ASSIGN = ['gdp_per_capita','population']",
                "for i in ASSIGN :",
                "ASSIGN = np.log(ASSIGN)",
                "ASSIGN = pd.Series(X.columns)",
                "ASSIGN = list(X.filter(like='continent').columns)",
                "for i in ASSIGN :",
                "ASSIGN = i+'_gdp'",
                "ASSIGN = ASSIGN*ASSIGN",
                "for i in ASSIGN :",
                "ASSIGN = i+'_population'",
                "ASSIGN = ASSIGN*ASSIGN",
                "ASSIGN = y_train",
                "return X,Y"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def count_unique_values(df) :",
                "ASSIGN = list(df.columns)",
                "print('Count unique values :')",
                "for i in ASSIGN :",
                "ASSIGN = len(df[i].unique())",
                "print(i,':',ASSIGN)",
                "def check_missing_values(df) :",
                "ASSIGN = len(df)",
                "ASSIGN = list(df.columns)",
                "ASSIGN = []",
                "ASSIGN = []",
                "print('Variable with missing values :')",
                "for i in ASSIGN :",
                "ASSIGN = np.sum(df[i].isna())",
                "ASSIGN = round(count*100path, 2)",
                "if ASSIGN > 0 :",
                "print(i,':',ASSIGN,'path',ASSIGN,'%')",
                "ASSIGN.append(i)",
                "ASSIGN.append(ASSIGN)",
                "return missing_var, missing_count",
                "def stepwise_selection(X, y,",
                "ASSIGN=[],",
                "ASSIGN=0.01,",
                "ASSIGN = 0.05,",
                "ASSIGN=True):",
                "ASSIGN = list(initial_list)",
                "while True:",
                "ASSIGN=False",
                "ASSIGN = list(set(X.columns)-set(included))",
                "ASSIGN = pd.Series(index=excluded)",
                "for new_column in ASSIGN:",
                "ASSIGN = sm.genmod.GLM(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))",
                ",family=sm.genmod.families.Gamma(link=sm.genmod.families.links.log)).fit()",
                "ASSIGN[new_column] = ASSIGN.pvalues[new_column]",
                "ASSIGN = new_pval.min()",
                "if ASSIGN < ASSIGN:",
                "ASSIGN = new_pval.argmin()",
                "ASSIGN.append(ASSIGN)",
                "ASSIGN=True",
                "if ASSIGN:",
                "print('Add {:30} with p-value {:.6}'.format(ASSIGN, ASSIGN))",
                "ASSIGN = sm.genmod.GLM(y, sm.add_constant(pd.DataFrame(X[included]))",
                ",family=sm.genmod.families.Gamma(link=sm.genmod.families.links.log)).fit()",
                "ASSIGN = model.ASSIGN.iloc[1:]",
                "ASSIGN = pvalues.max()",
                "if ASSIGN > ASSIGN:",
                "ASSIGN=True",
                "ASSIGN = pvalues.argmax()",
                "ASSIGN.remove(ASSIGN)",
                "if ASSIGN:",
                "print('Drop {:30} with p-value {:.6}'.format(ASSIGN, ASSIGN))",
                "if not ASSIGN:",
                "break",
                "return included",
                "def dataset_ready(x_train, y_train) :",
                "ASSIGN = pd.get_dummies(x_train)",
                "ASSIGN = [1]*len(X)",
                "ASSIGN['gdp_pop'] = np.log(ASSIGN['gdp_per_capita']*ASSIGN['population'])",
                "ASSIGN = ['gdp_per_capita','population']",
                "for i in ASSIGN :",
                "ASSIGN = np.log(ASSIGN)",
                "ASSIGN = pd.Series(X.columns)",
                "ASSIGN = list(X.filter(like='continent').columns)",
                "for i in ASSIGN :",
                "ASSIGN = i+'_gdp'",
                "ASSIGN = ASSIGN*ASSIGN",
                "for i in ASSIGN :",
                "ASSIGN = i+'_population'",
                "ASSIGN = ASSIGN*ASSIGN",
                "ASSIGN = y_train",
                "return X,Y"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "rcParams['figure.figsize'] = [10,5]",
                "warnings.filterwarnings('ignore')",
                "pd.set_option('display.max_rows', 50)",
                "pd.set_option('display.max_columns', 50)",
                "sns.set()",
                "sns.set_style('whitegrid')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "rcParams['figure.figsize'] = [10,5]",
                "warnings.filterwarnings('ignore')",
                "pd.set_option('display.max_rows', 50)",
                "pd.set_option('display.max_columns', 50)",
                "sns.set()",
                "sns.set_style('whitegrid')"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_train.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_train.rename(columns={' gdp_for_year ($) ':'gdp_for_year', 'gdp_per_capita ($)':'gdp_per_capita'}, inplace=True)",
                "ASSIGN = df_train.copy()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_train.rename(columns={' gdp_for_year ($) ':'gdp_for_year', 'gdp_per_capita ($)':'gdp_per_capita'}, inplace=True)",
                "ASSIGN = df_train.copy()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df_train.describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_train.describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print('Data types of the dataset :')",
                "print(df_train.dtypes)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "print('Data types of the dataset :')",
                "print(df_train.dtypes)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = []",
                "for i in df_train['gdp_for_year'] :",
                "ASSIGN = i.ASSIGN(',')",
                "ASSIGN = ''",
                "for j in ASSIGN :",
                "ASSIGN = ASSIGN + j",
                "ASSIGN.append(int(ASSIGN))",
                "df_train['gdp_for_year'] = ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "for i in df_train['gdp_for_year'] :",
                "ASSIGN = i.ASSIGN(',')",
                "ASSIGN = ''",
                "for j in ASSIGN :",
                "ASSIGN = ASSIGN + j",
                "ASSIGN.append(int(ASSIGN))",
                "df_train['gdp_for_year'] = ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "rcParams['figure.figsize'] = [10,5]",
                "sns.heatmap(df_train.corr(), annot=True, linewidths=0.2, cmap='coolwarm' )",
                "plt.title('Correlation heatmap of the dataset', size=15, fontweight='bold') ;",
                "plt.xticks(rotation=45)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "rcParams['figure.figsize'] = [10,5]",
                "sns.heatmap(df_train.corr(), annot=True, linewidths=0.2, cmap='coolwarm' )",
                "plt.title('Correlation heatmap of the dataset', size=15, fontweight='bold') ;",
                "plt.xticks(rotation=45)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = check_missing_values(df_train)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = check_missing_values(df_train)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "df_train_v2.drop(columns=['country-year','HDI for year','gdp_for_year'], inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "df_train_v2.drop(columns=['country-year','HDI for year','gdp_for_year'], inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ['country','year','sex','age','generation']",
                "count_unique_values(df_train[ASSIGN])"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['country','year','sex','age','generation']",
                "count_unique_values(df_train[ASSIGN])"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "rcParams['figure.figsize'] = [15,5]",
                "ASSIGN = gridspec.GridSpec(1,2)",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[0,1])",
                "sns.distplot(df_train['suicides_no'], color='",
                "ASSIGN.set_title('Distribution of the suicides_no', size=15, fontweight='bold') ;",
                "sns.distplot(np.log(df_train[df_train['suicides_no']>0]['suicides_no']), color='",
                "ASSIGN.set_title('Distribution of the log of population', size=15, fontweight='bold') ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "rcParams['figure.figsize'] = [15,5]",
                "ASSIGN = gridspec.GridSpec(1,2)",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[0,1])",
                "sns.distplot(df_train['suicides_no'], color='",
                "ASSIGN.set_title('Distribution of the suicides_no', size=15, fontweight='bold') ;",
                "sns.distplot(np.log(df_train[df_train['suicides_no']>0]['suicides_no']), color='",
                "ASSIGN.set_title('Distribution of the log of population', size=15, fontweight='bold') ;"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = df_train_v2['ASSIGN'].unique()",
                "ASSIGN = ['Europe','Central America','South America','Asia','Central America'",
                ",'Australia','Europe','Asia','Central America','Asia'",
                ",'Central America','Europe','Europe','Central America'",
                ",'Europe','South America','Europe','Africa'",
                ",'North America','South America','South America','Central America','Europe','Central America'",
                ",'Asia','Europe','Europe','Central America','South America'",
                ",'Central America','Europe','Oceania','Europe','Europe','Asia'",
                ",'Europe','Europe','Central America','Central America','South America','Europe'",
                ",'Europe','Europe','Asia','Europe','Central America','Asia'",
                ",'Asia','Oceania','Asia','Asia','Europe'",
                ",'Europe','Europe','Asia','Asia','Europe'",
                ",'Africa','North America','Asia','Europe','Europe'",
                ",'Oceania','Central America','Europe','Asia','Central America','South America'",
                ",'Asia','Europe','Europe','Central America','Asia'",
                ",'Asia','Europe','Europe'",
                ",'Central America','Central America'",
                ",'Central America','Europe','Europe'",
                ",'Africa','Asia','Europe','Europe','Africa'",
                ",'Europe','Asia','South America','Europe','Europe'",
                ",'Asia','Central America','Asia','Asia'",
                ",'Europe','Asia','Europe'",
                ",'North America','South America','Asia']",
                "ASSIGN = []",
                "for i in range(len(ASSIGN)) :",
                "ASSIGN = len(df_train[df_train['country']==country[i]])",
                "for j in range(ASSIGN) :",
                "ASSIGN.append(ASSIGN[i])",
                "df_train_v2['continent'] = ASSIGN"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df_train_v2['ASSIGN'].unique()",
                "ASSIGN = ['Europe','Central America','South America','Asia','Central America'",
                ",'Australia','Europe','Asia','Central America','Asia'",
                ",'Central America','Europe','Europe','Central America'",
                ",'Europe','South America','Europe','Africa'",
                ",'North America','South America','South America','Central America','Europe','Central America'",
                ",'Asia','Europe','Europe','Central America','South America'",
                ",'Central America','Europe','Oceania','Europe','Europe','Asia'",
                ",'Europe','Europe','Central America','Central America','South America','Europe'",
                ",'Europe','Europe','Asia','Europe','Central America','Asia'",
                ",'Asia','Oceania','Asia','Asia','Europe'",
                ",'Europe','Europe','Asia','Asia','Europe'",
                ",'Africa','North America','Asia','Europe','Europe'",
                ",'Oceania','Central America','Europe','Asia','Central America','South America'",
                ",'Asia','Europe','Europe','Central America','Asia'",
                ",'Asia','Europe','Europe'",
                ",'Central America','Central America'",
                ",'Central America','Europe','Europe'",
                ",'Africa','Asia','Europe','Europe','Africa'",
                ",'Europe','Asia','South America','Europe','Europe'",
                ",'Asia','Central America','Asia','Asia'",
                ",'Europe','Asia','Europe'",
                ",'North America','South America','Asia']",
                "ASSIGN = []",
                "for i in range(len(ASSIGN)) :",
                "ASSIGN = len(df_train[df_train['country']==country[i]])",
                "for j in range(ASSIGN) :",
                "ASSIGN.append(ASSIGN[i])",
                "df_train_v2['continent'] = ASSIGN"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = df_train_v2.groupby(by=['country','continent']).median()[['suicides_no','population','gdp_per_capita']].sort_values('suicides_no',ascending=False).reset_index()",
                "ASSIGN = list(df_check.head(10)['country'])",
                "print('Top 10 country with highest suicide median ')",
                "print(ASSIGN.head(10))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = df_train_v2.groupby(by=['country','continent']).median()[['suicides_no','population','gdp_per_capita']].sort_values('suicides_no',ascending=False).reset_index()",
                "ASSIGN = list(df_check.head(10)['country'])",
                "print('Top 10 country with highest suicide median ')",
                "print(ASSIGN.head(10))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_train.groupby(by=['country','year']).median()['suicides_no'].reset_index()",
                "rcParams['figure.figsize'] = [10,6]",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[1,0])",
                "for i in cat[:3] :",
                "sns.lineplot(data=ASSIGN[ASSIGN['country']==i], x='year', y='suicides_no', ax=ASSIGN) ;",
                "ASSIGN.legend(cat[:3], loc=7, bbox_to_anchor=(1.3, 0.5)) ;",
                "ASSIGN.set_title('Number of suicide growth of top 3 country', size=15, fontweight='bold') ;",
                "for i in cat[3:] :",
                "sns.lineplot(data=ASSIGN[ASSIGN['country']==i], x='year', y='suicides_no', ax=ASSIGN) ;",
                "ASSIGN.legend(cat[3:], loc=7, bbox_to_anchor=(1.3, 0.5)) ;",
                "ASSIGN.set_xlabel('Number of suicide growth of reminding country', size=15, fontweight='bold') ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df_train.groupby(by=['country','year']).median()['suicides_no'].reset_index()",
                "rcParams['figure.figsize'] = [10,6]",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[1,0])",
                "for i in cat[:3] :",
                "sns.lineplot(data=ASSIGN[ASSIGN['country']==i], x='year', y='suicides_no', ax=ASSIGN) ;",
                "ASSIGN.legend(cat[:3], loc=7, bbox_to_anchor=(1.3, 0.5)) ;",
                "ASSIGN.set_title('Number of suicide growth of top 3 country', size=15, fontweight='bold') ;",
                "for i in cat[3:] :",
                "sns.lineplot(data=ASSIGN[ASSIGN['country']==i], x='year', y='suicides_no', ax=ASSIGN) ;",
                "ASSIGN.legend(cat[3:], loc=7, bbox_to_anchor=(1.3, 0.5)) ;",
                "ASSIGN.set_xlabel('Number of suicide growth of reminding country', size=15, fontweight='bold') ;"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = list(df_train_v2['ASSIGN'].unique())",
                "ASSIGN = pd.Series(ASSIGN)",
                "ASSIGN = []",
                "print('Count contry in each ASSIGN recorded in the dataset :')",
                "for i in ASSIGN :",
                "ASSIGN = len(new_val[new_val==i])",
                "ASSIGN.append(ASSIGN)",
                "print(i,':',ASSIGN)",
                "ASSIGN = pd.DataFrame({'continent':continent, 'count':count})",
                "ASSIGN.sort_values(by='ASSIGN', ascending=False, inplace=True)",
                "sns.catplot(data=ASSIGN, x='ASSIGN', y='ASSIGN') ;",
                "plt.xticks(rotation=45)",
                "plt.title('How many country in each ASSIGN', size=15, fontweight='bold') ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = list(df_train_v2['ASSIGN'].unique())",
                "ASSIGN = pd.Series(ASSIGN)",
                "ASSIGN = []",
                "print('Count contry in each ASSIGN recorded in the dataset :')",
                "for i in ASSIGN :",
                "ASSIGN = len(new_val[new_val==i])",
                "ASSIGN.append(ASSIGN)",
                "print(i,':',ASSIGN)",
                "ASSIGN = pd.DataFrame({'continent':continent, 'count':count})",
                "ASSIGN.sort_values(by='ASSIGN', ascending=False, inplace=True)",
                "sns.catplot(data=ASSIGN, x='ASSIGN', y='ASSIGN') ;",
                "plt.xticks(rotation=45)",
                "plt.title('How many country in each ASSIGN', size=15, fontweight='bold') ;"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = df_train_v2.groupby(by=['continent','year']).median()['suicides_no'].reset_index()",
                "rcParams['figure.figsize'] = [10,6]",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[1,0])",
                "sns.lineplot(data=ASSIGN[ASSIGN['continent']=='North America'], x='year', y='suicides_no', ax=ASSIGN ) ;",
                "ASSIGN.legend(['North America'], loc=7, bbox_to_anchor=(1.3, 0.5)) ;",
                "ASSIGN.set_title('Number of suicide growth of North America', size=15, fontweight='bold') ;",
                "ASSIGN = pd.Series(ASSIGN)",
                "for i in ASSIGN[ASSIGN!='North America'] :",
                "sns.lineplot(data=ASSIGN[ASSIGN['ASSIGN']==i], x='year', y='suicides_no', ax=ASSIGN) ;",
                "ASSIGN.legend(ASSIGN[ASSIGN!='North America'], loc=7, bbox_to_anchor=(1.3, 0.5)) ;",
                "ASSIGN.set_xlabel('Number of suicide growth of reminding ASSIGN', size=15, fontweight='bold') ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = df_train_v2.groupby(by=['continent','year']).median()['suicides_no'].reset_index()",
                "rcParams['figure.figsize'] = [10,6]",
                "ASSIGN = gridspec.GridSpec(2,1)",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[1,0])",
                "sns.lineplot(data=ASSIGN[ASSIGN['continent']=='North America'], x='year', y='suicides_no', ax=ASSIGN ) ;",
                "ASSIGN.legend(['North America'], loc=7, bbox_to_anchor=(1.3, 0.5)) ;",
                "ASSIGN.set_title('Number of suicide growth of North America', size=15, fontweight='bold') ;",
                "ASSIGN = pd.Series(ASSIGN)",
                "for i in ASSIGN[ASSIGN!='North America'] :",
                "sns.lineplot(data=ASSIGN[ASSIGN['ASSIGN']==i], x='year', y='suicides_no', ax=ASSIGN) ;",
                "ASSIGN.legend(ASSIGN[ASSIGN!='North America'], loc=7, bbox_to_anchor=(1.3, 0.5)) ;",
                "ASSIGN.set_xlabel('Number of suicide growth of reminding ASSIGN', size=15, fontweight='bold') ;"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "rcParams['figure.figsize'] = [15,5]",
                "ASSIGN = gridspec.GridSpec(1,2)",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[0,1])",
                "sns.barplot(data=df_train_v2, x='sex', y='suicides_no', hue='age', ax=ASSIGN",
                ",hue_order=['5-14 years','15-24 years','25-34 years','35-54 years','55-74 years','75+ years']) ;",
                "ASSIGN.set_title('Disrtibution of suicide count by sex', size=15, fontweight='bold') ;",
                "sns.barplot(data=df_train_v2, x='sex', y='suicidespath', hue='age', ax=ASSIGN",
                ",hue_order=['5-14 years','15-24 years','25-34 years','35-54 years','55-74 years','75+ years']) ;",
                "ASSIGN.set_title('Disrtibution of suicide count (rescale) by sex ', size=15, fontweight='bold') ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "rcParams['figure.figsize'] = [15,5]",
                "ASSIGN = gridspec.GridSpec(1,2)",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[0,1])",
                "sns.barplot(data=df_train_v2, x='sex', y='suicides_no', hue='age', ax=ASSIGN",
                ",hue_order=['5-14 years','15-24 years','25-34 years','35-54 years','55-74 years','75+ years']) ;",
                "ASSIGN.set_title('Disrtibution of suicide count by sex', size=15, fontweight='bold') ;",
                "sns.barplot(data=df_train_v2, x='sex', y='suicidespath', hue='age', ax=ASSIGN",
                ",hue_order=['5-14 years','15-24 years','25-34 years','35-54 years','55-74 years','75+ years']) ;",
                "ASSIGN.set_title('Disrtibution of suicide count (rescale) by sex ', size=15, fontweight='bold') ;"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "rcParams['figure.figsize'] = [16,5]",
                "ASSIGN = gridspec.GridSpec(1,3, width_ratios=[2,8,6])",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[0,1])",
                "ASSIGN = plt.subplot(gs[0,2])",
                "sns.barplot(data=df_train_v2[df_train_v2['continent']=='North America'], x='continent', y='suicides_no', ax=ASSIGN",
                ",hue_order=['G.I. Generation','Silent','Boomers','Generation X','Milennials','Generation Z'], hue='generation',) ;",
                "ASSIGN.get_legend().remove()",
                "ASSIGN.set_title('(NA)', size=15, fontweight='bold') ;",
                "sns.barplot(data=df_train_v2[df_train_v2['continent'].isin(['Europe','South America','Asia','Australia'])]",
                ", x='continent', y='suicides_no'",
                ",hue='generation', ax=ax2",
                ",hue_order=['G.I. Generation','Silent','Boomers','Generation X','Milennials','Generation Z']) ;",
                "ASSIGN.set_title('Suicide count by generation (E,SA,AS,AUS)', size=15, fontweight='bold') ;",
                "sns.barplot(data=df_train_v2[df_train_v2['continent'].isin(['Central America','Oceania','Africa'])]",
                ", x='continent', y='suicides_no'",
                ",hue='generation', ax=ax3",
                ",hue_order=['G.I. Generation','Silent','Boomers','Generation X','Milennials','Generation Z']) ;",
                "ASSIGN.get_legend().remove()",
                "ASSIGN.set_title('(CA,O,AF)', size=15, fontweight='bold') ;"
            ],
            "output_type": "not_existent",
            "content_old": [
                "rcParams['figure.figsize'] = [16,5]",
                "ASSIGN = gridspec.GridSpec(1,3, width_ratios=[2,8,6])",
                "ASSIGN = plt.subplot(gs[0,0])",
                "ASSIGN = plt.subplot(gs[0,1])",
                "ASSIGN = plt.subplot(gs[0,2])",
                "sns.barplot(data=df_train_v2[df_train_v2['continent']=='North America'], x='continent', y='suicides_no', ax=ASSIGN",
                ",hue_order=['G.I. Generation','Silent','Boomers','Generation X','Milennials','Generation Z'], hue='generation',) ;",
                "ASSIGN.get_legend().remove()",
                "ASSIGN.set_title('(NA)', size=15, fontweight='bold') ;",
                "sns.barplot(data=df_train_v2[df_train_v2['continent'].isin(['Europe','South America','Asia','Australia'])]",
                ", x='continent', y='suicides_no'",
                ",hue='generation', ax=ax2",
                ",hue_order=['G.I. Generation','Silent','Boomers','Generation X','Milennials','Generation Z']) ;",
                "ASSIGN.set_title('Suicide count by generation (E,SA,AS,AUS)', size=15, fontweight='bold') ;",
                "sns.barplot(data=df_train_v2[df_train_v2['continent'].isin(['Central America','Oceania','Africa'])]",
                ", x='continent', y='suicides_no'",
                ",hue='generation', ax=ax3",
                ",hue_order=['G.I. Generation','Silent','Boomers','Generation X','Milennials','Generation Z']) ;",
                "ASSIGN.get_legend().remove()",
                "ASSIGN.set_title('(CA,O,AF)', size=15, fontweight='bold') ;"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = pd.Series(df_train_v2.columns)",
                "ASSIGN = df_train_v2[df_train_v2>0].dropna()",
                "ASSIGN = dummy[~dummy.isin(['country','suicides_no','suicidespath'])]",
                "ASSIGN = 'suicidespath'",
                "ASSIGN = train_test_split(df_train_v3[x], df_train_v3[y], test_size=0.2, random_state=11)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = pd.Series(df_train_v2.columns)",
                "ASSIGN = df_train_v2[df_train_v2>0].dropna()",
                "ASSIGN = dummy[~dummy.isin(['country','suicides_no','suicidespath'])]",
                "ASSIGN = 'suicidespath'",
                "ASSIGN = train_test_split(df_train_v3[x], df_train_v3[y], test_size=0.2, random_state=11)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "X, Y = dataset_ready(x_train, y_train)",
                "X2, Y2 = dataset_ready(x_valid, y_valid)",
                "ASSIGN = stepwise_selection(X,Y, list(X.columns))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "X, Y = dataset_ready(x_train, y_train)",
                "X2, Y2 = dataset_ready(x_valid, y_valid)",
                "ASSIGN = stepwise_selection(X,Y, list(X.columns))"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity",
                "Model Training Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = sm.genmod.GLM(endog=Y, exog=X[best_var]",
                ",family=sm.genmod.families.Gamma(link=sm.genmod.families.links.log))",
                "ASSIGN = GLM_gamma.fit()",
                "print(ASSIGN.summary())",
                "print('Model AIC :',ASSIGN.aic)",
                "print('Model BIC :',ASSIGN.bic)",
                "print('Model deviance :',ASSIGN.deviance)",
                "print('Model RMSE :',rmse(ASSIGN.predict(X2[best_var]),Y2))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "ASSIGN = sm.genmod.GLM(endog=Y, exog=X[best_var]",
                ",family=sm.genmod.families.Gamma(link=sm.genmod.families.links.log))",
                "ASSIGN = GLM_gamma.fit()",
                "print(ASSIGN.summary())",
                "print('Model AIC :',ASSIGN.aic)",
                "print('Model BIC :',ASSIGN.bic)",
                "print('Model deviance :',ASSIGN.deviance)",
                "print('Model RMSE :',rmse(ASSIGN.predict(X2[best_var]),Y2))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity",
                "Model Evaluation Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.Series(df_train_v3.columns)",
                "ASSIGN = var[~var.isin(['country','suicides_no','suicidespath'])]",
                "ASSIGN = 'suicidespath'",
                "ASSIGN = df_train_v3[x]",
                "ASSIGN = df_train_v3[y]",
                "ASSIGN = len(X3)",
                "ASSIGN = len(Y3)",
                "ASSIGN.loc[ASSIGN+1] = [2016, 'male', '25-34 years', 21845000, 57588, 'Millenials', 'North America']",
                "ASSIGN.loc[ASSIGN+2] = [2016, 'female', '25-34 years', 21917000, 57588, 'Millenials', 'North America']",
                "ASSIGN.loc[ASSIGN+3] = [2016, 'male', '35-54 years', 40539000, 57588, 'Generation X', 'North America']",
                "ASSIGN.loc[ASSIGN+4] = [2016, 'female', '35-54 years', 42031000, 57588, 'Generation X', 'North America']",
                "ASSIGN.loc[ASSIGN+5] = [2016, 'male', '15-24 years', 21719000, 57588, 'Millenials', 'North America']",
                "ASSIGN.loc[ASSIGN+6] = [2016, 'female', '15-24 years', 21169000, 57588, 'Millenials', 'North America']",
                "ASSIGN.loc[ASSIGN+1] = 26.95",
                "ASSIGN.loc[ASSIGN+2] = 6.75",
                "ASSIGN.loc[ASSIGN+3] = 28.35",
                "ASSIGN.loc[ASSIGN+4] = 9.46",
                "ASSIGN.loc[ASSIGN+5] = 21.06",
                "ASSIGN.loc[ASSIGN+6] = 5.42",
                "ASSIGN,ASSIGN = dataset_ready(ASSIGN, ASSIGN)",
                "ASSIGN = ASSIGN.loc[nx+1:nx+6]",
                "ASSIGN = ASSIGN.loc[ny+1:nx+6]",
                "ASSIGN = GLM_result.ASSIGN(X3[best_var])",
                "for i in range(len(ASSIGN)) :",
                "print('Option',i+1)",
                "print('Predicted suicide rates :',round(ASSIGN.iloc[i],2))",
                "print('Actual suicide rates :',ASSIGN.iloc[i])",
                "print('')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.Series(df_train_v3.columns)",
                "ASSIGN = var[~var.isin(['country','suicides_no','suicidespath'])]",
                "ASSIGN = 'suicidespath'",
                "ASSIGN = df_train_v3[x]",
                "ASSIGN = df_train_v3[y]",
                "ASSIGN = len(X3)",
                "ASSIGN = len(Y3)",
                "ASSIGN.loc[ASSIGN+1] = [2016, 'male', '25-34 years', 21845000, 57588, 'Millenials', 'North America']",
                "ASSIGN.loc[ASSIGN+2] = [2016, 'female', '25-34 years', 21917000, 57588, 'Millenials', 'North America']",
                "ASSIGN.loc[ASSIGN+3] = [2016, 'male', '35-54 years', 40539000, 57588, 'Generation X', 'North America']",
                "ASSIGN.loc[ASSIGN+4] = [2016, 'female', '35-54 years', 42031000, 57588, 'Generation X', 'North America']",
                "ASSIGN.loc[ASSIGN+5] = [2016, 'male', '15-24 years', 21719000, 57588, 'Millenials', 'North America']",
                "ASSIGN.loc[ASSIGN+6] = [2016, 'female', '15-24 years', 21169000, 57588, 'Millenials', 'North America']",
                "ASSIGN.loc[ASSIGN+1] = 26.95",
                "ASSIGN.loc[ASSIGN+2] = 6.75",
                "ASSIGN.loc[ASSIGN+3] = 28.35",
                "ASSIGN.loc[ASSIGN+4] = 9.46",
                "ASSIGN.loc[ASSIGN+5] = 21.06",
                "ASSIGN.loc[ASSIGN+6] = 5.42",
                "ASSIGN,ASSIGN = dataset_ready(ASSIGN, ASSIGN)",
                "ASSIGN = ASSIGN.loc[nx+1:nx+6]",
                "ASSIGN = ASSIGN.loc[ny+1:nx+6]",
                "ASSIGN = GLM_result.ASSIGN(X3[best_var])",
                "for i in range(len(ASSIGN)) :",
                "print('Option',i+1)",
                "print('Predicted suicide rates :',round(ASSIGN.iloc[i],2))",
                "print('Actual suicide rates :',ASSIGN.iloc[i])",
                "print('')"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN='path'"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN='path'"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity"
            ],
            "content": [
                "ASSIGN = pd.read_csv(input_folder+'train.csv')",
                "ASSIGN = pd.read_csv(input_folder+'test.csv')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv(input_folder+'train.csv')",
                "ASSIGN = pd.read_csv(input_folder+'test.csv')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "print(train_data.isnull().sum()*100path().count())",
                "sns.heatmap(train_data.isnull(),",
                "ASSIGN=True,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN='plasma')"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(train_data.isnull().sum()*100path().count())",
                "sns.heatmap(train_data.isnull(),",
                "ASSIGN=True,",
                "ASSIGN=False,",
                "ASSIGN=False,",
                "ASSIGN='plasma')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "train_data['Sex'] = train_data['Sex'].astype('category')",
                "train_data['Sex'] = train_data['Sex'].cat.codes",
                "sns.heatmap(train_data.corr(),",
                "ASSIGN=True,",
                "ASSIGN=False)"
            ],
            "output_type": "execute_result",
            "content_old": [
                "train_data['Sex'] = train_data['Sex'].astype('category')",
                "train_data['Sex'] = train_data['Sex'].cat.codes",
                "sns.heatmap(train_data.corr(),",
                "ASSIGN=True,",
                "ASSIGN=False)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = train_data.filter(['Survived','Pclass','Sex','Age','Fare'])",
                "ASSIGN.dropna(how='any',axis='rows', inplace=True)",
                "ASSIGN = test_data.filter(['Survived','Pclass','Sex','Age','Fare','PassengerId'])",
                "ASSIGN.dropna(how='any',axis='rows', inplace=True)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train_data.filter(['Survived','Pclass','Sex','Age','Fare'])",
                "ASSIGN.dropna(how='any',axis='rows', inplace=True)",
                "ASSIGN = test_data.filter(['Survived','Pclass','Sex','Age','Fare','PassengerId'])",
                "ASSIGN.dropna(how='any',axis='rows', inplace=True)"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "train_filtered['Sex'] = train_filtered['Sex'].astype('category')",
                "train_filtered['Sex'] = train_filtered['Sex'].cat.codes",
                "test_filtered['Sex'] = test_filtered['Sex'].astype('category')",
                "test_filtered['Sex'] = test_filtered['Sex'].cat.codes"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train_filtered['Sex'] = train_filtered['Sex'].astype('category')",
                "train_filtered['Sex'] = train_filtered['Sex'].cat.codes",
                "test_filtered['Sex'] = test_filtered['Sex'].astype('category')",
                "test_filtered['Sex'] = test_filtered['Sex'].cat.codes"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = sns.jointplot(train_filtered.groupby(['Pclass']).sum().index,",
                "train_filtered.groupby(['Pclass']).sum()['Survived']",
                ")",
                "ASSIGN = sns.jointplot(train_filtered.groupby(['Sex']).sum().index,",
                "train_filtered.groupby(['Sex']).sum()['Survived']",
                ")",
                "ASSIGN = sns.jointplot(train_filtered.groupby(['Age']).sum().index,",
                "train_filtered.groupby(['Age']).sum()['Survived']",
                ")",
                "ASSIGN = sns.jointplot(train_filtered.groupby(['Fare']).sum().index,",
                "train_filtered.groupby(['Fare']).sum()['Survived']",
                ")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = sns.jointplot(train_filtered.groupby(['Pclass']).sum().index,",
                "train_filtered.groupby(['Pclass']).sum()['Survived']",
                ")",
                "ASSIGN = sns.jointplot(train_filtered.groupby(['Sex']).sum().index,",
                "train_filtered.groupby(['Sex']).sum()['Survived']",
                ")",
                "ASSIGN = sns.jointplot(train_filtered.groupby(['Age']).sum().index,",
                "train_filtered.groupby(['Age']).sum()['Survived']",
                ")",
                "ASSIGN = sns.jointplot(train_filtered.groupby(['Fare']).sum().index,",
                "train_filtered.groupby(['Fare']).sum()['Survived']",
                ")"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "X_train, X_test, y_train, y_test = train_test_split(",
                "train_filtered.drop('Survived', axis=1), train_filtered['Survived'], test_size=0.33)",
                "ASSIGN = LR().fit(y=y_train,X=X_train)",
                "ASSIGN = model.predict(X_test)",
                "ASSIGN = pd.DataFrame(data=y_test.tolist(),columns=['Survived actual'])",
                "ASSIGN['Survived predicted'] = ASSIGN",
                "ASSIGN=m.confusion_matrix(res['Survived actual'],res['Survived predicted'])",
                "sns.heatmap(ASSIGN,annot=True,fmt='d',cbar=0).set_title('Confusion Matrix')",
                "print('Accuracy: '+str(m.accuracy_score(ASSIGN['Survived actual'],ASSIGN['Survived predicted'])))",
                "print('Precision: '+str(m.precision_score(ASSIGN['Survived actual'],ASSIGN['Survived predicted'])))",
                "print('Recall: '+str(m.recall_score(ASSIGN['Survived actual'],ASSIGN['Survived predicted'])))"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "X_train, X_test, y_train, y_test = train_test_split(",
                "train_filtered.drop('Survived', axis=1), train_filtered['Survived'], test_size=0.33)",
                "ASSIGN = LR().fit(y=y_train,X=X_train)",
                "ASSIGN = model.predict(X_test)",
                "ASSIGN = pd.DataFrame(data=y_test.tolist(),columns=['Survived actual'])",
                "ASSIGN['Survived predicted'] = ASSIGN",
                "ASSIGN=m.confusion_matrix(res['Survived actual'],res['Survived predicted'])",
                "sns.heatmap(ASSIGN,annot=True,fmt='d',cbar=0).set_title('Confusion Matrix')",
                "print('Accuracy: '+str(m.accuracy_score(ASSIGN['Survived actual'],ASSIGN['Survived predicted'])))",
                "print('Precision: '+str(m.precision_score(ASSIGN['Survived actual'],ASSIGN['Survived predicted'])))",
                "print('Recall: '+str(m.recall_score(ASSIGN['Survived actual'],ASSIGN['Survived predicted'])))"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = LR().fit(y=train_filtered['Survived'],X=train_filtered.drop('Survived', axis=1))",
                "ASSIGN = model.predict(test_filtered.drop('PassengerId', axis=1))",
                "ASSIGN = pd.DataFrame(data=results.tolist(), columns = ['Survived'])",
                "ASSIGN = ASSIGN.astype(int)",
                "print(ASSIGN)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = LR().fit(y=train_filtered['Survived'],X=train_filtered.drop('Survived', axis=1))",
                "ASSIGN = model.predict(test_filtered.drop('PassengerId', axis=1))",
                "ASSIGN = pd.DataFrame(data=results.tolist(), columns = ['Survived'])",
                "ASSIGN = ASSIGN.astype(int)",
                "print(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "res.to_csv('results.csv', index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "res.to_csv('results.csv', index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"..path\", index_col='Id')",
                "train"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"..path\", index_col='Id')",
                "train"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train.describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train.describe()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "(train == '?').any()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "(train == '?').any()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[train == '?'].count()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train[train == '?'].count()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "train['workclass'].value_counts().plot(kind = 'bar')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train['workclass'].value_counts().plot(kind = 'bar')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "train['occupation'].value_counts().plot(kind = 'bar')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train['occupation'].value_counts().plot(kind = 'bar')"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "train['native.country'].value_counts().plot(kind = 'bar')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train['native.country'].value_counts().plot(kind = 'bar')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.replace(to_replace = '?', value = 'Private')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.replace(to_replace = '?', value = 'Private')"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "train['native.country'] = train['native.country'].replace(to_replace = '?', value = 'United-States')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train['native.country'] = train['native.country'].replace(to_replace = '?', value = 'United-States')"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "train[train == '?'].count()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "train[train == '?'].count()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN.loc[ASSIGN.occupation != '?']"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN.loc[ASSIGN.occupation != '?']"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "train"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "train"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = train.loc[:,'age':'native.country']",
                "ASSIGN = train.income",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = train.loc[:,'age':'native.country']",
                "ASSIGN = train.income",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "Ytrain.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "Ytrain.head()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.get_dummies(ASSIGN)",
                "Xtrain"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.get_dummies(ASSIGN)",
                "Xtrain"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = KNeighborsClassifier(n_neighbors = 10)",
                "ASSIGN = cross_val_score(knn, Xtrain, Ytrain, cv=10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = KNeighborsClassifier(n_neighbors = 10)",
                "ASSIGN = cross_val_score(knn, Xtrain, Ytrain, cv=10)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "scores.mean()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "scores.mean()"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = []",
                "for i in range(1,25):",
                "ASSIGN = KNeighborsClassifier(n_neighbors = i)",
                "ASSIGN = cross_val_score(knn, Xtrain, Ytrain, cv=10)",
                "ASSIGN.append(ASSIGN.mean())"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = []",
                "for i in range(1,25):",
                "ASSIGN = KNeighborsClassifier(n_neighbors = i)",
                "ASSIGN = cross_val_score(knn, Xtrain, Ytrain, cv=10)",
                "ASSIGN.append(ASSIGN.mean())"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.plot(scores_array, 'ro')"
            ],
            "output_type": "not_existent",
            "content_old": [
                "plt.plot(scores_array, 'ro')"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('..path', na_values='?', index_col='Id')",
                "test"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv('..path', na_values='?', index_col='Id')",
                "test"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "ASSIGN = pd.get_dummies(test)",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.get_dummies(test)",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = set( Xtrain.columns ) - set( Xtest.columns )",
                "for c in ASSIGN:",
                "ASSIGN = 0",
                "ASSIGN = ASSIGN[Xtrain.columns]"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = set( Xtrain.columns ) - set( Xtest.columns )",
                "for c in ASSIGN:",
                "ASSIGN = 0",
                "ASSIGN = ASSIGN[Xtrain.columns]"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = ASSIGN = KNeighborsClassifier(n_neighbors = 21)",
                "ASSIGN.fit(Xtrain,Ytrain)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ASSIGN = KNeighborsClassifier(n_neighbors = 21)",
                "ASSIGN.fit(Xtrain,Ytrain)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "YtestPred = knn.predict(Xtest)",
                "YtestPred"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "YtestPred = knn.predict(Xtest)",
                "YtestPred"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = pd.DataFrame(index = test.index)",
                "ASSIGN = YtestPred"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.DataFrame(index = test.index)",
                "ASSIGN = YtestPred"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "prediction"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "prediction"
            ]
        },
        {
            "tags": [
                "Post Development Phase"
            ],
            "content": [
                "prediction.to_csv(\"submition.csv\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "prediction.to_csv(\"submition.csv\")"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "ASSIGN = \"..path\"",
                "ASSIGN = root_dir + \"path\"",
                "ASSIGN = root_dir + \"path\"",
                "ASSIGN = root_dir + \"path\"",
                "ASSIGN = root_dir + \"sample_submission.csv\"",
                "ASSIGN  = pd.read_csv(csv_path)",
                "ASSIGN  = np.array([ imread(train_dir+p)path])",
                "ASSIGN  = df.has_cactus.values"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = \"..path\"",
                "ASSIGN = root_dir + \"path\"",
                "ASSIGN = root_dir + \"path\"",
                "ASSIGN = root_dir + \"path\"",
                "ASSIGN = root_dir + \"sample_submission.csv\"",
                "ASSIGN  = pd.read_csv(csv_path)",
                "ASSIGN  = np.array([ imread(train_dir+p)path])",
                "ASSIGN  = df.has_cactus.values"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "SETUP",
                "ASSIGN = train_test_split(x, y, test_size=0.20,stratify=y)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = train_test_split(x, y, test_size=0.20,stratify=y)"
            ]
        },
        {
            "tags": [
                "Model Evaluation Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "def display_images(imgs,y=None, y_pred=None):",
                "ASSIGN = imgs.shape[0]",
                "ASSIGN = 5",
                "ASSIGN = n_imagespath",
                "ASSIGN = 1",
                "plt.figure(figsize=(10,6),frameon=False)",
                "for i in range(ASSIGN):",
                "for j in range(ASSIGN):",
                "plt.subplot(ASSIGN, ASSIGN, ASSIGN)",
                "plt.imshow(imgs[ASSIGN-1])",
                "plt.axis(\"off\")",
                "if (y is not None) and (y_pred is not None):",
                "plt.title(\"y=%d | pred=%0.1f\"%(y[ASSIGN-1],y_pred[ASSIGN-1]))",
                "elif y is not None:",
                "plt.title(\"y=%d\"%y[ASSIGN-1])",
                "ASSIGN+=1",
                "plt.tight_layout()",
                "plt.show()",
                "def getProb(model, x):",
                "ASSIGN = model.preprocess(x)",
                "ASSIGN = model.data_transformer.transform_test(xprocessed)",
                "ASSIGN = model.cnn.predict(loader)",
                "ASSIGN  = np.exp(probs[:,1])",
                "ASSIGN = num + np.exp(probs[:,0])",
                "ASSIGN = num path",
                "return probs"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def display_images(imgs,y=None, y_pred=None):",
                "ASSIGN = imgs.shape[0]",
                "ASSIGN = 5",
                "ASSIGN = n_imagespath",
                "ASSIGN = 1",
                "plt.figure(figsize=(10,6),frameon=False)",
                "for i in range(ASSIGN):",
                "for j in range(ASSIGN):",
                "plt.subplot(ASSIGN, ASSIGN, ASSIGN)",
                "plt.imshow(imgs[ASSIGN-1])",
                "plt.axis(\"off\")",
                "if (y is not None) and (y_pred is not None):",
                "plt.title(\"y=%d | pred=%0.1f\"%(y[ASSIGN-1],y_pred[ASSIGN-1]))",
                "elif y is not None:",
                "plt.title(\"y=%d\"%y[ASSIGN-1])",
                "ASSIGN+=1",
                "plt.tight_layout()",
                "plt.show()",
                "def getProb(model, x):",
                "ASSIGN = model.preprocess(x)",
                "ASSIGN = model.data_transformer.transform_test(xprocessed)",
                "ASSIGN = model.cnn.predict(loader)",
                "ASSIGN  = np.exp(probs[:,1])",
                "ASSIGN = num + np.exp(probs[:,0])",
                "ASSIGN = num path",
                "return probs"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = 20",
                "ASSIGN = np.random.randint(0,len(x_train),n_samples)",
                "display_images(x_train[ASSIGN], y_train[ASSIGN])"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = 20",
                "ASSIGN = np.random.randint(0,len(x_train),n_samples)",
                "display_images(x_train[ASSIGN], y_train[ASSIGN])"
            ]
        },
        {
            "tags": [
                "Model Training Activity"
            ],
            "content": [
                "ASSIGN = 5",
                "ASSIGN = ak.ImageClassifier(verbose=True, augment=True )",
                "ASSIGN.fit(x_train, y_train, time_limit=4*60*60)"
            ],
            "output_type": "stream",
            "content_old": [
                "ASSIGN = 5",
                "ASSIGN = ak.ImageClassifier(verbose=True, augment=True )",
                "ASSIGN.fit(x_train, y_train, time_limit=4*60*60)"
            ]
        },
        {
            "tags": [
                "Model Training Activity",
                "Model Evaluation Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = model.predict(x_train)",
                "ASSIGN = getProb(model, x_train)",
                "print(, accuracy_score(y_train, ASSIGN))",
                "print(, recall_score(y_train, ASSIGN))",
                "print(, precision_score(y_train, ASSIGN))",
                "print(, roc_auc_score(y_train, ASSIGN))",
                "print(, f1_score(y_train, ASSIGN))",
                "ASSIGN = model.predict(x_val)",
                "ASSIGN = getProb(model, x_val)",
                "print(, accuracy_score(y_val, ASSIGN))",
                "print(, recall_score(y_val, ASSIGN))",
                "print(, precision_score(y_val, ASSIGN))",
                "print(,roc_auc_score(y_val, ASSIGN))",
                "print(, f1_score(y_val, ASSIGN))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = model.predict(x_train)",
                "ASSIGN = getProb(model, x_train)",
                "print(, accuracy_score(y_train, ASSIGN))",
                "print(, recall_score(y_train, ASSIGN))",
                "print(, precision_score(y_train, ASSIGN))",
                "print(, roc_auc_score(y_train, ASSIGN))",
                "print(, f1_score(y_train, ASSIGN))",
                "ASSIGN = model.predict(x_val)",
                "ASSIGN = getProb(model, x_val)",
                "print(, accuracy_score(y_val, ASSIGN))",
                "print(, recall_score(y_val, ASSIGN))",
                "print(, precision_score(y_val, ASSIGN))",
                "print(,roc_auc_score(y_val, ASSIGN))",
                "print(, f1_score(y_val, ASSIGN))"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Post Development Phase"
            ],
            "content": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = np.array([ imread(test_dir+p)path])",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = getProb(model, x_test)",
                "ASSIGN['has_cactus'] = ASSIGN",
                "ASSIGN.to_csv('cactus_net_submission.csv', index=False)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = pd.read_csv('..path')",
                "ASSIGN = np.array([ imread(test_dir+p)path])",
                "ASSIGN = np.array(ASSIGN)",
                "ASSIGN = getProb(model, x_test)",
                "ASSIGN['has_cactus'] = ASSIGN",
                "ASSIGN.to_csv('cactus_net_submission.csv', index=False)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"..path\")",
                "print(ASSIGN.isnull().sum())",
                "ASSIGN.dropna(inplace=True)",
                "ASSIGN = ASSIGN[ASSIGN['country']!='World']"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "ASSIGN = pd.read_csv(\"..path\")",
                "print(ASSIGN.isnull().sum())",
                "ASSIGN.dropna(inplace=True)",
                "ASSIGN = ASSIGN[ASSIGN['country']!='World']"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df.head()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "df['record'].value_counts()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "df['record'].value_counts()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ['crop_land','grazing_land','forest_land','fishing_ground','built_up_land','carbon','total']",
                "for columns in ASSIGN:",
                "plt.figure(figsize=(15,10))",
                "ASSIGN = df.groupby('year')[columns].mean()",
                "sns.barplot(ASSIGN.index,ASSIGN.values).set_xticklabels(sns.barplot(ASSIGN.index,ASSIGN.values).get_xticklabels(),rotation=\"90\")",
                "plt.title(\"Year Comparation with \"+columns)",
                "plt.xlabel(columns)",
                "plt.ylabel(\"Count\")"
            ],
            "output_type": "display_data",
            "content_old": [
                "ASSIGN = ['crop_land','grazing_land','forest_land','fishing_ground','built_up_land','carbon','total']",
                "for columns in ASSIGN:",
                "plt.figure(figsize=(15,10))",
                "ASSIGN = df.groupby('year')[columns].mean()",
                "sns.barplot(ASSIGN.index,ASSIGN.values).set_xticklabels(sns.barplot(ASSIGN.index,ASSIGN.values).get_xticklabels(),rotation=\"90\")",
                "plt.title(\"Year Comparation with \"+columns)",
                "plt.xlabel(columns)",
                "plt.ylabel(\"Count\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, most Carbon Producing Countring\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['carbon'].sort_values(ascending=False)[:10].plot.bar()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, most Carbon Producing Countring\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['carbon'].sort_values(ascending=False)[:10].plot.bar()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, lowest Carbon Producing Countring\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['carbon'].sort_values(ascending=True)[:10].plot.bar()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, lowest Carbon Producing Countring\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['carbon'].sort_values(ascending=True)[:10].plot.bar()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, Lowest Country with Forst Land\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['forest_land'].sort_values(ascending=True)[:10].plot.bar()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, Lowest Country with Forst Land\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['forest_land'].sort_values(ascending=True)[:10].plot.bar()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, Highest Country with Forst Land\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['forest_land'].sort_values(ascending=False)[:10].plot.bar()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, Highest Country with Forst Land\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['forest_land'].sort_values(ascending=False)[:10].plot.bar()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, Highest Country with Build Up Land\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['built_up_land'].sort_values(ascending=False)[:10].plot.bar()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, Highest Country with Build Up Land\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['built_up_land'].sort_values(ascending=False)[:10].plot.bar()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, Lowest Country with Build Up Land\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['built_up_land'].sort_values(ascending=True)[:10].plot.bar()"
            ],
            "output_type": "execute_result",
            "content_old": [
                "plt.figure(figsize=(10,10))",
                "plt.title(\"Total 10, Lowest Country with Build Up Land\")",
                "plt.xlabel(\"Country\")",
                "plt.ylabel(\"Rank\")",
                "df.groupby(['country']).mean()['built_up_land'].sort_values(ascending=True)[:10].plot.bar()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(os.listdir('..path'))"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(os.listdir('..path'))"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):",
                "ASSIGN = df.ASSIGN()",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if nunique[col] > 1 and nunique[col] < 50]]",
                "nRow, nCol = ASSIGN.shape",
                "ASSIGN = list(df)",
                "ASSIGN = (nCol + nGraphPerRow - 1) path",
                "plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * ASSIGN), dpi = 80, facecolor = 'w', edgecolor = 'k')",
                "for i in range(min(nCol, nGraphShown)):",
                "plt.subplot(ASSIGN, nGraphPerRow, i + 1)",
                "ASSIGN = df.iloc[:, i]",
                "if (not np.issubdtype(type(ASSIGN.iloc[0]), np.number)):",
                "ASSIGN = columnDf.value_counts()",
                "ASSIGN.plot.bar()",
                "else:",
                "ASSIGN.hist()",
                "plt.ylabel('counts')",
                "plt.xticks(rotation = 90)",
                "plt.title(f'{ASSIGN[i]} (column {i})')",
                "plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "CHECKPOINT",
                "def plotCorrelationMatrix(df, graphWidth):",
                "ASSIGN = df.dataframeName",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "if ASSIGN.shape[1] < 2:",
                "print(f'No correlation plots shown: The number of non-NaN or constant columns ({ASSIGN.shape[1]}) is less than 2')",
                "return",
                "ASSIGN = df.ASSIGN()",
                "plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')",
                "ASSIGN = plt.matshow(corr, fignum = 1)",
                "plt.xticks(range(len(ASSIGN.columns)), ASSIGN.columns, rotation=90)",
                "plt.yticks(range(len(ASSIGN.columns)), ASSIGN.columns)",
                "plt.gca().xaxis.tick_bottom()",
                "plt.colorbar(ASSIGN)",
                "plt.title(f'Correlation Matrix for {ASSIGN}', fontsize=15)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def plotScatterMatrix(df, plotSize, textSize):",
                "ASSIGN = ASSIGN.select_dtypes(include =[np.number])",
                "ASSIGN = ASSIGN.dropna('columns')",
                "ASSIGN = ASSIGN[[col for col in ASSIGN if ASSIGN[col].nunique() > 1]]",
                "ASSIGN = list(df)",
                "if len(ASSIGN) > 10:",
                "ASSIGN = ASSIGN[:10]",
                "ASSIGN = ASSIGN[columnNames]",
                "ASSIGN = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')",
                "ASSIGN = df.corr().values",
                "for i, j in zip(*plt.np.triu_indices_from(ASSIGN, k = 1)):",
                "ASSIGN[i, j].annotate('Corr. coef = %.3f' % ASSIGN[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)",
                "plt.suptitle('Scatter and Density Plot')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP",
                "warnings.filterwarnings(\"ignore\")"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "def display(driving ):",
                "ASSIGN = plt.figure(figsize=(10, 6))",
                "ASSIGN = []",
                "for i in range(len(driving)):",
                "ASSIGN = plt.imshow(driving[i], animated=True)",
                "plt.axis('off')",
                "ASSIGN.append([ASSIGN])",
                "ASSIGN = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)",
                "plt.close()",
                "return ani"
            ],
            "output_type": "not_existent",
            "content_old": [
                "def display(driving ):",
                "ASSIGN = plt.figure(figsize=(10, 6))",
                "ASSIGN = []",
                "for i in range(len(driving)):",
                "ASSIGN = plt.imshow(driving[i], animated=True)",
                "plt.axis('off')",
                "ASSIGN.append([ASSIGN])",
                "ASSIGN = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)",
                "plt.close()",
                "return ani"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = imageio.get_reader('..path')",
                "ASSIGN = reader.get_meta_data()['ASSIGN']",
                "ASSIGN = []",
                "try:",
                "for im in ASSIGN:",
                "ASSIGN.append(im)",
                "except RuntimeError:",
                "pass",
                "ASSIGN.close()",
                "ASSIGN = [resize(frame, (256, 256))[..., :3] for frame in ASSIGN]",
                "HTML(display(ASSIGN).to_html5_video())"
            ],
            "output_type": "execute_result",
            "content_old": [
                "ASSIGN = imageio.get_reader('..path')",
                "ASSIGN = reader.get_meta_data()['ASSIGN']",
                "ASSIGN = []",
                "try:",
                "for im in ASSIGN:",
                "ASSIGN.append(im)",
                "except RuntimeError:",
                "pass",
                "ASSIGN.close()",
                "ASSIGN = [resize(frame, (256, 256))[..., :3] for frame in ASSIGN]",
                "HTML(display(ASSIGN).to_html5_video())"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Pre-Processing Activity",
                "Model Training Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "sys.path.append('..path')",
                "binder.bind(globals())",
                "print()",
                "ASSIGN = pd.read_csv('..path', nrows=50000)",
                "ASSIGN = ASSIGN.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +",
                "'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +",
                "'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +",
                "'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +",
                "'fare_amount > 0'",
                ")",
                "ASSIGN = data.fare_amount",
                "ASSIGN = ['pickup_longitude',",
                "'pickup_latitude',",
                "'dropoff_longitude',",
                "'dropoff_latitude']",
                "ASSIGN = data[base_features]",
                "train_X, val_X, train_y, val_y = train_test_split(ASSIGN, ASSIGN, random_state=1)",
                "ASSIGN = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y)",
                "print()",
                "ASSIGN.head()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "sys.path.append('..path')",
                "binder.bind(globals())",
                "print()",
                "ASSIGN = pd.read_csv('..path', nrows=50000)",
                "ASSIGN = ASSIGN.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +",
                "'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +",
                "'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +",
                "'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +",
                "'fare_amount > 0'",
                ")",
                "ASSIGN = data.fare_amount",
                "ASSIGN = ['pickup_longitude',",
                "'pickup_latitude',",
                "'dropoff_longitude',",
                "'dropoff_latitude']",
                "ASSIGN = data[base_features]",
                "train_X, val_X, train_y, val_y = train_test_split(ASSIGN, ASSIGN, random_state=1)",
                "ASSIGN = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y)",
                "print()",
                "ASSIGN.head()"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "data.describe()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "data.describe()"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = 'pickup_longitude'",
                "ASSIGN = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)",
                "pdp.pdp_plot(ASSIGN, ASSIGN)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP",
                "ASSIGN = 'pickup_longitude'",
                "ASSIGN = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)",
                "pdp.pdp_plot(ASSIGN, ASSIGN)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "for feat_name in base_features:",
                "ASSIGN = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)",
                "pdp.pdp_plot(ASSIGN, feat_name)",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for feat_name in base_features:",
                "ASSIGN = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)",
                "pdp.pdp_plot(ASSIGN, feat_name)",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ['pickup_longitude', 'dropoff_longitude']",
                "ASSIGN = pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=feats)",
                "pdp.pdp_interact_plot(pdp_interact_out=ASSIGN, feature_names=ASSIGN, plot_type='contour')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['pickup_longitude', 'dropoff_longitude']",
                "ASSIGN = pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=feats)",
                "pdp.pdp_interact_plot(pdp_interact_out=ASSIGN, feature_names=ASSIGN, plot_type='contour')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ['pickup_latitude', 'dropoff_latitude']",
                "ASSIGN = pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=feats)",
                "pdp.pdp_interact_plot(pdp_interact_out=ASSIGN, feature_names=ASSIGN, plot_type='contour')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['pickup_latitude', 'dropoff_latitude']",
                "ASSIGN = pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=feats)",
                "pdp.pdp_interact_plot(pdp_interact_out=ASSIGN, feature_names=ASSIGN, plot_type='contour')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Visualization Phase"
            ],
            "content": [
                "ASSIGN = ['pickup_latitude', 'dropoff_longitude']",
                "ASSIGN = ['pickup_longitude', 'dropoff_longitude']",
                "ASSIGN = pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=feats)",
                "pdp.pdp_interact_plot(pdp_interact_out=ASSIGN, feature_names=ASSIGN, plot_type='contour')",
                "plt.show()"
            ],
            "output_type": "not_existent",
            "content_old": [
                "ASSIGN = ['pickup_latitude', 'dropoff_longitude']",
                "ASSIGN = ['pickup_longitude', 'dropoff_longitude']",
                "ASSIGN = pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=feats)",
                "pdp.pdp_interact_plot(pdp_interact_out=ASSIGN, feature_names=ASSIGN, plot_type='contour')",
                "plt.show()"
            ]
        },
        {
            "tags": [
                "Data Pre-Processing Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "(np.random.rand(10) < .5).astype(float)",
                "np.random.choice([1, -1], 10)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "(np.random.rand(10) < .5).astype(float)",
                "np.random.choice([1, -1], 10)"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Checkpoint Activity"
            ],
            "content": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ],
            "output_type": "stream",
            "content_old": [
                "SETUP",
                "CHECKPOINT",
                "for dirname, _, filenames in os.walk('path'):",
                "for filename in filenames:",
                "print(os.path.join(dirname, filename))"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "pip install face_recognition"
            ],
            "output_type": "stream",
            "content_old": [
                "pip install face_recognition"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Setup Activity",
                "Data Ingestion Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "SETUP",
                "ASSIGN = Image.open('path')",
                "display(ASSIGN)"
            ],
            "output_type": "display_data",
            "content_old": [
                "SETUP",
                "ASSIGN = Image.open('path')",
                "display(ASSIGN)"
            ]
        },
        {
            "tags": [
                "Setup Activity"
            ],
            "content": [
                "SETUP"
            ],
            "output_type": "not_existent",
            "content_old": [
                "SETUP"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print('Loading known faces...')",
                "ASSIGN = []",
                "ASSIGN = []"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print('Loading known faces...')",
                "ASSIGN = []",
                "ASSIGN = []"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Data Pre-Processing Activity"
            ],
            "content": [
                "for name in os.listdir(KNOWN_FACES_DIR):",
                "for filename in os.listdir(f'{KNOWN_FACES_DIR}path{name}'):",
                "ASSIGN = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}path{name}path{filename}')",
                "ASSIGN = face_recognition.face_encodings(image)[0]",
                "known_faces.append(ASSIGN)",
                "known_names.append(name)"
            ],
            "output_type": "not_existent",
            "content_old": [
                "for name in os.listdir(KNOWN_FACES_DIR):",
                "for filename in os.listdir(f'{KNOWN_FACES_DIR}path{name}'):",
                "ASSIGN = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}path{name}path{filename}')",
                "ASSIGN = face_recognition.face_encodings(image)[0]",
                "known_faces.append(ASSIGN)",
                "known_names.append(name)"
            ]
        },
        {
            "tags": [
                "Checkpoint Activity"
            ],
            "content": [
                "CHECKPOINT",
                "print(known_names)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "print(known_names)"
            ]
        },
        {
            "tags": [
                "Data Ingestion Activity",
                "Checkpoint Activity",
                "Data Visualization Phase"
            ],
            "content": [
                "CHECKPOINT",
                "for filename in os.listdir(UNKNOWN_FACES_DIR):",
                "print(f'Filename {filename}', end='')",
                "ASSIGN = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}path{filename}')",
                "ASSIGN = face_recognition.ASSIGN(unknown_image)",
                "ASSIGN = face_recognition.ASSIGN(unknown_image, face_locations)",
                "ASSIGN = Image.fromarray(unknown_image)",
                "ASSIGN = ImageDraw.Draw(pil_image)",
                "for (top, right, bottom, left), face_encoding in zip(ASSIGN, ASSIGN):",
                "ASSIGN = face_recognition.compare_faces(known_faces, face_encoding,TOLERANCE)",
                "ASSIGN = \"Unknown\"",
                "ASSIGN = face_recognition.face_distance(known_faces, face_encoding)",
                "ASSIGN = np.argmin(face_distances)",
                "if ASSIGN[ASSIGN]:",
                "ASSIGN = known_names[best_match_index]",
                "ASSIGN.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))",
                "ASSIGN = draw.textsize(name)",
                "ASSIGN.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))",
                "ASSIGN.text((left + 6, bottom - text_height - 5), ASSIGN, fill=(255, 255, 255, 255))",
                "del draw",
                "display(ASSIGN)"
            ],
            "output_type": "stream",
            "content_old": [
                "CHECKPOINT",
                "for filename in os.listdir(UNKNOWN_FACES_DIR):",
                "print(f'Filename {filename}', end='')",
                "ASSIGN = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}path{filename}')",
                "ASSIGN = face_recognition.ASSIGN(unknown_image)",
                "ASSIGN = face_recognition.ASSIGN(unknown_image, face_locations)",
                "ASSIGN = Image.fromarray(unknown_image)",
                "ASSIGN = ImageDraw.Draw(pil_image)",
                "for (top, right, bottom, left), face_encoding in zip(ASSIGN, ASSIGN):",
                "ASSIGN = face_recognition.compare_faces(known_faces, face_encoding,TOLERANCE)",
                "ASSIGN = \"Unknown\"",
                "ASSIGN = face_recognition.face_distance(known_faces, face_encoding)",
                "ASSIGN = np.argmin(face_distances)",
                "if ASSIGN[ASSIGN]:",
                "ASSIGN = known_names[best_match_index]",
                "ASSIGN.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))",
                "ASSIGN = draw.textsize(name)",
                "ASSIGN.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))",
                "ASSIGN.text((left + 6, bottom - text_height - 5), ASSIGN, fill=(255, 255, 255, 255))",
                "del draw",
                "display(ASSIGN)"
            ]
        }
    ]
}