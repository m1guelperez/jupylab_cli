{"cells":[{"metadata":{"_uuid":"554a048d4dcc0b568f36913cbd2684a91c74bdc3","_cell_guid":"cec81818-3600-48d7-a19d-dc8409930bfe"},"cell_type":"markdown","source":"<table>\n    <tr>\n        <td>\n        <center>\n        <font size=\"+1\">If you haven't used BigQuery datasets on Kaggle previously, check out the <a href = \"https://www.kaggle.com/rtatman/sql-scavenger-hunt-handbook/\">Scavenger Hunt Handbook</a> kernel to get started.</font>\n        </center>\n        </td>\n    </tr>\n</table>\n\n___ \n\n## Previous days:\n\n* [**Day 1:** SELECT, FROM & WHERE](https://www.kaggle.com/rtatman/sql-scavenger-hunt-day-1/)\n* [**Day 2:** GROUP BY, HAVING & COUNT()](https://www.kaggle.com/rtatman/sql-scavenger-hunt-day-2/)\n* [**Day 3:** ORDER BY & Dates](https://www.kaggle.com/rtatman/sql-scavenger-hunt-day-3/)\n* [**Day 4:** WITH & AS](https://www.kaggle.com/rtatman/sql-scavenger-hunt-day-4/)\n\n____\n","outputs":[],"execution_count":null},{"metadata":{"_uuid":"cd878ab863234c829f6b0c5d40970d6e2e7b05dc","_cell_guid":"dd8e1d44-3b6b-4734-8b7b-ccd299ae3b55"},"cell_type":"markdown","source":"## JOIN\n___\n\nWhew, we've come a long way from Day 1! By now, you have the tools to get many different configurations of information from a single table. But what if your database has more than one table and you want to look at information from multiple tables?\n\nThat's where JOIN comes in! Today, we're going to learn about how to use JOIN to combine data from two tables. This will let us answer more types of questions. It's also one of the more complex parts of SQL. Don't worry, though, we're going to go through some examples together. \n\n### JOIN\n___\n\nLet's keep working with our imaginary Pets dataset, but this time let's add a second table. The first table, \"Pets\", has three columns, with information on the ID number of each pet, the pet's name and the type of animal it is. The new table, \"Owners\", has three columns, with the ID number of each owner, the name of the owner and the ID number of their pet. \n\n![](https://i.imgur.com/W4gYoNg.png)\n\nEach row in each table is associated with a single pet and we refer to the same pets in both tables. We can tell this because there are two columns (ID in the \"Pets\" table and Pet_ID in the \"Owners\" table) that have the same information in them: the ID number of the pet. We can match rows that have the same value in these columns to get information that applies to a certain pet.\n\nFor example, we can see by looking at the Pets table that the pet that has the ID 1 is named Dr. Harris Bonkers. We can also tell by looking at the Owners table that the name of the owner who owns the pet with the ID 1 is named Aubrey Little. We can use this information to figure out that Dr. Harris Bonkers is owned by Aubrey Little. \n\nFortunately, we don't have to do this by hand to figure out which owner's name goes with which pet name. We can use JOIN to do this for us! JOIN allows us to create a third, new, table that has information from both tables. For example, we might want to have a single table with just two columns: one with the name of the pet and one with the name of the owner. This would look something like this: \n\n![](https://i.imgur.com/zqQdJTI.png)\n\nThe syntax to create that table looks like this:\n\n    SELECT p.Name AS Pet_Name, o.Name as Owner_Name\n    FROM `bigquery-public-data.pet_records.pets` as p\n    INNER JOIN `bigquery-public-data.pet_records.owners` as o ON p.ID = o.Pet_ID\nNotice that since the ID column exists in both datasets, we have to clarify which one we want to use. When you're joining tables, it's a good habit to specificy which table all of your columns come from. That way you don't have to pull up the schema every time you go back to read the query.\n\nThe type of JOIN we're using today is called an INNER JOIN. That just means that a row will only be put in the final output table if the value in the column you're using to combine them shows up in both the tables you're joining. For example, if Tom's ID code of 4 didn't exist in the `Pets` table, we would only get 3 rows back from this query. There are other types of JOIN, but an INNER JOIN won't give you an output that's larger than your input tables, so it's a good one to start with.   \n\n> **What does \"ON\" do?** It says which column in each table to look at to combine the tables. Here were using the \"ID\" column from the Pets table and the \"Pet_ID\" table from the Owners table.\n\nNow that we've talked about the concept behind using JOIN, let's work through an example together.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"d3a4faea2d05628aad3254f0aa5e884899b6d04a","_cell_guid":"ef431a97-04fc-49f3-ba4c-8f5a09e915df"},"cell_type":"markdown","source":"## Example: How many files are covered by each license?\n____\n\nToday we're going to be using the GitHub Repos dataset. GitHub is an place for people to store & collaborate on different versions of their computer code. A \"repo\" is a collection of code associated with a specific project. \n\nMost public code on Github is shared under a specific license, which determines how it can be used and by who. For our example, we're going to look at how many different files have been released under each licenses. \n\nFirst, of course, we need to get our environment ready to go:","outputs":[],"execution_count":null},{"metadata":{"_uuid":"7d374b8d3f3d0014c74ee370038a5f927c2d790a","collapsed":true,"_cell_guid":"77af0d7f-ad5e-4296-b2a8-114cd7c228eb","trusted":true},"cell_type":"code","source":"# import package with helper functions \nimport bq_helper\n\n# create a helper object for this dataset\ngithub = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                              dataset_name=\"github_repos\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a13315b4345edff6264d4bbe0ef16e1db8940d1d","_cell_guid":"a2806bda-371b-4c95-92ed-bc70919922b6"},"cell_type":"markdown","source":"Now we're ready to get started on our query. This one is going to be a bit of a beast, so stick with me! The only new syntax we'll see is around the JOIN clause, everything is something we've already learned. :)\n\nFirst, I'm going to specify which columns I'd like to be returned in the final table that's returned to me. Here, I'm selecting the COUNT of the \"path\" column from the sample_files table and then calling it \"number_of_files\". I'm *also* specifying that I was to include the \"license\" column, even though there's no \"license\" column in the \"sample_files\" table.\n\n        SELECT L.license, COUNT(sf.path) AS number_of_files\n        FROM `bigquery-public-data.github_repos.sample_files` as sf\nSpeaking of the JOIN clause, we still haven't actually told SQL we want to join anything! To do this, we need to specify what type of join we want (in this case an inner join) and how which columns we want to JOIN ON. Here, I'm using ON to specify that I want to use the \"repo_name\" column from the each table.\n\n    INNER JOIN `bigquery-public-data.github_repos.licenses` as L \n            ON sf.repo_name = L.repo_name\nAnd, finally, we have a GROUP BY and ORDER BY clause that apply to the final table that's been returned to us. We've seen these a couple of times at this point. :)\n\n        GROUP BY license\n        ORDER BY number_of_files DESC\n Alright, that was a lot, but you should have an idea what each part of this query is doing. :) Without any further ado, let' put it into action.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"6bc97eef84b58534150aae434df38e1a21348fbb","collapsed":true,"_cell_guid":"6827dc13-ec68-45f2-9a0d-56612e2849ca","trusted":true},"cell_type":"code","source":"# You can use two dashes (--) to add comments in SQL\nquery = (\"\"\"\n        -- Select all the columns we want in our joined table\n        SELECT L.license, COUNT(sf.path) AS number_of_files\n        FROM `bigquery-public-data.github_repos.sample_files` as sf\n        -- Table to merge into sample_files\n        INNER JOIN `bigquery-public-data.github_repos.licenses` as L \n            ON sf.repo_name = L.repo_name -- what columns should we join on?\n        GROUP BY L.license\n        ORDER BY number_of_files DESC\n        \"\"\")\n\nfile_count_by_license = github.query_to_pandas_safe(query, max_gb_scanned=6)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6436a3edcdf91ee115c1abf12e6337566274954d","_cell_guid":"67b338a5-69d5-4dc8-90bf-04cec2459204"},"cell_type":"markdown","source":"Whew, that was a big query! But it gave us a nice tidy little table that nicely summarizes how many files have been committed under each license:  ","outputs":[],"execution_count":null},{"metadata":{"_uuid":"fe0c791791d501a49bcbcce86948357f552888a3","_cell_guid":"6b468869-6125-475c-95ef-424a85e06b5b","trusted":true},"cell_type":"code","source":"# print out all the returned results\nprint(file_count_by_license)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d4000d1bca5c05b76960a00f5c8e096a65fda76","_cell_guid":"80698da7-8e48-4f68-9913-1c6969b9739a"},"cell_type":"markdown","source":"And that's how to get started using JOIN in BigQuery! There are many other kinds of joins (you can [read about some here](https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#join-types)), so once you're very comfortable with INNER JOIN you can start exploring some of them. :)","outputs":[],"execution_count":null},{"metadata":{"_uuid":"02471d34ed7a800f149a4b757f119d656d7306d0","_cell_guid":"d4e528a6-ea14-47ac-a82e-a31c92bbc083"},"cell_type":"markdown","source":"# Scavenger hunt\n___\n\nNow it's your turn! Here is the question I would like you to get the data to answer. Just one today, since you've been working hard this week. :)\n\n*  How many commits (recorded in the \"sample_commits\" table) have been made in repos written in the Python programming language? (I'm looking for the number of commits per repo for all the repos written in Python.\n    * You'll want to JOIN the sample_files and sample_commits questions to answer this.\n    * **Hint:** You can figure out which files are written in Python by filtering results from the \"sample_files\" table using `WHERE path LIKE '%.py'`. This will return results where the \"path\" column ends in the text \".py\", which is one way to identify which files have Python code.\n\nIn order to answer these questions, you can fork this notebook by hitting the blue \"Fork Notebook\" at the very top of this page (you may have to scroll up). \"Forking\" something is making a copy of it that you can edit on your own without changing the original.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"5ba7b51df28c665db0db0e183aef095759a1ea58"},"cell_type":"markdown","source":"# Scavenger hunt Answer 1\n___\n*  How many commits (recorded in the \"sample_commits\" table) have been made in repos written in the Python programming language? (I'm looking for the number of commits per repo for all the repos written in Python.\n    * You'll want to JOIN the sample_files and sample_commits questions to answer this.\n    * **Hint:** You can figure out which files are written in Python by filtering results from the \"sample_files\" table using `WHERE path LIKE '%.py'`. This will return results where the \"path\" column ends in the text \".py\", which is one way to identify which files have Python code.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"2c7648bc2e0ecaa97f78fde441e104a570c3bc9c","_cell_guid":"dc5ecdc2-d107-414f-b185-e68ee13f54f0","trusted":true},"cell_type":"code","source":"# print the first couple rows of the \"sample_commits\" table\ngithub.head(\"sample_commits\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7035cb234822449044acac1fb32932c6c2f1eac6"},"cell_type":"code","source":"# You can use two dashes (--) to add comments in SQL\nquery_commit = (\"\"\"\n        WITH repolist AS \n            (\n                SELECT repo_name\n                FROM  `bigquery-public-data.github_repos.sample_files`\n                WHERE path LIKE '%.py'\n                GROUP BY repo_name\n            )\n        SELECT sf.repo_name, COUNT(sc.commit) AS number_of_commits\n        FROM \n        repolist as sf \n        INNER JOIN `bigquery-public-data.github_repos.sample_commits` as sc\n            ON sc.repo_name = sf.repo_name \n        GROUP BY sf.repo_name\n        ORDER BY number_of_commits DESC\n        \"\"\")\n\n# check how big this query will be\ngithub.estimate_query_size(query_commit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79fe8aa30ffa10c710fb1be576e00e04701aaecc"},"cell_type":"code","source":"python_commits = github.query_to_pandas_safe(query_commit, max_gb_scanned=6)\npython_commits","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c4c2765f9786c518d3d2e8abc80f5e3ed6f9ec8"},"cell_type":"markdown","source":"My first attempt was to simply JOIN both table and count the number of commits, but the count return are far more larger than my final answer. Further checking I found that there are >1 phyton files in some repo, hence the commit count got multiplied. I leverage CTE to get a distinct repo_name using GROUP_BY, and join the CTE with sample_commits which gives me a more realistic outcome.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"9f231f459e13f0dc2f9347d38cc7c684c0dada18","_cell_guid":"cbd1f587-cddd-4f06-b4ae-ce215b32ac20"},"cell_type":"markdown","source":"Please feel free to ask any questions you have in this notebook or in the [Q&A forums](https://www.kaggle.com/questions-and-answers)! \n\nAlso, if you want to share or get comments on your kernel, remember you need to make it public first! You can change the visibility of your kernel under the \"Settings\" tab, on the right half of your screen.","outputs":[],"execution_count":null}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}