{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2be48ddb-1f53-4bfd-a5e1-9380f7a6754e",
    "_uuid": "293ac51fbc6c09f8d3b380ad30351d3f9cf2198b"
   },
   "source": [
    "Hi guys,\n",
    "\n",
    "This will be a very short example of how we can utilize TFIDF in combination with Chi2 test to find predictive features (and by that I mean filthy words). If you dare, read on...\n",
    "# Data Import\n",
    "We'll start by importing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "080820d8-71b0-46e0-b36c-c3004bec227f",
    "_uuid": "c0f57ccd91197d2f43b4299a7b08270699af8e04",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54037174</td>\n",
       "      <td>\"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77493077</td>\n",
       "      <td>Asking some his nationality is a Racial offenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79357270</td>\n",
       "      <td>The reader here is not going by my say so for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text  toxic  \\\n",
       "0  22256635  Nonsense?  kiss off, geek. what I said is true...      1   \n",
       "1  27450690  \"\\n\\n Please do not vandalize pages, as you di...      0   \n",
       "2  54037174  \"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...      0   \n",
       "3  77493077  Asking some his nationality is a Racial offenc...      0   \n",
       "4  79357270  The reader here is not going by my say so for ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../input/train.csv', header = 0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "406e8070-b5db-4e0d-8255-49a3a706c146",
    "_uuid": "45a07670b1a4d89316de8e83185141f0d2c20a1b"
   },
   "source": [
    "We'll just check if there are any empty fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "ad4e0c2b-4d8a-4260-be60-9f129cca5c8d",
    "_uuid": "31d90feabfd409fd52385f4823673823e31fda83",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95851 entries, 0 to 95850\n",
      "Data columns (total 8 columns):\n",
      "id               95851 non-null int64\n",
      "comment_text     95851 non-null object\n",
      "toxic            95851 non-null int64\n",
      "severe_toxic     95851 non-null int64\n",
      "obscene          95851 non-null int64\n",
      "threat           95851 non-null int64\n",
      "insult           95851 non-null int64\n",
      "identity_hate    95851 non-null int64\n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b30d4f7-ddc4-4e90-bc45-8d82ea454797",
    "_uuid": "0d2234d546f7f434855e747f6b38fbee39905700"
   },
   "source": [
    "Let's see if we can get some insights into the data by checking some standard metrics on the target fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "3294c951-61aa-4cec-9ac5-368d3de2c965",
    "_uuid": "c0884fffda624a9ce5ec8cb50378b698923227ac",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.585100e+04</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "      <td>95851.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.994359e+11</td>\n",
       "      <td>0.096368</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.053301</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>0.008492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.890136e+11</td>\n",
       "      <td>0.295097</td>\n",
       "      <td>0.099832</td>\n",
       "      <td>0.224635</td>\n",
       "      <td>0.056320</td>\n",
       "      <td>0.217352</td>\n",
       "      <td>0.091762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.225664e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.473437e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.001297e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.501088e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999882e+11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         toxic  severe_toxic       obscene        threat  \\\n",
       "count  9.585100e+04  95851.000000  95851.000000  95851.000000  95851.000000   \n",
       "mean   4.994359e+11      0.096368      0.010068      0.053301      0.003182   \n",
       "std    2.890136e+11      0.295097      0.099832      0.224635      0.056320   \n",
       "min    2.225664e+07      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    2.473437e+11      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    5.001297e+11      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    7.501088e+11      0.000000      0.000000      0.000000      0.000000   \n",
       "max    9.999882e+11      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             insult  identity_hate  \n",
       "count  95851.000000   95851.000000  \n",
       "mean       0.049713       0.008492  \n",
       "std        0.217352       0.091762  \n",
       "min        0.000000       0.000000  \n",
       "25%        0.000000       0.000000  \n",
       "50%        0.000000       0.000000  \n",
       "75%        0.000000       0.000000  \n",
       "max        1.000000       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e8f4edf-0cc3-4675-8c5a-d997b0c3a6bc",
    "_uuid": "60e90c1f1cbcd8d1142a4548a3fb0d451486fb7a"
   },
   "source": [
    "Looks like the mean value for the 'toxic' column is the highest. This means that more comments are labeled as 'toxic' than as 'severe toxic' or any other category. With the limited resources that the kernels provide, it would be best to focus only on predicting for that column.\n",
    "\n",
    "To do that, we'll further split our training set into 'train' and 'test' set. This will help us at least partially evaluate our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "9323c61c-51ac-48c6-b7fa-20c1d2a7cd14",
    "_uuid": "e7fb7f93509d34f387b4deafdd93c44b08e3e62f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import words\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = train[['comment_text']], train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4f72a56a-6208-45c3-821f-43170bf0126d",
    "_uuid": "b7482c19219918b3a99f20c1ed2d6ffee9e264ba"
   },
   "source": [
    "# The Vectorizer\n",
    "We'll then instantiate a count vectorizer and create a matrix of all the tokens contained in each comment. The matrix will exclude all English stop words and vectorize only valid English words. This will have some consequences:\n",
    "\n",
    "* Our algorithm will be optimized for English (other languages will be ignored)\n",
    "* Our algorithm will not take into account purposefully misspelled obscenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "85a52c7d-5988-4edd-b053-6235bc114891",
    "_uuid": "d847fa3b10d91dd84ad1e765c21ce421dbdbfa63",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english',\\\n",
    "                             lowercase = True,\\\n",
    "                             max_df = 0.95,\\\n",
    "                             min_df = 0.05,\\\n",
    "                             vocabulary = set(words.words()))\n",
    "\n",
    "vectorized_text = vectorizer.fit_transform(X_train.comment_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cffb6caf-0df8-4d30-91f3-774601756d27",
    "_uuid": "3a3b07f2e8db6ff94f1fd7983f7782a6fc68b9c4"
   },
   "source": [
    "We'll now use our vectorized matrix and run TFIDF on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8deef4b3-67b7-4b00-b4de-5863f21af2f3",
    "_uuid": "30d4310c2f68267df32ae5cc14309821f8cbf8db",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(float(n_samples) / df) + 1.0\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer(smooth_idf = False)\n",
    "tfidf = transformer.fit_transform(vectorized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "44a3a9b2-6245-48ec-92ae-d865979df70d",
    "_uuid": "6d06d6f8da0854d3e0daa2753ecfe3541f2d090f"
   },
   "source": [
    "Here comes the interesting part, we'll use the weighted matrix terms to select the 200 best predictors of toxic comments. We can expect that those would be quite obscene terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b058239a-5708-4355-89be-17a8811995da",
    "_uuid": "4a4587cdad59a5337806836a340cb56aa32bd8b8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "ch2 = SelectKBest(chi2, k = 200)\n",
    "best_features = ch2.fit_transform(tfidf, y_train.toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e68bf98-d791-41f9-89a2-b7ff76e0e8bc",
    "_uuid": "92ce083756499e250b19a1f81999e721e03273a5"
   },
   "source": [
    "Fair warning, the next code snippet wil display the distilled essence of online hatred. Scroll further only if you can stomach it... [Otherwise, jump directly to the next section.](#The-Analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "5a538198-bd42-4580-93aa-a78b6107e911",
    "_uuid": "61adaf0e854dd5c15df107a97a052dc252056620",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['add', 'anal', 'anus', 'arrogant', 'arse', 'article', 'ass', 'bag', 'ban', 'basement', 'bastard', 'bet', 'big', 'bitch', 'blah', 'block', 'bloody', 'blow', 'bout', 'boy', 'bully', 'bunch', 'burn', 'butt', 'cancer', 'chink', 'choke', 'chump', 'cock', 'commie', 'consensus', 'content', 'continue', 'cougar', 'coward', 'crap', 'crazy', 'cum', 'damn', 'dare', 'deletion', 'dick', 'die', 'dirty', 'discussion', 'disgrace', 'disgusting', 'dog', 'donkey', 'dont', 'douche', 'dude', 'dumb', 'dumbhead', 'eat', 'face', 'fag', 'fascist', 'fat', 'feces', 'filthy', 'fool', 'freak', 'fu', 'garbage', 'gay', 'geek', 'god', 'grow', 'ha', 'hairy', 'hate', 'hater', 'head', 'hell', 'help', 'hey', 'hoe', 'hole', 'homo', 'homosexual', 'hypocrite', 'idiot', 'idiotic', 'ignorant', 'ill', 'image', 'imbecile', 'impotent', 'information', 'ing', 'issue', 'jackass', 'jerk', 'kick', 'kike', 'kill', 'kiss', 'lame', 'liar', 'lick', 'licker', 'licking', 'life', 'link', 'links', 'list', 'listen', 'little', 'looser', 'loser', 'lover', 'maggot', 'man', 'masturbate', 'moron', 'moronic', 'mother', 'mouth', 'mum', 'new', 'nigger', 'note', 'oh', 'page', 'pansy', 'pants', 'pathetic', 'pee', 'penis', 'pervert', 'piece', 'pig', 'piss', 'pompous', 'poop', 'pretentious', 'prick', 'prostitute', 'punch', 'punk', 'pussy', 'queer', 'quit', 'racist', 'rape', 'raping', 'rapist', 'redirect', 'removed', 'retard', 'retarded', 'rot', 'sack', 'sad', 'screw', 'scum', 'section', 'seriously', 'sex', 'shoot', 'shove', 'shut', 'sick', 'sissy', 'sit', 'slut', 'smelly', 'son', 'source', 'spastic', 'speedy', 'stop', 'stupid', 'stupidity', 'suck', 'sucker', 'sucking', 'swallow', 'tag', 'talk', 'template', 'thank', 'thanks', 'trash', 'troll', 'turd', 'twat', 'ugly', 'ur', 'use', 'used', 'useless', 'vagina', 'welcome', 'whore', 'worm', 'worthless', 'ya', 'yo']\n"
     ]
    }
   ],
   "source": [
    "filth = [feature for feature, mask in\\\n",
    "         zip(vectorizer.get_feature_names(), ch2.get_support())\\\n",
    "         if mask == True]\n",
    "\n",
    "print(filth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca213432-de35-48e8-b15b-99c0aa1a9b56",
    "_uuid": "20b33a44430fe23b85c3b37e80ef771b8c45b4d7"
   },
   "source": [
    "# The Analyzer\n",
    "We'll now build a new count vectorizer. We'll call it analyzer (analogous to 2 polarizing glasses) and it will vectorize again our input by only counting the predictive obscenities from above. This will give us a new matrix of n features, where n is the number of predictive words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b50bcd4c-ac70-40f1-933a-5227b2731d16",
    "_uuid": "f68d027909a2e3b8c55f6793cb209741e56d7c73",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer = CountVectorizer(lowercase = True,\\\n",
    "                             vocabulary = filth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f85fc2a-8f03-44c7-8b67-de3b2b0edfb0",
    "_uuid": "048d0ccde5c39f5f1677aa1e70e43865bfbc647f"
   },
   "source": [
    "Now, let's define a function that vectorizes comment texts and weighs the vectors using the already trained TFIDF transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "1783839d-acfd-4bb9-a535-34b179891d16",
    "_uuid": "40a14b799377790f059eab576ae6bab9c0241186",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(frame):\n",
    "    result = pd.DataFrame(\\\n",
    "                transformer.fit_transform(\\\n",
    "                analyzer.fit_transform(\\\n",
    "                frame.comment_text)\\\n",
    "                                         ).todense(),\\\n",
    "                                            index = frame.index)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "24923534-620c-449d-aa17-42e5dd112414",
    "_uuid": "39f705ac0d91ca14fd1b50a9702c7300d69de202"
   },
   "source": [
    "We'll also define a dictionary which will contain our input train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "1a6197c2-a193-414e-954a-a0bc5cad3014",
    "_uuid": "4e974fc8abdef35359536a122028efdaec83b2a2",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 86265 entries, 84226 to 15795\n",
      "Columns: 200 entries, 0 to 199\n",
      "dtypes: float64(200)\n",
      "memory usage: 132.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(float(n_samples) / df) + 1.0\n"
     ]
    }
   ],
   "source": [
    "feature_frames = {}\n",
    "\n",
    "for frame in ('train', 'test'):\n",
    "    feature_frames[frame] = get_features(eval('X_%s' % frame))\n",
    "\n",
    "feature_frames['train'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "158f462d-f5cc-4976-952f-775f6a897709",
    "_uuid": "433a6379306a8c6f89258804f9dbb41e0f986c8b"
   },
   "source": [
    "# Training\n",
    "We can now train our algorithm of choice using the feature frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "7bece7e7-ed06-4d34-9183-69dd44557ab5",
    "_uuid": "b2a19f43dcfbf75c9fa1c9d2bd2dffca624a5468",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors = 10)\n",
    "knc.fit(feature_frames['train'], y_train.toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aacd3ee7-bb94-41c9-8a17-784196858bc0",
    "_uuid": "089ad6b76bbc7faf24d0dabc347b58de1254cc14"
   },
   "source": [
    "# Log Loss and Conclusion\n",
    "Finally, we assess our log loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "139ef0e9-e328-4461-87dd-7448faa7d74b",
    "_uuid": "08800dd660c75d6d9cd5ba768310cf5430d809ad",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943145538092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "result = pd.DataFrame(knc.predict_proba(feature_frames['test']), index = feature_frames['test'].index)\n",
    "\n",
    "result['actual'] = y_test.toxic\n",
    "result['text'] = X_test.comment_text\n",
    "\n",
    "print(log_loss(y_test.toxic, result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33c40ec7-0fe0-4107-8b63-3ab0db89a541",
    "_uuid": "10815c95b5e49e6c61ba922a3dfc8d1186abf414"
   },
   "source": [
    "And here are some examples of predictions and their corresponding comments (again, viewer discretion is advised):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "a8259dfb-5a79-4f34-b431-9da616c67e79",
    "_uuid": "81e175ddd986729fb9ec2aa7be11729a415206f6",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>actual</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51076</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\n\\nSmash Lab, Part II\\nYou really are a piece of work.  This is not what \"\"some people in chat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45407</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, all you have to do is stop being such a bitch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64130</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>FUCK YOU, YOU FUCKING DIRTY KIKE. YOU SUPPORT THOSE WHO VANDALIZE PAGES, NOW IT IS TURNED ON YOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94993</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I have a valid reason, stop being a bitch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\nHe is a washout.  Do you have any facts to prove that he is not a washout?  Fine, in AR 635-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48529</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>you are gay gay gay gay gay gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\nI haven't the slightest idea of what you talking about. But you probably need to screw myself...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30274</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>Tool Box\\nFuck you piece of shit. You think your in control, fucking faggot? You think you can h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18387</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>new name \\n\\nPerezhilton has changed his name to dick sucker.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72992</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>hello \\n\\nwill you suck my dick for $5? please reply</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1  actual  \\\n",
       "51076  0.7       1   \n",
       "45407  1.0       1   \n",
       "64130  0.7       1   \n",
       "94993  1.0       1   \n",
       "10540  0.6       1   \n",
       "48529  0.8       1   \n",
       "28729  0.6       1   \n",
       "30274  0.7       1   \n",
       "18387  0.9       1   \n",
       "72992  1.0       1   \n",
       "\n",
       "                                                                                                      text  \n",
       "51076  \"\\n\\nSmash Lab, Part II\\nYou really are a piece of work.  This is not what \"\"some people in chat...  \n",
       "45407                                                 Yeah, all you have to do is stop being such a bitch.  \n",
       "64130     FUCK YOU, YOU FUCKING DIRTY KIKE. YOU SUPPORT THOSE WHO VANDALIZE PAGES, NOW IT IS TURNED ON YOU  \n",
       "94993                                                           I have a valid reason, stop being a bitch.  \n",
       "10540  \"\\nHe is a washout.  Do you have any facts to prove that he is not a washout?  Fine, in AR 635-2...  \n",
       "48529                                                                      you are gay gay gay gay gay gay  \n",
       "28729  \"\\nI haven't the slightest idea of what you talking about. But you probably need to screw myself...  \n",
       "30274  Tool Box\\nFuck you piece of shit. You think your in control, fucking faggot? You think you can h...  \n",
       "18387                                        new name \\n\\nPerezhilton has changed his name to dick sucker.  \n",
       "72992                                                 hello \\n\\nwill you suck my dick for $5? please reply  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 100)\n",
    "result[[1, 'actual', 'text']][(result.actual == 1) & (result[1] > 0.5)][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b422850a-5387-4092-8f11-ab6f70cd4b30",
    "_uuid": "c5a1609800b7c0a014bce7fae35da6f6384375ab"
   },
   "source": [
    "Afterword:\n",
    "\n",
    "* In a live system such a model should use additional matching criteria for pursposefully misspelled obscenities (e.g. 'id10t' instead of 'idiot')\n",
    "* The model could be improved by using ngrams \n",
    "* The model could be improved by using an ensemble of models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
