{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear para maximizar o crescimento da banca de estratégia de apostas com Pytorch\n",
    "\n",
    "Nesse notebook irei demonostrar como aplicar, a partir de vários inputs, a regressão para definir quando e quanto apostar afim de maximar o crescimento da banca de apostas (bankroll),que é isso que queremos, ter o máximo de dinheiro no menor tempo possível.\n",
    "\n",
    "Um modelo linear é o mais simples que podemos criar, entretanto para definição estratégia de apostas ainda não encontrei um modelo mais eficiente. O Pytorch permite criar modelos mais complexos expandindo o modelo linear aqui proposto.\n",
    "\n",
    "A classe [linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) é forma mais simples e popular de fazer uma regressão linear em Python, mas aqui vamos utilizar o Pytorch, pois esse último permite com facilidade a definção de uma **Função Custo Personalizada (Custom Loss Function)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, nosso dataset possui os inputs rolutados  de \"A\" a \"P\", os quais podem ser quaisquer estatísiticas do esporte que podem inlufuenciar no desfecho da apostas como:\n",
    "\n",
    "\n",
    "**Para o futebol:**\n",
    "* gols;\n",
    "* chutes, \n",
    "* escanteios \n",
    "* minutos sem tomar gols\n",
    "\n",
    "\n",
    "**Para o tênis:**\n",
    "* aces;\n",
    "* duplas faltas;\n",
    "* quebras de serviço;\n",
    "\n",
    "\n",
    "**Para o beisebol:**\n",
    "* home runs;\n",
    "* rebatidas;\n",
    "\n",
    "\n",
    "Sejam somas ou médias das estatísticas de uma dado período de tempo. A determinação de qual estatística ou qual intervalo temporal é mais relevante para a definição da estratégia é um processo de tentativa e erro. Normalmente quanto mais melhor, mas há casos no quais menos variávies deixa o modelo mais eficiente.\n",
    "\n",
    "\n",
    "### PL\n",
    "PL é a variável dependente, é o que vamos modelar, é o Y do modelo onde os inputs são os Xs.\n",
    "\n",
    "A sigla PL pode ser Profit-Loss ou Perda-Lucro, tanto em português quanto em inglês faz sentido. PL é o retorno líquido da aposta, quanto ganhamos ou perdemos em dada aposta resolvida. Numa aposta de odds 1.95, se ganhamos -> <span style=\"color:green\">PL=0.95</span>,  se perdemos -> <span style=\"color:red\">PL=-1.00</span>\n",
    "\n",
    "Veja abaixo está nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>PL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.800</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.975</td>\n",
       "      <td>1.825</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355368</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.775</td>\n",
       "      <td>2.025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355369</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355370</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355371</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1.950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355372</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.825</td>\n",
       "      <td>1.975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355373 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A  B   C   D  E  F   G  H  I     J      K      L  M  N  O  P    PL\n",
       "0       0  2  55  16  0  2   5  4  0  1.75  1.800  2.000  0  0  0  1 -0.50\n",
       "1       2  4  28  11  0  0   6  5  0  1.50  1.900  1.900  0  0  1  0 -1.00\n",
       "2       3  9  52   6  1  5   2  0  0  1.25  1.975  1.825  0  1  0  0 -1.00\n",
       "3       1  8  34   9  1  8   0  3  0  1.50  1.750  2.050  0  0  1  0 -1.00\n",
       "4       0  2  66   6  0  2  10  4  0  1.25  1.950  1.850  0  1  0  0 -1.00\n",
       "...    .. ..  ..  .. .. ..  .. .. ..   ...    ...    ... .. .. .. ..   ...\n",
       "355368  0  7  80   8  0  3  10  4  0  1.75  1.775  2.025  0  0  0  1 -0.50\n",
       "355369  0  3  60  11  0  1   6  3  0  2.00  1.900  1.900  1  0  0  0 -1.00\n",
       "355370  2  4  51   8  2  0  11  4  0  1.50  1.950  1.850  0  0  1  0  0.95\n",
       "355371  2  3  39  16  0  3   9  0  0  1.50  1.900  1.950  0  0  1  0  0.90\n",
       "355372  0  2  98  11  0  0  20  5  0  1.50  1.825  1.975  0  0  1  0 -1.00\n",
       "\n",
       "[355373 rows x 17 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "\n",
    "df=pd.read_csv('/kaggle/input/exemplo-regresso-apostas/under.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é natural, por se tratar de apostas, na média as casas de aposta levam vantagem sobre os apostadores. Se apostarmos sem qualquer critério, na média, teremos prejuízo mensurado pela média do PL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PL médio: -2.28 %\n"
     ]
    }
   ],
   "source": [
    "print('PL médio:',round(df.PL.mean()*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo, se apostarmos sem qualquer critério nosso prejuízo será de 2.28% por aposta, mas através da regressão podemo selecionar apenas as apostas que nos fornecerão PL médio positivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "É desejável, mas não indispensável, que os inputs estejam transformados em escala de ** 0 a 1**. Testei com e sem, e a transformação a melhorou eficácia e lucratividade do modelo. Portanto, abaixo vamos selecionar as colunas dos inputs e transforma-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>PL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.179402</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.164491</td>\n",
       "      <td>0.216710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.089701</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.190601</td>\n",
       "      <td>0.190601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.169435</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.210183</td>\n",
       "      <td>0.171018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.109635</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.151436</td>\n",
       "      <td>0.229765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.215947</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.177546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355368</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.262458</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.157963</td>\n",
       "      <td>0.223238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355369</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.196013</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.190601</td>\n",
       "      <td>0.190601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355370</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166113</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.177546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355371</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.126246</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.190601</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355372</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.322259</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.171018</td>\n",
       "      <td>0.210183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355373 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C         D         E         F         G  \\\n",
       "0       0.000  0.071429  0.179402  0.205128  0.000000  0.117647  0.037313   \n",
       "1       0.250  0.142857  0.089701  0.141026  0.000000  0.000000  0.044776   \n",
       "2       0.375  0.321429  0.169435  0.076923  0.142857  0.294118  0.014925   \n",
       "3       0.125  0.285714  0.109635  0.115385  0.142857  0.470588  0.000000   \n",
       "4       0.000  0.071429  0.215947  0.076923  0.000000  0.117647  0.074627   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "355368  0.000  0.250000  0.262458  0.102564  0.000000  0.176471  0.074627   \n",
       "355369  0.000  0.107143  0.196013  0.141026  0.000000  0.058824  0.044776   \n",
       "355370  0.250  0.142857  0.166113  0.102564  0.285714  0.000000  0.082090   \n",
       "355371  0.250  0.107143  0.126246  0.205128  0.000000  0.176471  0.067164   \n",
       "355372  0.000  0.071429  0.322259  0.141026  0.000000  0.000000  0.149254   \n",
       "\n",
       "               H    I         J         K         L    M    N    O    P    PL  \n",
       "0       0.060606  0.0  0.272727  0.164491  0.216710  0.0  0.0  0.0  1.0 -0.50  \n",
       "1       0.075758  0.0  0.227273  0.190601  0.190601  0.0  0.0  1.0  0.0 -1.00  \n",
       "2       0.000000  0.0  0.181818  0.210183  0.171018  0.0  1.0  0.0  0.0 -1.00  \n",
       "3       0.045455  0.0  0.227273  0.151436  0.229765  0.0  0.0  1.0  0.0 -1.00  \n",
       "4       0.060606  0.0  0.181818  0.203655  0.177546  0.0  1.0  0.0  0.0 -1.00  \n",
       "...          ...  ...       ...       ...       ...  ...  ...  ...  ...   ...  \n",
       "355368  0.060606  0.0  0.272727  0.157963  0.223238  0.0  0.0  0.0  1.0 -0.50  \n",
       "355369  0.045455  0.0  0.318182  0.190601  0.190601  1.0  0.0  0.0  0.0 -1.00  \n",
       "355370  0.060606  0.0  0.227273  0.203655  0.177546  0.0  0.0  1.0  0.0  0.95  \n",
       "355371  0.000000  0.0  0.227273  0.190601  0.203655  0.0  0.0  1.0  0.0  0.90  \n",
       "355372  0.075758  0.0  0.227273  0.171018  0.210183  0.0  0.0  1.0  0.0 -1.00  \n",
       "\n",
       "[355373 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Essa construção faz sentido se você for reprimir alguma coluna de input\n",
    "colunas='A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P'.split(',')\n",
    "df=df[colunas+['PL']] \n",
    "\n",
    "#Defina defini a escala a partir dos dados e faz a trasnformação dos inputs, mas não do PL\n",
    "escala=MinMaxScaler().fit(df[colunas])\n",
    "df[colunas]=escala.transform(df[colunas])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir a divisão do nosso dataframe entre 80% treinamento e 20% teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: 284298 rows\n",
      "df_test : 71074 rows\n"
     ]
    }
   ],
   "source": [
    "df_train=df[:int(len(df)*0.8)]\n",
    "df_test=df[-int(len(df)*0.2):]\n",
    "\n",
    "print('df_train:', len(df_train), 'rows')\n",
    "print('df_test :', len(df_test), 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos a biblioteca do Pytroch e criamos dois [Tensors](https://pytorch.org/docs/stable/tensors.html), um para o PL e outro para os INPUTs do dataframe de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUTS:  tensor([[0.0000, 0.0714, 0.1794,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.2500, 0.1429, 0.0897,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.3750, 0.3214, 0.1694,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.1250, 0.2857, 0.1229,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0357, 0.2625,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.1296,  ..., 1.0000, 0.0000, 0.0000]])\n",
      "PL:  tensor([[-0.5000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        ...,\n",
      "        [-1.0000],\n",
      "        [ 0.4375],\n",
      "        [-1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "INPUTS=torch.from_numpy(df_train[colunas].values).float()\n",
    "PL=torch.from_numpy(df_train[['PL']].values).float()\n",
    "\n",
    "print('INPUTS: ',INPUTS)\n",
    "print('PL: ',PL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, a definição do modelo linear com tantas entradas quantos campos de inputs e 1 saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=16, out_features=1, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODELO=torch.nn.Linear(INPUTS.shape[1], 1)\n",
    "\n",
    "MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar nosso MODELO para prever o PL médio da aposta baseado nos inputs. \n",
    "\n",
    "Para tanto, será utilizado, como função custo, a [MSELoss](https://pytorch.org/docs/stable/nn.html#mseloss) que a fim de reduzir o quadrado da diferença entre PL_pred (previsto) e o PL (real). (PL_pred-PL)<sup>2</sup>\n",
    "\n",
    "O algoritmo de otimização será o [Adam](https://pytorch.org/docs/stable/optim.html#algorithms) (que se mostrou superior a outros testados), com taxa de aprendizado 0.1 ( a faixa mais se mostrou eficiente foi em 0.01 e 1.0 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função Custo: MSELoss()\n",
      "Otimizador: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.1\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loss_func = torch.nn.MSELoss()\n",
    "otimizador = torch.optim.Adam(MODELO.parameters(), lr = 0.1) \n",
    "print('Função Custo:',loss_func)\n",
    "print('Otimizador:',otimizador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos para otimização propriamente dita. Criamos um loop for e para cada passada, mais reduzimos nossa função custo e por conseguinte, mais o PL_pred estará próximo do PL real.\n",
    "\n",
    "O número de passadas (epochs) vai depender da quantidade de inputs e taxa de aprendizado, acompanhamos decaimento da função custo para escolher quando parar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list=[]\n",
    "for _ in range(100):\n",
    "    PL_pred=MODELO( INPUTS )        #calcula  PL_pred usando o modelo \n",
    "    loss=loss_func(PL_pred, PL)     #calcula o erro médio da estimativa do PL_pred \n",
    "    \n",
    "    otimizador.zero_grad() #limpa gradientes antigos\n",
    "    loss.backward()       #calcula a derivada do loss, através do retropropação\n",
    "    otimizador.step()     #faz com que o otimizador dê um passo com base nos gradientes dos parâmetros. \n",
    "    \n",
    "    loss_list+=[loss.item()] #acumula o valor para análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando evolução da função custo vemos que com 100 passadas já não apresenta substancial melhoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso nosso modelo linear esteja bem treinado e com capactidade preditiva, a média do PL das apostas cujo o PL_pred é positivo também será positivo. Ou seja,caso apostarmos apenas em apostas cujo PL_pred>0 teremo lucro a longo prazo.\n",
    "\n",
    "Vamos verificar lucratividade da estratégia no dataframe de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PL_medio_test: 3.07 %\n"
     ]
    }
   ],
   "source": [
    "INPUTS_test=torch.from_numpy(df_test[colunas].values).float()  #Transforma em tensor o inputs de testes\n",
    "PL_pred=MODELO(INPUTS_test).detach().numpy()  #Calcula os PL previstos para cada input de testes\n",
    "\n",
    "#Calcula a média do PL reais das apostas cujo o PL previsto é positivo, ou seja lucrativas.\n",
    "PL_medio_test=np.mean([pl for pl_pred,pl in zip(PL_pred, df_test.PL.values ) if pl_pred[0]>0])\n",
    "\n",
    "print('PL_medio_test:',round(PL_medio_test*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tivessemos seguido o critério de só apostar quando o PL_pred>0 teríamos o lucro acima contra o prejuízo de -2.28% por aposta sem qualquer critério. 😃\n",
    "\n",
    "É de se esperar que, quanto maior for o critério de corte para apostar maior será a lucratividade média também. \n",
    "\n",
    "Abaixo está plotado no eixo X os cortes e o no Y o PL médio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cortes=[i*0.01 for i in range(10)]\n",
    "pl_medios=[np.mean([pl for pl_pred,pl in zip(PL_pred, df_test.PL.values ) if pl_pred[0]>i*0.01]) for i in range(10) ]\n",
    "\n",
    "plt.plot(cortes, pl_medios)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximização do Crescimento da Banca\n",
    "\n",
    "Acima definimos um critério de quando apostar, mas quanto apostar em cada seleção ? Podemos investir um valor fixo cada aposta, mas nossa banca crescerá linearmente. Se investirmos um percentual da banca em cada aposta nossa banca crescerá de forma exponencial.\n",
    "\n",
    "Vamos através da regressão definir o percentual da banca ótimo a fim de maximizar o crescimento.\n",
    "\n",
    "\n",
    "Contiuamos com o mesmo modelo linear, mas vamos treiná-lo usando uma função de custo personalizada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.loss_somalog(P_pred, PL)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Otimiza para maximizar o crescimento da banca    \n",
    "def loss_somalog(P_pred,PL):\n",
    "    return -torch.log(1+PL*P_pred.relu()).sum()\n",
    "\n",
    "loss_somalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P_pred** é percentual ótimo da banca previsto a fim de maximar o crecimento da banca\n",
    "\n",
    "Se **P_pred<0** então **P_pred.relu()** será 0, ou seja, nada será apostado\n",
    "\n",
    "PL é pl ocorrido da aposta\n",
    "\n",
    "O sinal negativo se faz necessário, pois, por padrão,o otimizador procura minimizar a função custo ao passo que, necessitamos maximizar o soma do log do crescimento da banca.\n",
    "\n",
    "\n",
    "\n",
    "O otimizador será igual o anterior, mas com taxa de aprendizagem bem menor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mesmo otimizador, mas com taxa de aprendizagem menor\n",
    "otimizador = torch.optim.Adam(MODELO.parameters(), lr = 0.001) \n",
    "\n",
    "otimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos para otimização, como a taxa de aprendizado é menor será necessário mais passadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_list=[]\n",
    "for _ in range(2000):\n",
    "    P_pred=MODELO( INPUTS )         #P_pred (percentual ótimo da banca ) usando o modelo \n",
    "    loss=loss_somalog(P_pred, PL)     #loss (quanto menor maior o lucro) dado P_pred \n",
    "    \n",
    "    otimizador.zero_grad() #limpa gradientes antigos\n",
    "    loss.backward()       #calcula a derivada do loss, através do retropropação\n",
    "    otimizador.step()     #faz com que o otimizador dê um passo com base nos gradientes dos parâmetros. \n",
    "    \n",
    "    loss_list+=[loss.item()] #acumula o valor para análise\n",
    "    \n",
    "\n",
    "#Plota o gráfico da evolução do loss\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor  da função custo próximo a -150, como a cima, significa se fossem realizadas todas apostas com o percentual ótimo da banca calculado pelo MODELO, no conjunto de treinamento, teríamos na teoria, nossa banca multiplicada por exp(150) \n",
    "\n",
    "exp(150)=139370958066638000000000000000000000000000000000000000000000000000 😱\n",
    "\n",
    "Vamos agora testar a lucratividade dos dados de treinamento, que o que importa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log do Crescimento da Banca do Cojunto de Teste: [32.835896]\n"
     ]
    }
   ],
   "source": [
    "P_pred=MODELO(INPUTS_test).detach().numpy()\n",
    "\n",
    "somalog=sum(np.log(1+pl*p_pred ) for p_pred,pl in zip(P_pred, df_test.PL.values) if p_pred>0)\n",
    "\n",
    "print('Log do Crescimento da Banca do Cojunto de Teste:', somalog )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na teoria também, se tivessemos realizadas todas as apostas com o percentual ótimo definido pelo MODELO com nossos dados de teste, teríamos nossa banca multiplicada por exp(32), quase 79 trilhões (coisa pouca né).\n",
    "\n",
    "O valor absoluto da somalog não importa tanto, mas sim, a evolução desse número dada a melhoria no modelo.\n",
    "\n",
    "\n",
    "Por fim, vamos ver a equação do modelo linear, que será como usaremos na prática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENT_BANCA=\n",
      "-0.00958 * A +\n",
      "-0.00971 * B +\n",
      "-0.00061 * C +\n",
      "-0.00878 * D +\n",
      "-0.06208 * E +\n",
      "-0.00266 * F +\n",
      "-0.0011 * G +\n",
      "-0.00285 * H +\n",
      "0.01239 * I +\n",
      "0.17904 * J +\n",
      "0.03263 * K +\n",
      "-0.13409 * L +\n",
      "0.00795 * M +\n",
      "0.01584 * N +\n",
      "-0.00075 * O +\n",
      "-0.01164 * P +\n",
      "0.1196\n"
     ]
    }
   ],
   "source": [
    "parms=[parm.data.numpy() for parm in MODELO.parameters()][0][0]\n",
    "inter=[parm.data.numpy() for parm in MODELO.parameters()][1][0]\n",
    "\n",
    "print('PERCENT_BANCA=')\n",
    "for p,c in zip(parms/(escala.data_max_-escala.data_min_), colunas):\n",
    "    print(round(p,5),'*',c,'+')\n",
    "    \n",
    "print(round(sum(-parms*escala.data_min_/(escala.data_max_-escala.data_min_))+inter,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa equação já está com a transformação inversa de escala, pronta para ser usada.\n",
    "\n",
    "Conhecidos os parametros de \"A\" a \"P\", teremos o percentual ótimo da banca para apostar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
