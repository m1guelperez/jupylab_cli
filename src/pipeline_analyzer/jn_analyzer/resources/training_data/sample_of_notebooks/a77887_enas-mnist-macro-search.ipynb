{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# https://www.kaggle.com/shihabshahriar/cifar-10-using-pytorch-1-0/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD,Adam,lr_scheduler\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from torchvision import transforms,models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10-batches-py/\r\n",
      "cifar-10-batches-py/data_batch_4\r\n",
      "cifar-10-batches-py/readme.html\r\n",
      "cifar-10-batches-py/test_batch\r\n",
      "cifar-10-batches-py/data_batch_3\r\n",
      "cifar-10-batches-py/batches.meta\r\n",
      "cifar-10-batches-py/data_batch_2\r\n",
      "cifar-10-batches-py/data_batch_5\r\n",
      "cifar-10-batches-py/data_batch_1\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zxvf ../input/cifar10-python/cifar-10-python.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "img_size = 28 #224\n",
    "trainset_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "#     transforms.RandomHorizontalFlip(p=.40),\n",
    "#     transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "traindata = torchvision.datasets.CIFAR10(root='.', train=True,download=False, transform=train_transform)\n",
    "\n",
    "trainset,valset = random_split(traindata,[trainset_size,50000-trainset_size])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='.', train=False,download=False, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "a = next(iter(trainloader))\n",
    "print(a[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "imshow(a[0][0])\n",
    "print(classes[a[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import networkx as nx\n",
    "\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available() :\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, the decision of what computation operation to use sets a particular layer into convolution or average pooling or max pooing.\n",
    "\n",
    "The 6 operations available for the controller are:\n",
    "\n",
    "convolutions with filter sizes 3 × 3 and 5 × 5,\n",
    "\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "depthwise-separable convolutions with filter sizes 3×3 and 5×5 (Chollet, 2017), \n",
    "\n",
    "class depthwise_separable_conv(nn.Module):\n",
    "\n",
    "    def __init__(self, nin, kernels_per_layer, nout):\n",
    "    \n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        \n",
    "        self.depthwise = nn.Conv2d(nin, nin * kernels_per_layer, kernel_size=3, padding=1, groups=nin)\n",
    "        \n",
    "        self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        out = self.depthwise(x)\n",
    "        \n",
    "        out = self.pointwise(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "and max pooling and average pooling of kernel size 3 × 3:\n",
    "\n",
    "torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "\n",
    "torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_pool_layer(ksize):\n",
    "    return nn.MaxPool2d(ksize).apply(weights_init)\n",
    "\n",
    "\n",
    "def get_avg_pool_layer(ksize):\n",
    "    return nn.AvgPool2d(ksize).apply(weights_init)\n",
    "\n",
    "def get_conv_layer(in_lyr,out_lyr,ksize):\n",
    "    seq_layer = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_lyr, out_lyr, ksize),\n",
    "            nn.BatchNorm2d(out_lyr),\n",
    "    )\n",
    "    return seq_layer.apply(weights_init)\n",
    "\n",
    "class depthwise_separable_conv(nn.Module):\n",
    "    def __init__(self, nin, kernels_per_layer, nout):\n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin * kernels_per_layer, kernel_size=3, padding=1, groups=nin).apply(weights_init)\n",
    "        self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1).apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "def get_sep_layer(in_lyr,out_lyr,ksize):\n",
    "    return depthwise_separable_conv(in_lyr,ksize,out_lyr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Conv 3\n",
    "# 2. Conv 5\n",
    "# 3. Sep 3\n",
    "# 4. Sep 5\n",
    "# 5. MaxPool\n",
    "# 6. AvgPool\n",
    "\n",
    "out_features_shape = [10,24,32,64,128]\n",
    "output_size = 10\n",
    "num_actvn_fns = 6\n",
    "\n",
    "def get_new_layer(actvn,x):\n",
    "    ofsindex = 1\n",
    "    actvn = actvn -1\n",
    "#     print(\"Actvn -- \"+str(actvn))\n",
    "    \n",
    "    out_features_shape[ofsindex] = x.shape[1]\n",
    "    \n",
    "    if actvn == 0:\n",
    "        return get_conv_layer(x.shape[1],out_features_shape[ofsindex],3).to(device)\n",
    "    if actvn == 1:\n",
    "        return get_conv_layer(x.shape[1],out_features_shape[ofsindex],5).to(device)\n",
    "    if actvn == 2:\n",
    "        return get_sep_layer(x.shape[1],out_features_shape[ofsindex],3).to(device)\n",
    "    if actvn == 3:\n",
    "        return get_sep_layer(x.shape[1],out_features_shape[ofsindex],5).to(device)\n",
    "    if actvn == 4:\n",
    "        return get_max_pool_layer(3).to(device)\n",
    "    if actvn == 5:\n",
    "        return get_avg_pool_layer(3).to(device)\n",
    "    return get_avg_pool_layer(3).to(device)\n",
    "\n",
    "def get_out_layer(size):\n",
    "    nlayer = nn.Sequential(\n",
    "            nn.Linear(in_features=size[1]*size[2]*size[3], out_features=10),\n",
    "            nn.LogSoftmax(),\n",
    "        )\n",
    "    return nlayer.apply(weights_init).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatzeroes(max_height,max_width,b):\n",
    "    dim = 2\n",
    "    pad_size_1 = int((max_height-b.shape[dim]) / 2)\n",
    "    pad_size_2 = (max_height-b.shape[dim]) - pad_size_1\n",
    "    b = F.pad(input=b, pad=(0, 0, pad_size_1, pad_size_2), mode='constant', value=0)\n",
    "\n",
    "    dim = 3\n",
    "    pad_size_1 = int((max_width-b.shape[dim]) / 2)\n",
    "    pad_size_2 = (max_width-b.shape[dim]) - pad_size_1\n",
    "    b = F.pad(input=b, pad=(pad_size_1, pad_size_2,0,0), mode='constant', value=0)\n",
    "    \n",
    "    return b\n",
    "\n",
    "def downsizetensors(max_height,max_width,b):\n",
    "    size = (max_height,max_width)\n",
    "    return F.interpolate(b, size=size, mode='bilinear', align_corners=False)\n",
    "\n",
    "def concatenate2(a,b,increase_size):\n",
    "    if(increase_size):\n",
    "        max_height = max(a.shape[2],b.shape[2])\n",
    "        max_width = max(a.shape[3],b.shape[3])\n",
    "        a = concatzeroes(max_height,max_width,a)\n",
    "        b = concatzeroes(max_height,max_width,b)\n",
    "        return torch.cat((a, b), 1)\n",
    "    else:\n",
    "        max_height = min(a.shape[2],b.shape[2])\n",
    "        max_width = min(a.shape[3],b.shape[3])\n",
    "        a = downsizetensors(max_height,max_width,a)\n",
    "        b = downsizetensors(max_height,max_width,b)\n",
    "        return torch.cat((a, b), 1)\n",
    "\n",
    "\n",
    "def concatenate3(a,b,c,increase_size):\n",
    "    if(increase_size):\n",
    "        max_height = max(a.shape[2],b.shape[2],c.shape[2])\n",
    "        max_width = max(a.shape[3],b.shape[3],c.shape[3])\n",
    "        a = concatzeroes(max_height,max_width,a)\n",
    "        b = concatzeroes(max_height,max_width,b)\n",
    "        c = concatzeroes(max_height,max_width,c)\n",
    "        return torch.cat((torch.cat((a, b), 1), c), 1)\n",
    "    else:\n",
    "        \n",
    "        max_height = min(a.shape[2],b.shape[2],c.shape[2])\n",
    "        max_width = min(a.shape[3],b.shape[3],c.shape[3])\n",
    "        a = downsizetensors(max_height,max_width,a)\n",
    "        b = downsizetensors(max_height,max_width,b)\n",
    "        c = downsizetensors(max_height,max_width,c)\n",
    "        return torch.cat((torch.cat((a, b), 1), c), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAG(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_layers):\n",
    "        super(DAG, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.myparameters = nn.ParameterList()\n",
    "        self.dag = {}\n",
    "        self.dag_calculated = {}\n",
    "        self.loose_ends = []\n",
    "        self.first_run = 0\n",
    "        self.config = \"0\"\n",
    "    def get_key(self,lnum):\n",
    "        nconfig = self.config[0:int(3 * (lnum-1) )+1]\n",
    "        key = \"\"\n",
    "        for c in nconfig:\n",
    "            key+=str(c)\n",
    "        return key\n",
    "\n",
    "    def initialize_param_grads(self):\n",
    "        for p in self.myparameters:\n",
    "            p.requires_grad = True\n",
    "#         for lnum in range(1,self.num_layers+1):\n",
    "# #             print(self.dag[get_key(lnum,config)])\n",
    "#             for p in nn.ParameterList(self.dag[get_key(lnum,config)].parameters()):\n",
    "#                 p.requires_grad = True\n",
    "#         out_layer_key = get_key(self.num_layers,config)+\"9\"\n",
    "#         for p in nn.ParameterList(self.dag[out_layer_key].parameters()):\n",
    "#             p.requires_grad = True\n",
    "        return\n",
    "\n",
    "        \n",
    "    #fac == forward acc to config\n",
    "    def fac(self,x):\n",
    "        self.loose_ends = []\n",
    "        for i in range(1,self.num_layers+1):\n",
    "            self.loose_ends.append(i)\n",
    "            \n",
    "        layer_activation = int(self.config[0])\n",
    "        key = self.get_key(1)\n",
    "        \n",
    "        if key not in self.dag.keys():\n",
    "            layer_t = get_new_layer(layer_activation,x)\n",
    "            self.myparameters += nn.ParameterList(layer_t.parameters())\n",
    "            self.dag[key] = layer_t\n",
    "            for p in nn.ParameterList(layer_t.parameters()):\n",
    "                p.requires_grad = True\n",
    "\n",
    "            \n",
    "        x = self.dag[key](x)\n",
    "        self.dag_calculated[key] = x\n",
    "#         print(x.shape)\n",
    "        \n",
    "        for lnum in range(2,self.num_layers+1):\n",
    "#             print(lnum)\n",
    "            key = self.get_key(lnum)\n",
    "            prev_layer_1 = int(self.config[3*(lnum-1)+1 -3])\n",
    "            prev_layer_2 = int(self.config[3*(lnum-1)+2 -3])\n",
    "            layer_activation = int(self.config[3*(lnum-1)])\n",
    "            \n",
    "            if prev_layer_1 > lnum or prev_layer_2 > lnum:\n",
    "                return None\n",
    "            \n",
    "            prev_layer_1_key = self.get_key(prev_layer_1)\n",
    "            prev_layer_2_key = self.get_key(prev_layer_2)\n",
    "            \n",
    "            \n",
    "            if key not in self.dag.keys():\n",
    "                layer_t = get_new_layer(layer_activation,x)\n",
    "                self.myparameters += nn.ParameterList(layer_t.parameters())\n",
    "                self.dag[key] = layer_t\n",
    "                for p in nn.ParameterList(layer_t.parameters()):\n",
    "                    p.requires_grad = True\n",
    "            x = self.dag[key](x)\n",
    "            if prev_layer_1_key != prev_layer_2_key:\n",
    "                x = concatenate3(self.dag_calculated[prev_layer_1_key],self.dag_calculated[prev_layer_2_key],x,0)\n",
    "            else:\n",
    "                x = concatenate2(self.dag_calculated[prev_layer_1_key],x,0)\n",
    "            self.dag_calculated[key] = x\n",
    "            \n",
    "            \n",
    "#             print(self.loose_ends)\n",
    "            if self.loose_ends!=None and prev_layer_1 in self.loose_ends:\n",
    "                self.loose_ends.remove(prev_layer_1)\n",
    "            if self.loose_ends!=None and prev_layer_2 in self.loose_ends:\n",
    "                self.loose_ends.remove(prev_layer_2)\n",
    "#             print(self.loose_ends)\n",
    "            \n",
    "        num_loose_ends = len(self.loose_ends)\n",
    "        if(num_loose_ends<=0):\n",
    "            return None\n",
    "        \n",
    "        out = self.dag_calculated[self.get_key(self.loose_ends[0])]\n",
    "        for i in range(1,num_loose_ends):\n",
    "            out = concatenate2(out,self.dag_calculated[self.get_key(self.loose_ends[i])],0)\n",
    "        \n",
    "        out_layer_key = self.get_key(self.num_layers)+\"9\"\n",
    "        if out_layer_key not in self.dag.keys():\n",
    "            layer_t= get_out_layer(out.shape)\n",
    "            self.dag[out_layer_key] = layer_t\n",
    "            self.myparameters += nn.ParameterList(layer_t.parameters())\n",
    "#         print(out.shape)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        self.dag_calculated[out_layer_key] = self.dag[out_layer_key](out)\n",
    "        return self.dag_calculated[out_layer_key]\n",
    "\n",
    "    def forward(self, x,config=None):\n",
    "        return self.fac(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 6\n",
    "dag_model = DAG(num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "# Initialize BCELoss function\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = None\n",
    "\n",
    "\n",
    "def model_train_loop(cnn_config):\n",
    "    dag_model.config = cnn_config\n",
    "    dag_model.initialize_param_grads()\n",
    "    for epoch in range(10):\n",
    "        # For each batch in the dataloader\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device),labels.to(device)\n",
    "            output = dag_model(images)\n",
    "            if i==0 and epoch==0:\n",
    "                optimizer = optim.Adam(dag_model.myparameters, lr=lr, betas=(0.5, 0.999))\n",
    "            dag_model.zero_grad()\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#         print(loss)\n",
    "#             if i%100==0:\n",
    "#                 print(((torch.sum(torch.argmax(output,1) == labels)).float()/labels.shape[0]).item())\n",
    "#     #             print(loss.item())\n",
    "        \n",
    "    return Variable(((torch.sum(torch.argmax(output,1) == labels)).float()/labels.shape[0]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6875, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train_loop([2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 4, 1, 4, 4, 5, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controller Part ToDo : \n",
    "1. Define LSTM that generates 3*num_nodes -2 integers in the expected ranges and create configurations.\n",
    "\n",
    "2. Write cost function and Back Propogation for the controller\n",
    "\n",
    "nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "\n",
    "https://stackoverflow.com/questions/48302810/whats-the-difference-between-hidden-and-output-in-pytorch-lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_num_epochs = 1\n",
    "controller_optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Controller(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(Controller, self).__init__()\n",
    "#         self.n_layers = 3\n",
    "#         self.generated_config = []\n",
    "#         self.policy_history = []\n",
    "\n",
    "#         self.lstm1 = nn.LSTM(num_actvn_fns, num_nodes ,self.n_layers).to(device)\n",
    "#         self.hidden1 = (torch.randn(self.n_layers, 1, num_nodes).to(device),torch.randn(self.n_layers, 1, num_nodes).to(device))\n",
    "#         self.prev_out1 = torch.randn(1,1,num_nodes).to(device)\n",
    "\n",
    "#         self.lstm2 = nn.LSTM(num_nodes, num_nodes ,self.n_layers).to(device)\n",
    "#         self.hidden2 = (torch.randn(self.n_layers, 1, num_nodes).to(device),torch.randn(self.n_layers, 1, num_nodes).to(device))\n",
    "#         self.prev_out2 = torch.randn(1, 1, num_nodes).to(device)\n",
    "        \n",
    "#         self.lstm3 = nn.LSTM(num_nodes, num_actvn_fns ,self.n_layers).to(device)\n",
    "#         self.hidden3 = (torch.randn(self.n_layers, 1, num_actvn_fns).to(device),torch.randn(self.n_layers, 1, num_actvn_fns).to(device))\n",
    "#         self.prev_out3 = torch.randn(1, 1, num_actvn_fns).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "#     def update_controller(self,rewards):\n",
    "#         self.zero_grad()\n",
    "#         rewards = torch.Tensor(rewards)\n",
    "#         loss = (torch.sum(torch.mul(torch.Tensor(self.policy_history), Variable(rewards,requires_grad=True)).mul(-1), -1))\n",
    "#         loss.backward(retain_graph=True)\n",
    "#         controller_optimizer.step()\n",
    "#         print(loss)\n",
    "#         return loss\n",
    "    \n",
    "#     def get_reward(self):\n",
    "#         lent = len(self.generated_config)\n",
    "#         lnum = int(lent/3) + 1\n",
    "#         rewards = [0]*lent\n",
    "#         if self.generated_config[lent-1] >= lnum :\n",
    "#             rewards[lent-1] = 1000\n",
    "#             self.update_controller(rewards)\n",
    "#             return 1\n",
    "# #         self.update_controller(rewards)\n",
    "#         return 0\n",
    "    \n",
    "    \n",
    "#     def forward(self):\n",
    "#         self.generated_config = []\n",
    "#         self.policy_history = []\n",
    "#         self.zero_grad()\n",
    "#         rewards = []\n",
    "#         for i in range(3*num_nodes-2):\n",
    "#             if i%3 ==0:\n",
    "#                 out, self.hidden1 = self.lstm1(self.prev_out3, self.hidden1)\n",
    "#                 out = F.sigmoid(out)\n",
    "#                 self.prev_out1 = out\n",
    "#                 probs = Categorical(out)\n",
    "#                 action = probs.sample()\n",
    "#                 self.policy_history.append(Variable(probs.log_prob(action),requires_grad=True))\n",
    "#                 self.generated_config.append(action.item())\n",
    "#             if i%3 ==1:\n",
    "#                 out, self.hidden2 = self.lstm2(self.prev_out1, self.hidden2)\n",
    "#                 out = F.sigmoid(out)\n",
    "#                 self.prev_out2 = out\n",
    "#                 probs = Categorical(out)\n",
    "#                 action = probs.sample()\n",
    "#                 self.policy_history.append(Variable(probs.log_prob(action),requires_grad=True))\n",
    "#                 self.generated_config.append(torch.argmax(out).item())\n",
    "#                 if self.get_reward():\n",
    "#                     return None\n",
    "#                 return\n",
    "#             if i%3 ==2:\n",
    "#                 out, self.hidden3 = self.lstm3(self.prev_out2, self.hidden3)\n",
    "#                 out = F.sigmoid(out)\n",
    "#                 self.prev_out3 = out\n",
    "#                 probs = Categorical(out)\n",
    "#                 action = probs.sample()\n",
    "#                 self.policy_history.append(Variable(probs.log_prob(action),requires_grad=True))\n",
    "#                 self.generated_config.append(torch.argmax(out).item())\n",
    "#                 if self.get_reward():\n",
    "#                     return None\n",
    "#         return self.generated_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Controller, self).__init__()\n",
    "        self.n_layers = 3\n",
    "        self.generated_config = []\n",
    "        self.policy_history = []\n",
    "\n",
    "        self.lstm = nn.LSTM(num_actvn_fns, num_nodes ,self.n_layers).to(device)\n",
    "        self.hidden = (torch.randn(self.n_layers, 1, num_nodes).to(device),torch.randn(self.n_layers, 1, num_nodes).to(device))\n",
    "        self.prev_out = torch.randn(1,1,num_nodes).to(device)\n",
    "\n",
    "    def update_controller(self,rewards):\n",
    "        self.zero_grad()\n",
    "        rewards = torch.Tensor(rewards)\n",
    "        loss = (torch.sum(torch.mul(torch.Tensor(self.policy_history), Variable(rewards,requires_grad=True)).mul(-1), -1))\n",
    "        loss.backward(retain_graph=True)\n",
    "        controller_optimizer.step()\n",
    "#         print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def get_reward(self):\n",
    "        lent = len(self.generated_config)\n",
    "        lnum = int(lent/3) + 1\n",
    "        rewards = [0]*lent\n",
    "        if (lent-1)%3 == 0:\n",
    "            if self.generated_config[lent-1] == 0 or self.generated_config[lent-1] > 6:\n",
    "                rewards[lent-1] = -1\n",
    "                self.update_controller(rewards)\n",
    "                return 1\n",
    "        if (lent-2)%3 == 0:\n",
    "            if self.generated_config[lent-1] == 0 or self.generated_config[lent-1] >= lnum:\n",
    "                rewards[lent-1] = -1\n",
    "                self.update_controller(rewards)\n",
    "                return 1\n",
    "        if (lent)%3 == 0:\n",
    "            if self.generated_config[lent-1] == 0 or self.generated_config[lent-1] >= lnum:\n",
    "                rewards[lent-1] = -1\n",
    "                self.update_controller(rewards)\n",
    "                return 1\n",
    "#         self.update_controller(rewards)\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        self.generated_config = []\n",
    "        self.policy_history = []\n",
    "        self.zero_grad()\n",
    "        rewards = []\n",
    "        for i in range(3*num_nodes-2):\n",
    "            out, self.hidden = self.lstm(self.prev_out, self.hidden)\n",
    "            out = F.sigmoid(out)\n",
    "            self.prev_out = out\n",
    "            probs = Categorical(out)\n",
    "            action = probs.sample()\n",
    "            self.policy_history.append(Variable(probs.log_prob(action),requires_grad=True))\n",
    "            self.generated_config.append(torch.argmax(out).item())\n",
    "            if self.get_reward():\n",
    "                return None\n",
    "        return self.generated_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "controller_model = Controller().to(device)\n",
    "controller_optimizer = optim.Adam(controller_model.parameters(), lr=0.1, betas=(0.5, 0.999))\n",
    "controller_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_num_epochs = 100000\n",
    "for controller_epoch in range(controller_num_epochs):\n",
    "    config = controller_model()\n",
    "    if config!=None:\n",
    "        print(config)\n",
    "        print(model_train_loop(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
