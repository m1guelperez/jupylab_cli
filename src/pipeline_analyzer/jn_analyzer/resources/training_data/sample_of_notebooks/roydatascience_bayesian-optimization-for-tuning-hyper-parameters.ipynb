{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of hyperparameter optimization in machine learning is to find the hyperparameters of a given machine learning algorithm that return the best performance as measured on a validation set. (Hyperparameters, in contrast to model parameters, are set by the machine learning engineer before training. The number of trees in a random forest is a hyperparameter while the weights in a neural network are model parameters learned during training. if you are looking for better scores in this competition, you may ignore the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are four common methods of hyperparameter optimization for machine learning in order of increasing efficiency:\n",
    "\n",
    "* Manual\n",
    "* Grid search\n",
    "* Random search\n",
    "* Bayesian model-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel provides an example to tuning the hyper - parameters using Bayesian Optimization on Light GBM (one of the most popular algorithm in Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creditcard.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "# Data processing, metrics and modeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold,KFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "# Lgbm\n",
    "import lightgbm as lgb\n",
    "# Suppr warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "from scipy import interp\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "import os\n",
    "print(os.listdir('../input/'))\n",
    "Random_Seed = 4520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.08 s, sys: 212 ms, total: 3.29 s\n",
      "Wall time: 3.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DataFile = pd.read_csv('../input/creditcard.csv')\n",
    "train_df = DataFile.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_df)\n",
    "features.remove('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut tr and val\n",
    "bayesian_tr_idx, bayesian_val_idx = train_test_split(train_df, test_size = 0.3, random_state = 42, stratify = train_df['Class'])\n",
    "bayesian_tr_idx = bayesian_tr_idx.index\n",
    "bayesian_val_idx = bayesian_val_idx.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Take the hyper parameters you want to consider\n",
    "\n",
    "paramsLGB = {\n",
    "    'learning_rate': (0.001,0.005),\n",
    "    'num_leaves': (50, 500), \n",
    "    'bagging_fraction' : (0.1, 0.9),\n",
    "    'feature_fraction' : (0.1, 0.9),\n",
    "    'min_child_weight': (0.00001, 0.01),   \n",
    "    'min_data_in_leaf': (20, 70),\n",
    "    'max_depth':(-1,50),\n",
    "    'reg_alpha': (1, 2), \n",
    "    'reg_lambda': (1, 2)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    learning_rate,\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    feature_fraction,\n",
    "    min_child_weight, \n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'feature_fraction' : feature_fraction,\n",
    "              'learning_rate' : learning_rate,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'objective': 'binary',\n",
    "              'save_binary': True,\n",
    "              'seed': Random_Seed,\n",
    "              'feature_fraction_seed': Random_Seed,\n",
    "              'bagging_seed': Random_Seed,\n",
    "              'drop_seed': Random_Seed,\n",
    "              'data_random_seed': Random_Seed,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'verbose': 1,\n",
    "              'is_unbalance': False,\n",
    "              'boost_from_average': True,\n",
    "              'metric':'auc'}    \n",
    "    \n",
    "    oof = np.zeros(len(train_df))\n",
    "    trn_data= lgb.Dataset(train_df.iloc[bayesian_tr_idx][features].values, label=train_df.iloc[bayesian_tr_idx]['Class'].values)\n",
    "    val_data= lgb.Dataset(train_df.iloc[bayesian_val_idx][features].values, label=train_df.iloc[bayesian_val_idx]['Class'].values)\n",
    "\n",
    "    clf = lgb.train(param, trn_data,  num_boost_round=50, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds = 50)\n",
    "    \n",
    "    oof[bayesian_val_idx]  = clf.predict(train_df.iloc[bayesian_val_idx][features].values, num_iteration=clf.best_iteration)  \n",
    "    \n",
    "    score = roc_auc_score(train_df.iloc[bayesian_val_idx]['Class'].values, oof[bayesian_val_idx])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_bayesian, paramsLGB, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagging_fraction', 'feature_fraction', 'learning_rate', 'max_depth', 'min_child_weight', 'min_data_in_leaf', 'num_leaves', 'reg_alpha', 'reg_lambda']\n"
     ]
    }
   ],
   "source": [
    "print(LGB_BO.space.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_points = 9\n",
    "n_iter = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_ch... | min_da... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9526  \u001b[0m | \u001b[0m 0.3996  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.003928\u001b[0m | \u001b[0m 29.53   \u001b[0m | \u001b[0m 0.001569\u001b[0m | \u001b[0m 27.8    \u001b[0m | \u001b[0m 76.14   \u001b[0m | \u001b[0m 1.866   \u001b[0m | \u001b[0m 1.601   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9638  \u001b[0m | \u001b[95m 0.6665  \u001b[0m | \u001b[95m 0.1165  \u001b[0m | \u001b[95m 0.00488 \u001b[0m | \u001b[95m 41.45   \u001b[0m | \u001b[95m 0.002131\u001b[0m | \u001b[95m 29.09   \u001b[0m | \u001b[95m 132.5   \u001b[0m | \u001b[95m 1.304   \u001b[0m | \u001b[95m 1.525   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9656  \u001b[0m | \u001b[95m 0.4456  \u001b[0m | \u001b[95m 0.333   \u001b[0m | \u001b[95m 0.003447\u001b[0m | \u001b[95m 6.114   \u001b[0m | \u001b[95m 0.002929\u001b[0m | \u001b[95m 38.32   \u001b[0m | \u001b[95m 255.2   \u001b[0m | \u001b[95m 1.785   \u001b[0m | \u001b[95m 1.2     \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9572  \u001b[0m | \u001b[0m 0.5114  \u001b[0m | \u001b[0m 0.5739  \u001b[0m | \u001b[0m 0.001186\u001b[0m | \u001b[0m 29.98   \u001b[0m | \u001b[0m 0.001714\u001b[0m | \u001b[0m 23.25   \u001b[0m | \u001b[0m 477.0   \u001b[0m | \u001b[0m 1.966   \u001b[0m | \u001b[0m 1.808   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.9657  \u001b[0m | \u001b[95m 0.3437  \u001b[0m | \u001b[95m 0.1781  \u001b[0m | \u001b[95m 0.003737\u001b[0m | \u001b[95m 21.45   \u001b[0m | \u001b[95m 0.001229\u001b[0m | \u001b[95m 44.76   \u001b[0m | \u001b[95m 65.47   \u001b[0m | \u001b[95m 1.909   \u001b[0m | \u001b[95m 1.259   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9698  \u001b[0m | \u001b[95m 0.63    \u001b[0m | \u001b[95m 0.3494  \u001b[0m | \u001b[95m 0.00308 \u001b[0m | \u001b[95m 26.88   \u001b[0m | \u001b[95m 0.001857\u001b[0m | \u001b[95m 68.48   \u001b[0m | \u001b[95m 398.8   \u001b[0m | \u001b[95m 1.939   \u001b[0m | \u001b[95m 1.895   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 0.5783  \u001b[0m | \u001b[0m 0.8375  \u001b[0m | \u001b[0m 0.001354\u001b[0m | \u001b[0m 8.995   \u001b[0m | \u001b[0m 0.000461\u001b[0m | \u001b[0m 36.27   \u001b[0m | \u001b[0m 224.9   \u001b[0m | \u001b[0m 1.271   \u001b[0m | \u001b[0m 1.829   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9657  \u001b[0m | \u001b[0m 0.3854  \u001b[0m | \u001b[0m 0.3247  \u001b[0m | \u001b[0m 0.003171\u001b[0m | \u001b[0m 6.187   \u001b[0m | \u001b[0m 0.008024\u001b[0m | \u001b[0m 23.73   \u001b[0m | \u001b[0m 494.1   \u001b[0m | \u001b[0m 1.772   \u001b[0m | \u001b[0m 1.199   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9586  \u001b[0m | \u001b[0m 0.1044  \u001b[0m | \u001b[0m 0.7524  \u001b[0m | \u001b[0m 0.003827\u001b[0m | \u001b[0m 36.18   \u001b[0m | \u001b[0m 0.007715\u001b[0m | \u001b[0m 23.7    \u001b[0m | \u001b[0m 211.3   \u001b[0m | \u001b[0m 1.116   \u001b[0m | \u001b[0m 1.863   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9667  \u001b[0m | \u001b[0m 0.837   \u001b[0m | \u001b[0m 0.225   \u001b[0m | \u001b[0m 0.003043\u001b[0m | \u001b[0m 49.73   \u001b[0m | \u001b[0m 0.004079\u001b[0m | \u001b[0m 69.32   \u001b[0m | \u001b[0m 57.79   \u001b[0m | \u001b[0m 1.83    \u001b[0m | \u001b[0m 1.32    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9593  \u001b[0m | \u001b[0m 0.2882  \u001b[0m | \u001b[0m 0.5206  \u001b[0m | \u001b[0m 0.002689\u001b[0m | \u001b[0m-0.3055  \u001b[0m | \u001b[0m 0.00479 \u001b[0m | \u001b[0m 20.05   \u001b[0m | \u001b[0m 387.2   \u001b[0m | \u001b[0m 1.966   \u001b[0m | \u001b[0m 1.228   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.97    \u001b[0m | \u001b[95m 0.6409  \u001b[0m | \u001b[95m 0.3476  \u001b[0m | \u001b[95m 0.003226\u001b[0m | \u001b[95m 49.81   \u001b[0m | \u001b[95m 0.000230\u001b[0m | \u001b[95m 69.35   \u001b[0m | \u001b[95m 285.9   \u001b[0m | \u001b[95m 1.866   \u001b[0m | \u001b[95m 1.809   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9544  \u001b[0m | \u001b[0m 0.6782  \u001b[0m | \u001b[0m 0.7624  \u001b[0m | \u001b[0m 0.001412\u001b[0m | \u001b[0m 49.65   \u001b[0m | \u001b[0m 0.000769\u001b[0m | \u001b[0m 69.18   \u001b[0m | \u001b[0m 498.7   \u001b[0m | \u001b[0m 1.844   \u001b[0m | \u001b[0m 1.099   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9501  \u001b[0m | \u001b[0m 0.1096  \u001b[0m | \u001b[0m 0.141   \u001b[0m | \u001b[0m 0.002725\u001b[0m | \u001b[0m-0.8965  \u001b[0m | \u001b[0m 0.000567\u001b[0m | \u001b[0m 69.45   \u001b[0m | \u001b[0m 93.75   \u001b[0m | \u001b[0m 1.578   \u001b[0m | \u001b[0m 1.978   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9591  \u001b[0m | \u001b[0m 0.7981  \u001b[0m | \u001b[0m 0.1246  \u001b[0m | \u001b[0m 0.002495\u001b[0m | \u001b[0m-0.7821  \u001b[0m | \u001b[0m 0.005212\u001b[0m | \u001b[0m 68.85   \u001b[0m | \u001b[0m 476.1   \u001b[0m | \u001b[0m 1.495   \u001b[0m | \u001b[0m 1.504   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9692  \u001b[0m | \u001b[0m 0.8815  \u001b[0m | \u001b[0m 0.2226  \u001b[0m | \u001b[0m 0.003625\u001b[0m | \u001b[0m-0.632   \u001b[0m | \u001b[0m 0.00931 \u001b[0m | \u001b[0m 69.34   \u001b[0m | \u001b[0m 342.7   \u001b[0m | \u001b[0m 1.139   \u001b[0m | \u001b[0m 1.077   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9669  \u001b[0m | \u001b[0m 0.8919  \u001b[0m | \u001b[0m 0.3419  \u001b[0m | \u001b[0m 0.00127 \u001b[0m | \u001b[0m 48.61   \u001b[0m | \u001b[0m 0.002073\u001b[0m | \u001b[0m 21.49   \u001b[0m | \u001b[0m 326.7   \u001b[0m | \u001b[0m 1.413   \u001b[0m | \u001b[0m 1.32    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9673  \u001b[0m | \u001b[0m 0.4363  \u001b[0m | \u001b[0m 0.2532  \u001b[0m | \u001b[0m 0.002475\u001b[0m | \u001b[0m 49.83   \u001b[0m | \u001b[0m 0.006289\u001b[0m | \u001b[0m 66.58   \u001b[0m | \u001b[0m 158.4   \u001b[0m | \u001b[0m 1.929   \u001b[0m | \u001b[0m 1.189   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.944   \u001b[0m | \u001b[0m 0.7174  \u001b[0m | \u001b[0m 0.4421  \u001b[0m | \u001b[0m 0.001364\u001b[0m | \u001b[0m 2.563   \u001b[0m | \u001b[0m 0.004341\u001b[0m | \u001b[0m 69.8    \u001b[0m | \u001b[0m 50.2    \u001b[0m | \u001b[0m 1.217   \u001b[0m | \u001b[0m 1.371   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9658  \u001b[0m | \u001b[0m 0.1742  \u001b[0m | \u001b[0m 0.3163  \u001b[0m | \u001b[0m 0.002028\u001b[0m | \u001b[0m 28.99   \u001b[0m | \u001b[0m 0.009342\u001b[0m | \u001b[0m 49.8    \u001b[0m | \u001b[0m 323.2   \u001b[0m | \u001b[0m 1.94    \u001b[0m | \u001b[0m 1.16    \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 0.9738  \u001b[0m | \u001b[95m 0.4031  \u001b[0m | \u001b[95m 0.3094  \u001b[0m | \u001b[95m 0.003864\u001b[0m | \u001b[95m 49.87   \u001b[0m | \u001b[95m 0.006122\u001b[0m | \u001b[95m 68.54   \u001b[0m | \u001b[95m 392.9   \u001b[0m | \u001b[95m 1.071   \u001b[0m | \u001b[95m 1.099   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.961   \u001b[0m | \u001b[0m 0.4789  \u001b[0m | \u001b[0m 0.1366  \u001b[0m | \u001b[0m 0.004978\u001b[0m | \u001b[0m 49.19   \u001b[0m | \u001b[0m 0.006149\u001b[0m | \u001b[0m 68.81   \u001b[0m | \u001b[0m 101.1   \u001b[0m | \u001b[0m 1.311   \u001b[0m | \u001b[0m 1.012   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9597  \u001b[0m | \u001b[0m 0.3453  \u001b[0m | \u001b[0m 0.109   \u001b[0m | \u001b[0m 0.004759\u001b[0m | \u001b[0m 49.63   \u001b[0m | \u001b[0m 0.006801\u001b[0m | \u001b[0m 44.83   \u001b[0m | \u001b[0m 248.4   \u001b[0m | \u001b[0m 1.891   \u001b[0m | \u001b[0m 1.031   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9706  \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 0.2793  \u001b[0m | \u001b[0m 0.002432\u001b[0m | \u001b[0m-0.8547  \u001b[0m | \u001b[0m 0.007653\u001b[0m | \u001b[0m 20.37   \u001b[0m | \u001b[0m 302.3   \u001b[0m | \u001b[0m 1.666   \u001b[0m | \u001b[0m 1.938   \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('-' * 130)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9738001102691296"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.40307482543609074,\n",
       " 'feature_fraction': 0.30936918479656117,\n",
       " 'learning_rate': 0.003864060110011894,\n",
       " 'max_depth': 49.86592069494108,\n",
       " 'min_child_weight': 0.006122053816563716,\n",
       " 'min_data_in_leaf': 68.53540118195922,\n",
       " 'num_leaves': 392.9337084513254,\n",
       " 'reg_alpha': 1.0714588372460156,\n",
       " 'reg_lambda': 1.0989869905198146}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = {\n",
    "        'min_data_in_leaf': int(LGB_BO.max['params']['min_data_in_leaf']), \n",
    "        'num_leaves': int(LGB_BO.max['params']['num_leaves']), \n",
    "        'learning_rate': LGB_BO.max['params']['learning_rate'],\n",
    "        'min_child_weight': LGB_BO.max['params']['min_child_weight'],\n",
    "        'bagging_fraction': LGB_BO.max['params']['bagging_fraction'], \n",
    "        'feature_fraction': LGB_BO.max['params']['feature_fraction'],\n",
    "        'reg_lambda': LGB_BO.max['params']['reg_lambda'],\n",
    "        'reg_alpha': LGB_BO.max['params']['reg_alpha'],\n",
    "        'max_depth': int(LGB_BO.max['params']['max_depth']), \n",
    "        'objective': 'binary',\n",
    "        'save_binary': True,\n",
    "        'seed': Random_Seed,\n",
    "        'feature_fraction_seed': Random_Seed,\n",
    "        'bagging_seed': Random_Seed,\n",
    "        'drop_seed': Random_Seed,\n",
    "        'data_random_seed': Random_Seed,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose': 1,\n",
    "        'is_unbalance': False,\n",
    "        'boost_from_average': True,\n",
    "        'metric':'auc'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use these parameters for your final model. You can use a similar technique for any other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some references for the text  : https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f\n",
    "\n",
    "Some references for the code : https://www.kaggle.com/vincentlugat/ieee-lgb-bayesian-opt (Please upvote his kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
