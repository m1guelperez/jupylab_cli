{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "13a083b9-c1ba-682e-5f96-62ac2d8f585c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapdata_copyright_openstreetmap_contributors.rds\n",
      "mapdata_copyright_openstreetmap_contributors.txt\n",
      "noaa_weather_qclcd_documentation.pdf\n",
      "sampleSubmission.csv\n",
      "spray.csv\n",
      "test.csv\n",
      "train.csv\n",
      "weather.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:245: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzfw/9va5en63lp0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f915480e940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import gpxpy.geo\n",
    "from datetime import datetime\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "#TODO: add variable names for each category\n",
    "\n",
    "###################################### reading files\n",
    "def readfile(filename,offset=0):\n",
    "    f = open(filename, 'r')\n",
    "    data =[]\n",
    "    for i,line in enumerate(f):\n",
    "        line = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '',line)\n",
    "        if i == 0:\n",
    "            labels = line.strip().replace('\\\"','').split(\",\")\n",
    "        if i > 0: \n",
    "            data += [line.strip().replace('\\\"','').split(\",\")]\n",
    "    return labels[offset:], np.array(data)[:,offset:]\n",
    "\n",
    "sprayfile = \"../input/spray.csv\"\n",
    "weatherfile = \"../input/weather.csv\" \n",
    "trainfile = \"../input/train.csv\"\n",
    "testfile = \"../input/test.csv\"\n",
    "\n",
    "spraylabels,spray = readfile(sprayfile)\n",
    "weatherlabels,weather = readfile(weatherfile)\n",
    "trainlabels,train = readfile(trainfile)\n",
    "testlabels,test = readfile(testfile,1)\n",
    "\n",
    "\n",
    "########################################### create dictionaries for categorical vars\n",
    "# find indeces for aggregations - and build dictionaries {[key,indeces in train/test sets]}\n",
    "def indeces(dataset):\n",
    "    addressIndeces = {}\n",
    "    speciesIndeces = {}\n",
    "    dateIndeces = {}\n",
    "    for i,line in enumerate(dataset):\n",
    "        address = line[1]\n",
    "        date = line[0].replace('/', '-')\n",
    "        species = line[2]\n",
    "        if address in addressIndeces: addressIndeces[address] += [i]\n",
    "        else: addressIndeces[address] = [i]\n",
    "        if species in speciesIndeces: speciesIndeces[species] += [i]\n",
    "        else: speciesIndeces[species] = [i]\n",
    "        if date in dateIndeces: dateIndeces[date] += [i]\n",
    "        else: dateIndeces[date] = [i]\n",
    "    return addressIndeces,speciesIndeces,dateIndeces\n",
    "    \n",
    "TrainaddressIndeces,TrainspeciesIndeces,TraindateIndeces = indeces(train)\n",
    "TestaddressIndeces,TestspeciesIndeces,TestdateIndeces = indeces(test)\n",
    "\n",
    "\n",
    "\n",
    "############################################################### do a stupid clustering on sites\n",
    "############################################################### TODO: make it smarter\n",
    "x = np.array(train[:,11],dtype=int) # Y variable\n",
    "N = len(train)\n",
    "Ntest = len(test)\n",
    "\n",
    "NInf = sum(x)\n",
    "d = 10 # number of site cohorots\n",
    "dn = np.ceil(NInf/d-1) # #infections in each cohorot\n",
    "\n",
    "n = len(TrainaddressIndeces) # number of different addresses\n",
    "addressCohorot = np.zeros([n,2],dtype='int32') # for each address in TrainaddressIndeces find the sum(x) and put them in an array [sum(x),var_number]\n",
    "addressSums = {} # {(key in TrainaddressIndeces):sum(x)}\n",
    "for i,key in enumerate(TrainaddressIndeces):\n",
    "    sumx = np.sum(x[TrainaddressIndeces[key]])\n",
    "    addressCohorot[i,0] = sumx \n",
    "    addressSums[key] = sumx\n",
    "\n",
    "addressCohorot = addressCohorot[(-addressCohorot[:,0]).argsort(),:] # sort addressCohorot in descending order by sum(x) over the site address\n",
    "\n",
    "## assign category number for each\n",
    "s = 0\n",
    "category = 0\n",
    "for i in range(n):\n",
    "    s += addressCohorot[i,0]\n",
    "    if addressCohorot[i,0] >= dn:\n",
    "        addressCohorot[i,1] = category\n",
    "        category += 1\n",
    "        s = 0\n",
    "        continue\n",
    "    elif s >= dn:\n",
    "        category += 1\n",
    "        s = 0\n",
    "    addressCohorot[i,1] = category\n",
    "\n",
    "#################################################################### create categorical var for site clusters on train/test clusters\n",
    "addressCategory = {}\n",
    "XCohorot = np.zeros([N,d])\n",
    "XCohorottest = np.zeros([Ntest,d]) \n",
    "for i,key in enumerate(TrainaddressIndeces):\n",
    "    # XCohorot at the indeces of this category and the column equal to the allocated cohorot should be 1\n",
    "    category = addressCohorot[np.where(addressCohorot[:,0]==addressSums[key])[0],1][0]\n",
    "    addressCategory[key] = category\n",
    "    XCohorot[TrainaddressIndeces[key],category] = 1\n",
    "    if TestaddressIndeces.get(key) != None:\n",
    "        XCohorottest[TestaddressIndeces[key],category] = 1\n",
    "\t\t\n",
    "\t\t\n",
    "############################################################ create var for each site with the distance to main two addresses\n",
    "\t\t\n",
    "addressCordinates = {} # dict with {address:array([latitude,longitude])} of all sites\n",
    "for k, v in TrainaddressIndeces.items():\n",
    "\taddressCordinates[k] = np.array(train[v[0],[7,8]],dtype=float)\n",
    "for k, v in TestaddressIndeces.items():\n",
    "\tif k not in addressCordinates:\n",
    "\t\taddressCordinates[k] = np.array(test[v[0],[7,8]],dtype=float)\n",
    "\t\n",
    "#extract the outlier addresses\n",
    "outbreaks = {} # dict with {address:array([latitude,longitude])} of outbreak sites\n",
    "for k, v in addressSums.items(): \n",
    "\tif v > 30: # manual condition for outbreak. TODO: update if needed\n",
    "\t\toutbreaks[k] = addressCordinates[k]\n",
    "\n",
    "outbreaksDist = {}\n",
    "for address, cordinates in addressCordinates.items():\n",
    "\td = []\n",
    "\tfor OBaddress, OBcordinates in outbreaks.items():\n",
    "\t\tif address == OBaddress:\n",
    "\t\t\td += [0]\n",
    "\t\telse:\n",
    "\t\t\td += [gpxpy.geo.haversine_distance(cordinates[0],cordinates[1],OBcordinates[0],OBcordinates[1])]\n",
    "\toutbreaksDist[address] = np.array(d,dtype=float)\n",
    "\n",
    "\n",
    "Xoutbreaks = np.zeros([N,len(outbreaks)])\n",
    "Xoutbreakstest = np.zeros([Ntest,len(outbreaks)])\n",
    "for k, v in TrainaddressIndeces.items():\n",
    "\tXoutbreaks[v,:] = (outbreaksDist[k]/1000)**2\n",
    "for k, v in TestaddressIndeces.items():\n",
    "\tXoutbreakstest[v,:] = (outbreaksDist[k]/1000)**2\n",
    "\n",
    "############################################################ create var for mosquito species\n",
    "\n",
    "##### classify species to 4 categories:\n",
    "#CULEX PIPIENS/RESTUANS 0\n",
    "#CULEX RESTUANS 1\n",
    "#CULEX PIPIENS 2\n",
    "#CULEX SALINARIUS 3\n",
    "#CULEX TERRITANS 3\n",
    "#CULEX TARSALIS 3\n",
    "#CULEX ERRATICUS 3\n",
    "\n",
    "XSpecis = np.zeros([N,4])\n",
    "for k,v in TrainspeciesIndeces.items():\n",
    "\tif k == \"CULEX PIPIENS/RESTUANS\": XSpecis[v,0] = 1\n",
    "\telif k == \"CULEX RESTUANS\": XSpecis[v,1] = 1\n",
    "\telif k == \"CULEX PIPIENS\": XSpecis[v,2] = 1\n",
    "\telse:  XSpecis[v,3] = 1\n",
    "\n",
    "XSpecistest = np.zeros([Ntest,4])\n",
    "for k,v in TestspeciesIndeces.items():\n",
    "\tif k == \"CULEX PIPIENS/RESTUANS\": XSpecistest[v,0] = 1\n",
    "\telif k == \"CULEX RESTUANS\": XSpecistest[v,1] = 1\n",
    "\telif k == \"CULEX PIPIENS\": XSpecistest[v,2] = 1\n",
    "\telse:  XSpecistest[v,3] = 1\n",
    "\t\n",
    "############################################################ climate variables - only based on station1\n",
    "weather0  = weather[weather[:,0]=='1'] # only station 1\n",
    "dates = weather0[:,1]\n",
    "vars = [4,6,7,10,11,17,19,21]\n",
    "for v in vars:\n",
    "\tweather0[np.where(weather0[:,v]=='M')[0],v]='-1'\n",
    "\t\n",
    "sunset_minutes = np.array(weather0[:,[11]],dtype=float)\n",
    "sunrise_minutes = np.array(weather0[:,[10]],dtype=float)\n",
    "sunset_minutes = np.floor(sunset_minutes/100) * 60 + (sunset_minutes%100)\n",
    "sunrise_minutes = np.array(weather0[:,[10]],dtype=float)\n",
    "sunrise_minutes = np.floor(sunrise_minutes/100) * 60 + (sunrise_minutes%100)\n",
    "daylight_minutes = sunset_minutes - sunrise_minutes # sunset - sunrise times\n",
    "\n",
    "windows = [1,7,28]\n",
    "other_vars = np.array(weather0[:,[4,6,7,17,19,21]],dtype=float) \n",
    "XweatherRaw = np.hstack([other_vars,daylight_minutes])\n",
    "nw,dw = np.shape(XweatherRaw)\n",
    "dwMA = dw * len(windows)\n",
    "XweatherMA = np.zeros([nw,dwMA],dtype=float)\n",
    "XweatherMAcol = 0\n",
    "for var in range(dw):\n",
    "\tfor line in range(nw):\n",
    "\t\tif XweatherRaw[line,var] == -1:\n",
    "\t\t\tif line == 0: XweatherRaw[line,var] = XweatherRaw[line+1,var]\n",
    "\t\t\telif line == nw-1: XweatherRaw[line,var] = XweatherRaw[line-1,var]\n",
    "\t\t\telse: XweatherRaw[line,var] = (XweatherRaw[line-1,var] + XweatherRaw[line+1,var])/2\n",
    "\tfor window in windows:\n",
    "\t\tXweatherMA[:,XweatherMAcol] = np.convolve(XweatherRaw[:,var], np.ones((window,))/window, mode='full')[:nw]\n",
    "\t\tXweatherMAcol += 1\n",
    "\n",
    "# move data in XweatherMA to X variables according to the dates\n",
    "XweatherNonLinear = np.zeros([N,dwMA],dtype=float)\n",
    "XweatherNonLineartest = np.zeros([Ntest,dwMA],dtype=float)\n",
    "for i,d in enumerate(dates):\n",
    "\tif d in TraindateIndeces: \n",
    "\t\tXweatherNonLinear[TraindateIndeces[d],:] = XweatherMA[i,:]\n",
    "\tif d in TestdateIndeces: \n",
    "\t\tXweatherNonLineartest[TestdateIndeces[d],:] = XweatherMA[i,:]\n",
    "\n",
    "# produce categorical variables for linear models\n",
    "quantiles = range(10,100,10)\n",
    "dwMAInd = dwMA * (1+len(quantiles))\n",
    "XweatherMAInd = np.zeros([nw,dwMAInd],dtype=float) # dividing XweatherMA for 10 quantiles indicators per each line\n",
    "XweatherMAIndcol = 0\n",
    "for var in range(dwMA):\n",
    "\tquant_prev = -float(\"inf\") #previous quantie in the loop\n",
    "\tfor q in quantiles:\n",
    "\t\tquant = np.percentile(XweatherMA[:,var],q)\n",
    "\t\tXweatherMAInd[ (XweatherMA[:,var]>quant_prev)*(XweatherMA[:,var]<quant) , XweatherMAIndcol] = 1\n",
    "\t\tXweatherMAIndcol += 1\n",
    "\t\tquant_prev = quant\n",
    "\tquant = float(\"inf\")\n",
    "\tXweatherMAInd[ np.where((XweatherMA[:,var]>quant_prev)*(XweatherMA[:,var]<quant))[0] , XweatherMAIndcol] = 1\n",
    "\tXweatherMAIndcol += 1\n",
    "\n",
    "# move data in XweatherMAIndcol to X variables according to the dates\n",
    "XweatherLinear = np.zeros([N,dwMAInd],dtype=float)\n",
    "XweatherLineartest = np.zeros([Ntest,dwMAInd],dtype=float)\n",
    "for i,d in enumerate(dates):\n",
    "\tif d in TraindateIndeces: \n",
    "\t\tXweatherLinear[TraindateIndeces[d],:] = XweatherMAInd[i,:]\n",
    "\tif d in TestdateIndeces: \n",
    "\t\tXweatherLineartest[TestdateIndeces[d],:] = XweatherMAInd[i,:]\t\n",
    "\n",
    "\n",
    "############################################################ spray variables\n",
    "\n",
    "dists = []\n",
    "prevLine = None\n",
    "for line in spray:\n",
    "\tif prevLine == None: \n",
    "\t\tprevLine = line\n",
    "\t\tcontinue\n",
    "\tif line[0] == prevLine[0]:\n",
    "\t\tdists += [gpxpy.geo.haversine_distance(float(line[2]),float(line[3]),float(prevLine[2]),float(prevLine[3]))]\n",
    "\t\tprevLine = line\n",
    "\n",
    "plt.hist(dists,bins = 100) \n",
    "# base on this, I choose 100meters as the radius of full effect, and after this it start decaying\n",
    "\n",
    "SprayEfforts = {} # a dict of {date:[all locations]}\n",
    "for line in spray:\n",
    "\tdate = line[0]\n",
    "\tcoordinates = (float(line[2]),float(line[3]))\n",
    "\tif date in SprayEfforts: SprayEfforts[date] += [coordinates]\n",
    "\telse: SprayEfforts[date] = [coordinates]\n",
    "\n",
    "addressSprayEfforts = {} # a dict of dicts: {site:{Spraydate:minDist}} where the value refers to spraying in the area of at most 1KM to the site\n",
    "for kaddress,vCordinate in addressCordinates.items():\n",
    "\tSprayEffortsPeraddress = {}\n",
    "\tfor SprayDate,SprayLocations in SprayEfforts.items():\n",
    "\t\tminDist = float(\"inf\")\n",
    "\t\tfor SprayCoordinates in SprayLocations:\n",
    "\t\t\tdist = gpxpy.geo.haversine_distance(float(vCordinate[0]),float(vCordinate[1]),float(SprayCoordinates[0]),float(SprayCoordinates[1]))\n",
    "\t\t\tif dist < min(minDist,1000):\n",
    "\t\t\t\tminDist = dist\n",
    "\t\t\t\tSprayEffortsPeraddress[SprayDate] = minDist\n",
    "\t\t\t\taddressSprayEfforts[kaddress] = SprayEffortsPeraddress\n"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
