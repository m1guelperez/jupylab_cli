{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60a5b54d-f63f-5810-6e37-b95340f0dd10",
    "_uuid": "7b017d279eb2580916f4cbd18b7a35f51f509c55"
   },
   "source": [
    "# Topic Modeling Daily Patent Assignments\n",
    "\n",
    "This dataset contains a record of every [patent assignment](https://www.legalzoom.com/assets/legalforms/Patent%20Assignment.pdf) which took place on October 18, 2016. A patent assignment occurs whenever a patent is either issued experiences a change in ownership. There are apparently perhaps 2 million or so active patents in the United States, and this dataset is a window into what a day in their movements looks like.\n",
    "\n",
    "This notebook has three parts: flatenning; general exploration; and, finally, topic modeling. The goal is to outline the basics of how natural language processing, specifically topic modeling, works.\n",
    "\n",
    "**[Click here to skip directly to the topic modeling](#Topic-Modeling).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ef550a3-d7b3-9888-f5d7-935fd2f6b7c3",
    "_uuid": "2817f1bfc1dcece91643274e436c1a653a850e1c"
   },
   "source": [
    "## Flattening\n",
    "\n",
    "The dataset is provided in an XML format, which is a bit awkward to work with. Before doing anything else with it, I've written a pipe that turns it into a more easily workable CSV file (note, however, that this CSV file's format is not ideal for all possible applications...).\n",
    "\n",
    "The details of this code are explained in [another notebook](https://www.kaggle.com/residentmario/d/uspto/patent-assignment-daily/flattening-the-patent-assignment-daily-dataset), and we will gloss over them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "198e4c31-83b1-986f-8d05-860e9142eafe",
    "_uuid": "c5aa58ce366f2d44b0428f7a89f6e0068467a2bb"
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "3d45b09c-446e-09a5-3bbc-574c24779d9d",
    "_uuid": "14f9a7e079f7531107ea64d8588fd7bdcb667c7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:50: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents = etree.parse(\"../input/ad20161018.xml\")\n",
    "root = patents.getroot()\n",
    "assignments = list(list(root)[2])\n",
    "\n",
    "def serialize(assn):\n",
    "    srs = pd.Series()\n",
    "    # Metadata\n",
    "    srs['last-update-date'] = assn.find(\"assignment-record\").find(\"last-update-date\").find(\"date\").text\n",
    "    srs['recorded-date'] = assn.find(\"assignment-record\").find(\"recorded-date\").find(\"date\").text\n",
    "    srs['patent-assignors'] = \"|\".join([assn.find(\"name\").text for assn in assn.find(\"patent-assignors\")])\n",
    "    srs['patent-assignees'] = \"|\".join([assn.find(\"name\").text for assn in assn.find(\"patent-assignees\")])\n",
    "    # WIP---below.\n",
    "    try:\n",
    "        srs['patent-numbers'] = \"|\".join(\n",
    "            [\"|\".join([d.find(\"doc-number\").text for d in p.findall(\"document-id\")])\\\n",
    "             for p in assn.find(\"patent-properties\").findall(\"patent-property\")]\n",
    "        )\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    try:\n",
    "        srs['patent-kinds'] = \"|\".join(\n",
    "            [\"|\".join([d.find(\"kind\").text for d in p.findall(\"document-id\")])\\\n",
    "             for p in assn.find(\"patent-properties\").findall(\"patent-property\")]\n",
    "        )\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    try:\n",
    "        srs['patent-dates'] = \"|\".join(\n",
    "            [\"|\".join([d.find(\"date\").text for d in p.findall(\"document-id\")])\\\n",
    "             for p in assn.find(\"patent-properties\").findall(\"patent-property\")]\n",
    "        )    \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    try:\n",
    "        srs['patent-countries'] = \"|\".join(\n",
    "            [\"|\".join([d.find(\"country\").text for d in p.findall(\"document-id\")])\\\n",
    "             for p in assn.find(\"patent-properties\").findall(\"patent-property\")]\n",
    "        )    \n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        srs['title'] = \"|\".join(\n",
    "            [p.find(\"invention-title\").text for p in assn.find(\"patent-properties\").findall(\"patent-property\")]\n",
    "        )        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return srs\n",
    "\n",
    "flattened = pd.concat([serialize(assn) for assn in assignments], axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "d2056426-7abc-f172-7786-192768c69a84",
    "_uuid": "12a49f36cb9daa64e70ab6a49221ff7befe3af85"
   },
   "outputs": [],
   "source": [
    "del patents\n",
    "del root\n",
    "del assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "bbc619b4-56f1-3a3e-a79c-51e5bf23c60b",
    "_uuid": "73dfe01b4680f5095d076b210da2472d7206b962"
   },
   "outputs": [],
   "source": [
    "assignments = flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "3691e1ef-e765-1116-6c95-6f3d33bd57e3",
    "_uuid": "fe509de6e135b80c30d8b928ca640d83f817a8ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last-update-date</th>\n",
       "      <th>patent-assignees</th>\n",
       "      <th>patent-assignors</th>\n",
       "      <th>patent-countries</th>\n",
       "      <th>patent-dates</th>\n",
       "      <th>patent-kinds</th>\n",
       "      <th>patent-numbers</th>\n",
       "      <th>recorded-date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20161018</td>\n",
       "      <td>FASTCASE</td>\n",
       "      <td>WALTERS, EDWARD J. III|ROSENTHAL, PHILIP J.</td>\n",
       "      <td>US|US</td>\n",
       "      <td>20001108|20161018</td>\n",
       "      <td>X0|B1</td>\n",
       "      <td>09707911|9471672</td>\n",
       "      <td>20010320</td>\n",
       "      <td>Relevance sorting for database searches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20161018</td>\n",
       "      <td>ANABASIS SRL</td>\n",
       "      <td>LAMBIASE, ALESSANDRO</td>\n",
       "      <td>US|US</td>\n",
       "      <td>20010726|20161018</td>\n",
       "      <td>X0|B1</td>\n",
       "      <td>09890088|9468665</td>\n",
       "      <td>20010720</td>\n",
       "      <td>METHOD OF TREATING INTRAOCCULAR TISSUE PATHOLO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20161018</td>\n",
       "      <td>QUALCOMM INCORPORATED</td>\n",
       "      <td>WALTON, J. RODNEY|KETCHUM, JOHN W.</td>\n",
       "      <td>US|US|US</td>\n",
       "      <td>20031201|20050602|20161018</td>\n",
       "      <td>X0|A1|B2</td>\n",
       "      <td>10725904|20050120097|9473269</td>\n",
       "      <td>20031201</td>\n",
       "      <td>METHOD AND APPARATUS FOR PROVIDING AN EFFICIEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20161018</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHINES CORPORATION</td>\n",
       "      <td>MORARIU, JANIS A.|STAPEL, STEVEN W.|STRAACH, J...</td>\n",
       "      <td>US|US|US</td>\n",
       "      <td>20040622|20051222|20161018</td>\n",
       "      <td>X0|A1|B2</td>\n",
       "      <td>10873346|20050282136|9472114</td>\n",
       "      <td>20040903</td>\n",
       "      <td>COMPUTER-IMPLEMENTED METHOD, SYSTEM AND PROGRA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20161018</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHINES CORPORATION</td>\n",
       "      <td>LI, XIN|ROBERTS, GREGORY WAYNE</td>\n",
       "      <td>US|US|US</td>\n",
       "      <td>20041019|20060420|20161018</td>\n",
       "      <td>X0|A1|B2</td>\n",
       "      <td>10967958|20060085754|9471332</td>\n",
       "      <td>20050208</td>\n",
       "      <td>Selecting graphical component types at runtime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last-update-date                        ...                                                                      title\n",
       "0         20161018                        ...                                    Relevance sorting for database searches\n",
       "1         20161018                        ...                          METHOD OF TREATING INTRAOCCULAR TISSUE PATHOLO...\n",
       "2         20161018                        ...                          METHOD AND APPARATUS FOR PROVIDING AN EFFICIEN...\n",
       "3         20161018                        ...                          COMPUTER-IMPLEMENTED METHOD, SYSTEM AND PROGRA...\n",
       "4         20161018                        ...                             Selecting graphical component types at runtime\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "58215e76-1541-512c-9149-459675e091fb",
    "_uuid": "f9acd4fd095c1904c31c550b452d127c4b868bb5"
   },
   "source": [
    "## Topic Modeling\n",
    "\n",
    "Let's get to building a topic model around our patents. To do this we're going to use `nltk`, the \"natural language toolkit\", and `gensim`, a popular Python topic modeling and querying framework.\n",
    "\n",
    "[Topic modeling](https://en.wikipedia.org/wiki/Topic_model) is a set of tasks in the natural language processing field organized around classifying individual documents according to their topics. The idea is that if you have, for example, two sets of documents, one about football and one about tennis, for example, we should be able to use a computer to seperate them into two different topical \"piles\".\n",
    "\n",
    "In this case, we're going to try out classifying our patents based on their titles. Note that this is a bit of a stretch, as topic modeling works best when given fulltexts of things (IBM's Watson tools for example always recommend you input at least 250 words per document, or thereabout), but it nevertheless makes for a good demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8dbb12d5-c970-7e9b-940c-4c4c081b6998",
    "_uuid": "29788518f08622b417656776db43a9e9f061b9f2"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4f6e3105-6050-de92-c324-5d052ebf0a02",
    "_uuid": "13d6e3c0bd3ac49656de9afc860c5530d2c2d43c"
   },
   "source": [
    "The first thing we have to do is **tokenize** our words. A naive way to do this would be to split our string based on spaces (e.g. `str.split(\" \")`), which is sometimes OK but has many edge cases (alternative punctuation marks like &mdash;, for example) and will fail to work as expected for larger problems.\n",
    "\n",
    "`nltk` comes with a built-in word tokenizer that we can take advantage of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "693d6757-2e64-d78d-5dd3-009a87386b52",
    "_uuid": "447234b693d2df36c398a2b50fb423568b44f2e4"
   },
   "outputs": [],
   "source": [
    "titles = assignments['title']\n",
    "title_tokens = [nltk.word_tokenize(title) for title in\\\n",
    "                    np.concatenate(titles.map(str).map(str.title).map(lambda s: s.split(\"|\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "5aebb115-1362-a229-6517-fbcfd6872eed",
    "_uuid": "783213eaa427d193df998ef9f12bd66fe4c91c5e"
   },
   "outputs": [],
   "source": [
    "title_tokens = [title for title in title_tokens if len(title_tokens) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c4ce2e7b-4883-2e1a-ee2f-34f8d0a5dccb",
    "_uuid": "d00b47ff828e4dd5da084f27b3650d1d6bbdfbc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370460"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "171944cc-21ac-61d3-0c61-18088150810e",
    "_uuid": "31d566e314497597b47156e7f956062ba53d9830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Relevance', 'Sorting', 'For', 'Database', 'Searches'],\n",
       " ['Method',\n",
       "  'Of',\n",
       "  'Treating',\n",
       "  'Intraoccular',\n",
       "  'Tissue',\n",
       "  'Pathologies',\n",
       "  'With',\n",
       "  'Nerve',\n",
       "  'Growth',\n",
       "  'Factor',\n",
       "  '.'],\n",
       " ['Method',\n",
       "  'And',\n",
       "  'Apparatus',\n",
       "  'For',\n",
       "  'Providing',\n",
       "  'An',\n",
       "  'Efficient',\n",
       "  'Control',\n",
       "  'Channel',\n",
       "  'Structure',\n",
       "  'In',\n",
       "  'A',\n",
       "  'Wireless',\n",
       "  'Communication',\n",
       "  'System']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tokens[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5306f96c-cf5a-297b-0359-954f15905b6c",
    "_uuid": "eeda38fbc8e8a745d0e77dac781c6d2d165c8609"
   },
   "source": [
    "Next, we will **stem** our words. Stemming is a procedure in natural language processing where we chop off everything except for the root of a word. So for example, the words go, going, and gone will all map to the same root&mdash;go.\n",
    "\n",
    "This is a good thing to do, particularly given the small size of our documents, because it increases the accuracy of classifications&mdash;more things end up being the same.\n",
    "\n",
    "`nltk` comes with several stemmers installed, we'll use the `PorterStemmer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "5eb78465-55b6-6247-2d8e-35ef46b89229",
    "_uuid": "414f4c9e0e6d32389056d71e4a8e901d1414b96a"
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "titles_stemmed = [[stemmer.stem(token) for token in tokens] for tokens in title_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "6da467ea-0de9-8259-a98d-8fc8ce63f7fb",
    "_uuid": "dcb70321d642fbc89d1741ebc14b7e1b42783c7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relev', 'sort', 'for', 'databas', 'search'],\n",
       " ['method',\n",
       "  'Of',\n",
       "  'treat',\n",
       "  'intraoccular',\n",
       "  'tissu',\n",
       "  'patholog',\n",
       "  'with',\n",
       "  'nerv',\n",
       "  'growth',\n",
       "  'factor',\n",
       "  '.'],\n",
       " ['method',\n",
       "  'and',\n",
       "  'apparatu',\n",
       "  'for',\n",
       "  'provid',\n",
       "  'An',\n",
       "  'effici',\n",
       "  'control',\n",
       "  'channel',\n",
       "  'structur',\n",
       "  'In',\n",
       "  'A',\n",
       "  'wireless',\n",
       "  'commun',\n",
       "  'system']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_stemmed[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c5879695-99f0-547b-f256-061d48379162",
    "_uuid": "780f1b2cd97768712aac14bbe84646ba6a16adf7"
   },
   "source": [
    "If we examine a list of words, however, we see that the most common English-language words dominate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "2b6988cf-ca49-ec4e-315b-d0d20920e61b",
    "_uuid": "8f9a615c65c3a00bb82617f979ebee45112a2071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and                    170856\n",
       "for                    145224\n",
       "method                 137910\n",
       "A                      101633\n",
       "Of                      91017\n",
       "system                  75843\n",
       "devic                   65015\n",
       "with                    46433\n",
       "In                      39461\n",
       ",                       37235\n",
       "apparatu                31147\n",
       "circuit                 29046\n",
       "memori                  28675\n",
       "semiconductor           26290\n",
       "use                     24697\n",
       "To                      23959\n",
       "data                    22710\n",
       "An                      22235\n",
       "control                 20957\n",
       "the                     20244\n",
       "have                    17662\n",
       "integr                  16994\n",
       "process                 16233\n",
       "structur                16052\n",
       "network                 14185\n",
       "form                    14012\n",
       "On                      12411\n",
       "commun                  12408\n",
       "power                   11927\n",
       "same                    10940\n",
       "                        ...  \n",
       "serr                        1\n",
       "faid                        1\n",
       "de-identifi                 1\n",
       "probationari                1\n",
       "columnstor                  1\n",
       "unvoic                      1\n",
       "n-tupl                      1\n",
       "non-monoton                 1\n",
       "self-disentangl             1\n",
       "liquid-mix                  1\n",
       "modulator/transmitt         1\n",
       "pyridazin-4-yl              1\n",
       "automamat                   1\n",
       "multi-broadcast             1\n",
       "bcch                        1\n",
       "randomili                   1\n",
       "asochron                    1\n",
       "gel-contain                 1\n",
       "advertisement-fund          1\n",
       "hfr-base                    1\n",
       "anti-ch                     1\n",
       "warm-humid                  1\n",
       "andsemiconductor            1\n",
       "range-switch                1\n",
       "-morphinan                  1\n",
       "flatwal                     1\n",
       "stored-pattern              1\n",
       "end-of-fram                 1\n",
       "photovoltaic-rel            1\n",
       "bzflash                     1\n",
       "Length: 32338, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.concatenate(titles_stemmed)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "66504c6e-f3e6-0d45-cc64-bc7b9d1a9332",
    "_uuid": "ce9a803f7e5446281c9b4971f7940ae2a29c0a28"
   },
   "source": [
    "These words carry no meaning and aren't very interesting. They're known as **stopwords** in NLP, and we're going to once again use `nltk` builtins to remove them from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "ad19f95c-cca4-e43d-c19a-a5901b81a181",
    "_uuid": "ee8e106565851ac9dfe385280d179491b4b27acc"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "379422ab-1b0b-1a56-00a9-257439d33c71",
    "_uuid": "fa8f56f7740da8bfbcc4dd2d754eae13955e2659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "4b708fa5-cc33-b470-0e2b-6ee28f7ff7f6",
    "_uuid": "fe657cedf941a38fcdfd5642de16f9750d6eec1b"
   },
   "outputs": [],
   "source": [
    "english_stopwords = set([word.title() for word in stopwords.words(\"english\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "c687a68b-9a4b-fc9c-4eee-b4a6bcf34478",
    "_uuid": "d6e656cb058b5d32e06e56b29442b1a6c56cae80"
   },
   "outputs": [],
   "source": [
    "stemmed_title_words = [[word for word in title if word not in english_stopwords] for title in titles_stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "59f2651a-16e0-fe35-a63d-545389b98978",
    "_uuid": "94b5525bed7986aff80c9f65c1c468241fcf1829"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relev', 'sort', 'for', 'databas', 'search'],\n",
       " ['method',\n",
       "  'treat',\n",
       "  'intraoccular',\n",
       "  'tissu',\n",
       "  'patholog',\n",
       "  'with',\n",
       "  'nerv',\n",
       "  'growth',\n",
       "  'factor',\n",
       "  '.'],\n",
       " ['method',\n",
       "  'and',\n",
       "  'apparatu',\n",
       "  'for',\n",
       "  'provid',\n",
       "  'effici',\n",
       "  'control',\n",
       "  'channel',\n",
       "  'structur',\n",
       "  'wireless',\n",
       "  'commun',\n",
       "  'system']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_words[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0fa943a-4b4c-b0de-eafc-e449dfb6a4bd",
    "_uuid": "3c01fc99731fe88704f6bc6983e88a57ad3bccd9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "38fb51ad-d7f8-e2a0-4fa0-c53e76ea170e",
    "_uuid": "c63049b217e8f098526a30849dc97d41e4949444"
   },
   "outputs": [],
   "source": [
    "word_counts = pd.Series(np.concatenate(stemmed_title_words)).value_counts()\n",
    "singular_words = set(word_counts[pd.Series(np.concatenate(stemmed_title_words)).value_counts() == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "bfcbe888-7d53-6f1c-6b4f-a3009fdc1f22",
    "_uuid": "43a8156b2856c295e8eb480f2356869c19e6cc3c"
   },
   "outputs": [],
   "source": [
    "stemmed_title_common_words = [[word for word in title if word not in singular_words] for title in stemmed_title_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "9749b713-a63f-f1d4-3203-a6b877611144",
    "_uuid": "17719766eb65bd73280ae10de757277f5c032b35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relev', 'sort', 'for', 'databas', 'search'],\n",
       " ['method',\n",
       "  'treat',\n",
       "  'intraoccular',\n",
       "  'tissu',\n",
       "  'patholog',\n",
       "  'with',\n",
       "  'nerv',\n",
       "  'growth',\n",
       "  'factor',\n",
       "  '.'],\n",
       " ['method',\n",
       "  'and',\n",
       "  'apparatu',\n",
       "  'for',\n",
       "  'provid',\n",
       "  'effici',\n",
       "  'control',\n",
       "  'channel',\n",
       "  'structur',\n",
       "  'wireless',\n",
       "  'commun',\n",
       "  'system']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_common_words[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e224bfc8-9aa2-015a-4107-5a2450e7df31",
    "_uuid": "b37dd8b7e5d99af727e66ed4c69b3399b11cdc57"
   },
   "source": [
    "Next, let's consider the opposite problem: words that occur to infrequently to be useful. Words that only ever appear once, for example, don't carry any information. Remember, we're going to split all of our patent titles into some small number of classes; just as in any other dataset, a data point which is only populated once isn't interesting, and can be safely dropped.\n",
    "\n",
    "In fact, we could probably drop a *lot* of words from consideration, not just ones appearing once but ones appearing tens or even hundreds of times. This would speed up our algorithms and won't significantly impact our results.\n",
    "\n",
    "After a certain point words do start to matter, however; figuring out where that point is is up to you.\n",
    "\n",
    "In our case we'll just be lazy and cut off at words that appear only once, and leave words appearing twice or more intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "c46e708d-fb77-167c-7569-dc1ff0759e61",
    "_uuid": "30cd7bfc2767e50c178022961d27cd707b94b553"
   },
   "outputs": [],
   "source": [
    "non_empty_indices = [i for i in range(len(stemmed_title_common_words)) if len(stemmed_title_common_words[i]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "5d2110cd-2cab-e186-5293-13e3d7663af6",
    "_uuid": "d76a3f5157b904ce082b96dc2519025773d17a10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5003"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty_indices[5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "06f558c4-0a32-cdea-8641-16ca7841f2c4",
    "_uuid": "169afb42d6387e12d37c72a74a96687b5c642513"
   },
   "source": [
    "Notice that discarding words from our set has resulted in a handful of empty titles. Apparently a few patents have nothing *but* unique words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "c7399792-bb44-6c9d-f35b-9ccb0b22e023",
    "_uuid": "c9d3fc80f41882a63729c141f05950a890bbd481"
   },
   "outputs": [],
   "source": [
    "stemmed_title_common_words_nonnull = np.asarray(stemmed_title_common_words)[non_empty_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "8d36068d-ffcd-c1ae-df11-c1542536989a",
    "_uuid": "e31bf057984d2b68af2a0c21e56f6a9da53d7745"
   },
   "outputs": [],
   "source": [
    "classifiable_titles = np.asarray(title_tokens)[non_empty_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cc083813-6d9e-6f1d-1378-38d843a4b8f5",
    "_uuid": "51ae9b5f4f84acf024f5805e2bd23825c94eb07a"
   },
   "source": [
    "With our titles adequately processed, now we switch over to `gensim`. The first thing we have to do is build a dictionary of words, which associates each word [stem] with a particular index number:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "caed6a95-151c-8dee-fe54-e01c6f820671",
    "_uuid": "d8fb3dd0036c9942628f3d58eb3454ea3c017608"
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(stemmed_title_common_words_nonnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "eba3c00c-de83-361f-71a4-2b941e59a313",
    "_uuid": "a721e71025dd301f463217bb9d5e8aa061913342"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'databas': 0, 'for': 1, 'relev': 2, 'search': 3, 'sort': 4, '.': 5, 'factor': 6, 'growth': 7, 'intraoccular': 8, 'method': 9, 'nerv': 10, 'patholog': 11, 'tissu': 12, 'treat': 13, 'with': 14, 'and': 15, 'apparatu': 16, 'channel': 17, 'commun': 18, 'control': 19, 'effici': 20, 'provid': 21, 'structur': 22, 'system': 23, 'wireless': 24, ',': 25, 'computer-impl': 26, 'educ': 27, 'product': 28, 'program': 29, 'compon': 30, 'graphic': 31, 'runtim': 32, 'select': 33, 'type': 34, 'aggreg': 35, 'chromatographi': 36, 'high': 37, 'hydroxyapatit': 38, 'molecular': 39, 'remov': 40, 'use': 41, 'weight': 42, 'aid': 43, 'differ': 44, 'further': 45, 'protocol': 46, 'station': 47, 'the': 48, 'transpond': 49, 'convert': 50, 'input': 51, 'languag': 52, 'output': 53, 'phonet': 54, 'written': 55, 'dataset': 56, 'from': 57, 'link': 58, 'methodolog': 59, 'multi-mod': 60, 'pattern': 61, 'charact': 62, 'digit': 63, 'media': 64, 'person': 65, 'replac': 66, 'airway': 67, 'detect': 68, 'instabl': 69, 'align': 70\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dictionary.token2id)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b32fff0b-2290-6ea2-18cc-1c939ab27d77",
    "_uuid": "55a2cc34110e6320cbd04eb7984e090246163d1a"
   },
   "source": [
    "Why are we doing this? Because shortly we're going to throw our corpus into a [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) algorithm. TF-IDF is an algorithm in information retrieval which converts a list of word \"vectors\" to a scaled Euclidian normal vector. It turns a count of the number of each word in our document into a unit vector in N-dimensional space, where N is, believe it or not, the number of individual words that we have in our dictionary (above).\n",
    "\n",
    "That means that, in this case, we have a \"dataset\" matrix with hundreds of thousands of columns in it!\n",
    "\n",
    "The beauty of TD-IDF is that it scales the words according to how frequent or rare they are. Words that appear a lot in your text but also appear a lot in the rest of the corpus are weighed less heavily than words that appear a lot in your text but more rarely outside of it.\n",
    "\n",
    "Thus we first use `gensim` to convert our words to word incidence vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "0b4d1ee5-7ae1-6d3d-bd60-cf32967296f1",
    "_uuid": "7cacf7f6566855c24a00c7fe5c9f3d610b7392a9"
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in stemmed_title_common_words_nonnull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "b17c8b3b-d92c-e527-2d6b-65eadf09ba9c",
    "_uuid": "3aaacf9dca077088583a8c54c3f59493c21d147d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['relev', 'sort', 'for', 'databas', 'search'],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_common_words_nonnull[0], corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "203a9350-f51f-bafe-6700-d46a0abdb906",
    "_uuid": "91c22bbe0a63e493a5ce9d880854267a9614abed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['passeng',\n",
       "  'transport',\n",
       "  'system',\n",
       "  'and',\n",
       "  'method',\n",
       "  'for',\n",
       "  'obtain',\n",
       "  'ticket',\n",
       "  'such',\n",
       "  'system'],\n",
       " [(1, 1),\n",
       "  (9, 1),\n",
       "  (15, 1),\n",
       "  (23, 2),\n",
       "  (300, 1),\n",
       "  (325, 1),\n",
       "  (326, 1),\n",
       "  (327, 1),\n",
       "  (328, 1)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_common_words_nonnull[100], corpus[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "712ffbc4-3f81-b2aa-9965-52b190f444bc",
    "_uuid": "c3bd1fd699da7d3161577a62d2bac8d92279462a"
   },
   "source": [
    "...then run `TfidfModel` from `gensim` on them to turn them into our word vectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "661e2c9f-bda7-85c7-10c9-b114725b40a6",
    "_uuid": "6ae069f141670cda0a956eb2da45f4e7374f9d7b"
   },
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "c27657ba-61cb-756e-bb3d-72a8a5b99d23",
    "_uuid": "2bd6fc21a61364a3943319c9faa5bb9842fca79b"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c2593e32-ed60-f2d6-c8a3-58aa75ff3df1",
    "_uuid": "b9c640730e68112ec4f77c3045eade892ee6ec39"
   },
   "source": [
    "Note that `gensim` doesn't follow the `scikit` access pattern, if you are familiar with it. It instead (1) defers computations on individual entries until necessary and (2) provides access to data using bracket indexing notation (`[]`).\n",
    "\n",
    "By contrast, `scikit` will run everything immediately by default, provides results using a `.values_` attribute, and seperates model initialization from runtime (the latter doesn't occur until you `fit()` your model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "3c61af5a-0178-db9a-e3ef-7326e229c2c3",
    "_uuid": "2b11ec729c3e4ca5cd7c0fe309a92289e43946dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['relev', 'sort', 'for', 'databas', 'search'],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(0, 0.4377475295381456),\n",
       "  (1, 0.07562061510033051),\n",
       "  (2, 0.5469009211535774),\n",
       "  (3, 0.36992777626242423),\n",
       "  (4, 0.6055670447985132)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_title_common_words_nonnull[0], corpus[0], tfidf[corpus[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "51dfbcbc-275e-262a-c963-1d7f3e1cbbb9",
    "_uuid": "280e77ec5089c7aa8676576f25ee2c3aa1232c59"
   },
   "source": [
    "With our words suitibly datified, we can now move on to fitting a model. Since our words are now, effectively, a very large dataset, it's possible to use any general purpose classifier to fit it. An [earlier notebook on this dataset](https://www.kaggle.com/the1owl/d/uspto/patent-assignment-daily/exploring-daily-patent-assignments-files), for example, uses a `scipy` `KMeans` clustering algorithm to arrive at its topics (you should go read that after you're done with this one).\n",
    "\n",
    "We'll instead use a model specifically adapted to natural language processing from the `gensim` built-ins, `LsiModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "918655c3-e0be-966e-17b4-f0d8e8e2fbbe",
    "_uuid": "39d6fea297351ea7014e25a2f5dada66180ce808"
   },
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "001d899e-bde9-e165-f56d-117b6c010d85",
    "_uuid": "86371160ba876e31a6910c1f03cf363b300fed35"
   },
   "source": [
    "Here's how we run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "8450e781-acda-3a3c-90dd-c6abd4aeb1ce",
    "_uuid": "53bc1755134fc64c220d0cb2172de4ed8516143f"
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "lsi = LsiModel(tfidf[corpus], id2word=dictionary, num_topics=10)\n",
    "corpus_lsi = lsi[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1b4840df-5e16-029c-7dbb-0604f9bdbf05",
    "_uuid": "46204dc80d277d9d72b9589be921dd88698471f2"
   },
   "source": [
    "Here's a printout of what words are important to our various topics. Notice that certain extremely common words, like `semiconductor`, appear in different positions in multiple classifiers. Also, note that this display is cut off at a certain number of displayed words; in reality the model considers far more than these (you can specify how many to display here, however, using the `num_words` parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "67f86c24-77ec-0e11-94d5-069087357353",
    "_uuid": "537c9e4b4a77e7b3b21171913d22bf0b9d7a0755"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.381*\"devic\" + 0.350*\"semiconductor\" + 0.298*\"method\" + 0.281*\"and\" + 0.229*\"for\" + 0.227*\"system\" + 0.194*\",\" + 0.188*\"memori\" + 0.183*\"circuit\" + 0.153*\"apparatu\"'),\n",
       " (1,\n",
       "  '-0.603*\"semiconductor\" + -0.354*\"devic\" + 0.328*\"system\" + 0.197*\"apparatu\" + 0.171*\"for\" + 0.166*\"data\" + 0.153*\"and\" + 0.152*\",\" + -0.146*\"manufactur\" + -0.132*\"form\"'),\n",
       " (2,\n",
       "  '-0.719*\"circuit\" + -0.501*\"integr\" + 0.162*\"system\" + 0.122*\"data\" + 0.115*\"semiconductor\" + -0.112*\"packag\" + 0.111*\"devic\" + 0.100*\"commun\" + -0.099*\"voltag\" + 0.096*\"network\"'),\n",
       " (3,\n",
       "  '0.670*\"memori\" + -0.339*\"commun\" + 0.282*\"cell\" + -0.200*\"handl\" + -0.174*\"semiconductor\" + -0.167*\"inform\" + 0.140*\"non-volatil\" + -0.122*\"wireless\" + -0.113*\"devic\" + 0.113*\"form\"'),\n",
       " (4,\n",
       "  '-0.562*\",\" + -0.303*\"imag\" + -0.261*\"apparatu\" + 0.234*\"system\" + 0.232*\"handl\" + 0.211*\"manag\" + -0.187*\"display\" + 0.182*\"power\" + 0.160*\"network\" + 0.153*\"inform\"'),\n",
       " (5,\n",
       "  '-0.575*\"fiber\" + -0.542*\"optic\" + -0.274*\"connector\" + -0.274*\"cabl\" + 0.178*\"handl\" + 0.176*\"inform\" + 0.135*\",\" + -0.105*\"with\" + -0.103*\"modul\" + -0.092*\"assembl\"'),\n",
       " (6,\n",
       "  '-0.512*\"handl\" + -0.420*\"inform\" + 0.367*\"commun\" + 0.242*\"network\" + -0.237*\"game\" + -0.178*\"system\" + 0.169*\"data\" + 0.154*\"wireless\" + -0.140*\"display\" + -0.134*\",\"'),\n",
       " (7,\n",
       "  '-0.834*\"game\" + -0.332*\"wager\" + -0.235*\"machin\" + 0.200*\"handl\" + 0.163*\"inform\" + -0.089*\"with\" + -0.083*\"commun\" + -0.066*\"featur\" + -0.057*\"network\" + -0.053*\"control\"'),\n",
       " (8,\n",
       "  '-0.500*\"light\" + -0.366*\"display\" + -0.282*\"organ\" + -0.271*\"emit\" + 0.257*\",\" + 0.234*\"form\" + -0.205*\"devic\" + 0.166*\"semiconductor\" + -0.147*\"same\" + -0.147*\"the\"'),\n",
       " (9,\n",
       "  '-0.462*\",\" + -0.330*\"network\" + 0.306*\"imag\" + 0.266*\"apparatu\" + 0.217*\"power\" + -0.216*\"memori\" + -0.196*\"commun\" + -0.156*\"devic\" + 0.146*\"form\" + 0.127*\"structur\"')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "559f39cb-0eac-1582-7389-c333e3442ef2",
    "_uuid": "e4c3248e26efd60d237a66916fedfa26a4c4a0df"
   },
   "source": [
    "Here are the scoring outputs for the first five documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "bf72f7e6-7ef2-1bbd-bbb3-e9cd794b141b",
    "_uuid": "0459874d0abc366aec8dcdce86e66bd97854a3c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.025505913724665038), (1, 0.027499880322717597), (2, 0.01426593619606057), (3, 0.0009908453639730559), (4, 0.010034513755037638), (5, 0.0031677506319896455), (6, 0.007341945673440692), (7, 0.0010426105087261027), (8, 0.0016127075703606755), (9, 0.00579595984066685)]\n",
      "[(0, 0.026358616443681843), (1, 0.007150780195027558), (2, -0.0015753877055622715), (3, 0.004530836932058682), (4, 0.003458390186545298), (5, -0.010173937921073961), (6, -0.002085055067646866), (7, -0.006282638143009672), (8, 0.0010517417740392848), (9, 0.016492222014504534)]\n",
      "[(0, 0.2644780037895393), (1, 0.226591928943143), (2, 0.11033380073002112), (3, -0.15922000707781936), (4, 0.02501138178478588), (5, 0.028925162486698443), (6, 0.20785703694213398), (7, -0.027280712424837966), (8, 0.014817728795491708), (9, 0.061294115583082016)]\n",
      "[(0, 0.13510394049920565), (1, 0.11694971928301032), (2, 0.03056331831469064), (3, 0.04932630336538833), (4, -0.11597052146596132), (5, 0.04686238922327079), (6, -0.04655090311702373), (7, 0.007934108350630974), (8, 0.07063122101605415), (9, -0.1148270517809842)]\n",
      "[(0, 0.0286447520311875), (1, 0.007935230881030701), (2, 0.008228065176593103), (3, -0.0011000754532729624), (4, 0.0055026208601350185), (5, -0.003913668226155092), (6, -0.007901600211266785), (7, -0.004377101355498305), (8, 0.0016215459293438608), (9, 0.015047759259422713)]\n"
     ]
    }
   ],
   "source": [
    "for scores in corpus_lsi[:5]:\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dc8c50e4-e263-e096-4621-03525d313a7e",
    "_uuid": "c3749b4167e643243ced4bcfa5632eb65f2a8532"
   },
   "source": [
    "Let's use these scores to fetch best-fit classifications for all of our (classifiable) patents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "2855d4ee-942f-bab2-24ae-945f9dbe964b",
    "_uuid": "c0ec09a35227b0aabc68f8f87358fac3e9a10b7f"
   },
   "outputs": [],
   "source": [
    "classifications = [np.argmax(np.asarray(corpus_lsi[i])[:,1]) for i in range(len(stemmed_title_common_words_nonnull))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "2b163046-d124-280e-14e2-d4eb507226a7",
    "_uuid": "640891eaa88911fd277efd1bab86a2385d93b1ce"
   },
   "outputs": [],
   "source": [
    "topics = pd.DataFrame({'topic': classifications, 'title': classifiable_titles})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "779ee546-f01f-e29a-c4d4-b77a9fbe2cce",
    "_uuid": "643ac124e4847bcab348c09265f8df035dba3157"
   },
   "source": [
    "Certain topics that our classifier arrives at are much more common than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "87afe15d-49cd-6681-c6ce-d0b3c711c07e",
    "_uuid": "749f7da0076ac8a18b13ef1a4f6dcaac41bd58c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    242086\n",
       "1     39351\n",
       "9     31661\n",
       "3     23469\n",
       "4     12435\n",
       "6     11829\n",
       "8      8925\n",
       "5       387\n",
       "7       238\n",
       "2        41\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bbc408a1-9600-242e-535b-d2edf4ea1c3a",
    "_uuid": "e4bd9cb470440a7cfd6755547408b37dc6920345"
   },
   "source": [
    "Let's see what our classes look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "e5def6a0-bb67-d8b7-494b-2e805280cdbc",
    "_uuid": "cb4b6c1ed4e302698b1fe83c04c3eb089c0fe4d8"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "af6f01a6-b517-5682-fcb3-10dbf24f6683",
    "_uuid": "22e35b6529e99ef5a2f4689f8fd63831820d5539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[Method, Of, Treating, Intraoccular, Tissue, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[Method, And, Apparatus, For, Providing, An, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[Computer-Implemented, Method, ,, System, And,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[Selecting, Graphical, Component, Types, At, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[Removal, Of, High, Molecular, Weight, Aggrega...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                                              title\n",
       "1      0  [Method, Of, Treating, Intraoccular, Tissue, P...\n",
       "2      0  [Method, And, Apparatus, For, Providing, An, E...\n",
       "3      0  [Computer-Implemented, Method, ,, System, And,...\n",
       "4      0  [Selecting, Graphical, Component, Types, At, R...\n",
       "5      0  [Removal, Of, High, Molecular, Weight, Aggrega..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Relevance, Sorting, For, Database, Searches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>[Implicit, Searching, For, Mobile, Content]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>[Physical, Navigation, Of, A, Mobile, Search, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>[Call, Control, Server]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>[Methods, And, Apparatus, For, Communicating, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                              title\n",
       "0       1      [Relevance, Sorting, For, Database, Searches]\n",
       "19      1        [Implicit, Searching, For, Mobile, Content]\n",
       "30      1  [Physical, Navigation, Of, A, Mobile, Search, ...\n",
       "53      1                            [Call, Control, Server]\n",
       "54      1  [Methods, And, Apparatus, For, Communicating, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>2</td>\n",
       "      <td>[Headphones]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34413</th>\n",
       "      <td>2</td>\n",
       "      <td>[Computer, Console, Case]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38916</th>\n",
       "      <td>2</td>\n",
       "      <td>[Computer, Console, Case]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43419</th>\n",
       "      <td>2</td>\n",
       "      <td>[Computer, Console, Case]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49696</th>\n",
       "      <td>2</td>\n",
       "      <td>[Keyscreen]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic                      title\n",
       "8962       2               [Headphones]\n",
       "34413      2  [Computer, Console, Case]\n",
       "38916      2  [Computer, Console, Case]\n",
       "43419      2  [Computer, Console, Case]\n",
       "49696      2                [Keyscreen]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3</td>\n",
       "      <td>[Driver, For, Non-Linear, Displays, Comprising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3</td>\n",
       "      <td>[Erasable, And, Programmable, Non-Volatile, Cell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>3</td>\n",
       "      <td>[Method, And, System, For, Accelerated, Access...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>3</td>\n",
       "      <td>[Two-Dimensional, Data, Memory]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3</td>\n",
       "      <td>[Error, Correction, Scheme, For, Use, In, Flas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                              title\n",
       "178      3  [Driver, For, Non-Linear, Displays, Comprising...\n",
       "198      3  [Erasable, And, Programmable, Non-Volatile, Cell]\n",
       "232      3  [Method, And, System, For, Accelerated, Access...\n",
       "256      3                    [Two-Dimensional, Data, Memory]\n",
       "322      3  [Error, Correction, Scheme, For, Use, In, Flas..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>[Resource, Consumption, Reduction, Via, Meetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>4</td>\n",
       "      <td>[Antenna, Configuration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>4</td>\n",
       "      <td>[Data, Carrier, For, Storing, Information, Rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4</td>\n",
       "      <td>[Digital, Rights, Management, Unit, For, A, Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>4</td>\n",
       "      <td>[Non-Linear, Distribution, Of, Voltage, Steps,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                              title\n",
       "40       4  [Resource, Consumption, Reduction, Via, Meetin...\n",
       "157      4                           [Antenna, Configuration]\n",
       "291      4  [Data, Carrier, For, Storing, Information, Rep...\n",
       "320      4  [Digital, Rights, Management, Unit, For, A, Di...\n",
       "524      4  [Non-Linear, Distribution, Of, Voltage, Steps,..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>5</td>\n",
       "      <td>[Method, Of, Calling, Up, Object-Specific, Inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>5</td>\n",
       "      <td>[Collecting, Information, Before, A, Call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>5</td>\n",
       "      <td>[Collecting, Information, Before, A, Call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>5</td>\n",
       "      <td>[Collecting, Information, Before, A, Call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>5</td>\n",
       "      <td>[Telephony, Usage, Derived, Presence, Informat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title\n",
       "285       5  [Method, Of, Calling, Up, Object-Specific, Inf...\n",
       "2050      5         [Collecting, Information, Before, A, Call]\n",
       "2557      5         [Collecting, Information, Before, A, Call]\n",
       "3357      5         [Collecting, Information, Before, A, Call]\n",
       "3963      5  [Telephony, Usage, Derived, Presence, Informat..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[Communication, Station, For, Communication, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>[Mobile, Search, Substring, Query, Completion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>[Creation, Of, A, Mobile, Search, Suggestion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>[Mobile, Pay-Per-Call, Campaign, Creation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>[Mobile, Pay-Per-Call, Campaign, Creation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                              title\n",
       "6       6  [Communication, Station, For, Communication, W...\n",
       "18      6     [Mobile, Search, Substring, Query, Completion]\n",
       "20      6  [Creation, Of, A, Mobile, Search, Suggestion, ...\n",
       "21      6         [Mobile, Pay-Per-Call, Campaign, Creation]\n",
       "22      6         [Mobile, Pay-Per-Call, Campaign, Creation]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>7</td>\n",
       "      <td>[Buddy, Lists, For, Information, Vehicles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>7</td>\n",
       "      <td>[Paper, Sheet, Handling, Apparatus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>7</td>\n",
       "      <td>[Setting, User-Preference, Information, On, Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22857</th>\n",
       "      <td>7</td>\n",
       "      <td>[Oral, Irrigator, Housing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22860</th>\n",
       "      <td>7</td>\n",
       "      <td>[Oral, Irrigator, Housing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic                                              title\n",
       "4809       7         [Buddy, Lists, For, Information, Vehicles]\n",
       "5255       7                [Paper, Sheet, Handling, Apparatus]\n",
       "9900       7  [Setting, User-Preference, Information, On, Th...\n",
       "22857      7                         [Oral, Irrigator, Housing]\n",
       "22860      7                         [Oral, Irrigator, Housing]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>8</td>\n",
       "      <td>[Connector, For, Chip-Card]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>8</td>\n",
       "      <td>[Multitrack, Optical, Disc, Reader]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>8</td>\n",
       "      <td>[Low-Voltage, ,, Low-Skew, Differential, Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>8</td>\n",
       "      <td>[High-Speed, ,, Low-Power, ,, Low-Skew, ,, Low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>8</td>\n",
       "      <td>[Coil, Construction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title\n",
       "618       8                        [Connector, For, Chip-Card]\n",
       "717       8                [Multitrack, Optical, Disc, Reader]\n",
       "1007      8  [Low-Voltage, ,, Low-Skew, Differential, Trans...\n",
       "1017      8  [High-Speed, ,, Low-Power, ,, Low-Skew, ,, Low...\n",
       "1213      8                               [Coil, Construction]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>[Image-Guided, Laser, Catheter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>9</td>\n",
       "      <td>[Sensor, Arrangement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>9</td>\n",
       "      <td>[Power, Converter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>9</td>\n",
       "      <td>[Acceptance, Filter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>9</td>\n",
       "      <td>[Power, Optimized, Collocated, Motion, Estimat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                              title\n",
       "37      9                    [Image-Guided, Laser, Catheter]\n",
       "69      9                              [Sensor, Arrangement]\n",
       "74      9                                 [Power, Converter]\n",
       "75      9                               [Acceptance, Filter]\n",
       "78      9  [Power, Optimized, Collocated, Motion, Estimat..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Topic\", i + 1)\n",
    "    display(topics.query('topic == @i').head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d9e8e42-4304-2cf3-cdda-dcfc4da4df63",
    "_uuid": "c39ad63c5f2dbcd521056dd097b3f5ff6671ee77"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "It's uncertain that our classifier found a \"good\" representation of our title data. Certainly I think that `METHOD OF TREATING INTRAOCCULAR TISSUE PATHOLOGIES` and `Selecting graphical component types at runtime` should find their way to seperate classes.\n",
    "\n",
    "However, given the low volume of information contained in a simple patent title&mdash;in some cases these titles are just one or two words long!&mdash;this is clearly just about the best that we can do.\n",
    "\n",
    "`TF-IDF` is not unique to `gensim`; it is also available in `scikit-learn`, among other places. `gensim` is a high-capacity but low-level library, and a classifier with very performance in much less code also on this data is available [here](https://www.kaggle.com/the1owl/d/uspto/patent-assignment-daily/exploring-daily-patent-assignments-files).\n",
    "\n",
    "Nevertheless, with \"wider\" datasets `gensim` models should be the most performant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d89701d-7a4d-5122-172d-e432a7f0e7dd",
    "_uuid": "b2b9f4a773df328119f0de2303185e420351c174"
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "* http://www.nltk.org/book/ch01.html\n",
    "* https://radimrehurek.com/gensim/tutorial.html\n",
    "* https://www.youtube.com/watch?v=oqfKz-PP9FU"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
