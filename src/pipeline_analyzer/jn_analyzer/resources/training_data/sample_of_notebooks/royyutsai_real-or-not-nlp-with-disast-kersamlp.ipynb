{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "33792bbe-6238-49ae-bc58-15df539f2d2d",
    "_uuid": "a9ffb41a-d4f5-4b15-a008-3865f3df3a57"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n",
    "sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 21637)\n",
      "(1, 21637)\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "(1, 21637)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n",
    "print(train_vectors.shape)\n",
    "print(train_vectors[0].todense().shape)\n",
    "print(train_vectors[0].todense())\n",
    "print(test_vectors[0].todense().shape)\n",
    "## Train\n",
    "# input: train_vectors\n",
    "# output: train_df[\"target\"]\n",
    "## Test\n",
    "# input: test_vectors\n",
    "# output: sample_submission[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_vectors[:-800]\n",
    "train_y = train_df[\"target\"][:-800]\n",
    "test_x = train_vectors[7000:7600]\n",
    "test_y = train_df[\"target\"][7000:7600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(train_vectors, train_df[\"target\"])\n",
    "# sample_submission[\"target\"] = clf.predict(test_vectors)\n",
    "# print(sample_submission.head())\n",
    "# sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6813/6813 [==============================] - 16s 2ms/step - loss: 0.4877 - accuracy: 0.7738\n",
      "Epoch 2/10\n",
      "6813/6813 [==============================] - 17s 2ms/step - loss: 0.2210 - accuracy: 0.9157\n",
      "Epoch 3/10\n",
      "6813/6813 [==============================] - 16s 2ms/step - loss: 0.0912 - accuracy: 0.9642\n",
      "Epoch 4/10\n",
      "6813/6813 [==============================] - 16s 2ms/step - loss: 0.0560 - accuracy: 0.9775\n",
      "Epoch 5/10\n",
      "6813/6813 [==============================] - 16s 2ms/step - loss: 0.0399 - accuracy: 0.9821\n",
      "Epoch 6/10\n",
      "6813/6813 [==============================] - 16s 2ms/step - loss: 0.0310 - accuracy: 0.9847\n",
      "Epoch 7/10\n",
      "6813/6813 [==============================] - 16s 2ms/step - loss: 0.0262 - accuracy: 0.9872\n",
      "Epoch 8/10\n",
      "6813/6813 [==============================] - 16s 2ms/step - loss: 0.0242 - accuracy: 0.9881\n",
      "Epoch 9/10\n",
      "6813/6813 [==============================] - 16s 2ms/step - loss: 0.0236 - accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "6813/6813 [==============================] - 17s 2ms/step - loss: 0.0237 - accuracy: 0.9894\n",
      "600/600 [==============================] - 0s 174us/step\n",
      "Accuracy: 77.00\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=train_vectors[0].todense().shape[1], activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "## Train\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=5)\n",
    "_, accuracy = model.evaluate(test_x, test_y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  target\n",
      "0   0       0\n",
      "1   2       1\n",
      "2   3       1\n",
      "3   9       1\n",
      "4  11       1\n",
      "    id  target\n",
      "0    0       0\n",
      "1    2       1\n",
      "2    3       1\n",
      "3    9       1\n",
      "4   11       1\n",
      "5   12       0\n",
      "6   21       0\n",
      "7   22       0\n",
      "8   27       0\n",
      "9   29       0\n",
      "10  30       0\n",
      "11  35       0\n",
      "12  42       0\n",
      "13  43       0\n",
      "14  45       0\n",
      "15  46       0\n",
      "16  47       0\n",
      "17  51       1\n",
      "18  58       0\n",
      "19  60       0\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(test_vectors)\n",
    "# for i in range(5):\n",
    "# \tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))\n",
    "sample_submission[\"target\"] = predictions\n",
    "print(sample_submission.head())\n",
    "print(sample_submission[0:20])\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
