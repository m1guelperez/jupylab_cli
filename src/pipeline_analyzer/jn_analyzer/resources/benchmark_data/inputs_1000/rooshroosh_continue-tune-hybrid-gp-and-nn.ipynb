{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...continue microoptimization \n",
    "V8 => 0.01367 \n",
    "\n",
    "The following kernel here shows how the excellent kernel [here](https://www.kaggle.com/scirpus/hybrid-gp-and-nn) may benefit from adding some regularisation. Overfitting was suspected because the validation scores on the neural network were considerably below the public leaderboard score. [scirpus](https://www.kaggle.com/scirpus) produces a lot of high quality kernels for Kaggle so please be sure to upvote the kernel listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.layers import Dropout, PReLU, BatchNormalization, ELU, GaussianNoise, Activation\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2020/train.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/test.csv.encrypted\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/sample_submission.csv.encrypted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', usecols=['GameId', 'PlayId', 'Team', 'X', 'Y', 'S', 'A', 'Dis',\n",
    "                                                                               'Orientation', 'Dir', 'NflId', 'DisplayName', 'YardLine',\n",
    "                                                                               'Quarter', 'GameClock', 'PossessionTeam', 'Down', 'Distance',\n",
    "                                                                               'FieldPosition', 'NflIdRusher', 'OffenseFormation', \n",
    "                                                                               'OffensePersonnel', 'DefendersInTheBox', 'DefensePersonnel', \n",
    "                                                                               'PlayDirection', 'TimeHandoff', 'TimeSnap', 'Yards',\n",
    "                                                                              'WindSpeed', 'Temperature', 'Humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for anchoring offense moving left from {0,0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, deploy=False):\n",
    "    def new_X(x_coordinate, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            return 120.0 - x_coordinate\n",
    "        else:\n",
    "            return x_coordinate\n",
    "\n",
    "    def new_line(rush_team, field_position, yardline):\n",
    "        if rush_team == field_position:\n",
    "            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n",
    "            return 10.0 + yardline\n",
    "        else:\n",
    "            # half the field plus the yards between midfield and the line of scrimmage\n",
    "            return 60.0 + (50 - yardline)\n",
    "\n",
    "    def new_orientation(angle, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            new_angle = 360.0 - angle\n",
    "            if new_angle == 360.0:\n",
    "                new_angle = 0.0\n",
    "            return new_angle\n",
    "        else:\n",
    "            return angle\n",
    "\n",
    "    def euclidean_distance(x1,y1,x2,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def update_yardline(df):\n",
    "        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n",
    "        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n",
    "        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n",
    "\n",
    "        return new_yardline\n",
    "\n",
    "    def update_orientation(df, yardline):\n",
    "        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n",
    "        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "\n",
    "        df = df.drop('YardLine', axis=1)\n",
    "        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "    \n",
    "#     def wind_features(df):\n",
    "#         df['WindSpeed'] = df['WindSpeed'].apply(lambda x: str(x).lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "#         df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "#         df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "#         return df\n",
    "\n",
    "    def projection_features(df):\n",
    "        rad = 2 * np.pi * (90 - df[['Orientation']]) / 360\n",
    "        v_0 = df['S'].values * np.cos(rad).values.reshape(-1)\n",
    "        v_1 = np.sin(rad).values.reshape(-1)\n",
    "\n",
    "        a_0 = df['A'].values * np.cos(rad).values.reshape(-1)\n",
    "        a_1 = np.sin(rad)\n",
    "\n",
    "        df['v_0'] = v_0\n",
    "        df['v_1'] = v_1\n",
    "        df['a_0'] = a_0\n",
    "        df['a_1'] = a_1\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def back_features(df):\n",
    "        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n",
    "        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n",
    "        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n",
    "        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n",
    "        carriers = carriers.rename(columns={'X':'back_X',\n",
    "                                            'Y':'back_Y'})\n",
    "        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n",
    "\n",
    "        return carriers\n",
    "\n",
    "    def features_relative_to_back(df, carriers):\n",
    "        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n",
    "        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n",
    "        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n",
    "        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n",
    "                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n",
    "                                         .reset_index()\n",
    "        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n",
    "                                   'min_dist','max_dist','mean_dist','std_dist']\n",
    "\n",
    "        return player_distance\n",
    "\n",
    "    def defense_features(df):\n",
    "        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n",
    "        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n",
    "\n",
    "        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n",
    "        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n",
    "        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        defense = defense.groupby(['GameId','PlayId'])\\\n",
    "                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n",
    "                         .reset_index()\n",
    "        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n",
    "\n",
    "\n",
    "        return defense\n",
    "\n",
    "    def static_features(df):\n",
    "        static_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n",
    "                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n",
    "        static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n",
    "\n",
    "        return static_features\n",
    "\n",
    "\n",
    "    def combine_features(relative_to_back, defense, static, speed_frame, deploy=deploy):\n",
    "        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n",
    "        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n",
    "        df = pd.merge(df, speed_frame, on=['GameId','PlayId'],how='inner')\n",
    "        if not deploy:\n",
    "            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "    \n",
    "#     df = wind_features(df)\n",
    "    df = projection_features(df)\n",
    "    speed_frame= df[['GameId','PlayId',\n",
    "#                      'WindSpeed',\n",
    "                     'a_0','a_1','v_0','v_1', 'Temperature', 'Humidity']]\n",
    "    \n",
    "    yardline = update_yardline(df)\n",
    "    df = update_orientation(df, yardline)\n",
    "    back_feats = back_features(df)\n",
    "    rel_back = features_relative_to_back(df, back_feats)\n",
    "    def_feats = defense_features(df)\n",
    "    static_feats = static_features(df)\n",
    "    basetable = combine_features(rel_back, def_feats, static_feats,  speed_frame, deploy=deploy)\n",
    "    basetable[['a_0','a_1','v_0','v_1']] = basetable[['a_0','a_1','v_0','v_1']].fillna(0)\n",
    "    basetable['Temperature'] = basetable['Temperature'].fillna(60.436442)\n",
    "    basetable['Humidity'] =     basetable['Humidity'].fillna(59.0)\n",
    "    return basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['WindSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 1.76 s, total: 2min 28s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%time train_basetable = create_features(train, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's split our data into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_basetable.copy()\n",
    "yards = X.Yards\n",
    "\n",
    "y = np.zeros((yards.shape[0], 1))\n",
    "_y =  np.zeros((yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(yards)):\n",
    "    y[idx] = target#[99 + target] = 1\n",
    "    _y[idx][99 + target] = 1\n",
    "\n",
    "X.drop(['GameId','PlayId','Yards'], axis=1, inplace=True)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below class Metric based entirely on: https://www.kaggle.com/kingychiu/keras-nn-starter-crps-early-stopping\n",
    "<br></br>\n",
    "Below early stopping entirely based on: https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112868#latest-656533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(size=X.shape[1]):\n",
    "    model = Sequential()\n",
    "    model.add(GaussianNoise(0.05))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, input_dim=size, activation=None))\n",
    "    model.add(ELU())\n",
    "    model.add(GaussianNoise(0.05))\n",
    "    model.add(Dropout(0.5)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation=None))\n",
    "    model.add(ELU())\n",
    "    model.add(GaussianNoise(0.05))\n",
    "#     model.add(Dropout(0.2))\n",
    "     #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation=None))\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='mae')\n",
    "   \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_v2(size=X.shape[1]):\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=size, activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.5)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "    model.add(Dense(256, activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "#     model.add(Dropout(0.2))\n",
    "     #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "    model.add(BatchNormalization())\n",
    "     #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "    model.add(Dense(199, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=0.0005), loss='categorical_crossentropy', metrics=[])\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 463628 samples, validate on 46134 samples\n",
      "Epoch 1/200\n",
      "463628/463628 [==============================] - 16s 35us/step - loss: 3.5837 - val_loss: 3.3790\n",
      "Epoch 2/200\n",
      "463628/463628 [==============================] - 15s 33us/step - loss: 3.3936 - val_loss: 3.3412\n",
      "Epoch 3/200\n",
      "463628/463628 [==============================] - 15s 33us/step - loss: 3.3651 - val_loss: 3.3533\n",
      "Epoch 4/200\n",
      "463628/463628 [==============================] - 15s 33us/step - loss: 3.3495 - val_loss: 3.3364\n",
      "Epoch 5/200\n",
      "463628/463628 [==============================] - 15s 33us/step - loss: 3.3380 - val_loss: 3.3255\n",
      "Epoch 6/200\n",
      "463628/463628 [==============================] - 15s 32us/step - loss: 3.3270 - val_loss: 3.3271\n",
      "Epoch 7/200\n",
      "463628/463628 [==============================] - 15s 32us/step - loss: 3.3186 - val_loss: 3.3284\n",
      "Epoch 8/200\n",
      "463628/463628 [==============================] - 15s 32us/step - loss: 3.3082 - val_loss: 3.3248\n",
      "Epoch 9/200\n",
      "463628/463628 [==============================] - 16s 34us/step - loss: 3.3019 - val_loss: 3.3408\n",
      "Epoch 10/200\n",
      "463628/463628 [==============================] - 15s 32us/step - loss: 3.2938 - val_loss: 3.3416\n",
      "Epoch 11/200\n",
      "463628/463628 [==============================] - 15s 33us/step - loss: 3.2848 - val_loss: 3.3338\n",
      "Epoch 12/200\n",
      "463628/463628 [==============================] - 15s 33us/step - loss: 3.2771 - val_loss: 3.3391\n",
      "Epoch 13/200\n",
      "463628/463628 [==============================] - 15s 33us/step - loss: 3.2681 - val_loss: 3.3524\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00013: early stopping\n",
      "1\n",
      "Train on 463760 samples, validate on 46002 samples\n",
      "Epoch 1/200\n",
      "463760/463760 [==============================] - 16s 35us/step - loss: 3.5773 - val_loss: 3.4205\n",
      "Epoch 2/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.3880 - val_loss: 3.3957\n",
      "Epoch 3/200\n",
      "463760/463760 [==============================] - 16s 34us/step - loss: 3.3611 - val_loss: 3.3854\n",
      "Epoch 4/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.3428 - val_loss: 3.3751\n",
      "Epoch 5/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.3323 - val_loss: 3.3792\n",
      "Epoch 6/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.3236 - val_loss: 3.3793\n",
      "Epoch 7/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.3164 - val_loss: 3.3751\n",
      "Epoch 8/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.3059 - val_loss: 3.3702\n",
      "Epoch 9/200\n",
      "463760/463760 [==============================] - 15s 33us/step - loss: 3.2984 - val_loss: 3.3771\n",
      "Epoch 10/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.2912 - val_loss: 3.3780\n",
      "Epoch 11/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.2823 - val_loss: 3.3635\n",
      "Epoch 12/200\n",
      "463760/463760 [==============================] - 15s 32us/step - loss: 3.2736 - val_loss: 3.3696\n",
      "Epoch 13/200\n",
      "463760/463760 [==============================] - 15s 33us/step - loss: 3.2651 - val_loss: 3.3696\n",
      "Epoch 14/200\n",
      "463122/463122 [==============================] - 16s 35us/step - loss: 3.5797 - val_loss: 3.4325\n",
      "Epoch 2/200\n",
      "463122/463122 [==============================] - 15s 33us/step - loss: 3.3898 - val_loss: 3.4113\n",
      "Epoch 3/200\n",
      "463144/463144 [==============================] - 15s 32us/step - loss: 3.3372 - val_loss: 3.3503\n",
      "Epoch 6/200\n",
      "463144/463144 [==============================] - 15s 32us/step - loss: 3.3277 - val_loss: 3.3561\n",
      "Epoch 7/200\n",
      "463144/463144 [==============================] - 15s 33us/step - loss: 3.3190 - val_loss: 3.3478\n",
      "Epoch 8/200\n",
      "463144/463144 [==============================] - 15s 33us/step - loss: 3.3103 - val_loss: 3.3452\n",
      "Epoch 9/200\n",
      "463144/463144 [==============================] - 15s 33us/step - loss: 3.3037 - val_loss: 3.3444\n",
      "Epoch 10/200\n",
      "463144/463144 [==============================] - 15s 32us/step - loss: 3.2957 - val_loss: 3.3456\n",
      "Epoch 11/200\n",
      "463144/463144 [==============================] - 15s 33us/step - loss: 3.2893 - val_loss: 3.3469\n",
      "Epoch 12/200\n",
      "463144/463144 [==============================] - 16s 34us/step - loss: 3.2787 - val_loss: 3.3494\n",
      "Epoch 13/200\n",
      "463144/463144 [==============================] - 15s 33us/step - loss: 3.2711 - val_loss: 3.3433\n",
      "Epoch 14/200\n",
      "463144/463144 [==============================] - 15s 33us/step - loss: 3.2628 - val_loss: 3.3473\n",
      "Epoch 15/200\n",
      "463144/463144 [==============================] - 15s 33us/step - loss: 3.2519 - val_loss: 3.3490\n",
      "Epoch 16/200\n",
      "463144/463144 [==============================] - 15s 32us/step - loss: 3.2440 - val_loss: 3.3487\n",
      "Epoch 17/200\n",
      "463144/463144 [==============================] - 15s 32us/step - loss: 3.2362 - val_loss: 3.3457\n",
      "Epoch 18/200\n",
      "463144/463144 [==============================] - 16s 33us/step - loss: 3.2277 - val_loss: 3.3623\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "5\n",
      "Train on 463166 samples, validate on 46596 samples\n",
      "Epoch 1/200\n",
      "463166/463166 [==============================] - 16s 35us/step - loss: 3.5631 - val_loss: 3.5373\n",
      "Epoch 2/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.3717 - val_loss: 3.5270\n",
      "Epoch 3/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.3489 - val_loss: 3.5138\n",
      "Epoch 4/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.3330 - val_loss: 3.4918\n",
      "Epoch 5/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.3206 - val_loss: 3.5050\n",
      "Epoch 6/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.3118 - val_loss: 3.4854\n",
      "Epoch 7/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.3028 - val_loss: 3.4899\n",
      "Epoch 8/200\n",
      "463166/463166 [==============================] - 15s 32us/step - loss: 3.2945 - val_loss: 3.4896\n",
      "Epoch 9/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.2853 - val_loss: 3.4875\n",
      "Epoch 10/200\n",
      "463166/463166 [==============================] - 15s 32us/step - loss: 3.2770 - val_loss: 3.4848\n",
      "Epoch 11/200\n",
      "463166/463166 [==============================] - 15s 32us/step - loss: 3.2670 - val_loss: 3.4996\n",
      "Epoch 12/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.2586 - val_loss: 3.4916\n",
      "Epoch 13/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.2504 - val_loss: 3.4813\n",
      "Epoch 14/200\n",
      "463166/463166 [==============================] - 16s 34us/step - loss: 3.2439 - val_loss: 3.4981\n",
      "Epoch 15/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.2372 - val_loss: 3.5092\n",
      "Epoch 16/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.2239 - val_loss: 3.4881\n",
      "Epoch 17/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.2155 - val_loss: 3.4992\n",
      "Epoch 18/200\n",
      "463166/463166 [==============================] - 15s 33us/step - loss: 3.2109 - val_loss: 3.4943\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "6\n",
      "Train on 463166 samples, validate on 46596 samples\n",
      "Epoch 1/200\n",
      "463166/463166 [==============================] - 16s 35us/step - loss: 3.5719 - val_loss: 3.4926\n",
      "Epoch 2/200\n",
      " 23552/463166 [>.............................] - ETA: 14s - loss: 3.4097"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "oof_predictions = np.zeros(shape=(X.shape[0]))\n",
    "\n",
    "rkf = GroupKFold(11)\n",
    "FOLD_LIST = list(rkf.split(train_basetable['GameId'],train_basetable['GameId'],train_basetable['GameId']))\n",
    "\n",
    "for fold_id, (tr_idx, vl_idx) in enumerate(FOLD_LIST):\n",
    "    \n",
    "    print(fold_id)\n",
    "\n",
    "    x_tr, y_tr = X[tr_idx], y[tr_idx]\n",
    "    x_vl, y_vl = X[vl_idx], y[vl_idx]    \n",
    "\n",
    "    model= get_model(X.shape[1])\n",
    "    es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=1, \n",
    "                   patience=5)\n",
    "#     es.set_model(model)\n",
    "\n",
    "    model.fit(x_tr, y_tr, epochs=200, batch_size=1024, validation_data=[x_vl, y_vl], callbacks=[es])\n",
    "    oof_predictions[vl_idx] += model.predict(x_vl).reshape(-1)\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD/ZJREFUeJzt3X+s3XV9x/Hna0XU6BSUakjLVjb7h2gyfzRI4rIYdVBgWVkiC2yZnSHpYiDRZMks/gNTWeqyiWNTEiaNxTgr8cdotIZ1iHFLFCnqgNIw7rCTOxpaU0SIUYO+98f9VE/u59zecy+9Pee0z0dyc77f9/dzzn2fntO++vl+v+d7UlVIkjTo18bdgCRp8hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6pw27gaW66yzzqp169aNuw1Jmhr33XffD6pq9ShjpzYc1q1bx969e8fdhiRNjST/O+pYdytJkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjpT+wlpTZZ1W7/8y+UD2y4dYyeSjgdnDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSep4KquWbfD01YXqntYqTSdnDpKkjuEgSeoYDpKkjscctCQLHWeQdHIZeeaQZFWS7yT5Uls/N8k9SR5J8tkkp7f689v6TNu+buAxrm31h5NcNFDf2GozSbYev6cnSVqOpexWeg+wf2D9w8CNVbUeeBK4qtWvAp6sqlcBN7ZxJDkPuAJ4DbAR+HgLnFXAx4CLgfOAK9tYSdKYjBQOSdYClwKfaOsB3gp8rg3ZAVzWlje1ddr2t7Xxm4CdVfXTqvoeMAOc335mqurRqvoZsLONlSSNyagzh48CfwX8oq2/HPhhVT3b1meBNW15DfAYQNv+VBv/y/q8+yxU7yTZkmRvkr2HDx8esXVJ0lItGg5J/gA4VFX3DZaHDK1Fti213herbqmqDVW1YfXq1cfoWpL0XIxyttKbgT9McgnwAuAlzM0kzkhyWpsdrAUeb+NngXOA2SSnAS8FjgzUjxq8z0J1SdIYLDpzqKprq2ptVa1j7oDyV6vqT4G7gXe0YZuBO9ryrrZO2/7VqqpWv6KdzXQusB74FnAvsL6d/XR6+x27jsuzkyQty3P5nMP7gJ1JPgR8B7i11W8FPpVkhrkZwxUAVbUvye3AQ8CzwNVV9XOAJNcAdwKrgO1Vte859CVJeo6WFA5V9TXga235UebONJo/5ifA5Qvc/wbghiH13cDupfQiSVo5Xj5DktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHb8JTovy29+kU48zB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHU8lVUravA02APbLh1jJ5KWwpmDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOqeNuwFNpnVbvzzuFiSN0aIzhyQvSPKtJP+VZF+Sv271c5Pck+SRJJ9NcnqrP7+tz7Tt6wYe69pWfzjJRQP1ja02k2Tr8X+akqSlGGW30k+Bt1bV7wCvAzYmuQD4MHBjVa0HngSuauOvAp6sqlcBN7ZxJDkPuAJ4DbAR+HiSVUlWAR8DLgbOA65sYyVJY7LobqWqKuCZtvq89lPAW4E/afUdwPXAzcCmtgzwOeCfkqTVd1bVT4HvJZkBzm/jZqrqUYAkO9vYh57LE9PkGdxVdWDbpWPsRNJiRjog3f6H/13gELAH+B/gh1X1bBsyC6xpy2uAxwDa9qeAlw/W591nofqwPrYk2Ztk7+HDh0dpXZK0DCOFQ1X9vKpeB6xl7n/7rx42rN1mgW1LrQ/r45aq2lBVG1avXr1445KkZVnSqaxV9UPga8AFwBlJju6WWgs83pZngXMA2vaXAkcG6/Pus1BdkjQmo5yttDrJGW35hcDbgf3A3cA72rDNwB1teVdbp23/ajtusQu4op3NdC6wHvgWcC+wvp39dDpzB613HY8nJ0lanlE+53A2sKOdVfRrwO1V9aUkDwE7k3wI+A5waxt/K/CpdsD5CHP/2FNV+5LcztyB5meBq6vq5wBJrgHuBFYB26tq33F7hpKkJRvlbKX7gdcPqT/Kr842Gqz/BLh8gce6AbhhSH03sHuEfiVJJ4CXz5AkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdUa5ZLdOEYPf8Szp1ObMQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLU8dpKGovB6zgd2HbpGDuRNIwzB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx885nOL83mhJwzhzkCR1DAdJUsdwkCR1DAdJUmfRcEhyTpK7k+xPsi/Je1r9ZUn2JHmk3Z7Z6klyU5KZJPcnecPAY21u4x9Jsnmg/sYkD7T73JQkK/FkJUmjGWXm8Czwl1X1auAC4Ook5wFbgbuqaj1wV1sHuBhY3362ADfDXJgA1wFvAs4HrjsaKG3MloH7bXzuT02StFyLhkNVHayqb7flp4H9wBpgE7CjDdsBXNaWNwG31ZxvAmckORu4CNhTVUeq6klgD7CxbXtJVX2jqgq4beCxJEljsKRjDknWAa8H7gFeWVUHYS5AgFe0YWuAxwbuNttqx6rPDqlLksZk5HBI8mLg88B7q+pHxxo6pFbLqA/rYUuSvUn2Hj58eLGWJUnLNFI4JHkec8Hw6ar6Qis/0XYJ0W4PtfoscM7A3dcCjy9SXzuk3qmqW6pqQ1VtWL169SitS5KWYZSzlQLcCuyvqo8MbNoFHD3jaDNwx0D9ne2spQuAp9pupzuBC5Oc2Q5EXwjc2bY9neSC9rveOfBYkqQxGOXaSm8G/gx4IMl3W+39wDbg9iRXAd8HLm/bdgOXADPAj4F3AVTVkSQfBO5t4z5QVUfa8ruBTwIvBL7SfiRJY7JoOFTVfzL8uADA24aML+DqBR5rO7B9SH0v8NrFepEknRh+QlqS1DEcJEkdv89BYzf4nRIHtl06xk4kHeXMQZLUMRwkSR3DQZLU8ZjDKcjvjZa0GGcOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6vhlP6cIv+BH0lI4c5AkdQwHSVLHcJAkdQwHSVLHcJAkdTxbSRNl8KyqA9suHWMn0qnNmYMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqbNoOCTZnuRQkgcHai9LsifJI+32zFZPkpuSzCS5P8kbBu6zuY1/JMnmgfobkzzQ7nNTkhzvJylJWppRZg6fBDbOq20F7qqq9cBdbR3gYmB9+9kC3AxzYQJcB7wJOB+47migtDFbBu43/3dJkk6wRcOhqr4OHJlX3gTsaMs7gMsG6rfVnG8CZyQ5G7gI2FNVR6rqSWAPsLFte0lVfaOqCrht4LEkSWOy3GMOr6yqgwDt9hWtvgZ4bGDcbKsdqz47pC5JGqPjfUB62PGCWkZ9+IMnW5LsTbL38OHDy2xRkrSY5YbDE22XEO32UKvPAucMjFsLPL5Ife2Q+lBVdUtVbaiqDatXr15m65KkxSz3+xx2AZuBbe32joH6NUl2Mnfw+amqOpjkTuBvBg5CXwhcW1VHkjyd5ALgHuCdwD8usyfNM/jdCNPI73aQxmfRcEjyGeAtwFlJZpk762gbcHuSq4DvA5e34buBS4AZ4MfAuwBaCHwQuLeN+0BVHT3I/W7mzoh6IfCV9iNJGqNFw6Gqrlxg09uGjC3g6gUeZzuwfUh9L/DaxfqQJJ04fkJaktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktRZ7iekNaGm/VPRC/HT0tKJ5cxBktQxHCRJHcNBktQxHCRJHcNBktTxbKWTwMl6hpKk8XHmIEnqGA6SpI7hIEnqGA6SpI7hIEnqeLaSpo7XWZJWnjMHSVLHcJAkdQwHSVLHYw5TyE9ES1ppzhwkSR3DQZLUcbeSppqntUorw5mDJKljOEiSOu5W0klj/llc7maSls9wmBKevirpRHK3kiSp48xhgjlbkDQuzhwkSR1nDjpp+RkIafmcOUiSOs4cdEpwFiEtjeEwATzwLGnSGA465TiLkBY3MeGQZCPwD8Aq4BNVtW3MLa0oZwuSJtlEhEOSVcDHgN8HZoF7k+yqqofG29nxZSBMHmcR0nATEQ7A+cBMVT0KkGQnsAmY+nAwEKbHUl8rw0Qns0kJhzXAYwPrs8CbxtRLx3/gNczxChNnL5pEkxIOGVKrblCyBdjSVp9J8vAK9HIW8IMVeNwTxf7Ha8H+8+HF7zzKmBV20v75T4mV7v83Rx04KeEwC5wzsL4WeHz+oKq6BbhlJRtJsreqNqzk71hJ9j9e9j9e9n/8TMonpO8F1ic5N8npwBXArjH3JEmnrImYOVTVs0muAe5k7lTW7VW1b8xtSdIpayLCAaCqdgO7x90HK7zb6gSw//Gy//Gy/+MkVd1xX0nSKW5SjjlIkiaI4TBPkuuT/F+S77afS8bd0yiSbEzycJKZJFvH3c9SJTmQ5IH2Z7533P0sJsn2JIeSPDhQe1mSPUkeabdnjrPHY1mg/6l57yc5J8ndSfYn2ZfkPa0+Fa/BMfqfmNfA3UrzJLkeeKaq/m7cvYyqXX7kvxm4/Ahw5TRdfiTJAWBDVU3FOepJfg94Britql7ban8LHKmqbS2gz6yq942zz4Us0P/1TMl7P8nZwNlV9e0kvw7cB1wG/DlT8Boco/8/ZkJeA2cOJ4dfXn6kqn4GHL38iFZIVX0dODKvvAnY0ZZ3MPeXfSIt0P/UqKqDVfXttvw0sJ+5Ky1MxWtwjP4nhuEw3DVJ7m9T74mcls4z7PIjE/VGG0EB/5bkvvZJ+Gn0yqo6CHN/+YFXjLmf5Zi29z5J1gGvB+5hCl+Def3DhLwGp2Q4JPn3JA8O+dkE3Az8NvA64CDw92NtdjQjXX5kwr25qt4AXAxc3XZ76MSauvd+khcDnwfeW1U/Gnc/SzWk/4l5DSbmcw4nUlW9fZRxSf4Z+NIKt3M8jHT5kUlWVY+320NJvsjcrrKvj7erJXsiydlVdbDtUz407oaWoqqeOLo8De/9JM9j7h/WT1fVF1p5al6DYf1P0mtwSs4cjqW9oY76I+DBhcZOkKm+/EiSF7WDciR5EXAh0/HnPt8uYHNb3gzcMcZelmya3vtJAtwK7K+qjwxsmorXYKH+J+k18GyleZJ8irkpXQEHgL84ug9zkrVT3j7Kry4/csOYWxpZkt8CvthWTwP+ZdL7T/IZ4C3MXUXzCeA64F+B24HfAL4PXF5VE3nQd4H+38KUvPeT/C7wH8ADwC9a+f3M7bef+NfgGP1fyYS8BoaDJKnjbiVJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1/h/75byw0iJUEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(oof_predictions, bins=100)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.28604757207734266, 0.0) SpearmanrResult(correlation=0.41479075007941857, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pearsonr(y.reshape(-1), oof_predictions.reshape(-1)),\n",
    "    spearmanr(y.reshape(-1), oof_predictions.reshape(-1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = np.hstack([X, oof_predictions.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((509762, 29), (509762,), (509762, 30))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, oof_predictions.shape, _X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(Callback):\n",
    "    def __init__(self, model, callbacks, data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.callbacks = callbacks\n",
    "        self.data = data\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end(logs)\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        logs['tr_CRPS'] = 0\n",
    "\n",
    "        X_valid, y_valid = self.data[1][0], self.data[1][1]\n",
    "\n",
    "        y_pred = self.model.predict(X_valid)\n",
    "        y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "        val_s = np.round(val_s, 6)\n",
    "        logs['val_CRPS'] = val_s\n",
    "        print('tr CRPS', 'Grr', 'val CRPS', val_s)\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 463628 samples, validate on 46134 samples\n",
      "Epoch 1/5\n",
      "463628/463628 [==============================] - 19s 41us/step - loss: 3.5683 - val_loss: 2.7727\n",
      "tr CRPS Grr val CRPS 0.012997\n",
      "Epoch 2/5\n",
      "463628/463628 [==============================] - 19s 40us/step - loss: 2.6983 - val_loss: 2.7305\n",
      "tr CRPS Grr val CRPS 0.012857\n",
      "Epoch 3/5\n",
      "463628/463628 [==============================] - 18s 39us/step - loss: 2.6528 - val_loss: 2.7433\n",
      "tr CRPS Grr val CRPS 0.012869\n",
      "Epoch 4/5\n",
      "463628/463628 [==============================] - 19s 40us/step - loss: 2.6169 - val_loss: 2.7632\n",
      "tr CRPS Grr val CRPS 0.012898\n",
      "Epoch 5/5\n",
      "463628/463628 [==============================] - 18s 39us/step - loss: 2.5816 - val_loss: 2.7822\n",
      "tr CRPS Grr val CRPS 0.012891\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "1\n",
      "Train on 463760 samples, validate on 46002 samples\n",
      "Epoch 1/5\n",
      "463760/463760 [==============================] - 19s 42us/step - loss: 3.5671 - val_loss: 2.8116\n",
      "tr CRPS Grr val CRPS 0.012974\n",
      "Epoch 2/5\n",
      "463760/463760 [==============================] - 18s 39us/step - loss: 2.6930 - val_loss: 2.7746\n",
      "tr CRPS Grr val CRPS 0.012925\n",
      "Epoch 3/5\n",
      "463760/463760 [==============================] - 18s 39us/step - loss: 2.6462 - val_loss: 2.7780\n",
      "tr CRPS Grr val CRPS 0.012928\n",
      "Epoch 4/5\n",
      "463760/463760 [==============================] - 18s 39us/step - loss: 2.6117 - val_loss: 2.7912\n",
      "tr CRPS Grr val CRPS 0.012949\n",
      "Epoch 5/5\n",
      "463760/463760 [==============================] - 18s 39us/step - loss: 2.5769 - val_loss: 2.8066\n",
      "tr CRPS Grr val CRPS 0.01297\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "2\n",
      "Train on 463122 samples, validate on 46640 samples\n",
      "Epoch 1/5\n",
      "463122/463122 [==============================] - 20s 42us/step - loss: 3.5784 - val_loss: 2.7731\n",
      "tr CRPS Grr val CRPS 0.01312\n",
      "Epoch 2/5\n",
      "463122/463122 [==============================] - 18s 39us/step - loss: 2.6948 - val_loss: 2.7410\n",
      "tr CRPS Grr val CRPS 0.012977\n",
      "Epoch 3/5\n",
      "463122/463122 [==============================] - 18s 39us/step - loss: 2.6494 - val_loss: 2.7493\n",
      "tr CRPS Grr val CRPS 0.012957\n",
      "Epoch 4/5\n",
      "463122/463122 [==============================] - 18s 39us/step - loss: 2.6140 - val_loss: 2.7627\n",
      "tr CRPS Grr val CRPS 0.01298\n",
      "Epoch 5/5\n",
      "463122/463122 [==============================] - 18s 39us/step - loss: 2.5794 - val_loss: 2.7807\n",
      "tr CRPS Grr val CRPS 0.013001\n",
      "3\n",
      "Train on 463122 samples, validate on 46640 samples\n",
      "Epoch 1/5\n",
      "463122/463122 [==============================] - 19s 41us/step - loss: 3.5756 - val_loss: 2.7695\n",
      "tr CRPS Grr val CRPS 0.012491\n",
      "Epoch 2/5\n",
      "463122/463122 [==============================] - 19s 40us/step - loss: 2.6992 - val_loss: 2.7281\n",
      "tr CRPS Grr val CRPS 0.012284\n",
      "Epoch 3/5\n",
      "463122/463122 [==============================] - 18s 39us/step - loss: 2.6524 - val_loss: 2.7270\n",
      "tr CRPS Grr val CRPS 0.012284\n",
      "Epoch 4/5\n",
      "463122/463122 [==============================] - 18s 39us/step - loss: 2.6170 - val_loss: 2.7463\n",
      "tr CRPS Grr val CRPS 0.012345\n",
      "Epoch 5/5\n",
      "463122/463122 [==============================] - 18s 39us/step - loss: 2.5818 - val_loss: 2.7598\n",
      "tr CRPS Grr val CRPS 0.012328\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "4\n",
      "Train on 463144 samples, validate on 46618 samples\n",
      "Epoch 1/5\n",
      "463144/463144 [==============================] - 19s 41us/step - loss: 3.5702 - val_loss: 2.7497\n",
      "tr CRPS Grr val CRPS 0.012995\n",
      "Epoch 2/5\n",
      "463144/463144 [==============================] - 18s 39us/step - loss: 2.6981 - val_loss: 2.7174\n",
      "tr CRPS Grr val CRPS 0.012855\n",
      "Epoch 3/5\n",
      "463144/463144 [==============================] - 18s 39us/step - loss: 2.6528 - val_loss: 2.7214\n",
      "tr CRPS Grr val CRPS 0.012876\n",
      "Epoch 4/5\n",
      "463144/463144 [==============================] - 18s 39us/step - loss: 2.6175 - val_loss: 2.7351\n",
      "tr CRPS Grr val CRPS 0.012872\n",
      "Epoch 5/5\n",
      "463144/463144 [==============================] - 19s 40us/step - loss: 2.5837 - val_loss: 2.7585\n",
      "tr CRPS Grr val CRPS 0.012901\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "5\n",
      "Train on 463166 samples, validate on 46596 samples\n",
      "Epoch 1/5\n",
      "463166/463166 [==============================] - 19s 42us/step - loss: 3.5624 - val_loss: 2.8051\n",
      "tr CRPS Grr val CRPS 0.013653\n",
      "Epoch 2/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.6953 - val_loss: 2.7636\n",
      "tr CRPS Grr val CRPS 0.013481\n",
      "Epoch 3/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.6492 - val_loss: 2.7722\n",
      "tr CRPS Grr val CRPS 0.013461\n",
      "Epoch 4/5\n",
      "463166/463166 [==============================] - 19s 41us/step - loss: 2.6146 - val_loss: 2.7844\n",
      "tr CRPS Grr val CRPS 0.013515\n",
      "Epoch 5/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.5805 - val_loss: 2.8085\n",
      "tr CRPS Grr val CRPS 0.013591\n",
      "6\n",
      "Train on 463166 samples, validate on 46596 samples\n",
      "Epoch 1/5\n",
      "463166/463166 [==============================] - 19s 41us/step - loss: 3.5688 - val_loss: 2.8371\n",
      "tr CRPS Grr val CRPS 0.013264\n",
      "Epoch 2/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.6929 - val_loss: 2.7954\n",
      "tr CRPS Grr val CRPS 0.013045\n",
      "Epoch 3/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.6477 - val_loss: 2.7965\n",
      "tr CRPS Grr val CRPS 0.013052\n",
      "Epoch 4/5\n",
      "463166/463166 [==============================] - 19s 40us/step - loss: 2.6128 - val_loss: 2.8132\n",
      "tr CRPS Grr val CRPS 0.013069\n",
      "Epoch 5/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.5782 - val_loss: 2.8332\n",
      "tr CRPS Grr val CRPS 0.013076\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "7\n",
      "Train on 463166 samples, validate on 46596 samples\n",
      "Epoch 1/5\n",
      "463166/463166 [==============================] - 19s 41us/step - loss: 3.5749 - val_loss: 2.8140\n",
      "tr CRPS Grr val CRPS 0.013398\n",
      "Epoch 2/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.6955 - val_loss: 2.7617\n",
      "tr CRPS Grr val CRPS 0.013184\n",
      "Epoch 3/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.6496 - val_loss: 2.7643\n",
      "tr CRPS Grr val CRPS 0.013189\n",
      "Epoch 4/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.6146 - val_loss: 2.7758\n",
      "tr CRPS Grr val CRPS 0.013223\n",
      "Epoch 5/5\n",
      "463166/463166 [==============================] - 18s 39us/step - loss: 2.5809 - val_loss: 2.7890\n",
      "tr CRPS Grr val CRPS 0.013226\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "8\n",
      "Train on 463782 samples, validate on 45980 samples\n",
      "Epoch 1/5\n",
      "463782/463782 [==============================] - 19s 42us/step - loss: 3.5743 - val_loss: 2.7545\n",
      "tr CRPS Grr val CRPS 0.01269\n",
      "Epoch 2/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.6986 - val_loss: 2.7221\n",
      "tr CRPS Grr val CRPS 0.012514\n",
      "Epoch 3/5\n",
      "463782/463782 [==============================] - 19s 40us/step - loss: 2.6531 - val_loss: 2.7275\n",
      "tr CRPS Grr val CRPS 0.0125\n",
      "Epoch 4/5\n",
      "463782/463782 [==============================] - 19s 40us/step - loss: 2.6182 - val_loss: 2.7429\n",
      "tr CRPS Grr val CRPS 0.012521\n",
      "Epoch 5/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.5815 - val_loss: 2.7622\n",
      "tr CRPS Grr val CRPS 0.012579\n",
      "9\n",
      "Train on 463782 samples, validate on 45980 samples\n",
      "Epoch 1/5\n",
      "463782/463782 [==============================] - 19s 42us/step - loss: 3.5812 - val_loss: 2.7747\n",
      "tr CRPS Grr val CRPS 0.012554\n",
      "Epoch 2/5\n",
      "463782/463782 [==============================] - 19s 40us/step - loss: 2.6970 - val_loss: 2.7408\n",
      "tr CRPS Grr val CRPS 0.012413\n",
      "Epoch 3/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.6517 - val_loss: 2.7455\n",
      "tr CRPS Grr val CRPS 0.012429\n",
      "Epoch 4/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.6185 - val_loss: 2.7560\n",
      "tr CRPS Grr val CRPS 0.012429\n",
      "Epoch 5/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.5844 - val_loss: 2.7731\n",
      "tr CRPS Grr val CRPS 0.012479\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "10\n",
      "Train on 463782 samples, validate on 45980 samples\n",
      "Epoch 1/5\n",
      "463782/463782 [==============================] - 19s 41us/step - loss: 3.5751 - val_loss: 2.8053\n",
      "tr CRPS Grr val CRPS 0.013033\n",
      "Epoch 2/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.6934 - val_loss: 2.7671\n",
      "tr CRPS Grr val CRPS 0.012861\n",
      "Epoch 3/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.6472 - val_loss: 2.7636\n",
      "tr CRPS Grr val CRPS 0.01287\n",
      "Epoch 4/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.6118 - val_loss: 2.7689\n",
      "tr CRPS Grr val CRPS 0.01286\n",
      "Epoch 5/5\n",
      "463782/463782 [==============================] - 18s 39us/step - loss: 2.5765 - val_loss: 2.7851\n",
      "tr CRPS Grr val CRPS 0.012898\n"
     ]
    }
   ],
   "source": [
    "_models = []\n",
    "oof_predictions = np.zeros(shape=(_X.shape[0]))\n",
    "\n",
    "for fold_id, (tr_idx, vl_idx) in enumerate(FOLD_LIST):\n",
    "    \n",
    "    print(fold_id)\n",
    "\n",
    "    x_tr, y_tr = _X[tr_idx], _y[tr_idx]\n",
    "    x_vl, y_vl = _X[vl_idx], _y[vl_idx]    \n",
    "\n",
    "    model= get_model_v2(_X.shape[1])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_CRPS', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=1, \n",
    "                   patience=3)\n",
    "    es.set_model(model)\n",
    "    \n",
    "    metric = Metric(model, [es], [(x_tr, y_tr), (x_vl, y_vl)])\n",
    "    model.fit(x_tr, y_tr, callbacks=[metric], epochs=5, batch_size=1024, validation_data=[x_vl, y_vl])\n",
    "\n",
    "    _models.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP:\n",
    "    def __init__(self):\n",
    "        self.classes = 20\n",
    "        self.class_names = [ 'class_0',\n",
    "                             'class_1',\n",
    "                             'class_2',\n",
    "                             'class_3',\n",
    "                             'class_4',\n",
    "                             'class_5',\n",
    "                             'class_6',\n",
    "                             'class_7',\n",
    "                             'class_8',\n",
    "                             'class_9',\n",
    "                             'class_10',\n",
    "                             'class_11',\n",
    "                             'class_12',\n",
    "                             'class_13',\n",
    "                            'class_14',\n",
    "                            'class_15',\n",
    "                            'class_16',\n",
    "                            'class_17',\n",
    "                            'class_18',\n",
    "                            'class_19',\n",
    "                           ]\n",
    "\n",
    "\n",
    "    def GrabPredictions(self, data):\n",
    "        oof_preds = np.zeros((len(data), len(self.class_names)))\n",
    "        oof_preds[:,0] = self.GP_class_0(data)\n",
    "        oof_preds[:,1] = self.GP_class_1(data)\n",
    "        oof_preds[:,2] = self.GP_class_2(data)\n",
    "        oof_preds[:,3] = self.GP_class_3(data)\n",
    "        oof_preds[:,4] = self.GP_class_4(data)\n",
    "        oof_preds[:,5] = self.GP_class_5(data)\n",
    "        oof_preds[:,6] = self.GP_class_6(data)\n",
    "        oof_preds[:,7] = self.GP_class_7(data)\n",
    "        oof_preds[:,8] = self.GP_class_8(data)\n",
    "        oof_preds[:,9] = self.GP_class_9(data)\n",
    "        oof_preds[:,10] = self.GP_class_10(data)\n",
    "        oof_preds[:,11] = self.GP_class_11(data)\n",
    "        oof_preds[:,12] = self.GP_class_12(data)\n",
    "        oof_preds[:,13] = self.GP_class_13(data)\n",
    "        oof_preds[:,14] = self.GP_class_14(data)\n",
    "        oof_preds[:,15] = self.GP_class_15(data)\n",
    "        oof_preds[:,16] = self.GP_class_16(data)\n",
    "        oof_preds[:,17] = self.GP_class_17(data)\n",
    "        oof_preds[:,18] = self.GP_class_18(data)\n",
    "        oof_preds[:,19] = self.GP_class_19(data)\n",
    "        oof_df = pd.DataFrame(np.exp(oof_preds), columns=self.class_names)\n",
    "        oof_df =oof_df.div(oof_df.sum(axis=1), axis=0)\n",
    "        \n",
    "        return oof_df.values\n",
    "\n",
    "\n",
    "    def GP_class_0(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,0]) - (((data[:,0]) + (data[:,0]))))) + (data[:,0]))) + (((((data[:,0]) * 2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,2]) - (data[:,7]))) * 2.0)) + (data[:,7]))) * 2.0)) + (data[:,0]))) + (((((data[:,2]) + (data[:,0]))) - (data[:,7]))))) +\n",
    "                0.250000*np.tanh(((((((((((((((((((data[:,3]) - (data[:,7]))) - (((data[:,0]) / 2.0)))) + (data[:,0]))) - (data[:,7]))) + (data[:,2]))) + (((data[:,7]) + (data[:,2]))))) + (data[:,7]))) - (data[:,7]))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,0]) - (data[:,7]))) - (data[:,14]))) + (((data[:,17]) - (data[:,14]))))) + (((((((data[:,0]) - ((1.0)))) - (data[:,0]))) + (data[:,20]))))) +\n",
    "                0.250000*np.tanh(((((data[:,18]) + (((((((data[:,0]) - (data[:,7]))) + (data[:,2]))) + (data[:,0]))))) - (((data[:,7]) + (data[:,2]))))) +\n",
    "                0.250000*np.tanh((((((((data[:,8]) + ((((((((data[:,13]) + (data[:,3]))) + (data[:,0]))/2.0)) + ((((((((data[:,0]) + (((((data[:,0]) - (data[:,0]))) / 2.0)))) + (data[:,17]))/2.0)) + (data[:,11]))))))/2.0)) + (data[:,0]))) - (data[:,13]))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) * 2.0)) + (((((((((data[:,2]) + (data[:,2]))) * 2.0)) - (((data[:,14]) - (((np.tanh((data[:,2]))) * 2.0)))))) - (data[:,7]))))) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,17]) - (((data[:,17]) * (((((data[:,17]) * (data[:,17]))) * 2.0)))))) + (((((((data[:,17]) * 2.0)) * 2.0)) * 2.0)))/2.0)) / 2.0)) + (((data[:,17]) - ((7.76236486434936523)))))/2.0)) + (((((((data[:,17]) * (data[:,17]))) * 2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,17]) + (data[:,17]))/2.0)) + ((((data[:,17]) + ((((data[:,17]) + (data[:,17]))/2.0)))/2.0)))/2.0)) * (data[:,17]))) - (data[:,13]))) +\n",
    "                0.250000*np.tanh((((((data[:,19]) + (((((((((data[:,19]) * 2.0)) + (data[:,19]))) - ((1.07645297050476074)))) + (((data[:,22]) + (data[:,22]))))))/2.0)) + (((data[:,22]) + (data[:,4]))))))\n",
    "    \n",
    "    def GP_class_1(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((((data[:,3]) + (((np.tanh((data[:,2]))) - (data[:,14]))))) - ((10.0)))) - ((4.88989353179931641)))) - ((13.92175483703613281)))) / 2.0)) - (data[:,6]))) +\n",
    "                0.250000*np.tanh(data[:,3]) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((np.tanh((((data[:,14]) * 2.0)))) - (((((((data[:,7]) * 2.0)) - (((((data[:,0]) - (data[:,14]))) - (data[:,7]))))) - (data[:,0]))))) + (data[:,0]))))) +\n",
    "                0.250000*np.tanh(((((((data[:,0]) - ((-1.0*((data[:,14])))))) + ((((((((((data[:,0]) - (data[:,7]))) - ((((data[:,14]) + (data[:,14]))/2.0)))) + (((data[:,2]) - (((data[:,0]) * (data[:,14]))))))/2.0)) - (data[:,14]))))) - (data[:,7]))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) / 2.0)) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((data[:,19]) - (data[:,19]))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((np.tanh((((np.tanh((data[:,5]))) - ((((1.69341480731964111)) + ((((((np.tanh((data[:,14]))) - (data[:,14]))) + (data[:,14]))/2.0)))))))) - (data[:,2]))) - (((data[:,14]) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,22]) + (((data[:,0]) + ((((((((data[:,22]) / 2.0)) + ((-1.0*((data[:,13])))))/2.0)) + (data[:,19]))))))/2.0)) - (data[:,13]))) +\n",
    "                0.250000*np.tanh(((((((data[:,17]) / 2.0)) * (data[:,17]))) * (((data[:,17]) + (((data[:,17]) * (((((((((data[:,17]) + (data[:,17]))) * (data[:,17]))) * (data[:,17]))) + (((np.tanh((data[:,17]))) / 2.0)))))))))) +\n",
    "                0.250000*np.tanh((((((data[:,14]) * (((data[:,13]) + (data[:,3]))))) + (((data[:,14]) * (((data[:,14]) - ((-1.0*((data[:,3])))))))))/2.0)))\n",
    "    \n",
    "    def GP_class_2(self,data):\n",
    "        return(0.250000*np.tanh(((data[:,0]) + (np.tanh((((((((((data[:,2]) + (((data[:,2]) / 2.0)))/2.0)) + (data[:,0]))/2.0)) * (data[:,7]))))))) +\n",
    "                0.250000*np.tanh((((data[:,22]) + (data[:,22]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + ((-1.0*((((((4.73206138610839844)) + (((((((((((np.tanh((data[:,7]))) + (data[:,1]))/2.0)) - (np.tanh((((((data[:,0]) - (data[:,20]))) - (data[:,14]))))))) * ((7.0)))) + (data[:,14]))/2.0)))/2.0))))))/2.0)) - (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((data[:,1]) + ((4.15603733062744141)))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,0]) - (data[:,7]))) - (data[:,7]))) + ((((data[:,0]) + (data[:,0]))/2.0)))) * 2.0)) + (data[:,0]))) * 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,11]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((((((((((((data[:,2]) / 2.0)) + (((data[:,2]) / 2.0)))/2.0)) / 2.0)) / 2.0)) / 2.0)) + ((((-1.0*((((data[:,0]) / 2.0))))) * (((data[:,0]) / 2.0)))))/2.0)) + (data[:,0]))/2.0)) + (np.tanh((data[:,0]))))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((data[:,0]) + (((((((data[:,14]) * (data[:,14]))) + (data[:,14]))) - (data[:,0]))))))) - (data[:,14]))) +\n",
    "                0.250000*np.tanh((((((np.tanh((np.tanh(((0.0)))))) * (data[:,15]))) + (data[:,20]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) * ((((data[:,13]) + ((((data[:,13]) + ((((data[:,14]) + ((((((data[:,14]) + ((((data[:,14]) + (((data[:,13]) - ((((-1.0*(((((data[:,14]) + (data[:,14]))/2.0))))) * 2.0)))))/2.0)))) + (data[:,14]))/2.0)))/2.0)))/2.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_3(self,data):\n",
    "        return(0.250000*np.tanh(((((((((8.0)) + (((((((5.33416414260864258)) + ((9.0)))/2.0)) + ((((8.0)) * 2.0)))))) * 2.0)) + ((5.33416414260864258)))/2.0)) +\n",
    "                0.250000*np.tanh((((9.48088836669921875)) + (((((10.56953334808349609)) + ((((4.48959350585937500)) + (np.tanh(((((3.0)) + ((9.0)))))))))/2.0)))) +\n",
    "                0.250000*np.tanh((((((((((data[:,22]) / 2.0)) + (data[:,22]))/2.0)) * 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((10.44883441925048828)) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((data[:,0]) + ((-1.0*((data[:,9])))))))) + (((((data[:,0]) - (data[:,7]))) - (data[:,9]))))) +\n",
    "                0.250000*np.tanh(((np.tanh((data[:,6]))) - (data[:,21]))) +\n",
    "                0.250000*np.tanh(((data[:,0]) - (((((data[:,14]) + (((((data[:,14]) + (((data[:,14]) + (((data[:,14]) - (data[:,0]))))))) - (((((data[:,0]) - (data[:,14]))) + (data[:,14]))))))) - (((((data[:,14]) * (data[:,14]))) + (data[:,18]))))))) +\n",
    "                0.250000*np.tanh(((data[:,14]) * ((((data[:,13]) + (data[:,14]))/2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,8]) * (((data[:,8]) / 2.0)))) + ((((((data[:,9]) * (data[:,8]))) + (data[:,8]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh((((data[:,2]) + (((((((data[:,2]) + (data[:,20]))/2.0)) + ((((((((data[:,2]) + (data[:,8]))/2.0)) / 2.0)) - (data[:,8]))))/2.0)))/2.0)))\n",
    "    \n",
    "    def GP_class_4(self,data):\n",
    "        return(0.250000*np.tanh((((12.98819637298583984)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((4.75780344009399414)) + (((((((8.66014671325683594)) + ((4.18107128143310547)))/2.0)) * ((8.97841739654541016)))))/2.0)) +\n",
    "                0.250000*np.tanh((((9.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((10.0)) + (np.tanh((((((6.0)) + ((((13.80149555206298828)) + ((7.0)))))/2.0)))))) + ((10.0)))) + (((((((data[:,0]) + ((8.0)))) / 2.0)) / 2.0)))/2.0)) + ((((-1.0*((((data[:,2]) * (data[:,9])))))) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((((((data[:,22]) + (data[:,22]))/2.0)) + (data[:,22]))/2.0)))) + ((((((data[:,22]) + ((((((data[:,22]) * 2.0)) + (data[:,22]))/2.0)))) + (data[:,18]))/2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((np.tanh((data[:,18]))) + ((((data[:,1]) + (data[:,18]))/2.0)))/2.0)) * (data[:,18]))) * (data[:,18]))) + (((data[:,18]) * (data[:,18]))))/2.0)) - (((((((np.tanh((data[:,18]))) + (((data[:,18]) * (data[:,18]))))/2.0)) + (data[:,17]))/2.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh(((((((np.tanh((data[:,6]))) - (((np.tanh((data[:,6]))) - (data[:,6]))))) + (np.tanh((data[:,6]))))/2.0)))) - ((((data[:,10]) + ((((data[:,2]) + (((np.tanh((data[:,6]))) - (((np.tanh((np.tanh((data[:,6]))))) - (data[:,10]))))))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh((((((((((((data[:,10]) + (data[:,4]))) + (((data[:,10]) + (((data[:,0]) * (data[:,10]))))))/2.0)) + (((data[:,4]) * (((data[:,10]) + (data[:,4]))))))/2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,11]) + (((((data[:,18]) / 2.0)) * (((data[:,11]) * (data[:,18]))))))/2.0)) * (((data[:,18]) * (((((((((data[:,18]) * (((((((data[:,11]) / 2.0)) / 2.0)) * (data[:,18]))))) / 2.0)) / 2.0)) * ((-1.0*((data[:,21])))))))))) +\n",
    "                0.250000*np.tanh((((-1.0*((((((((((((data[:,2]) - (data[:,2]))) * (np.tanh((data[:,2]))))) + (np.tanh((((data[:,14]) * 2.0)))))/2.0)) + (data[:,2]))/2.0))))) - (data[:,2]))))\n",
    "    \n",
    "    def GP_class_5(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((3.46574378013610840)) + ((((np.tanh(((3.46574378013610840)))) + ((8.46705245971679688)))/2.0)))/2.0)) * 2.0)) + ((((3.46574378013610840)) + ((4.0)))))) + ((((4.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((10.55856513977050781)) / 2.0)) +\n",
    "                0.250000*np.tanh((((3.76695251464843750)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((6.0)) / 2.0)) + ((((8.57984828948974609)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((((((((3.42168045043945312)) + (data[:,7]))) + (np.tanh((data[:,7]))))) + (np.tanh((np.tanh((np.tanh(((3.42168045043945312)))))))))/2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((data[:,6]) - (data[:,9]))) + (data[:,7]))/2.0)) * 2.0)) + ((((((data[:,7]) + (data[:,9]))/2.0)) - (data[:,9]))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((data[:,22]) + (data[:,22]))) + (data[:,11]))/2.0)) + (data[:,22]))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((0.76044219732284546)) / 2.0)) + ((0.76044219732284546)))/2.0)) + (np.tanh((np.tanh((((((((0.76043862104415894)) / 2.0)) + ((1.0)))/2.0)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,12]) + (np.tanh((data[:,9]))))/2.0)) + (((((((((((data[:,12]) + (((((0.0)) + (np.tanh((((((((data[:,7]) + (data[:,6]))/2.0)) + (data[:,7]))/2.0)))))/2.0)))/2.0)) / 2.0)) / 2.0)) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,20]) / 2.0)) / 2.0)) * (((np.tanh((data[:,20]))) * (((data[:,20]) / 2.0)))))) * ((((((data[:,20]) / 2.0)) + (((data[:,20]) / 2.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_6(self,data):\n",
    "        return(0.250000*np.tanh(((((((11.68076229095458984)) + (((((11.68075847625732422)) + ((((11.47270107269287109)) + (((((11.47269725799560547)) + ((11.68076229095458984)))/2.0)))))/2.0)))/2.0)) + ((((4.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((8.0)) + ((((10.0)) + ((6.59042119979858398)))))) +\n",
    "                0.250000*np.tanh(((((((((((13.33760547637939453)) + (((((3.86388397216796875)) + (((((((8.18321037292480469)) + (data[:,4]))) + (((((((5.95386552810668945)) + ((12.93883609771728516)))) + (((((10.73907089233398438)) + ((4.0)))/2.0)))/2.0)))/2.0)))/2.0)))/2.0)) + (np.tanh(((3.0)))))) - ((2.0)))) + (((((10.61559963226318359)) + (data[:,1]))/2.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh(((((((((((7.13513946533203125)) + ((12.48778533935546875)))/2.0)) + (((((((7.13513565063476562)) - ((8.12031841278076172)))) + (((((((((7.13513565063476562)) + ((((10.69830417633056641)) + ((10.69830799102783203)))))) + ((10.69830799102783203)))) + ((7.83078956604003906)))/2.0)))/2.0)))/2.0)) * 2.0)))) + ((3.0)))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,7]) - (data[:,0]))) * 2.0)) - (data[:,7]))) + (data[:,7]))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((data[:,7]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((1.0)) + (((((((data[:,2]) + (((((((1.0)) * (data[:,2]))) + (data[:,14]))/2.0)))/2.0)) + ((1.0)))/2.0)))) + ((((1.0)) - (((data[:,2]) * (data[:,14]))))))/2.0)) - (data[:,2]))) * 2.0)) + (data[:,14]))/2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((np.tanh((np.tanh(((((((data[:,19]) * ((0.0)))) + ((0.0)))/2.0)))))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((0.0)) / 2.0)) / 2.0)) * (((((((((data[:,15]) / 2.0)) * ((0.0)))) / 2.0)) * ((((-1.0*(((0.0))))) / 2.0)))))) +\n",
    "                0.250000*np.tanh(((((data[:,15]) * (((((((((((((np.tanh(((((0.09032609313726425)) / 2.0)))) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)))) / 2.0)))\n",
    "    \n",
    "    def GP_class_7(self,data):\n",
    "        return(0.250000*np.tanh((10.27210903167724609)) +\n",
    "                0.250000*np.tanh((((((((((10.0)) + (((((((((8.26972770690917969)) + ((11.06334972381591797)))/2.0)) * 2.0)) / 2.0)))) + ((((((5.0)) + ((((5.0)) + ((7.92727756500244141)))))) * 2.0)))) * ((7.92728137969970703)))) + ((10.0)))) +\n",
    "                0.250000*np.tanh((8.42519950866699219)) +\n",
    "                0.250000*np.tanh(((((((data[:,14]) + (data[:,14]))) + ((((((1.59392631053924561)) + (data[:,14]))) + (data[:,14]))))) + (np.tanh((((((data[:,14]) + (((((((3.0)) + (((data[:,14]) * 2.0)))/2.0)) + ((1.59391915798187256)))))) + ((1.59392631053924561)))))))) +\n",
    "                0.250000*np.tanh((((data[:,7]) + (((data[:,0]) + (((((((data[:,7]) + (data[:,4]))/2.0)) + (((data[:,7]) * 2.0)))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((data[:,9]) - (((data[:,0]) - (data[:,0]))))) - (((data[:,0]) / 2.0)))) / 2.0)) - (((data[:,21]) - (data[:,7]))))) + (data[:,21]))/2.0)) - (data[:,0]))) +\n",
    "                0.250000*np.tanh((((((((((2.0)) + ((((((data[:,21]) + ((((data[:,13]) + (((((((((((data[:,13]) * 2.0)) + (data[:,21]))/2.0)) + (data[:,13]))/2.0)) * 2.0)))/2.0)))/2.0)) - (np.tanh(((((0.0)) - (data[:,21]))))))))) + ((1.0)))/2.0)) + (data[:,13]))/2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,14]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((-1.0*(((((((data[:,21]) / 2.0)) + (data[:,8]))/2.0))))) / 2.0)) / 2.0)) / 2.0)) + (data[:,9]))/2.0)) / 2.0)) + ((((((((((((data[:,7]) / 2.0)) / 2.0)) / 2.0)) / 2.0)) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((np.tanh(((1.0)))) / 2.0)) / 2.0)) / 2.0)))\n",
    "    \n",
    "    def GP_class_8(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,0]) + (((((6.71804094314575195)) + (data[:,15]))/2.0)))) + ((((((11.56385326385498047)) * 2.0)) * ((((10.48986148834228516)) + ((11.56385326385498047)))))))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((data[:,14]) / 2.0)) + ((2.83755254745483398)))/2.0)) + ((((((data[:,12]) + (data[:,14]))/2.0)) + (data[:,14]))))) + ((((data[:,9]) + (((data[:,12]) + (data[:,14]))))/2.0)))) +\n",
    "                0.250000*np.tanh(((((((((data[:,6]) + (((((((3.50821948051452637)) + ((((data[:,21]) + ((11.92932796478271484)))/2.0)))) + ((1.0)))/2.0)))) + (data[:,10]))/2.0)) + (data[:,21]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) + (np.tanh((np.tanh(((-1.0*((((data[:,22]) - (data[:,13])))))))))))) +\n",
    "                0.250000*np.tanh(((((1.0)) + ((((data[:,7]) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,21]) / 2.0)) / 2.0)) * (((((((np.tanh((((np.tanh((data[:,13]))) / 2.0)))) / 2.0)) + (((((((np.tanh(((((data[:,21]) + (data[:,21]))/2.0)))) / 2.0)) - (data[:,12]))) / 2.0)))) / 2.0)))) - (data[:,12]))) +\n",
    "                0.250000*np.tanh((((data[:,7]) + (np.tanh(((((data[:,12]) + (((data[:,7]) * ((((data[:,13]) + (data[:,13]))/2.0)))))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,13]) / 2.0)) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((np.tanh((data[:,9]))) + (data[:,13]))/2.0)) + ((((((((data[:,21]) / 2.0)) * 2.0)) + ((((3.94983267784118652)) / 2.0)))/2.0)))/2.0)) + ((((np.tanh(((3.94983267784118652)))) + (data[:,9]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((((data[:,14]) * (((((((((data[:,19]) / 2.0)) * (np.tanh((((data[:,2]) / 2.0)))))) / 2.0)) / 2.0)))) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)) * (((((data[:,11]) / 2.0)) / 2.0)))))\n",
    "    \n",
    "    def GP_class_9(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,14]) * 2.0)) / 2.0)) + (((((data[:,14]) + (np.tanh((((data[:,14]) * 2.0)))))) + (data[:,14]))))) +\n",
    "                0.250000*np.tanh(((data[:,9]) - (((((-1.0*((data[:,11])))) + (data[:,9]))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,21]) * 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,14]))/2.0)) + ((((data[:,13]) + ((((np.tanh((((data[:,9]) + ((6.0)))))) + (data[:,9]))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh(np.tanh(((1.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh((np.tanh(((((np.tanh((((data[:,20]) * (((((((np.tanh((((data[:,20]) / 2.0)))) + (data[:,12]))/2.0)) + ((((data[:,15]) + ((((data[:,17]) + (data[:,9]))/2.0)))/2.0)))/2.0)))))) + (data[:,9]))/2.0)))))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,2]) - (data[:,11]))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,13]) / 2.0)) + (((data[:,7]) + (data[:,7]))))/2.0)) - (((((data[:,22]) + (((((data[:,14]) * (((((data[:,7]) * (((data[:,13]) - ((((data[:,7]) + (((((data[:,13]) / 2.0)) + (data[:,7]))))/2.0)))))) / 2.0)))) * 2.0)))) / 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((((data[:,1]) / 2.0)) + ((1.0)))/2.0)) + ((1.0)))/2.0)) + ((((((((((1.0)) / 2.0)) + (np.tanh(((1.0)))))/2.0)) + (np.tanh((((((1.0)) + ((1.0)))/2.0)))))/2.0)))/2.0)) + ((((data[:,20]) + ((1.0)))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,1]) * ((((data[:,14]) + (np.tanh(((((0.0)) / 2.0)))))/2.0)))))\n",
    "    \n",
    "    def GP_class_10(self,data):\n",
    "        return(0.250000*np.tanh((((((((((data[:,2]) + (((data[:,9]) * (np.tanh((data[:,14]))))))/2.0)) + ((((((data[:,14]) + (data[:,20]))/2.0)) + (data[:,0]))))/2.0)) + (data[:,14]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,9]) + ((-1.0*((((((((2.04309988021850586)) + (((data[:,11]) + (((np.tanh((data[:,0]))) / 2.0)))))/2.0)) * 2.0))))))/2.0)) + (data[:,2]))) +\n",
    "                0.250000*np.tanh(data[:,21]) +\n",
    "                0.250000*np.tanh((((((((data[:,14]) + (np.tanh((((data[:,6]) / 2.0)))))/2.0)) + (data[:,14]))) + (((((data[:,14]) * 2.0)) + ((((data[:,13]) + (data[:,14]))/2.0)))))) +\n",
    "                0.250000*np.tanh(data[:,9]) +\n",
    "                0.250000*np.tanh(((((((data[:,15]) * 2.0)) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((2.72836518287658691)) * ((((1.0)) / 2.0)))) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((np.tanh((((data[:,7]) + (np.tanh(((((((((((0.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)))))))) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(np.tanh((((np.tanh(((11.43236827850341797)))) / 2.0)))) +\n",
    "                0.250000*np.tanh(np.tanh((((data[:,7]) / 2.0)))))\n",
    "    \n",
    "    def GP_class_11(self,data):\n",
    "        return(0.250000*np.tanh((-1.0*((((((((((((((data[:,5]) - (((data[:,9]) - ((((-1.0*(((11.40053558349609375))))) / 2.0)))))) + ((((11.40053558349609375)) + ((((11.40053558349609375)) * 2.0)))))) / 2.0)) - (data[:,7]))) - ((-1.0*(((11.40053939819335938))))))) * 2.0))))) +\n",
    "                0.250000*np.tanh(((((data[:,14]) * 2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((data[:,5]) + (data[:,3]))) + ((((data[:,2]) + (((data[:,3]) * 2.0)))/2.0)))))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,21]) + (data[:,21]))) + ((-1.0*(((((np.tanh((np.tanh((((data[:,14]) / 2.0)))))) + (data[:,21]))/2.0))))))/2.0)) * 2.0)) + ((((data[:,14]) + (data[:,3]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,0]) + ((((data[:,9]) + ((((data[:,9]) + (((((((((((((((data[:,9]) / 2.0)) - (data[:,10]))) + (data[:,5]))/2.0)) - (data[:,9]))) + (data[:,9]))/2.0)) / 2.0)))/2.0)))/2.0)))/2.0)) + (data[:,9]))/2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,13]) + ((((data[:,13]) + (data[:,13]))/2.0)))) + (data[:,1]))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(data[:,14]) +\n",
    "                0.250000*np.tanh(((((data[:,2]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((data[:,9]) + (data[:,9]))/2.0)) +\n",
    "                0.250000*np.tanh(data[:,2]))\n",
    "    \n",
    "    def GP_class_12(self,data):\n",
    "        return(0.250000*np.tanh((((((((-1.0*((data[:,18])))) - (np.tanh((data[:,9]))))) + ((8.0)))) - ((14.74865913391113281)))) +\n",
    "                0.250000*np.tanh((((((data[:,21]) + (np.tanh((data[:,9]))))) + ((((((((data[:,5]) / 2.0)) * 2.0)) + (data[:,5]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,14]) + (data[:,14]))) + (((data[:,14]) * 2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((((data[:,14]) + ((((np.tanh((data[:,10]))) + (data[:,17]))/2.0)))/2.0)) + (data[:,21]))/2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,9]) + ((((((((((((data[:,9]) + ((((((data[:,9]) / 2.0)) + (((data[:,9]) * 2.0)))/2.0)))/2.0)) + ((-1.0*((data[:,21])))))/2.0)) * (data[:,9]))) + (((((np.tanh((((data[:,21]) / 2.0)))) / 2.0)) / 2.0)))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((0.0)) + (data[:,13]))/2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,2]) / 2.0)) * 2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) * 2.0)) + (np.tanh((data[:,14]))))/2.0)) +\n",
    "                0.250000*np.tanh(np.tanh((((((((((-1.0*((((np.tanh((data[:,9]))) / 2.0))))) / 2.0)) / 2.0)) + (((data[:,3]) * (data[:,13]))))/2.0)))) +\n",
    "                0.250000*np.tanh((-1.0*((((((((-1.0*(((((((-1.0*((data[:,18])))) - ((((0.0)) / 2.0)))) / 2.0))))) + (np.tanh(((((-1.0*(((-1.0*((data[:,22]))))))) / 2.0)))))/2.0)) / 2.0))))))\n",
    "    \n",
    "    def GP_class_13(self,data):\n",
    "        return(0.250000*np.tanh(((((np.tanh((np.tanh((data[:,2]))))) - ((10.0)))) - (np.tanh((((((data[:,7]) - ((((((6.0)) - ((4.87243366241455078)))) - ((9.0)))))) - ((14.80352973937988281)))))))) +\n",
    "                0.250000*np.tanh(((np.tanh((((((3.0)) + (data[:,1]))/2.0)))) - ((7.0)))) +\n",
    "                0.250000*np.tanh(((((np.tanh((np.tanh((np.tanh((data[:,6]))))))) * 2.0)) - ((6.10337877273559570)))) +\n",
    "                0.250000*np.tanh(((((((data[:,9]) + (data[:,14]))) + (data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((((np.tanh(((((-1.0*(((((((data[:,2]) + ((10.0)))/2.0)) / 2.0))))) - ((13.28130435943603516)))))) + ((10.0)))) - ((13.28130435943603516)))) + ((-1.0*((data[:,5])))))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,20]) + (((((((((data[:,20]) * 2.0)) * 2.0)) * 2.0)) + (data[:,13]))))/2.0)) + (((data[:,9]) + (((data[:,9]) + (((data[:,6]) + (data[:,9]))))))))/2.0)) + (data[:,20]))) + (data[:,15]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,14]) / 2.0)) + ((((data[:,9]) + (((data[:,15]) + (((data[:,5]) + ((((((data[:,9]) + (((data[:,5]) + (data[:,14]))))) + (data[:,9]))/2.0)))))))/2.0)))) * 2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh((((data[:,13]) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,9]) + ((((data[:,3]) + ((((data[:,21]) + (data[:,3]))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,2]) + (((((((((((((((data[:,20]) + (data[:,1]))) + (((data[:,2]) + (data[:,14]))))) + (data[:,2]))) + (np.tanh((data[:,2]))))/2.0)) + (((data[:,14]) + (data[:,2]))))) + (data[:,14]))/2.0)))/2.0)))\n",
    "    \n",
    "    def GP_class_14(self,data):\n",
    "        return(0.250000*np.tanh((((((((((((5.54024744033813477)) - ((((((9.0)) * 2.0)) * 2.0)))) - (data[:,0]))) - ((((7.0)) + ((4.74105215072631836)))))) - (((((7.0)) + (((data[:,5]) * 2.0)))/2.0)))) - ((9.0)))) +\n",
    "                0.250000*np.tanh(((((((((9.0)) - ((14.27298927307128906)))) - (data[:,0]))) + (np.tanh(((((12.77708148956298828)) - ((14.80560111999511719)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((0.0)) + ((-1.0*((((data[:,22]) + (((((((((13.30077362060546875)) - (np.tanh((data[:,4]))))) + (((data[:,22]) / 2.0)))/2.0)) / 2.0))))))))/2.0)) - (((np.tanh((((data[:,7]) - (data[:,7]))))) / 2.0)))) +\n",
    "                0.250000*np.tanh(((((((data[:,6]) + (data[:,14]))/2.0)) + (((np.tanh((((((data[:,14]) + (data[:,14]))) + (((data[:,6]) - (((data[:,5]) + (((np.tanh((data[:,21]))) + ((((data[:,14]) + ((((data[:,14]) + (data[:,14]))/2.0)))/2.0)))))))))))) + (data[:,5]))))/2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((((data[:,2]) + (data[:,16]))) + ((((((data[:,2]) / 2.0)) + (data[:,9]))/2.0)))/2.0)) + (np.tanh((data[:,10]))))/2.0)) + (data[:,9]))) + (data[:,9]))/2.0)) + (data[:,21]))) + (data[:,3]))) +\n",
    "                0.250000*np.tanh((((data[:,13]) + (((((((((((data[:,3]) / 2.0)) / 2.0)) / 2.0)) * (data[:,3]))) / 2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) + (((((((data[:,14]) / 2.0)) + (data[:,14]))) * 2.0)))) +\n",
    "                0.250000*np.tanh(data[:,9]) +\n",
    "                0.250000*np.tanh(((data[:,1]) / 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,2]) + ((((((data[:,13]) + (data[:,14]))) + (data[:,13]))/2.0)))) + (np.tanh((data[:,2]))))/2.0)))\n",
    "    \n",
    "    def GP_class_15(self,data):\n",
    "        return(0.250000*np.tanh((((((((4.0)) + ((((8.0)) / 2.0)))) - ((9.56193733215332031)))) - (((((np.tanh(((13.93556308746337891)))) - (data[:,18]))) + ((13.93556308746337891)))))) +\n",
    "                0.250000*np.tanh(((data[:,4]) - ((((12.76094818115234375)) - (data[:,8]))))) +\n",
    "                0.250000*np.tanh((((-1.0*(((12.35446166992187500))))) - (((((12.35446166992187500)) + ((((((12.35446166992187500)) - ((-1.0*(((0.0))))))) - (data[:,0]))))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,21]) - ((14.46367263793945312)))) +\n",
    "                0.250000*np.tanh(((((data[:,2]) + ((((data[:,9]) + ((-1.0*(((-1.0*(((-1.0*((((data[:,7]) * (((data[:,21]) * 2.0))))))))))))))/2.0)))) + (data[:,9]))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,7]) + (data[:,3]))/2.0)) + (data[:,20]))/2.0)) - ((((2.33354020118713379)) / 2.0)))) - ((((2.0)) + ((8.78930377960205078)))))) +\n",
    "                0.250000*np.tanh(((((((data[:,14]) + (((((((data[:,14]) + (((data[:,15]) + (data[:,14]))))) + (((data[:,15]) + (data[:,14]))))) + (((data[:,14]) / 2.0)))))) + (data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,13]) + (data[:,13]))) + (((data[:,13]) + (data[:,12]))))) + (data[:,9]))) + ((((((data[:,9]) + (((data[:,13]) + ((((data[:,9]) + (((((data[:,13]) * 2.0)) / 2.0)))/2.0)))))/2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,9]) + ((((((data[:,9]) + (data[:,9]))/2.0)) / 2.0)))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,8]))) + (data[:,14]))/2.0)))\n",
    "    \n",
    "    def GP_class_16(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((((9.37592792510986328)) - ((13.36316204071044922)))) + ((11.89122962951660156)))/2.0)) - ((((9.0)) - (((((((data[:,13]) / 2.0)) / 2.0)) + ((((-1.0*((((data[:,4]) / 2.0))))) * 2.0)))))))) - ((12.24639320373535156)))) - ((11.89122581481933594)))) +\n",
    "                0.250000*np.tanh(((((np.tanh(((4.51821422576904297)))) - ((13.23712635040283203)))) - ((((((13.23712635040283203)) + (((data[:,22]) - ((((11.40539550781250000)) - (((((9.0)) + ((((((((data[:,7]) + (((data[:,17]) / 2.0)))/2.0)) * 2.0)) / 2.0)))/2.0)))))))) - (data[:,5]))))) +\n",
    "                0.250000*np.tanh(((data[:,14]) - ((((4.0)) + (((((13.41770648956298828)) + ((12.42538261413574219)))/2.0)))))) +\n",
    "                0.250000*np.tanh((((5.0)) - ((9.27778816223144531)))) +\n",
    "                0.250000*np.tanh(((((data[:,16]) - (((((((data[:,1]) - (((np.tanh((((((((9.29507255554199219)) - (((((((14.34461498260498047)) * 2.0)) + (((((7.0)) + ((9.10683441162109375)))/2.0)))/2.0)))) + ((4.21145153045654297)))/2.0)))) * 2.0)))) - ((9.10683441162109375)))) * 2.0)))) - ((((14.34461498260498047)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((((((data[:,17]) / 2.0)) + (((data[:,13]) + (data[:,9]))))/2.0)) + (((data[:,17]) + (data[:,9]))))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((data[:,13]) + (((data[:,14]) - (data[:,21]))))) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,5]))/2.0)) + (((((((data[:,9]) / 2.0)) + (data[:,14]))) / 2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,17]) + (data[:,9]))) + (((((data[:,17]) / 2.0)) + ((((((((((data[:,9]) + (data[:,9]))) - ((3.0)))) + (data[:,7]))) + (data[:,9]))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh(np.tanh(((((((((((((((data[:,2]) + (((((((((((data[:,22]) + (data[:,21]))/2.0)) + (data[:,2]))/2.0)) * 2.0)) + ((((((data[:,21]) * 2.0)) + (data[:,21]))/2.0)))))) + (data[:,2]))/2.0)) + (data[:,17]))/2.0)) + (np.tanh((data[:,8]))))/2.0)) + (data[:,2]))))))\n",
    "    \n",
    "    def GP_class_17(self,data):\n",
    "        return(0.250000*np.tanh(((((data[:,14]) - ((((data[:,5]) + (((((14.43326377868652344)) + ((6.0)))/2.0)))/2.0)))) - (((((((10.0)) + ((14.84462165832519531)))/2.0)) - ((((7.0)) + (data[:,13]))))))) +\n",
    "                0.250000*np.tanh((((((((((data[:,14]) + (((((((((data[:,11]) - ((9.71331787109375000)))) / 2.0)) + ((9.0)))) - ((3.0)))))/2.0)) - ((10.0)))) - ((((10.0)) + ((((9.0)) - ((((((10.0)) - ((9.0)))) / 2.0)))))))) - ((10.0)))) +\n",
    "                0.250000*np.tanh((((((((((8.0)) - ((12.78277492523193359)))) - (data[:,10]))) - (np.tanh(((((((7.0)) - ((14.95321178436279297)))) - ((8.0)))))))) - ((14.95321178436279297)))) +\n",
    "                0.250000*np.tanh((((7.45682907104492188)) - ((14.98023796081542969)))) +\n",
    "                0.250000*np.tanh(((((((((((7.0)) + (((((np.tanh((((((((8.0)) * (data[:,8]))) + (data[:,11]))/2.0)))) / 2.0)) - ((8.0)))))/2.0)) - (data[:,20]))) - ((((8.0)) * 2.0)))) + ((8.0)))) +\n",
    "                0.250000*np.tanh(((data[:,8]) + (((data[:,4]) + (((np.tanh((data[:,4]))) + (((data[:,13]) + (data[:,13]))))))))) +\n",
    "                0.250000*np.tanh(data[:,14]) +\n",
    "                0.250000*np.tanh(((((((((((data[:,14]) + (np.tanh((((data[:,3]) * (data[:,13]))))))) + (data[:,14]))) + (data[:,0]))) + (data[:,8]))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,9]) + (np.tanh(((((((data[:,19]) * (((((((data[:,1]) + (((((((data[:,21]) + (data[:,9]))/2.0)) + (data[:,6]))/2.0)))/2.0)) + (data[:,17]))/2.0)))) + (((data[:,15]) / 2.0)))/2.0)))))/2.0)) * 2.0)) +\n",
    "                0.250000*np.tanh(((data[:,1]) + (((((data[:,3]) + (data[:,15]))) + (np.tanh(((((data[:,20]) + (((data[:,1]) * 2.0)))/2.0)))))))))\n",
    "    \n",
    "    def GP_class_18(self,data):\n",
    "        return(0.250000*np.tanh((((((((((12.59485149383544922)) - ((12.59485149383544922)))) - ((12.59485149383544922)))) - ((((11.47756862640380859)) / 2.0)))) - ((12.59485149383544922)))) +\n",
    "                0.250000*np.tanh((((((-1.0*(((11.26121807098388672))))) - (((((((((11.33140659332275391)) - ((-1.0*(((9.76293182373046875))))))) - (((((11.33140659332275391)) + ((8.0)))/2.0)))) + ((9.76293182373046875)))/2.0)))) - (data[:,11]))) +\n",
    "                0.250000*np.tanh(((((((((((3.40250444412231445)) - (np.tanh(((14.86789989471435547)))))) - ((14.86789989471435547)))) + ((((((data[:,5]) + ((-1.0*(((((14.86789989471435547)) * 2.0))))))/2.0)) - ((14.86789989471435547)))))/2.0)) - (((((14.86789989471435547)) + (((((7.0)) + ((-1.0*((data[:,16])))))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,18]) - ((11.84332561492919922)))) +\n",
    "                0.250000*np.tanh(((((np.tanh(((((8.96548557281494141)) * (data[:,12]))))) - ((-1.0*((((data[:,2]) * (((((data[:,4]) - ((-1.0*((data[:,9])))))) - ((9.0))))))))))) - ((8.96548557281494141)))) +\n",
    "                0.250000*np.tanh(((((((10.0)) - (data[:,12]))) + (((((((((data[:,13]) - ((12.43707370758056641)))) - ((((12.43707370758056641)) - (((data[:,12]) / 2.0)))))) - ((((12.43707370758056641)) - ((((data[:,13]) + ((12.43707370758056641)))/2.0)))))) - ((12.43707370758056641)))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((np.tanh((((np.tanh((data[:,14]))) + (data[:,13]))))) * 2.0)) + (data[:,14]))) + (data[:,13]))) +\n",
    "                0.250000*np.tanh(((np.tanh((data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((data[:,9]) + (((((data[:,13]) + (data[:,4]))) + (data[:,13]))))) / 2.0)) +\n",
    "                0.250000*np.tanh(((data[:,15]) - ((((data[:,3]) + ((5.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_19(self,data):\n",
    "        return(0.250000*np.tanh((((((data[:,13]) + (data[:,13]))/2.0)) + ((((((data[:,8]) + ((((data[:,14]) + (data[:,14]))/2.0)))/2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,3]) + (((data[:,8]) + (np.tanh(((((((-1.0*((((((9.05535793304443359)) + ((((data[:,14]) + (((((((data[:,1]) - (((data[:,12]) * 2.0)))) * ((-1.0*((data[:,17])))))) / 2.0)))/2.0)))/2.0))))) + (data[:,2]))) * 2.0)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,3]) + (((((data[:,14]) + (data[:,14]))) * 2.0)))) + ((((data[:,14]) + (np.tanh((((data[:,14]) + (np.tanh((data[:,14]))))))))/2.0)))) * 2.0)) + ((((data[:,14]) + (data[:,2]))/2.0)))) +\n",
    "                0.250000*np.tanh(((((data[:,8]) + (((data[:,4]) + (((data[:,13]) + (data[:,10]))))))) + (((((data[:,13]) + (((((data[:,13]) / 2.0)) + (data[:,9]))))) + (np.tanh(((((data[:,8]) + (data[:,8]))/2.0)))))))) +\n",
    "                0.250000*np.tanh((((((data[:,19]) + (((((data[:,10]) + ((((data[:,11]) + (data[:,19]))/2.0)))) + (data[:,10]))))/2.0)) + (data[:,2]))) +\n",
    "                0.250000*np.tanh((((((data[:,0]) + (((((((((data[:,0]) + (((((data[:,0]) - (data[:,11]))) / 2.0)))/2.0)) * 2.0)) + ((((((np.tanh((data[:,13]))) + (((data[:,0]) / 2.0)))/2.0)) / 2.0)))/2.0)))/2.0)) * 2.0)) +\n",
    "                0.250000*np.tanh(((((-1.0*((data[:,15])))) + (((data[:,14]) + (data[:,14]))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,0]) + (data[:,15]))/2.0)) + (((data[:,15]) * (data[:,15]))))/2.0)) - (data[:,11]))) +\n",
    "                0.250000*np.tanh(data[:,13]) +\n",
    "                0.250000*np.tanh(((((((((data[:,18]) + ((((data[:,4]) + (data[:,18]))/2.0)))) / 2.0)) + ((((data[:,18]) + (data[:,4]))/2.0)))) * (data[:,4])))    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for the actual submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from kaggle.competitions import nflrush\n",
    "env = nflrush.make_env()\n",
    "iter_test = env.iter_test()\n",
    "gp = GP()\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    basetable = create_features(test_df, deploy=True)\n",
    "    basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n",
    "    scaled_basetable = scaler.transform(basetable)\n",
    "    \n",
    "    p = [m.predict(scaled_basetable) for m in models]\n",
    "    features = (np.array(p)).mean(0)\n",
    "    _scaled_basetable = np.hstack([scaled_basetable, features.reshape(-1,1)])\n",
    "    p =  [m.predict(_scaled_basetable) for m in _models]\n",
    "    y_pred_nn = (np.array(p)).mean(0)\n",
    "    \n",
    "    y_pred_gp = np.zeros((test_df.shape[0],199))\n",
    "    ans = gp.GrabPredictions(scaled_basetable)\n",
    "    y_pred_gp[:,96:96+20] = ans\n",
    "    \n",
    "    y_pred = (.8*y_pred_nn+.2*y_pred_gp)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n",
    "    \n",
    "    preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n",
    "    env.predict(preds_df)\n",
    "    \n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
