{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Gambar Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Gambar *Average* per Batch\n",
    "\n",
    "**Gambar Average** adalah gambar hasil rata-rata dari beberapa gambar.\n",
    "Karena pada *dataset* ini posisi pemotretan tidak berubah dan mobil \n",
    "sebagai foreground hanya akan meghalangi untuk beberapa gambar, \n",
    "maka dengan mengambil gambar average, kita bisa mendapatkan gambar \n",
    "baru dimana seolah-olah tidak ada mobil, hanya *backgound* saja.\n",
    "\n",
    "### Prosedur pembuatan gambar *Average* dengan batasan tipe data gambar\n",
    "Dari semua gambar pada dataset akan di buat beberapa batch, dimana setiap batch berisi 50 gambar. Hal ini untuk menghindari overflow dan overflow pada warnya gambar yang pada umumnya hanya menyimpan integer dengan range [0-255].\n",
    "\n",
    "## Improvement: Gambar *Medium*\n",
    "Kita dapat mendapatkan gambar *background* yang relatif lebih bersih dengan menghitung medium pada sebuah pixel pada semua gambar. Tetapi sayangnya saya tidak punya waktu yang cukup untuk melakukan ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './input/Image-Traffic/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b231baf49541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# List semua gambar pada dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./input/Image-Traffic/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Gambar pertama\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/Image-Traffic/'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# List semua gambar pada dataset\n",
    "image_files = os.listdir('./input/Image-Traffic/')\n",
    "\n",
    "# Gambar pertama\n",
    "image1 = cv2.imread('./input/Image-Traffic/00020 0001.jpg')\n",
    "\n",
    "# Gambar pertama dengan nilai 1/50\n",
    "# 1/100 + 1/100 = 1/50\n",
    "image1 = cv2.addWeighted(image1, 1/100, image1, 1/100, 0)\n",
    "\n",
    "# List gambar average dari setiap batch\n",
    "batch_avg = []\n",
    "\n",
    "# Membuat gambar average dari setiap batch\n",
    "for index, image_file in enumerate(image_files):\n",
    "    if index % 50==0:\n",
    "        batch_avg.append(image1)\n",
    "        image1 = cv2.imread('./input/Image-Traffic/'+image_file)\n",
    "        image1 = cv2.addWeighted(image1, 1/100, image1, 1/100, 0)\n",
    "    image = cv2.imread('./input/Image-Traffic/'+image_file)\n",
    "    image1 = cv2.addWeighted(image1, 1, image, 1/50, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_avg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-209dfb2ec1d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Membuat gambar average dari setiap gambar average batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbatches_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatches_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatches_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_avg' is not defined"
     ]
    }
   ],
   "source": [
    "# Membuat gambar average dari setiap gambar average batch\n",
    "batches_len = len(batch_avg)\n",
    "result = cv2.addWeighted(batch_avg[0], 1/(2*batches_len), batch_avg[0], 1/(2*batches_len), 0)\n",
    "batch_avg.pop(0)\n",
    "\n",
    "for batch_now in batch_avg:\n",
    "    result = cv2.addWeighted(result, 1, batch_now, 1/batches_len, 0)\n",
    "    \n",
    "# menuliskan output\n",
    "cv2.imwrite('./output/Mean_Average_BG.png', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Output\n",
    "![MeanAverage](output/Mean_Average_BG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Gambar untuk Labeling\n",
    "Cara mencari perbedaan pada gambar dengan background nya saya dapatkan dari\n",
    "[sumber ini]('https://www.pyimagesearch.com/2017/06/19/image-difference-with-opencv-and-python/')\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d95fc0d317e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import compare_ssim\n",
    "from random import randint\n",
    "\n",
    "# preprocessing gambar background menjadi grayscale\n",
    "bg = cv2.imread('./output/Mean_Average_BG.png')\n",
    "bg = cv2.cvtColor(bg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# list untuk diisi data-data\n",
    "# setiap data adalah data yang terdeteksi beda pada gambar dengan background\n",
    "# setiap data adalah tuple seperti berikut (x, y, w, h, score)\n",
    "# x, y adalah titik kiri bawah dari kotak. w, h adalah lebar dan tinggi kotak\n",
    "rows = []\n",
    "\n",
    "BANYAK_GAMBAR_TRAIN = 40\n",
    "\n",
    "# list semua gambar\n",
    "image_files = os.listdir('./input/Image-Traffic/')\n",
    "\n",
    "for index, image_file in enumerate(image_files):\n",
    "    #membuat gambar untuk labeling dengan jumlah yang ditentukan, pada kode ini digunakan 50\n",
    "    if index > BANYAK_GAMBAR_TRAIN:\n",
    "        break\n",
    "    \n",
    "    # preprocessing gambar menjadi grayscale\n",
    "    image_now_color = cv2.imread('./input/Image-Traffic/'+image_file)\n",
    "    image_now = cv2.cvtColor(image_now_color, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # menghitung score selisih gambar dengan background\n",
    "    # semakin besar score, semakin sedikit foreground\n",
    "    (score, diff) = compare_ssim(bg, image_now, full=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "    # angka 9 ini adalah magic number yang saya temukan dapat mendeteksi mobil dengan ukuran yang baik\n",
    "    # dapat dikatakan saya mendapat angka 9 ini dari human training\n",
    "    diffr = np.add(diff, 9)\n",
    "    thresh = cv2.threshold(diffr, 0, 255, \n",
    "                           cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    \n",
    "    detect_counter = 0\n",
    "    for c in cnts:\n",
    "        \n",
    "        # mendapatkan x, y, w, h dari setiap kontur\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # hanya menampilkan kontur dengan constraint tertentu, untuk mempermudah labeling\n",
    "        # angka 30, 500, dan 900 disini saya tentukan sendiri dengan asumsi tidak ada gambar mobil\n",
    "        # yang tidak memenuhi constrain tersebut\n",
    "        if w>30 and h>30 and h<900 and w<500:\n",
    "            \n",
    "            detect_counter+=1\n",
    "            \n",
    "            # nama kontur\n",
    "            name = str(index)+'#'+str(detect_counter)\n",
    "            \n",
    "            # warna kotak dan tulisan untuk setiap kontur dirandom untuk mempermudah labeling\n",
    "            color = (randint(100, 255),randint(100, 255),randint(100, 255))\n",
    "            cv2.rectangle(image_now_color, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(image_now_color, name, (x, y+25), cv2.FONT_HERSHEY_SIMPLEX, 1, color, thickness=2)\n",
    "            \n",
    "            # mencari score ssim untuk setiap kontur\n",
    "            bg_crop = bg[y:y+h, x:x+w]\n",
    "            image_now_crop = image_now[y:y+h, x:x+w]\n",
    "            (score_crop, _) = compare_ssim(bg_crop, image_now_crop, full=True)\n",
    "            \n",
    "            \n",
    "            # menyimpan data setiap kontur\n",
    "            # 0 disini adalah default value, artinya tidak terdeteksi mobil\n",
    "            rows.append((name,0,x,y,w,h,score_crop))\n",
    "            \n",
    "    # menyimpan gambar\n",
    "    cv2.imwrite('./output/Training/'+str(index)+'_training.png', image_now_color)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv('./output/training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "Menghitung jumlah mobil dengan real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./input/train_labeled.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-07a0bf5ad64b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'car_count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./input/train_labeled.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./input/train_labeled.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "names = ['index','name','car_count','x','y','w','h','score']\n",
    "train_df = pd.read_csv('./input/train_labeled.csv', names=names)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "X = train_df[['x','y','w','h','score']]\n",
    "X['area']= np.multiply(X['w'],X['h'])\n",
    "X['aspect_ratio']= np.divide(X['w'],X['h'])\n",
    "y = train_df['car_count']\n",
    "X.head()\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.measure import compare_ssim\n",
    "import imutils\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor()\n",
    "clf.fit(X,Y)\n",
    "\n",
    "bg = cv2.imread('./output/Mean_Average_BG.png')\n",
    "bg = cv2.cvtColor(bg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "LIMIT = 40\n",
    "\n",
    "a = [str(x).zfill(3) for x in range(52,400)]\n",
    "for index, image_file in enumerate(a):\n",
    "    if index>LIMIT:\n",
    "        break\n",
    "    \n",
    "    # preprocessing gambar menjadi grayscale\n",
    "    image_now_color = cv2.imread('./input/Image-Traffic/00020 0'+image_file+'.jpg')\n",
    "    image_now = cv2.cvtColor(image_now_color, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # menghitung score selisih gambar dengan background\n",
    "    # semakin besar score, semakin sedikit foreground\n",
    "    (score, diff) = compare_ssim(bg, image_now, full=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "    # angka 9 ini adalah magic number yang saya temukan dapat mendeteksi mobil dengan ukuran yang baik\n",
    "    # dapat dikatakan saya mendapat angka 9 ini dari human training\n",
    "    diffr = np.add(diff, 9)\n",
    "    thresh = cv2.threshold(diffr, 0, 255, \n",
    "                           cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    \n",
    "    car_count = 0\n",
    "    for c in cnts:\n",
    "        # mendapatkan x, y, w, h dari setiap kontur\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # hanya menampilkan kontur dengan constraint tertentu, untuk mempermudah labeling\n",
    "        # angka 30, 500, dan 900 disini saya tentukan sendiri dengan asumsi tidak ada gambar mobil\n",
    "        # yang tidak memenuhi constrain tersebut\n",
    "        if w>30 and h>30 and h<500 and w<500:\n",
    "            \n",
    "            # mencari score ssim untuk setiap kontur\n",
    "            bg_crop = bg[y:y+h, x:x+w]\n",
    "            image_now_crop = image_now[y:y+h, x:x+w]\n",
    "            (score_crop, _) = compare_ssim(bg_crop, image_now_crop, full=True)\n",
    "            data = pd.DataFrame([(x,y,w,h,score_crop,w*h,w/h)])\n",
    "            car_count_predict = int(round(clf.predict(data)[0]))\n",
    "            if car_count_predict>=1:\n",
    "                color = (0,0,255)\n",
    "                # menampilkan hasil deteksi dan prediksi jumlah mobil\n",
    "                cv2.rectangle(image_now_color, (x, y), (x + w, y + h), color, 3)\n",
    "                cv2.putText(image_now_color, str(car_count_predict), (x, y+35), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, thickness=3)\n",
    "                car_count += car_count_predict\n",
    "                \n",
    "    cv2.putText(image_now_color, 'car count:'+str(car_count), (0, 0+100), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,0,255), thickness=3)\n",
    "    cv2.imwrite('./output/Prediction/prediction_'+image_file+'.png',image_now_color)\n",
    "#     cv2.imshow('prediction result', image_now_color)\n",
    "#     cv2.waitKey(1)\n",
    "            \n",
    "            \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi\n",
    "\n",
    "Akan dipilih model untuk melakukan prediksi, dengan mengukur RMSE, MAE, dan akurasi pada ukuran sample tertentu. \n",
    "\n",
    "Akurasi adalah berapa banyaknya prediksi yang benar.\n",
    "\n",
    "Error dihitung dari selisih prediksi dengan label yang benar.\n",
    "\n",
    "Pengukuran dilakukan pada sample karena pengukuran pada populasi membutuhkan waktu yang lama, dan pengukuran dari random sample cukup untuk mengetahui model mana yang paling optimal.\n",
    "\n",
    "Model-model yang akan digunakan adalah model regresi. Saya memilih model regresi karena saya melakukan pelabelan pada setiap kontur, dengan menghitung jumlah mobil yang terdapat pada kotak kontur tersebut.\n",
    "\n",
    "Karena sample yang diberi label sedikit, ada kemungkinan ada angka yang tidak terdapat pada label.\n",
    "\n",
    "Misal saya tidak menemukan kontur yang berisi 5 mobil, maka dengan classifier kita tidak akan mendapatkan hasil prediksi 5.\n",
    "\n",
    "Sedangkan dengan regresi, model dapat menghitung jumlah mobil secara kontinyu dari fitur-fitur yang diberikan.\n",
    "\n",
    "Hasil prediksi regresi akan mengembalikan prediksi jumlah mobil dalam pecahan, maka setiap prediksinya saya bulatkan ke bilangan bulat terdekat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0b95f0d1854f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import randint\n",
    "from skimage.measure import compare_ssim\n",
    "from random import randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "labeled = pd.read_csv('./input/labeled.csv',header=None)\n",
    "labeled.head()\n",
    "\n",
    "names = ['index','name','car_count','x','y','w','h','score']\n",
    "train_df = pd.read_csv('./input/train_labeled.csv', names=names)\n",
    "train_df.head()\n",
    "\n",
    "X = train_df[['x','y','w','h','score']]\n",
    "X['area']= np.multiply(X['w'],X['h'])\n",
    "X['aspect_ratio']= np.divide(X['w'],X['h'])\n",
    "Y = train_df['car_count']\n",
    "\n",
    "bg = cv2.imread('./output/Mean_Average_BG.png')\n",
    "bg = cv2.cvtColor(bg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression':LinearRegression(),\n",
    "    'Ridge':Ridge(),\n",
    "    'Lasso':Lasso(),\n",
    "    'ElasticNet':ElasticNet(),\n",
    "    'Random Forest Regressor':RandomForestRegressor(),\n",
    "    'Ada Boost Regressor':AdaBoostRegressor(),\n",
    "    'Extra Tree Regressor':ExtraTreesRegressor(),\n",
    "    'SVR':SVR(),\n",
    "}\n",
    "\n",
    "model_errors = []\n",
    "rand = randint(1,300)\n",
    "for name, model in models.items():\n",
    "    start = time.time()\n",
    "    model.fit(X,Y)\n",
    "    end = time.time()\n",
    "    train_time = (end-start)\n",
    "    errors = []\n",
    "    frame_times = []\n",
    "    for index, image_file in enumerate(os.listdir('./input/Image-Traffic/')):\n",
    "        if index>rand+50:\n",
    "            break\n",
    "        if index<rand:\n",
    "            continue\n",
    "        start = time.time()\n",
    "        # preprocessing gambar menjadi grayscale\n",
    "        image_now_color = cv2.imread('./input/Image-Traffic/'+image_file)\n",
    "        image_now = cv2.cvtColor(image_now_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # menghitung score selisih gambar dengan background\n",
    "        # semakin besar score, semakin sedikit foreground\n",
    "        (score, diff) = compare_ssim(bg, image_now, full=True)\n",
    "        diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "        # angka 9 ini adalah magic number yang saya temukan dapat mendeteksi mobil dengan ukuran yang baik\n",
    "        # dapat dikatakan saya mendapat angka 9 ini dari human training\n",
    "        diffr = np.add(diff, 9)\n",
    "        thresh = cv2.threshold(diffr, 0, 255, \n",
    "                               cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "\n",
    "        car_count = 0\n",
    "        for c in cnts:\n",
    "            # mendapatkan x, y, w, h dari setiap kontur\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "            # hanya menampilkan kontur dengan constraint tertentu, untuk mempermudah labeling\n",
    "            # angka 30, 500, dan 900 disini saya tentukan sendiri dengan asumsi tidak ada gambar mobil\n",
    "            # yang tidak memenuhi constrain tersebut\n",
    "            if w>30 and h>30 and h<900 and w<500:\n",
    "\n",
    "                # mencari score ssim untuk setiap kontur\n",
    "                bg_crop = bg[y:y+h, x:x+w]\n",
    "                image_now_crop = image_now[y:y+h, x:x+w]\n",
    "                (score_crop, _) = compare_ssim(bg_crop, image_now_crop, full=True)\n",
    "                data = pd.DataFrame([(x,y,w,h,score_crop,w*h,w/h)])\n",
    "                car_count_predict = (model.predict(data)[0])\n",
    "                \n",
    "                if car_count_predict>0:\n",
    "                    car_count += car_count_predict\n",
    "                    \n",
    "        end = time.time()\n",
    "        frame_time = (end-start)\n",
    "                    \n",
    "        yang_bener = labeled[labeled[0]==image_file].iloc[0,1]\n",
    "        error = int(round(car_count))-yang_bener\n",
    "        errors.append((error,))\n",
    "        frame_times.append((frame_time,))\n",
    "\n",
    "    errors = pd.DataFrame(errors)\n",
    "    frame_time_avg = pd.DataFrame(frame_times)[0].mean()\n",
    "    rmse = np.sqrt(errors[0].pow(2).mean())\n",
    "    akurasi = len(errors[errors[0]==0])/len(errors)\n",
    "    mae = errors[0].abs().mean()\n",
    "    model_errors.append((name, rmse, mae, akurasi, train_time, frame_time_avg))\n",
    "    \n",
    "model_errors = pd.DataFrame(model_errors, columns=['Model Name','RMSE','MAE','Akurasi','Train Time','Frame Time Average'])\n",
    "model_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./input/train_labeled.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1a05c53ef1e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'car_count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./input/train_labeled.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./input/train_labeled.csv' does not exist"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "names = ['index','name','car_count','x','y','w','h','score']\n",
    "train_df = pd.read_csv('./input/train_labeled.csv', names=names)\n",
    "train_df.head()\n",
    "\n",
    "X = train_df[['x','y','w','h','score']]\n",
    "X['area']= np.multiply(X['w'],X['h'])\n",
    "X['aspect_ratio']= np.divide(X['w'],X['h'])\n",
    "Y = train_df['car_count']\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "def evaluate(model):\n",
    "    model.fit(X,Y)\n",
    "    errors = []\n",
    "    for index, image_file in enumerate(os.listdir('./input/Image-Traffic/')):\n",
    "        if index>rand+30:\n",
    "            break\n",
    "        if index<rand:\n",
    "            continue\n",
    "        # preprocessing gambar menjadi grayscale\n",
    "        image_now_color = cv2.imread('./input/Image-Traffic/'+image_file)\n",
    "        image_now = cv2.cvtColor(image_now_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # menghitung score selisih gambar dengan background\n",
    "        # semakin besar score, semakin sedikit foreground\n",
    "        (score, diff) = compare_ssim(bg, image_now, full=True)\n",
    "        diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "        # angka 9 ini adalah magic number yang saya temukan dapat mendeteksi mobil dengan ukuran yang baik\n",
    "        # dapat dikatakan saya mendapat angka 9 ini dari human training\n",
    "        diffr = np.add(diff, 9)\n",
    "        thresh = cv2.threshold(diffr, 0, 255, \n",
    "                               cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "\n",
    "        car_count = 0\n",
    "        for c in cnts:\n",
    "            # mendapatkan x, y, w, h dari setiap kontur\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "            # hanya menampilkan kontur dengan constraint tertentu, untuk mempermudah labeling\n",
    "            # angka 30, 500, dan 900 disini saya tentukan sendiri dengan asumsi tidak ada gambar mobil\n",
    "            # yang tidak memenuhi constrain tersebut\n",
    "            if w>30 and h>30 and h<900 and w<500:\n",
    "\n",
    "                # mencari score ssim untuk setiap kontur\n",
    "                bg_crop = bg[y:y+h, x:x+w]\n",
    "                image_now_crop = image_now[y:y+h, x:x+w]\n",
    "                (score_crop, _) = compare_ssim(bg_crop, image_now_crop, full=True)\n",
    "                data = pd.DataFrame([(x,y,w,h,score_crop,w*h,w/h)])\n",
    "                car_count_predict = (model.predict(data)[0])\n",
    "                if car_count_predict>0:\n",
    "\n",
    "                    color = (0,0,255)\n",
    "                    car_count += car_count_predict\n",
    "                    \n",
    "        yang_bener = labeled[labeled[0]==image_file].iloc[0,1]\n",
    "        error = int(round(car_count))-yang_bener\n",
    "        errors.append((error,))\n",
    "\n",
    "    errors = pd.DataFrame(errors)\n",
    "    rmse = np.sqrt(errors[0].pow(2).mean())\n",
    "    akurasi = len(errors[errors[0]==0])/len(errors)\n",
    "    mae = errors[0].abs().mean()\n",
    "    return (rmse, mae, akurasi)\n",
    "\n",
    "base_model =RandomForestRegressor()\n",
    "base_model.fit(X,Y)\n",
    "result = evaluate(base_model)\n",
    "\n",
    "print(\"Base Random Forest Regressor\")\n",
    "print(\"RMSE:\",result[0])\n",
    "print(\"MAE:\",result[1])\n",
    "print(\"Akurasi:\",result[2])\n",
    "print()\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_distributions=random_grid,\n",
    "    n_iter = 100,\n",
    "    cv = 3,\n",
    "    verbose = 2,\n",
    "    random_state = 42,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "rf_random.fit(X,Y)\n",
    "best_random = rf_random.best_estimator_\n",
    "result = evaluate(base_model)\n",
    "print(\"Bast Random Forest Regressor\")\n",
    "print(\"RMSE:\",result[0])\n",
    "print(\"MAE:\",result[1])\n",
    "print(\"Akurasi:\",result[2])\n",
    "print()\n",
    "\n",
    "print(rf_random.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
