{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import auc, roc_auc_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from hyperopt import hp, tpe, Trials, fmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "21dfee9a9b316f07c2bb52766c5b8dc06da1ff78",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9b53144cbe79cabd454615366b8717678bba5527"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 202), (200000, 201))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>var_21</th>\n",
       "      <th>var_22</th>\n",
       "      <th>var_23</th>\n",
       "      <th>var_24</th>\n",
       "      <th>var_25</th>\n",
       "      <th>var_26</th>\n",
       "      <th>var_27</th>\n",
       "      <th>var_28</th>\n",
       "      <th>var_29</th>\n",
       "      <th>var_30</th>\n",
       "      <th>var_31</th>\n",
       "      <th>var_32</th>\n",
       "      <th>var_33</th>\n",
       "      <th>var_34</th>\n",
       "      <th>var_35</th>\n",
       "      <th>var_36</th>\n",
       "      <th>var_37</th>\n",
       "      <th>...</th>\n",
       "      <th>var_160</th>\n",
       "      <th>var_161</th>\n",
       "      <th>var_162</th>\n",
       "      <th>var_163</th>\n",
       "      <th>var_164</th>\n",
       "      <th>var_165</th>\n",
       "      <th>var_166</th>\n",
       "      <th>var_167</th>\n",
       "      <th>var_168</th>\n",
       "      <th>var_169</th>\n",
       "      <th>var_170</th>\n",
       "      <th>var_171</th>\n",
       "      <th>var_172</th>\n",
       "      <th>var_173</th>\n",
       "      <th>var_174</th>\n",
       "      <th>var_175</th>\n",
       "      <th>var_176</th>\n",
       "      <th>var_177</th>\n",
       "      <th>var_178</th>\n",
       "      <th>var_179</th>\n",
       "      <th>var_180</th>\n",
       "      <th>var_181</th>\n",
       "      <th>var_182</th>\n",
       "      <th>var_183</th>\n",
       "      <th>var_184</th>\n",
       "      <th>var_185</th>\n",
       "      <th>var_186</th>\n",
       "      <th>var_187</th>\n",
       "      <th>var_188</th>\n",
       "      <th>var_189</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>2.9252</td>\n",
       "      <td>3.1821</td>\n",
       "      <td>14.0137</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>8.7989</td>\n",
       "      <td>14.5691</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>-7.2393</td>\n",
       "      <td>4.2840</td>\n",
       "      <td>30.7133</td>\n",
       "      <td>10.5350</td>\n",
       "      <td>16.2191</td>\n",
       "      <td>2.5791</td>\n",
       "      <td>2.4716</td>\n",
       "      <td>14.3831</td>\n",
       "      <td>13.4325</td>\n",
       "      <td>-5.1488</td>\n",
       "      <td>-0.4073</td>\n",
       "      <td>4.9306</td>\n",
       "      <td>5.9965</td>\n",
       "      <td>-0.3085</td>\n",
       "      <td>12.9041</td>\n",
       "      <td>-3.8766</td>\n",
       "      <td>16.8911</td>\n",
       "      <td>11.1920</td>\n",
       "      <td>10.5785</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>7.8871</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4576</td>\n",
       "      <td>5.3133</td>\n",
       "      <td>3.6159</td>\n",
       "      <td>5.0384</td>\n",
       "      <td>6.6760</td>\n",
       "      <td>12.6644</td>\n",
       "      <td>2.7004</td>\n",
       "      <td>-0.6975</td>\n",
       "      <td>9.5981</td>\n",
       "      <td>5.4879</td>\n",
       "      <td>-4.7645</td>\n",
       "      <td>-8.4254</td>\n",
       "      <td>20.8773</td>\n",
       "      <td>3.1531</td>\n",
       "      <td>18.5618</td>\n",
       "      <td>7.7423</td>\n",
       "      <td>-10.1245</td>\n",
       "      <td>13.7241</td>\n",
       "      <td>-3.5189</td>\n",
       "      <td>1.7202</td>\n",
       "      <td>-8.4051</td>\n",
       "      <td>9.0164</td>\n",
       "      <td>3.0657</td>\n",
       "      <td>14.3691</td>\n",
       "      <td>25.8398</td>\n",
       "      <td>5.8764</td>\n",
       "      <td>11.8411</td>\n",
       "      <td>-19.7159</td>\n",
       "      <td>17.5743</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>-0.4032</td>\n",
       "      <td>8.0585</td>\n",
       "      <td>14.0239</td>\n",
       "      <td>8.4135</td>\n",
       "      <td>5.4345</td>\n",
       "      <td>13.7003</td>\n",
       "      <td>13.8275</td>\n",
       "      <td>-15.5849</td>\n",
       "      <td>7.8000</td>\n",
       "      <td>28.5708</td>\n",
       "      <td>3.4287</td>\n",
       "      <td>2.7407</td>\n",
       "      <td>8.5524</td>\n",
       "      <td>3.3716</td>\n",
       "      <td>6.9779</td>\n",
       "      <td>13.8910</td>\n",
       "      <td>-11.7684</td>\n",
       "      <td>-2.5586</td>\n",
       "      <td>5.0464</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>-9.2987</td>\n",
       "      <td>7.8755</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>19.3710</td>\n",
       "      <td>11.3702</td>\n",
       "      <td>0.7399</td>\n",
       "      <td>2.7995</td>\n",
       "      <td>5.8434</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4846</td>\n",
       "      <td>5.8683</td>\n",
       "      <td>3.8208</td>\n",
       "      <td>15.8348</td>\n",
       "      <td>-5.0121</td>\n",
       "      <td>15.1345</td>\n",
       "      <td>3.2003</td>\n",
       "      <td>9.3192</td>\n",
       "      <td>3.8821</td>\n",
       "      <td>5.7999</td>\n",
       "      <td>5.5378</td>\n",
       "      <td>5.0988</td>\n",
       "      <td>22.0330</td>\n",
       "      <td>5.5134</td>\n",
       "      <td>30.2645</td>\n",
       "      <td>10.4968</td>\n",
       "      <td>-7.2352</td>\n",
       "      <td>16.5721</td>\n",
       "      <td>-7.3477</td>\n",
       "      <td>11.0752</td>\n",
       "      <td>-5.5937</td>\n",
       "      <td>9.4878</td>\n",
       "      <td>-14.9100</td>\n",
       "      <td>9.4245</td>\n",
       "      <td>22.5441</td>\n",
       "      <td>-4.8622</td>\n",
       "      <td>7.6543</td>\n",
       "      <td>-15.9319</td>\n",
       "      <td>13.3175</td>\n",
       "      <td>-0.3566</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>-0.3249</td>\n",
       "      <td>-11.2648</td>\n",
       "      <td>14.1929</td>\n",
       "      <td>7.3124</td>\n",
       "      <td>7.5244</td>\n",
       "      <td>14.6472</td>\n",
       "      <td>7.6782</td>\n",
       "      <td>-1.7395</td>\n",
       "      <td>4.7011</td>\n",
       "      <td>20.4775</td>\n",
       "      <td>17.7559</td>\n",
       "      <td>18.1377</td>\n",
       "      <td>1.2145</td>\n",
       "      <td>3.5137</td>\n",
       "      <td>5.6777</td>\n",
       "      <td>13.2177</td>\n",
       "      <td>-7.9940</td>\n",
       "      <td>-2.9029</td>\n",
       "      <td>5.8463</td>\n",
       "      <td>6.1439</td>\n",
       "      <td>-11.1025</td>\n",
       "      <td>12.4858</td>\n",
       "      <td>-2.2871</td>\n",
       "      <td>19.0422</td>\n",
       "      <td>11.0449</td>\n",
       "      <td>4.1087</td>\n",
       "      <td>4.6974</td>\n",
       "      <td>6.9346</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2070</td>\n",
       "      <td>5.8442</td>\n",
       "      <td>4.7086</td>\n",
       "      <td>5.7141</td>\n",
       "      <td>-1.0410</td>\n",
       "      <td>20.5092</td>\n",
       "      <td>3.2790</td>\n",
       "      <td>-5.5952</td>\n",
       "      <td>7.3176</td>\n",
       "      <td>5.7690</td>\n",
       "      <td>-7.0927</td>\n",
       "      <td>-3.9116</td>\n",
       "      <td>7.2569</td>\n",
       "      <td>-5.8234</td>\n",
       "      <td>25.6820</td>\n",
       "      <td>10.9202</td>\n",
       "      <td>-0.3104</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>-9.7009</td>\n",
       "      <td>2.4013</td>\n",
       "      <td>-4.2935</td>\n",
       "      <td>9.3908</td>\n",
       "      <td>-13.2648</td>\n",
       "      <td>3.1545</td>\n",
       "      <td>23.0866</td>\n",
       "      <td>-5.3000</td>\n",
       "      <td>5.3745</td>\n",
       "      <td>-6.2660</td>\n",
       "      <td>10.1934</td>\n",
       "      <td>-0.8417</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>2.3061</td>\n",
       "      <td>2.8102</td>\n",
       "      <td>13.8463</td>\n",
       "      <td>11.9704</td>\n",
       "      <td>6.4569</td>\n",
       "      <td>14.8372</td>\n",
       "      <td>10.7430</td>\n",
       "      <td>-0.4299</td>\n",
       "      <td>15.9426</td>\n",
       "      <td>13.7257</td>\n",
       "      <td>20.3010</td>\n",
       "      <td>12.5579</td>\n",
       "      <td>6.8202</td>\n",
       "      <td>2.7229</td>\n",
       "      <td>12.1354</td>\n",
       "      <td>13.7367</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>-0.9059</td>\n",
       "      <td>5.9070</td>\n",
       "      <td>2.8407</td>\n",
       "      <td>-15.2398</td>\n",
       "      <td>10.4407</td>\n",
       "      <td>-2.5731</td>\n",
       "      <td>6.1796</td>\n",
       "      <td>10.6093</td>\n",
       "      <td>-5.9158</td>\n",
       "      <td>8.1723</td>\n",
       "      <td>2.8521</td>\n",
       "      <td>...</td>\n",
       "      <td>31.8833</td>\n",
       "      <td>5.9684</td>\n",
       "      <td>7.2084</td>\n",
       "      <td>3.8899</td>\n",
       "      <td>-11.0882</td>\n",
       "      <td>17.2502</td>\n",
       "      <td>2.5881</td>\n",
       "      <td>-2.7018</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>5.3430</td>\n",
       "      <td>-7.1541</td>\n",
       "      <td>-6.1920</td>\n",
       "      <td>18.2366</td>\n",
       "      <td>11.7134</td>\n",
       "      <td>14.7483</td>\n",
       "      <td>8.1013</td>\n",
       "      <td>11.8771</td>\n",
       "      <td>13.9552</td>\n",
       "      <td>-10.4701</td>\n",
       "      <td>5.6961</td>\n",
       "      <td>-3.7546</td>\n",
       "      <td>8.4117</td>\n",
       "      <td>1.8986</td>\n",
       "      <td>7.2601</td>\n",
       "      <td>-0.4639</td>\n",
       "      <td>-0.0498</td>\n",
       "      <td>7.9336</td>\n",
       "      <td>-12.8279</td>\n",
       "      <td>12.4124</td>\n",
       "      <td>1.8489</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>-9.4458</td>\n",
       "      <td>-12.1419</td>\n",
       "      <td>13.8481</td>\n",
       "      <td>7.8895</td>\n",
       "      <td>7.7894</td>\n",
       "      <td>15.0553</td>\n",
       "      <td>8.4871</td>\n",
       "      <td>-3.0680</td>\n",
       "      <td>6.5263</td>\n",
       "      <td>11.3152</td>\n",
       "      <td>21.4246</td>\n",
       "      <td>18.9608</td>\n",
       "      <td>10.1102</td>\n",
       "      <td>2.7142</td>\n",
       "      <td>14.2080</td>\n",
       "      <td>13.5433</td>\n",
       "      <td>3.1736</td>\n",
       "      <td>-3.3423</td>\n",
       "      <td>5.9015</td>\n",
       "      <td>7.9352</td>\n",
       "      <td>-3.1582</td>\n",
       "      <td>9.4668</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>19.3239</td>\n",
       "      <td>12.4057</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>2.7922</td>\n",
       "      <td>5.8184</td>\n",
       "      <td>...</td>\n",
       "      <td>33.5107</td>\n",
       "      <td>5.6953</td>\n",
       "      <td>5.4663</td>\n",
       "      <td>18.2201</td>\n",
       "      <td>6.5769</td>\n",
       "      <td>21.2607</td>\n",
       "      <td>3.2304</td>\n",
       "      <td>-1.7759</td>\n",
       "      <td>3.1283</td>\n",
       "      <td>5.5518</td>\n",
       "      <td>1.4493</td>\n",
       "      <td>-2.6627</td>\n",
       "      <td>19.8056</td>\n",
       "      <td>2.3705</td>\n",
       "      <td>18.4685</td>\n",
       "      <td>16.3309</td>\n",
       "      <td>-3.3456</td>\n",
       "      <td>13.5261</td>\n",
       "      <td>1.7189</td>\n",
       "      <td>5.1743</td>\n",
       "      <td>-7.6938</td>\n",
       "      <td>9.7685</td>\n",
       "      <td>4.8910</td>\n",
       "      <td>12.2198</td>\n",
       "      <td>11.8503</td>\n",
       "      <td>-7.8931</td>\n",
       "      <td>6.4209</td>\n",
       "      <td>5.9270</td>\n",
       "      <td>16.0201</td>\n",
       "      <td>-0.2829</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1   ...     var_196  var_197  var_198  var_199\n",
       "0  train_0       0   8.9255 -6.7863   ...      7.8784   8.5635  12.7803  -1.0914\n",
       "1  train_1       0  11.5006 -4.1473   ...      8.1267   8.7889  18.3560   1.9518\n",
       "2  train_2       0   8.6093 -2.7457   ...     -6.5213   8.2675  14.7222   0.3965\n",
       "3  train_3       0  11.0604 -2.1518   ...     -2.9275  10.2922  17.9697  -8.9996\n",
       "4  train_4       0   9.8369 -1.4834   ...      3.9267   9.5031  17.9974  -8.8104\n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "07b5d8cf1d7305e75c82b12cd65ee5f628d1d36e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10049"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train['target']) / len(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "79279f17aded7c7a9e3bf7063294560bd943a377"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                        train.drop(['ID_code', 'target'], axis = 1),\n",
    "                                                        train['target'],\n",
    "                                                        test_size = 0.15,\n",
    "                                                        random_state = 42,\n",
    "                                                        stratify = train['target']\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "65a473cc18c84af1128888a1184cc7562a60a725"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10048823529411764, 0.1005)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train) / len(y_train), np.sum(y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "072b889710793689e0451a1fb868f794b6d5d199"
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    n_folds = 3\n",
    "    params = {\n",
    "                'n_estimators': int(params['n_estimators']),\n",
    "                'num_leaves': int(params['num_leaves']),\n",
    "                'learning_rate': float(params['learning_rate']),\n",
    "                'subsample_for_bin': int(params['subsample_for_bin']),\n",
    "                'min_child_samples': int(params['min_child_samples']),\n",
    "                'reg_alpha': float(params['reg_alpha']),\n",
    "                'reg_lambda': float(params['reg_lambda'])\n",
    "             }\n",
    "    \n",
    "    clf = LGBMClassifier(**params)\n",
    "    score1 = cross_val_score(clf, X_train, y_train, scoring = 'roc_auc', cv = StratifiedKFold(n_splits = n_folds)).mean()\n",
    "    clf.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set = [(X_test, y_test)],\n",
    "                eval_metric = 'auc',\n",
    "                early_stopping_rounds = 3,\n",
    "                verbose = False,\n",
    "            )\n",
    "    score2 = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    score = 2 / ((1 / score1) + (1 / score2))\n",
    "\n",
    "    return 1 - score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "bb01f78142bc73bf3136e1b3618db759ce6f1024"
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "            'n_estimators': hp.quniform('n_estimators', 50, 1500, 25),\n",
    "            'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "            'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "            'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "            'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "            'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "            'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0)\n",
    "        }\n",
    "tpe_algo = tpe.suggest\n",
    "tpe_trials = Trials()\n",
    "\n",
    "# tpe_best = fmin(fn = objective, space = space, algo = tpe_algo, trials = tpe_trials, \n",
    "#                 max_evals = 15, rstate = np.random.RandomState(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "3b6069aa886800d5198750f1a8758659a43fcec2"
   },
   "outputs": [],
   "source": [
    "# tpe_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2168a9080bea31caa65187dfe0227ba0688b47b5"
   },
   "outputs": [],
   "source": [
    "# params = {\n",
    "#             'n_estimators': int(tpe_best['n_estimators']),\n",
    "#             'num_leaves': int(tpe_best['num_leaves']),\n",
    "#             'learning_rate': float(tpe_best['learning_rate']),\n",
    "#             'subsample_for_bin': int(tpe_best['subsample_for_bin']),\n",
    "#             'min_child_samples': int(tpe_best['min_child_samples']),\n",
    "#             'reg_alpha': float(tpe_best['reg_alpha']),\n",
    "#             'reg_lambda': float(tpe_best['reg_lambda'])\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "edf9f26cb5310bf8c5b60bd086140b7fa66a65b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\tvalid_0's auc: 0.857988\n",
      "[2000]\tvalid_0's auc: 0.879314\n",
      "[3000]\tvalid_0's auc: 0.88762\n",
      "[4000]\tvalid_0's auc: 0.892024\n",
      "[5000]\tvalid_0's auc: 0.894185\n",
      "[6000]\tvalid_0's auc: 0.895363\n",
      "[7000]\tvalid_0's auc: 0.896013\n",
      "[8000]\tvalid_0's auc: 0.896308\n",
      "[9000]\tvalid_0's auc: 0.896479\n",
      "Early stopping, best iteration is:\n",
      "[8891]\tvalid_0's auc: 0.896513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_freq=5, bagging_seed=11, boosting='gbdt',\n",
       "        boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        feature_fraction=0.8201, importance_type='split',\n",
       "        learning_rate=0.0123, max_depth=16, metric='auc',\n",
       "        min_child_samples=20, min_child_weight=19.428902804238373,\n",
       "        min_data_in_leaf=42, min_gain_to_split=0.01077313523861969,\n",
       "        min_split_gain=0.0, n_estimators=20000, n_jobs=-1, num_leaves=8,\n",
       "        num_threads=4, objective='binary', random_state=42,\n",
       "        reg_alpha=1.728910519108444, reg_lambda=4.9847051755586085,\n",
       "        silent=True, subsample=0.81, subsample_for_bin=200000,\n",
       "        subsample_freq=0, verbosity=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "            'bagging_freq': 5,\n",
    "            'bagging_fraction': 0.331,\n",
    "            'boost_from_average':'false',\n",
    "            'boost': 'gbdt',\n",
    "            'feature_fraction': 0.0405,\n",
    "            'learning_rate': 0.0083,\n",
    "            'max_depth': -1,\n",
    "            'metric':'auc',\n",
    "            'min_data_in_leaf': 80,\n",
    "            'min_sum_hessian_in_leaf': 10.0,\n",
    "            'num_leaves': 13,\n",
    "            'num_threads': 8,\n",
    "            'tree_learner': 'serial',\n",
    "            'objective': 'binary',\n",
    "            'verbosity': 1\n",
    "        }\n",
    "\n",
    "params = {\n",
    "             'num_leaves': 8,\n",
    "             'min_data_in_leaf': 42,\n",
    "             'objective': 'binary',\n",
    "             'max_depth': 16,\n",
    "             'learning_rate': 0.0123,\n",
    "             'boosting': 'gbdt',\n",
    "             'bagging_freq': 5,\n",
    "             'feature_fraction': 0.8201,\n",
    "             'bagging_seed': 11,\n",
    "             'reg_alpha': 1.728910519108444,\n",
    "             'reg_lambda': 4.9847051755586085,\n",
    "             'random_state': 42,\n",
    "             'metric': 'auc',\n",
    "             'verbosity': -1,\n",
    "             'subsample': 0.81,\n",
    "             'min_gain_to_split': 0.01077313523861969,\n",
    "             'min_child_weight': 19.428902804238373,\n",
    "             'num_threads': 4\n",
    "         }\n",
    "\n",
    "lgb_base = LGBMClassifier(**params, n_estimators = 20000)\n",
    "\n",
    "lgb_base.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set = [(X_test, y_test)],\n",
    "                eval_metric = 'auc',\n",
    "                early_stopping_rounds = 200,\n",
    "                verbose = 1000,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "671d6af6e93a41c35e0d4b649821db8b2dfbf724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC:\n",
      "0.9461715902596058\n",
      "\n",
      "\n",
      "Testing AUC:\n",
      "0.89651303730867\n"
     ]
    }
   ],
   "source": [
    "print(\"Training AUC:\")\n",
    "print(roc_auc_score(y_train, lgb_base.predict_proba(X_train)[:, 1]))\n",
    "print(\"\\n\")\n",
    "print(\"Testing AUC:\")\n",
    "print(roc_auc_score(y_test, lgb_base.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "d861d39c9b39360ed56756dce7958ca3ea03197c"
   },
   "outputs": [],
   "source": [
    "submission['target'] = 1 - lgb_base.predict_proba(test.drop('ID_code', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "35f6c332e0f584476b7a0d0967077515c34ef186"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.091183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.216087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.205930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.169996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.049044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.091183\n",
       "1  test_1  0.216087\n",
       "2  test_2  0.205930\n",
       "3  test_3  0.169996\n",
       "4  test_4  0.049044"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "0e46a01e295f0267d514694ef834f6ac09b3aa76"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_hyperparams_borrowed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "dd05a78cb2e8e28c6d647fa429d7635ae9f07fbd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e6a7776e4e5171dd05d4b72938da4b117e780acc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "bd899780eb2e18c8786e9838be8898a423a546ed"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
