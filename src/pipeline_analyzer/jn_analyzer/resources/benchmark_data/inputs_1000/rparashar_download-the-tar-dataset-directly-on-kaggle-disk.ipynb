{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the tar dataset on kaggle disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disclaimer:\n",
    "> I created the whole program just as quick and dirty way to get what I want. \n",
    "> Have not put any best practices in place such as exception handling or proper naming conventions etc.\n",
    "> So please excuse if it's not up to your standard of standard code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what the program does:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Downloads the tar file one at a time\n",
    "2. Extracts the files in it\n",
    "3. Deletes the tar file after extraction\n",
    "3. Resizes all files with the given JPEG quality in a temp directory\n",
    "4. Moves the files to the main folder\n",
    "5. Removes the temp directory\n",
    "6. Moves to the next tar file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define settings for the process\n",
    "Most importantly define the tar file count below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAR_FILE_COUNT_TO_PROCESS = 0  # <----------------------- Change this parameter to the number of tar files you want to process\n",
    "ROOT_DIR = '/kaggle/working/'\n",
    "TEMP_FOLDER_NAME = 'processing/'\n",
    "\n",
    "IMAGE_W = 128                  # size of image, square images of this size will be generated\n",
    "JPG_QUALITY = 70               # quality of the jpg file\n",
    "VERBOSE = 0                    # if you want detailed log of what's going on\n",
    "TESTING = 0                    # to test the whole process with a few files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for i in range(TAR_FILE_COUNT_TO_PROCESS):\n",
    "    url = 'https://s3.amazonaws.com/google-landmark/train/images_' + \"{:03d}\".format(i) + '.tar'\n",
    "    urls.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "from PIL import Image\n",
    "import tarfile\n",
    "\n",
    "class ImageDownloadWorker:\n",
    "    \n",
    "    def process_image_files(self):\n",
    "        for i, new_url in enumerate(urls):\n",
    "            print('URL: ' + new_url)\n",
    "            self.download_zipfile_from_url(new_url)           #e.g. downloaded the tar file of images\n",
    "            filename = new_url[new_url.rfind(\"/\")+1:]         #e.g. image_000.tar\n",
    "            tar_file_path = os.path.join(ROOT_DIR, filename)\n",
    "            temp_dir_path = os.path.join(ROOT_DIR, TEMP_FOLDER_NAME)\n",
    "            self.untar(tar_file_path, temp_dir_path)          #e.g. extracts image_000.tar to target dir\n",
    "            self.remove_tar(tar_file_path)\n",
    "            self.process_images(temp_dir_path)\n",
    "            self.copytree(temp_dir_path, ROOT_DIR)\n",
    "            self.remove_temp_dir(temp_dir_path)\n",
    "            print('-------------- Done: ' + str(i+1))\n",
    "\n",
    "    def copytree(self, src, dst, symlinks=False, ignore=None):\n",
    "        if(VERBOSE == 1):\n",
    "            print('Processing directory: ' + src)\n",
    "        \n",
    "        for item in os.listdir(src):\n",
    "            s = os.path.join(src, item)\n",
    "            d = os.path.join(dst, item)\n",
    "            if os.path.isdir(s):\n",
    "                self.copytree(s, d, symlinks, ignore)\n",
    "            else:\n",
    "                if(VERBOSE == 1):\n",
    "                    print('source: ' + s + '\\n' + 'dest: ' + d)\n",
    "                head, tail = os.path.split(d)\n",
    "                if(not os.path.exists(head)):\n",
    "                    os.makedirs(head)\n",
    "                shutil.copy2(s, d)\n",
    "                if(VERBOSE == 1):\n",
    "                    print('Copied')\n",
    "            \n",
    "    def download_zipfile_from_url(self, _url):\n",
    "        filename = _url[_url.rfind(\"/\")+1:]\n",
    "        if(not os.path.exists(os.path.join(ROOT_DIR, filename)) ):\n",
    "            print('Downloading url: ' + _url + ' to file: ' + filename)\n",
    "            urlretrieve(_url, _url[_url.rfind(\"/\")+1:])\n",
    "            print('Done.')\n",
    "        else:\n",
    "            print('File already downloaded: ' + filename)\n",
    "    \n",
    "    def remove_tar(self, _file_path):\n",
    "        print('Removing tar file: ' + _file_path)\n",
    "        os.remove(_file_path)\n",
    "        print('Done.')\n",
    "\n",
    "    def remove_temp_dir(self, _dir_path):\n",
    "        print('Removing temp dir: ' + _dir_path)\n",
    "        shutil.rmtree(_dir_path)\n",
    "        print('Done.')        \n",
    "\n",
    "    def untar(self, _source_file_path, _target_dir_path):\n",
    "        print('Extracting file data: ' + _source_file_path + ' to: ' + _target_dir_path)\n",
    "        tf = tarfile.open(_source_file_path)\n",
    "        if(os.path.exists(_target_dir_path)):\n",
    "            print('Removing temp folder: ' + _target_dir_path)\n",
    "            shutil.rmtree(_target_dir_path)\n",
    "        \n",
    "        print('Creating temp folder at: ' + _target_dir_path)\n",
    "        os.mkdir(_target_dir_path)\n",
    "        \n",
    "        print('Extracting tar...')\n",
    "        tf.extractall(_target_dir_path)\n",
    "        print('Done.')\n",
    "        \n",
    "    def resize_image(self, _img_path):\n",
    "        if (VERBOSE == 1):\n",
    "            print('Resizing image: ' + _img_path)\n",
    "            \n",
    "        img = Image.open(_img_path)\n",
    "        old_size = img.size\n",
    "        ratio = float(IMAGE_W)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        img = img.resize(new_size, Image.ANTIALIAS)\n",
    "        new_img = Image.new(\"RGB\", (IMAGE_W, IMAGE_W))\n",
    "        new_img.paste(img, ((IMAGE_W-new_size[0])//2,\n",
    "                        (IMAGE_W-new_size[1])//2))\n",
    "        new_img.save(_img_path, \"JPEG\", optimize=True, quality=JPG_QUALITY)\n",
    "\n",
    "    \n",
    "    def process_images(self, _folder_path):\n",
    "        print('Processing images from folder: ' + _folder_path)\n",
    "        for root, subFolders, files in os.walk(_folder_path):\n",
    "            for file in files:\n",
    "                full_file_path = os.path.join(root, file)\n",
    "                if(VERBOSE == 1):\n",
    "                    print('Full file path: ' + full_file_path)\n",
    "                if(full_file_path[full_file_path.rfind('.jpg')+1:] == 'jpg'):\n",
    "                    self.resize_image(full_file_path)\n",
    "                    if(TESTING == 1):\n",
    "                        break\n",
    "    \n",
    "    \n",
    "    \n",
    "# Run the program\n",
    "\n",
    "worker = ImageDownloadWorker()\n",
    "worker.process_image_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
