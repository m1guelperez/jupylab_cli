{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:00:02.294520Z",
     "iopub.status.busy": "2020-09-27T03:00:02.293724Z",
     "iopub.status.idle": "2020-09-27T03:00:20.447115Z",
     "shell.execute_reply": "2020-09-27T03:00:20.446300Z"
    },
    "papermill": {
     "duration": 18.179152,
     "end_time": "2020-09-27T03:00:20.447252",
     "exception": false,
     "start_time": "2020-09-27T03:00:02.268100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.7/site-packages (1.1.1)\r\n",
      "Collecting lightgbm==2.2.3\r\n",
      "  Downloading lightgbm-2.2.3-py2.py3-none-manylinux1_x86_64.whl (1.2 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 574 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from lightgbm==2.2.3) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from lightgbm==2.2.3) (0.23.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lightgbm==2.2.3) (1.18.5)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->lightgbm==2.2.3) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->lightgbm==2.2.3) (2.1.0)\r\n",
      "Installing collected packages: lightgbm\r\n",
      "Successfully installed lightgbm-2.2.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode\n",
    "!pip install lightgbm==2.2.3 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-27T03:00:20.509837Z",
     "iopub.status.busy": "2020-09-27T03:00:20.508920Z",
     "iopub.status.idle": "2020-09-27T03:00:21.528381Z",
     "shell.execute_reply": "2020-09-27T03:00:21.527626Z"
    },
    "papermill": {
     "duration": 1.055965,
     "end_time": "2020-09-27T03:00:21.528502",
     "exception": false,
     "start_time": "2020-09-27T03:00:20.472537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "from unidecode import unidecode\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "#pd.options.display.max_columns = 50\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-27T03:00:21.587200Z",
     "iopub.status.busy": "2020-09-27T03:00:21.586456Z",
     "iopub.status.idle": "2020-09-27T03:00:24.028297Z",
     "shell.execute_reply": "2020-09-27T03:00:24.027479Z"
    },
    "papermill": {
     "duration": 2.475295,
     "end_time": "2020-09-27T03:00:24.028428",
     "exception": false,
     "start_time": "2020-09-27T03:00:21.553133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/klps-creditscring-challenge-for-students/train.csv')\n",
    "df_test = pd.read_csv('../input/klps-creditscring-challenge-for-students/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024397,
     "end_time": "2020-09-27T03:00:24.079445",
     "exception": false,
     "start_time": "2020-09-27T03:00:24.055048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocessing time columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:00:24.153662Z",
     "iopub.status.busy": "2020-09-27T03:00:24.148501Z",
     "iopub.status.idle": "2020-09-27T03:00:32.591900Z",
     "shell.execute_reply": "2020-09-27T03:00:32.591117Z"
    },
    "papermill": {
     "duration": 8.487695,
     "end_time": "2020-09-27T03:00:32.592025",
     "exception": false,
     "start_time": "2020-09-27T03:00:24.104330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time = [\"Field_{}\".format(i) for i in [1, 2, 43, 44]]\n",
    "date = [\"Field_{}\".format(i) for i in [5, 6, 7, 8, 9, 11, 15, 25, 32, 33, 35, 40]]\n",
    "other_date = [\"F_startDate\", \"F_endDate\", \"E_startDate\", \"E_endDate\", \"C_startDate\",\n",
    "              \"C_endDate\", \"G_startDate\", \"G_endDate\", \"A_startDate\", \"A_endDate\"\n",
    "             ]\n",
    "time = date + date_time + other_date\n",
    "\n",
    "def split_date_train(s):\n",
    "    try:\n",
    "        date = s.split('-')\n",
    "        return date\n",
    "    except:\n",
    "        return np.nan\n",
    "def split_date_test(s):\n",
    "    try:\n",
    "        date = s.split('/')\n",
    "        return date\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df_train_c = df_train.copy()\n",
    "df_test_c =  df_test.copy()\n",
    "for col in date:\n",
    "    df_train_c[col] = df_train_c[col].apply(split_date_train)\n",
    "for col in date:\n",
    "    df_test_c[col] = df_test_c[col].apply(split_date_test)\n",
    "\n",
    "new_col = []\n",
    "for col in date: \n",
    "    df_train_c[col+'year'] =[s[0] if type(s) == list else np.nan  for s in df_train_c[col]]\n",
    "    df_train_c[col+'month'] =[s[1]if type(s) == list and len(s) >1  else np.nan for s in df_train_c[col]]\n",
    "    df_train_c[col+'day'] =[s[2]if type(s) == list and len(s) > 2  else np.nan for s in df_train_c[col]]\n",
    "    new_col.append(col+'year')\n",
    "    new_col.append(col+'month')\n",
    "    new_col.append(col+'day')\n",
    "    \n",
    "# the columns in \"date\" are the ones with format year/month/day in train set   \n",
    "\n",
    "#new_col_test = []\n",
    "for col in date: \n",
    "    df_test_c[col+'year'] =[s[2]if type(s) == list and len(s) > 2  else np.nan for s in df_test_c[col]]\n",
    "    df_test_c[col+'month'] =[s[0] if type(s) == list else np.nan  for s in df_test_c[col]]\n",
    "    df_test_c[col+'day'] =[s[1]if type(s) == list and len(s) >1  else np.nan for s in df_test_c[col]]\n",
    "    #new_col_test.append(col+'year')\n",
    "    #new_col_test.append(col+'month')\n",
    "    #new_col_test.append(col+'day')\n",
    "    \n",
    "# the columns in \"date\" are the ones with format month/day/year in test set  \n",
    "\n",
    "\n",
    "df_train_c = df_train_c.drop(date,1)\n",
    "df_test_c = df_test_c.drop(date,1)\n",
    "# and then check if the columns are match between train and test\n",
    "\n",
    "list(df_train_c)[2:] == list(df_test_c)[1:]\n",
    "\n",
    "def get_date(s):\n",
    "    try:\n",
    "        return s[:10]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "for col in date_time:\n",
    "    df_train_c[col] = df_train_c[col].apply(get_date)\n",
    "    df_test_c[col] = df_test_c[col].apply(get_date)\n",
    "# the columns in date_time at the format year/month/day in both train/test set\n",
    "for col in date_time:\n",
    "    df_train_c[col+'year']=[s[:4]if type(s) == str else np.nan for s in df_train_c[col]]\n",
    "    \n",
    "    df_train_c[col+'month']=[s[5:7]if type(s) == str else np.nan for s in df_train_c[col]]\n",
    "    \n",
    "    df_train_c[col+'day']=[s[8:10] if type(s) == str else np.nan for s in df_train_c[col]]\n",
    "\n",
    "new_col_1 = []\n",
    "\n",
    "for col in date_time:\n",
    "    df_test_c[col+'year']=[s[:4]if type(s) == str else np.nan for s in df_test_c[col]]\n",
    "    \n",
    "    df_test_c[col+'month']=[s[5:7]if type(s) == str else np.nan for s in df_test_c[col]]\n",
    "    \n",
    "    df_test_c[col+'day']=[s[8:10] if type(s) == str else np.nan for s in df_test_c[col]]\n",
    "    new_col_1.append(col+'year')\n",
    "    new_col_1.append(col+'month')\n",
    "    new_col_1.append(col+'day')\n",
    "\n",
    "\n",
    "df_train_c = df_train_c.drop(date_time,1)\n",
    "\n",
    "df_test_c = df_test_c.drop(date_time,1)\n",
    "\n",
    "#check again if the columns are match\n",
    "\n",
    "list(df_train_c)[2:] == list(df_test_c)[1:]\n",
    "\n",
    "for col in other_date:\n",
    "    df_train_c[col] = df_train_c[col].apply(split_date_train)\n",
    "for col in other_date: \n",
    "    df_train_c[col+'year'] =[s[0] if type(s) == list else np.nan  for s in df_train_c[col]]\n",
    "    df_train_c[col+'month'] =[s[1]if type(s) == list and len(s) >1  else np.nan for s in df_train_c[col]]\n",
    "    df_train_c[col+'day'] =[s[2]if type(s) == list and len(s) > 2  else np.nan for s in df_train_c[col]]\n",
    "    \n",
    "    \n",
    "# this the data in other_date in format year-month-day in train set\n",
    "\n",
    "for col in other_date:\n",
    "    df_test_c[col] = df_test_c[col].apply(split_date_test)\n",
    "new_col_2 = []\n",
    "for col in other_date: \n",
    "    df_test_c[col+'year'] =[s[2]if type(s) == list and len(s) > 2  else np.nan for s in df_test_c[col]]\n",
    "    df_test_c[col+'month'] =[s[0] if type(s) == list else np.nan  for s in df_test_c[col]]\n",
    "    df_test_c[col+'day'] =[s[1]if type(s) == list and len(s) >1  else np.nan for s in df_test_c[col]]\n",
    "    new_col_2.append(col+'year')\n",
    "    new_col_2.append(col+'month')\n",
    "    new_col_2.append(col+'day')\n",
    "    \n",
    "# the columns in \"date\" are the ones with format month/day/year in test set   \n",
    "\n",
    "df_train_c = df_train_c.drop(other_date,1)\n",
    "df_test_c = df_test_c.drop(other_date,1)\n",
    "\n",
    "list(df_train_c)[2:] == list(df_test_c)[1:]\n",
    "\n",
    "#convert to string first\n",
    "df_train_c[\"ngaySinh\"]= df_train_c[\"ngaySinh\"].apply(str)\n",
    "df_test_c[\"ngaySinh\"] = df_test_c[\"ngaySinh\"].apply(str)\n",
    "\n",
    "def get_age(s):\n",
    "    try:\n",
    "        return 2020 - int(s[:4])\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "df_train_c[\"ngaySinh\"]= df_train_c[\"ngaySinh\"].apply(get_age)\n",
    "df_test_c[\"ngaySinh\"] = df_test_c[\"ngaySinh\"].apply(get_age)\n",
    "        \n",
    "#process \"Field_34\"\n",
    "df_train_c[\"Field_34\"]= df_train_c[\"Field_34\"].apply(str)\n",
    "df_test_c[\"Field_34\"] = df_test_c[\"Field_34\"].apply(str)\n",
    "def get_year_34(s):\n",
    "  try:\n",
    "    return (s[:4])\n",
    "  except:\n",
    "    return np.nan\n",
    "def get_month_34(s):\n",
    "  try:\n",
    "    return (s[4:6])\n",
    "  except:\n",
    "    return np.nan\n",
    "\n",
    "df_train_c[\"Field_34year\"]= df_train_c[\"Field_34\"].apply(get_year_34)\n",
    "df_train_c[\"Field_34month\"] = df_train_c[\"Field_34\"].apply(get_month_34)\n",
    "\n",
    "df_test_c[\"Field_34year\"]= df_test_c[\"Field_34\"].apply(get_year_34)\n",
    "df_test_c[\"Field_34month\"] = df_test_c[\"Field_34\"].apply(get_month_34)\n",
    "\n",
    "df_train_c = df_train_c.drop(\"Field_34\",1)\n",
    "\n",
    "df_test_c = df_test_c.drop(\"Field_34\",1)\n",
    "\n",
    "list(df_train_c)[2:] == list(df_test_c)[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024817,
     "end_time": "2020-09-27T03:00:32.642012",
     "exception": false,
     "start_time": "2020-09-27T03:00:32.617195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocessing other columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:00:32.737919Z",
     "iopub.status.busy": "2020-09-27T03:00:32.721918Z",
     "iopub.status.idle": "2020-09-27T03:01:02.232824Z",
     "shell.execute_reply": "2020-09-27T03:01:02.232032Z"
    },
    "papermill": {
     "duration": 29.565776,
     "end_time": "2020-09-27T03:01:02.232967",
     "exception": false,
     "start_time": "2020-09-27T03:00:32.667191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the list of province in Vietnam\n",
    "province_list = ['An Giang','Bà Rịa – Vũng Tàu','Bắc Giang','Bắc Kạn','Bạc Liêu','Bắc Ninh','Bến Tre',\n",
    "'Bình Định','Bình Dương','Bình Phước','Bình Thuận','Cà Mau','Cần Thơ','Cao Bằng','Đà Nẵng','Đắk Lắk',\n",
    "'Đắk Nông','Điện Biên','Đồng Nai','Đồng Tháp','Gia Lai','Hà Giang','Hà Nam','Hà Nội','Hà Tĩnh','Hải Dương',\n",
    "'Hải Phòng','Hậu Giang','Hòa Bình','Hưng Yên','Khánh Hòa','Kiên Giang','Kon Tum','Lai Châu','Lâm Đồng',\n",
    "'Lạng Sơn','Lào Cai','Long An','Nam Định','Nghệ An','Ninh Bình','Ninh Thuận','Phú Thọ','Phú Yên',\n",
    "'Quảng Bình','Quảng Nam','Quảng Ngãi','Quảng Ninh','Quảng Trị','Sóc Trăng','Sơn La','Tây Ninh',\n",
    "'Thái Bình','Thái Nguyên','Thanh Hóa','Huế','Tiền Giang','Hồ Chí Minh','Trà Vinh','Tuyên Quang','Vĩnh Long',\n",
    "'Vĩnh Phúc','Yên Bái' ]\n",
    "#make all lower case\n",
    "province_list = [i.lower() for i in province_list]\n",
    "\n",
    "field_46 = pd.read_csv(\"../input/field-46-groupcsv/field_46_group.csv\")\n",
    "field_46 = field_46.replace(np.nan, '@#', regex=True)\n",
    "for i in list(field_46):\n",
    "  field_46[i] = field_46[i].str.lower()\n",
    "#fucntion to correct diachi\n",
    "def diachi(s):\n",
    "  for i in province_list:\n",
    "    try:\n",
    "      if i in s:\n",
    "        return i\n",
    "    except:\n",
    "      pass\n",
    "  return s\n",
    "\n",
    "# fucntion to correct Field_46\n",
    "\n",
    "def group_46(s):\n",
    "  for col in list(field_46):\n",
    "    for i in set(field_46[col]):\n",
    "      try:\n",
    "        if i in s:\n",
    "          return col \n",
    "      except:\n",
    "        pass \n",
    "  return \"None\"\n",
    "\n",
    "df_fe = df_train_c.drop(['label'], 1).append(df_test_c)\n",
    "df_fe['Field_46'] = df_fe['Field_46'].str.lower()\n",
    "df_fe['Field_46'] = df_fe['Field_46'].apply(group_46)\n",
    "\n",
    "\n",
    "#Field_49\n",
    "df_fe['Field_49'] = df_fe['Field_49'].str.lower()\n",
    "df_fe['Field_49'] = df_fe['Field_49'] .apply(diachi)\n",
    "def group_hcm(s):\n",
    "  district_num = [ 'q.1','q.2','q.3','q.4','q.5','q.6','q.7','q.8','q.9'\n",
    "                   ,'q.10','q.11','q.12',\n",
    "                   'q1','q2','q3','q4','q5','q6','q7','q8','q9','q10','q11','q12','q.']\n",
    "  name = ['hcm', 'saigon','sài gòn','quận','tpcm']\n",
    "  district_str = ['tân phú','phú nhuận','thủ đức','gò vấp',\n",
    "                  'bình thạnh','bình tân','củ chi','hóc môn'\n",
    "                  ,'bình chánh','nhà bè','cần giờ','tân bình']\n",
    "  hcm_city = district_num + name + district_str\n",
    "  for i in hcm_city:\n",
    "    try:\n",
    "      if i in s:\n",
    "        return 'hồ chí minh'\n",
    "    except:\n",
    "      pass\n",
    "  return s\n",
    "\n",
    "df_fe['Field_49'] = df_fe['Field_49'].apply(group_hcm)\n",
    "\n",
    "\n",
    "# replace all the rest with nan\n",
    "def replace_more(s):\n",
    "  for i in province_list:\n",
    "    try:\n",
    "      if i in s: \n",
    "        return s         \n",
    "    except:\n",
    "      pass\n",
    "  return \"None\"\n",
    "  \n",
    "\n",
    "df_fe['Field_49'] = df_fe['Field_49'].apply(replace_more)\n",
    "\n",
    "df_fe['diaChi'] = df_fe['diaChi'].str.lower()\n",
    "df_fe['diaChi'] = df_fe['diaChi'].apply(diachi)\n",
    "df_fe['diaChi'] = df_fe['diaChi'].apply(group_hcm)\n",
    "df_fe['diaChi'] = df_fe['diaChi'].apply(replace_more)\n",
    "\n",
    "\n",
    "df_fe['Field_56'] = df_fe['Field_56'].str.lower()\n",
    "from collections import Counter\n",
    "counter_56 = Counter(df_fe['Field_56'])\n",
    "dict_56 = { \"ngoài quốc doanh\": [\"ngoài quốc doanh\"],\n",
    "           \n",
    "            \"nhà nước\":[\"nhà nước\",'đoàn thể',\"lực lượng vũ trang\",\"đại biểu\"],\n",
    "           \n",
    "           \"doanh nghiệp\":[\"doanh nghiệp\"], \n",
    "           \n",
    "           \"ngoài công lập\":[\"ngoài công lập\"],\n",
    "           \n",
    "           \"hành chánh\": [\"hành chánh\",'sự nghiệp quận',\"sự nghiệp\"],\n",
    "           \n",
    "           \"xã\": ['phường','xã', \"hợp tác xã\"],\n",
    "           \n",
    "           \"nghèo\": [\"nghèo\",\"thất nghiệp\",\"trợ cấp\",\"khó khăn\",\"bảo trợ\"], \n",
    "           \n",
    "           \"hộ gia đình\": [\"hộ gia đình\", \"sinh viên\", \"cá thể\",\"thân nhân\",\"đối tượng\"],\n",
    "           \n",
    "           \"others\": [\"nước ngoài\"]\n",
    "           \n",
    "           \n",
    "          }\n",
    "\n",
    "def group_56(s):\n",
    "    for col in list(dict_56):\n",
    "        for i in dict_56[col]:\n",
    "            try:\n",
    "                if i in s:\n",
    "                    return col\n",
    "            except:\n",
    "                pass\n",
    "    return \"None\"\n",
    "\n",
    "df_fe[\"Field_56\"] = df_fe[\"Field_56\"].apply(group_56)\n",
    "\n",
    "\n",
    "dict_61 = { \"ngoài quốc doanh\": [\"ngoài quốc doanh\"], \"hộ gia đình\":[\"hộ gia đình\",\"cán bộ\",\"cá thể\"],  \n",
    "           \n",
    "           \"ngoài công lập\": [\"ngoài công lập\"], \"nghèo\": [\"nghèo\", \"thất nghiệp\", \"dân tộc\",\"khó khăn\",\"trợ cấp\"], \n",
    "           \n",
    "           \"nước ngoài\": [\"dtnn\"],  \"nhà nước\": [\"đại biểu\",\"nhà nước\", \"đảng\"],\n",
    "           \n",
    "           \"others\": [\"sinh viên\",\"thân nhân\",\"người\",\"phường xã\"]\n",
    "           \n",
    "           \n",
    "               \n",
    "\n",
    "          }\n",
    "\n",
    "def group_61(s):\n",
    "    for col in list(dict_61):\n",
    "        for i in dict_61[col]:\n",
    "            try:\n",
    "                if i in s:\n",
    "                    return col\n",
    "            except:\n",
    "                pass\n",
    "    return \"None\"   \n",
    "\n",
    "\n",
    "df_fe['Field_61'] = df_fe['Field_61'].str.lower()\n",
    "df_fe[\"Field_61\"] = df_fe[\"Field_61\"].apply(group_61)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028799,
     "end_time": "2020-09-27T03:01:02.287634",
     "exception": false,
     "start_time": "2020-09-27T03:01:02.258835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**More preprocessing other columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:01:02.381761Z",
     "iopub.status.busy": "2020-09-27T03:01:02.380813Z",
     "iopub.status.idle": "2020-09-27T03:01:39.586303Z",
     "shell.execute_reply": "2020-09-27T03:01:39.587267Z"
    },
    "papermill": {
     "duration": 37.27421,
     "end_time": "2020-09-27T03:01:39.587487",
     "exception": false,
     "start_time": "2020-09-27T03:01:02.313277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 73411 entries, 0 to 20380\n",
      "Columns: 248 entries, id to gender\n",
      "dtypes: category(112), float64(133), int64(3)\n",
      "memory usage: 88.5 MB\n"
     ]
    }
   ],
   "source": [
    "def str_normalize(s):\n",
    "    s = str(s).strip().lower()\n",
    "    s = re.sub(' +', \" \", s)\n",
    "    return s\n",
    "\n",
    "def process_location(df):\n",
    "    for col in [\"currentLocationLocationId\", \"homeTownLocationId\", \"currentLocationLatitude\", \"currentLocationLongitude\", \n",
    "                   \"homeTownLatitude\", \"homeTownLongitude\"]:\n",
    "        df[col].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    df[\"currentLocationLocationId\"] = df[\"currentLocationLocationId\"].apply(str_normalize).astype(\"category\")\n",
    "    df[\"homeTownLocationId\"] = df[\"homeTownLocationId\"].apply(str_normalize).astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def job_category(x):\n",
    "    if type(x) == str:\n",
    "        if \"công nhân\" in x or \"cnv\" in x or \"cn\" in x or \"may công nghiệp\" in x or \"lao động\" in x\\\n",
    "        or \"thợ\" in x or \"coõng nhaõn trửùc tieỏp maựy may coõng nghieọp\" in x or \"c.n\" in x or \"lđ\" in x:\n",
    "            return \"CN\"\n",
    "        elif \"giáo viên\" in x or \"gv\" in x or \"gíao viên\" in x:\n",
    "            return \"GV\"\n",
    "        elif \"nhân viên\" in x or \"kế toán\" in x or \"cán bộ\" in x or \"nv\" in x or \"cb\" in x or \"nhõn viờn\" in x:\n",
    "            return \"NV\"\n",
    "        elif \"tài xế\" in x or \"lái\" in x or \"tài xê\" in x:\n",
    "            return \"TX\"\n",
    "        elif \"quản lý\" in x or \"phó phòng\" in x or \"hiệu phó\" in x:\n",
    "            return \"QL\"\n",
    "        elif \"undefined\" in x:\n",
    "            return \"missing\"\n",
    "        elif \"giám đốc\" in x or \"hiệu trưởng\" in x:\n",
    "            return \"GĐ\"\n",
    "        elif \"phục vụ\" in x:\n",
    "            return \"PV\"\n",
    "        elif \"chuyên viên\" in x:\n",
    "            return  \"CV\"\n",
    "        elif \"bác sĩ\" in x or \"dược sĩ\" in x or \"y sĩ\" in x or \"y sỹ\" in x:\n",
    "            return \"BS\"\n",
    "        elif \"y tá\" in x:\n",
    "            return \"YT\"\n",
    "        elif \"hộ sinh\" in x:\n",
    "            return \"HS\"\n",
    "        elif \"chủ tịch\" in x:\n",
    "            return \"CT\"\n",
    "        elif \"bếp\" in x:\n",
    "            return \"ĐB\"\n",
    "        elif \"sư\" in x:\n",
    "            return \"KS\"\n",
    "        elif \"dưỡng\" in x:\n",
    "            return \"ĐD\"\n",
    "        elif \"kỹ thuật\" in x or \"kĩ thuật\" in x:\n",
    "            return \"KTV\"\n",
    "        elif \"diễn viên\" in x:\n",
    "            return \"DV\"\n",
    "        else:\n",
    "            return \"missing\"\n",
    "    else:\n",
    "        return x    \n",
    "    \n",
    "def process_diaChi_maCv(df):\n",
    "    df[\"maCv\"] = df[\"maCv\"].apply(str_normalize).apply(job_category).astype(\"category\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_gender(s):\n",
    "    x, y = s\n",
    "    \n",
    "    if x != x and y != y:\n",
    "        return \"nan\"\n",
    "    \n",
    "    if x != x:\n",
    "        return y.lower()\n",
    "    \n",
    "    return x.lower()\n",
    "\n",
    "def process_gender(df):\n",
    "    df[\"gender\"] = df[[\"gioiTinh\", \"info_social_sex\"]].apply(combine_gender, axis=1).astype(\"category\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_misc(df):        \n",
    "    df[\"subscriberCount\"].replace(0, np.nan, inplace=True)\n",
    "    df[\"friendCount\"].replace(0, np.nan, inplace=True)\n",
    "    \n",
    "    df[\"Field_13\"] = df[\"Field_13\"].apply(lambda x: 1 if x == x else 0)\n",
    "    df[\"Field_38\"] = df[\"Field_38\"].map({0: 0.0, 1: 1.0, \"DN\": np.nan, \"TN\": np.nan, \"GD\": np.nan})\n",
    "    df[\"Field_62\"] = df[\"Field_62\"].map({\"I\": 1, \"II\": 2, \"III\": 3, \"IV\": 4, \"V\": 5, \"Ngoài quốc doanh Quận 7\": np.nan})\n",
    "    df[\"Field_47\"] = df[\"Field_47\"].map({\"Zezo\": 0, \"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4})\n",
    "    \n",
    "    df[\"Field_27\"] = df[\"Field_27\"].replace({0.0: np.nan})\n",
    "    df[\"Field_28\"] = df[\"Field_28\"].replace({0.0: np.nan})\n",
    "        \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name == \"object\":\n",
    "            df[col] = df[col].apply(str_normalize).astype(\"category\")\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "def transform(df):\n",
    "    df = process_gender(df)\n",
    "    df = process_location(df)\n",
    "    df = process_diaChi_maCv(df)\n",
    "    df = process_misc(df)\n",
    "    return df\n",
    "df_new_fe = transform(df_fe)\n",
    "df_new_fe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:01:39.658404Z",
     "iopub.status.busy": "2020-09-27T03:01:39.657608Z",
     "iopub.status.idle": "2020-09-27T03:01:42.468915Z",
     "shell.execute_reply": "2020-09-27T03:01:42.468182Z"
    },
    "papermill": {
     "duration": 2.854911,
     "end_time": "2020-09-27T03:01:42.469039",
     "exception": false,
     "start_time": "2020-09-27T03:01:39.614128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field_4: num of cat:    3\n",
      "Field_12: num of cat:    8\n",
      "diaChi: num of cat:    63\n",
      "Field_46: num of cat:    9\n",
      "Field_49: num of cat:    64\n",
      "Field_56: num of cat:    10\n",
      "Field_61: num of cat:    8\n",
      "Field_65: num of cat:    11\n",
      "Field_66: num of cat:    9\n",
      "maCv: num of cat:    18\n",
      "brief: num of cat:    21\n",
      "Field_34year: num of cat:    15\n",
      "Field_34month: num of cat:    13\n",
      "gender: num of cat:    3\n"
     ]
    }
   ],
   "source": [
    "df_new_fe = df_new_fe.drop([\"gioiTinh\",\"info_social_sex\"],1)\n",
    "def convert_int(s):\n",
    "  try:\n",
    "    return int(s)\n",
    "  except:\n",
    "    return np.nan\n",
    "\n",
    "for col in new_col + new_col_1 + new_col_2:\n",
    "  df_new_fe[col] = df_new_fe[col].apply(convert_int)\n",
    "\n",
    "\n",
    "drop_cat = [\"Field_48\", \"Field_45\", \"Field_68\", \"Field_18\", \"Field_55\", \n",
    "            \n",
    "            \"Field_54\", \"Field_36\", \"currentLocationLocationId\", \"homeTownLocationId\", \n",
    "\n",
    "            \"data.basic_info.locale\", \"currentLocationCity\", \"currentLocationCountry\", \n",
    "\n",
    "            \"currentLocationName\", \"currentLocationState\", \"homeTownCity\", \"homeTownName\", \n",
    "\n",
    "            \"homeTownCountry\", \"homeTownState\"\n",
    "\n",
    "\n",
    "\n",
    "            ]\n",
    "\n",
    "df_new_fe = df_new_fe.drop(drop_cat, 1)\n",
    "\n",
    "\n",
    "for i in list(df_new_fe.select_dtypes(['category'])):\n",
    "  print(i + \": num of cat:    \" + str(len(df_new_fe[i].unique())))\n",
    "\n",
    "df_new_fe[\"Field_34month\"] = df_new_fe[\"Field_34month\"].apply(convert_int)\n",
    "\n",
    "df_new_fe[\"Field_34year\"] = df_new_fe[\"Field_34year\"].apply(convert_int)\n",
    "\n",
    "#create one hot encoding for categorical column\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    res = res.drop([feature_to_encode], axis=1)\n",
    "    return(res)\n",
    "\n",
    "for col in list(df_new_fe.select_dtypes(['category'])):\n",
    "  df_new_fe = encode_and_bind(df_new_fe, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:01:42.531506Z",
     "iopub.status.busy": "2020-09-27T03:01:42.530681Z",
     "iopub.status.idle": "2020-09-27T03:01:42.630559Z",
     "shell.execute_reply": "2020-09-27T03:01:42.629622Z"
    },
    "papermill": {
     "duration": 0.13434,
     "end_time": "2020-09-27T03:01:42.630717",
     "exception": false,
     "start_time": "2020-09-27T03:01:42.496377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53030, 443)\n",
      "(20381, 443)\n"
     ]
    }
   ],
   "source": [
    "y_label = df_train[\"label\"]\n",
    "train_fe = df_new_fe[df_new_fe[\"id\"] < df_train.shape[0]]\n",
    "test_fe = df_new_fe[df_new_fe[\"id\"] >= df_train.shape[0]]\n",
    "\n",
    "print(train_fe.shape)\n",
    "print(test_fe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:01:42.714559Z",
     "iopub.status.busy": "2020-09-27T03:01:42.705265Z",
     "iopub.status.idle": "2020-09-27T03:11:27.783639Z",
     "shell.execute_reply": "2020-09-27T03:11:27.784441Z"
    },
    "papermill": {
     "duration": 585.125773,
     "end_time": "2020-09-27T03:11:27.784685",
     "exception": false,
     "start_time": "2020-09-27T03:01:42.658912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 0.5646257038000715/0.47548980225543147\n",
      "Fold 1: 0.5591914582820059/0.49285450287238364\n",
      "Fold 2: 0.5655891238904167/0.46915911822830636\n",
      "Fold 3: 0.5621448599884715/0.49404792152447685\n",
      "Fold 4: 0.5646296948460001/0.4753102093595063\n",
      "Seed 635: 0.5632361681613931/0.4813723108480209\n",
      "Fold 0: 0.5636746886835311/0.47948827267589356\n",
      "Fold 1: 0.5618800270098214/0.4928819443945205\n",
      "Fold 2: 0.5628572841157757/0.48883210155269285\n",
      "Fold 3: 0.564275960328342/0.47159759324705197\n",
      "Fold 4: 0.5627996715436403/0.4754824172349519\n",
      "Seed 485: 0.5630975263362221/0.4816564658210222\n",
      "Fold 0: 0.5634644123716406/0.47349563963040353\n",
      "Fold 1: 0.5609379587592005/0.4922043688464286\n",
      "Fold 2: 0.5616719157137104/0.47584223803195314\n",
      "Fold 3: 0.5609811219750089/0.48646679023293804\n",
      "Fold 4: 0.5638327748469694/0.47192791851576854\n",
      "Seed 7673: 0.562177636733306/0.47998739105149835\n",
      "------------------------------\n",
      "Avg train gini: 0.562837110410307\n",
      "Avg valid gini: 0.48100538924018044\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "def gini(y_true, y_score):\n",
    "    return roc_auc_score(y_true, y_score)*2 - 1\n",
    "\n",
    "def lgb_gini(y_pred, dataset_true):\n",
    "    y_true = dataset_true.get_label()\n",
    "    return 'gini', gini(y_true, y_pred), True\n",
    "\n",
    "NUM_BOOST_ROUND = 1000\n",
    "\n",
    "lgbm_param = {'objective':'binary',\n",
    "              'boosting_type': 'gbdt',\n",
    "              'metric' : 'auc',\n",
    "              'learning_rate': 0.015,\n",
    "              \"bagging_freq\": 1,\n",
    "              \"bagging_fraction\" : 0.25,\n",
    "              'tree_learner': 'serial',\n",
    "              'reg_lambda': 2,\n",
    "              'reg_alpha': 1,              \n",
    "              \"feature_fraction\": 0.15,\n",
    "              'num_leaves': 16,\n",
    "              'max_depth': 8,\n",
    "              'random_state': 16111997,\n",
    "            }\n",
    "\n",
    "seeds = np.random.randint(0, 10000, 3)\n",
    "preds = 0    \n",
    "feature_important = None\n",
    "avg_train_gini = 0\n",
    "avg_val_gini = 0\n",
    "\n",
    "for s in seeds:\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=s, shuffle=True)        \n",
    "    lgbm_param['random_state'] = s    \n",
    "    seed_train_gini = 0\n",
    "    seed_val_gini = 0\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(y_label)), y_label)):                \n",
    "        X_train, X_val = train_fe.iloc[train_idx].drop([\"id\"], 1), train_fe.iloc[val_idx].drop([\"id\"], 1)                \n",
    "        y_train, y_val = y_label[train_idx], y_label[val_idx]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval  = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "        evals_result = {} \n",
    "        model = lgb.train(lgbm_param,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=NUM_BOOST_ROUND,  \n",
    "                    early_stopping_rounds=50,\n",
    "                    feval=lgb_gini,\n",
    "                    verbose_eval=False,\n",
    "                    evals_result=evals_result,\n",
    "                    valid_sets=[lgb_train, lgb_eval])\n",
    "\n",
    "        seed_train_gini += model.best_score[\"training\"][\"gini\"] / skf.n_splits\n",
    "        seed_val_gini += model.best_score[\"valid_1\"][\"gini\"] / skf.n_splits\n",
    "\n",
    "        avg_train_gini += model.best_score[\"training\"][\"gini\"] / (len(seeds) * skf.n_splits)\n",
    "        avg_val_gini += model.best_score[\"valid_1\"][\"gini\"] / (len(seeds) * skf.n_splits)\n",
    "\n",
    "        if feature_important is None:\n",
    "            feature_important = model.feature_importance() / (len(seeds) * skf.n_splits)\n",
    "        else:\n",
    "            feature_important += model.feature_importance() / (len(seeds) * skf.n_splits)        \n",
    "\n",
    "        pred = model.predict(test_fe.drop([\"id\"], 1))\n",
    "        preds += pred / (skf.n_splits * len(seeds))\n",
    "        \n",
    "        print(\"Fold {}: {}/{}\".format(i, model.best_score[\"training\"][\"gini\"], model.best_score[\"valid_1\"][\"gini\"]))\n",
    "    print(\"Seed {}: {}/{}\".format(s, seed_train_gini, seed_val_gini))\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"Avg train gini: {}\".format(avg_train_gini))\n",
    "print(\"Avg valid gini: {}\".format(avg_val_gini))\n",
    "print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:11:27.886502Z",
     "iopub.status.busy": "2020-09-27T03:11:27.885621Z",
     "iopub.status.idle": "2020-09-27T03:11:28.064248Z",
     "shell.execute_reply": "2020-09-27T03:11:28.063617Z"
    },
    "papermill": {
     "duration": 0.239235,
     "end_time": "2020-09-27T03:11:28.064377",
     "exception": false,
     "start_time": "2020-09-27T03:11:27.825142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eliminte column with the feature importance less than 5\n",
    "features = train_fe.columns.tolist()\n",
    "features.remove(\"id\")\n",
    "df_imp = pd.DataFrame(data = {'col' : features , 'imp' : feature_important})\n",
    "df_imp = df_imp.sort_values(by='imp', ascending=False).reset_index(drop=True)\n",
    "drop_index = [i for i in range(len(df_imp['imp'])) if df_imp['imp'][i] <= 5]\n",
    "drop_again = df_imp['col'][drop_index]\n",
    "\n",
    "train_fe = train_fe.drop(drop_again,1)\n",
    "test_fe = test_fe.drop(drop_again,1)\n",
    "\n",
    "missing_col = []\n",
    "for col in list(train_fe):\n",
    "  if train_fe[col].isna().sum()/ 53030 >= 0.75:\n",
    "    missing_col.append(col)\n",
    "\n",
    "train_fe = train_fe.drop(missing_col,1)\n",
    "test_fe = test_fe.drop(missing_col,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033433,
     "end_time": "2020-09-27T03:11:28.131905",
     "exception": false,
     "start_time": "2020-09-27T03:11:28.098472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Apply catboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:11:28.234063Z",
     "iopub.status.busy": "2020-09-27T03:11:28.218525Z",
     "iopub.status.idle": "2020-09-27T03:14:44.750478Z",
     "shell.execute_reply": "2020-09-27T03:14:44.749869Z"
    },
    "papermill": {
     "duration": 196.585158,
     "end_time": "2020-09-27T03:14:44.750607",
     "exception": false,
     "start_time": "2020-09-27T03:11:28.165449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.7/site-packages (0.24.1)\r\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from catboost) (1.1.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost) (1.14.0)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost) (4.10.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from catboost) (3.2.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from catboost) (1.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from catboost) (1.18.5)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost) (0.8.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2019.3)\r\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost) (1.3.3)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (2.4.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (1.2.0)\r\n",
      "Requirement already satisfied: category_encoders in /opt/conda/lib/python3.7/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: pandas>=0.21.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.1.2)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.23.2)\r\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.11.1)\r\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.5.1)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.18.5)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2019.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.1->category_encoders) (1.14.0)\r\n",
      "0:\ttest: 0.6482310\tbest: 0.6482310 (0)\ttotal: 98.2ms\tremaining: 1m 38s\n",
      "500:\ttest: 0.7492735\tbest: 0.7503388 (410)\ttotal: 18.3s\tremaining: 18.2s\n",
      "999:\ttest: 0.7462329\tbest: 0.7503388 (410)\ttotal: 35.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7503387953\n",
      "bestIteration = 410\n",
      "\n",
      "Shrink model to first 411 iterations.\n",
      "Fold  1 GINI : 0.50068\n",
      "0:\ttest: 0.6534870\tbest: 0.6534870 (0)\ttotal: 42.1ms\tremaining: 42.1s\n",
      "500:\ttest: 0.7518048\tbest: 0.7534455 (327)\ttotal: 17.6s\tremaining: 17.6s\n",
      "999:\ttest: 0.7491246\tbest: 0.7534455 (327)\ttotal: 34.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.753445544\n",
      "bestIteration = 327\n",
      "\n",
      "Shrink model to first 328 iterations.\n",
      "Fold  2 GINI : 0.50689\n",
      "0:\ttest: 0.6483985\tbest: 0.6483985 (0)\ttotal: 37.9ms\tremaining: 37.9s\n",
      "500:\ttest: 0.7486143\tbest: 0.7487578 (341)\ttotal: 18.5s\tremaining: 18.4s\n",
      "999:\ttest: 0.7488390\tbest: 0.7498023 (787)\ttotal: 36s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7498022506\n",
      "bestIteration = 787\n",
      "\n",
      "Shrink model to first 788 iterations.\n",
      "Fold  3 GINI : 0.49960\n",
      "0:\ttest: 0.6448674\tbest: 0.6448674 (0)\ttotal: 37.4ms\tremaining: 37.4s\n",
      "500:\ttest: 0.7427993\tbest: 0.7429686 (496)\ttotal: 17.4s\tremaining: 17.3s\n",
      "999:\ttest: 0.7415957\tbest: 0.7429686 (496)\ttotal: 35.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7429686337\n",
      "bestIteration = 496\n",
      "\n",
      "Shrink model to first 497 iterations.\n",
      "Fold  4 GINI : 0.48594\n",
      "0:\ttest: 0.6541490\tbest: 0.6541490 (0)\ttotal: 36.9ms\tremaining: 36.9s\n",
      "500:\ttest: 0.7531640\tbest: 0.7532130 (480)\ttotal: 17.7s\tremaining: 17.6s\n",
      "999:\ttest: 0.7531559\tbest: 0.7542800 (645)\ttotal: 35.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.754279984\n",
      "bestIteration = 645\n",
      "\n",
      "Shrink model to first 646 iterations.\n",
      "Fold  5 GINI : 0.50856\n",
      "Avg GINI score: 0.4999293230844264\n",
      "GINI: 0.50033 +- 0.00798\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install category_encoders\n",
    "\n",
    "#from datetime import datetime\n",
    "#from unidecode import unidecode\n",
    "#from itertools import combinations\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "gini, feature_importance_df = {}, pd.DataFrame()\n",
    "\n",
    "TRAIN, TEST = train_fe.drop(['id'], axis=1), test_fe.drop(['id'], axis=1)\n",
    "LABEL = df_train['label']\n",
    "preds, oof_preds = np.zeros(TRAIN.shape[0]), {}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for i, (train_idx, val_idx) in enumerate(cv.split(TRAIN, LABEL)):\n",
    "    X_train, y_train = TRAIN.iloc[train_idx], LABEL.iloc[train_idx]\n",
    "    X_val, y_val = TRAIN.iloc[val_idx], LABEL.iloc[val_idx]\n",
    "\n",
    "    gbm = CatBoostClassifier(eval_metric='AUC', \n",
    "                             use_best_model=True,\n",
    "                             iterations=1000, \n",
    "                             learning_rate=0.1, \n",
    "                             random_seed=42).fit(X_train, y_train, \n",
    "                                                 #cat_features=set(cat_features),\n",
    "                                                 eval_set=(X_val, y_val), verbose=500)\n",
    "\n",
    "    y_pred = gbm.predict(X_val)\n",
    "    y_pred_proba = gbm.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "    preds[val_idx] = y_pred_proba\n",
    "    oof_preds[f'F{i+1}'] = gbm.predict_proba(TEST)[:, 1]\n",
    "    \n",
    "    gini[f'F{i+1}'] = 2 * roc_auc_score(y_val, y_pred_proba) - 1\n",
    "    \n",
    "    # For create feature importances\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = TRAIN.columns\n",
    "    fold_importance_df[\"importance\"] = gbm.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = i + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('Fold %2d GINI : %.5f' % (i + 1, 2*roc_auc_score(y_val, y_pred_proba) - 1))\n",
    "    \n",
    "# Resulting\n",
    "roc_auc = roc_auc_score(LABEL, preds)\n",
    "print('Avg GINI score:', 2*roc_auc - 1)\n",
    "\n",
    "result = np.array(list(gini.values()))\n",
    "print('GINI: {:.5f} +- {:.5f}'.format(result.mean(), result.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041572,
     "end_time": "2020-09-27T03:14:44.834505",
     "exception": false,
     "start_time": "2020-09-27T03:14:44.792933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Submisson catboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:14:44.928693Z",
     "iopub.status.busy": "2020-09-27T03:14:44.926621Z",
     "iopub.status.idle": "2020-09-27T03:14:45.360438Z",
     "shell.execute_reply": "2020-09-27T03:14:45.359600Z"
    },
    "papermill": {
     "duration": 0.484285,
     "end_time": "2020-09-27T03:14:45.360565",
     "exception": false,
     "start_time": "2020-09-27T03:14:44.876280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_test_c = df_test.copy()\n",
    "# save to csv file\n",
    "df_test_c['label'] = pd.DataFrame(oof_preds).mean(axis=1).values\n",
    "name = pd.Timestamp.now().strftime('%Y%m%d_%H_%M')\n",
    "df_test_c[['id', 'label']].to_csv('submisson_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042539,
     "end_time": "2020-09-27T03:14:45.446162",
     "exception": false,
     "start_time": "2020-09-27T03:14:45.403623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Apply LGBM again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:14:45.553125Z",
     "iopub.status.busy": "2020-09-27T03:14:45.552298Z",
     "iopub.status.idle": "2020-09-27T03:14:45.556397Z",
     "shell.execute_reply": "2020-09-27T03:14:45.555633Z"
    },
    "papermill": {
     "duration": 0.067763,
     "end_time": "2020-09-27T03:14:45.556520",
     "exception": false,
     "start_time": "2020-09-27T03:14:45.488757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def gini(y_true, y_score):\n",
    "    return roc_auc_score(y_true, y_score)*2 - 1\n",
    "\n",
    "def lgb_gini(y_pred, dataset_true):\n",
    "    y_true = dataset_true.get_label()\n",
    "    return 'gini', gini(y_true, y_pred), True\n",
    "\n",
    "def model_lgb_gini(y_true, y_pred):\n",
    "    return 'gini', gini(y_true, y_pred), True\n",
    "\n",
    "def xgb_gini(y_pred, dataset_true):\n",
    "    y_true = dataset_true.get_label()\n",
    "    return 'gini', float(gini(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "def get_feat_imp(X, y):\n",
    "    model_lgb = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', \n",
    "        num_leaves=31, \n",
    "        max_depth= -1, \n",
    "        learning_rate=0.1, \n",
    "        n_estimators=1000, \n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        min_data_in_leaf=10, \n",
    "        lambda_l1=9.573264707286953, \n",
    "        lambda_l2=0.26292036067115865,\n",
    "        feature_fraction=0.5,\n",
    "        bagging_fraction=1.0,\n",
    "        bagging_freq=0,\n",
    "        n_jobs= cpu_count()\n",
    "        )\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=False, random_state=42)\n",
    "    oof = np.zeros(len(X))\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "        model_lgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=100, eval_metric=model_lgb_gini, verbose=50)\n",
    "        oof[val_idx] = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration_)\n",
    "    print(\"Best AUC score:\", model_lgb.best_score_['valid_0']['auc'])\n",
    "    print(\"Best Gini score:\", model_lgb.best_score_['valid_0']['gini'])\n",
    "    print(\"No. data's features: \", model_lgb.n_features_)\n",
    "    feature_imp = pd.DataFrame(sorted(zip(model_lgb.feature_importances_,X.columns)), columns=['Value','Feature'])\n",
    "    return feature_imp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:14:45.690055Z",
     "iopub.status.busy": "2020-09-27T03:14:45.688565Z",
     "iopub.status.idle": "2020-09-27T03:35:02.898283Z",
     "shell.execute_reply": "2020-09-27T03:35:02.897488Z"
    },
    "papermill": {
     "duration": 1217.299032,
     "end_time": "2020-09-27T03:35:02.898417",
     "exception": false,
     "start_time": "2020-09-27T03:14:45.599385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.734483\tvalid_0's gini: 0.468966\n",
      "[100]\tvalid_0's auc: 0.738606\tvalid_0's gini: 0.477212\n",
      "[150]\tvalid_0's auc: 0.740195\tvalid_0's gini: 0.48039\n",
      "[200]\tvalid_0's auc: 0.739615\tvalid_0's gini: 0.47923\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's auc: 0.740245\tvalid_0's gini: 0.480491\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.739432\tvalid_0's gini: 0.478863\n",
      "[100]\tvalid_0's auc: 0.743521\tvalid_0's gini: 0.487041\n",
      "[150]\tvalid_0's auc: 0.746134\tvalid_0's gini: 0.492268\n",
      "[200]\tvalid_0's auc: 0.745281\tvalid_0's gini: 0.490561\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's auc: 0.746244\tvalid_0's gini: 0.492489\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.747832\tvalid_0's gini: 0.495665\n",
      "[100]\tvalid_0's auc: 0.752052\tvalid_0's gini: 0.504105\n",
      "[150]\tvalid_0's auc: 0.754465\tvalid_0's gini: 0.50893\n",
      "[200]\tvalid_0's auc: 0.754885\tvalid_0's gini: 0.50977\n",
      "[250]\tvalid_0's auc: 0.754552\tvalid_0's gini: 0.509105\n",
      "[300]\tvalid_0's auc: 0.754193\tvalid_0's gini: 0.508386\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's auc: 0.755463\tvalid_0's gini: 0.510927\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.738407\tvalid_0's gini: 0.476814\n",
      "[100]\tvalid_0's auc: 0.743944\tvalid_0's gini: 0.487888\n",
      "[150]\tvalid_0's auc: 0.747108\tvalid_0's gini: 0.494215\n",
      "[200]\tvalid_0's auc: 0.747512\tvalid_0's gini: 0.495024\n",
      "[250]\tvalid_0's auc: 0.747188\tvalid_0's gini: 0.494375\n",
      "[300]\tvalid_0's auc: 0.746565\tvalid_0's gini: 0.493129\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's auc: 0.747546\tvalid_0's gini: 0.495092\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.749223\tvalid_0's gini: 0.498447\n",
      "[100]\tvalid_0's auc: 0.756138\tvalid_0's gini: 0.512276\n",
      "[150]\tvalid_0's auc: 0.758469\tvalid_0's gini: 0.516938\n",
      "[200]\tvalid_0's auc: 0.75867\tvalid_0's gini: 0.517339\n",
      "[250]\tvalid_0's auc: 0.758372\tvalid_0's gini: 0.516744\n",
      "[300]\tvalid_0's auc: 0.758914\tvalid_0's gini: 0.517827\n",
      "[350]\tvalid_0's auc: 0.758556\tvalid_0's gini: 0.517112\n",
      "Early stopping, best iteration is:\n",
      "[282]\tvalid_0's auc: 0.759117\tvalid_0's gini: 0.518233\n",
      "Best AUC score: 0.7591166960177298\n",
      "Best Gini score: 0.5182333920354596\n",
      "No. data's features:  198\n",
      "No. training features: 185\n",
      "Fold 0\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.800967\ttraining's gini: 0.601935\tvalid_1's auc: 0.740316\tvalid_1's gini: 0.480633\n",
      "[2000]\ttraining's auc: 0.83406\ttraining's gini: 0.66812\tvalid_1's auc: 0.741655\tvalid_1's gini: 0.483309\n",
      "[3000]\ttraining's auc: 0.857965\ttraining's gini: 0.71593\tvalid_1's auc: 0.741925\tvalid_1's gini: 0.483851\n",
      "[4000]\ttraining's auc: 0.876046\ttraining's gini: 0.752091\tvalid_1's auc: 0.741669\tvalid_1's gini: 0.483339\n",
      "[5000]\ttraining's auc: 0.890399\ttraining's gini: 0.780798\tvalid_1's auc: 0.741722\tvalid_1's gini: 0.483444\n",
      "Early stopping, best iteration is:\n",
      "[3073]\ttraining's auc: 0.859443\ttraining's gini: 0.718886\tvalid_1's auc: 0.741968\tvalid_1's gini: 0.483935\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.799056\ttraining's gini: 0.598112\tvalid_1's auc: 0.744874\tvalid_1's gini: 0.489748\n",
      "[2000]\ttraining's auc: 0.832096\ttraining's gini: 0.664193\tvalid_1's auc: 0.747652\tvalid_1's gini: 0.495304\n",
      "[3000]\ttraining's auc: 0.855246\ttraining's gini: 0.710491\tvalid_1's auc: 0.74769\tvalid_1's gini: 0.49538\n",
      "[4000]\ttraining's auc: 0.873364\ttraining's gini: 0.746729\tvalid_1's auc: 0.747551\tvalid_1's gini: 0.495101\n",
      "[5000]\ttraining's auc: 0.887924\ttraining's gini: 0.775847\tvalid_1's auc: 0.746804\tvalid_1's gini: 0.493608\n",
      "[6000]\ttraining's auc: 0.899544\ttraining's gini: 0.799088\tvalid_1's auc: 0.746263\tvalid_1's gini: 0.492527\n",
      "Early stopping, best iteration is:\n",
      "[3563]\ttraining's auc: 0.865869\ttraining's gini: 0.731739\tvalid_1's auc: 0.748066\tvalid_1's gini: 0.496131\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.799205\ttraining's gini: 0.59841\tvalid_1's auc: 0.75438\tvalid_1's gini: 0.508761\n",
      "[2000]\ttraining's auc: 0.832113\ttraining's gini: 0.664226\tvalid_1's auc: 0.75569\tvalid_1's gini: 0.511379\n",
      "[3000]\ttraining's auc: 0.855896\ttraining's gini: 0.711792\tvalid_1's auc: 0.756397\tvalid_1's gini: 0.512794\n",
      "[4000]\ttraining's auc: 0.873871\ttraining's gini: 0.747742\tvalid_1's auc: 0.755788\tvalid_1's gini: 0.511576\n",
      "[5000]\ttraining's auc: 0.888393\ttraining's gini: 0.776787\tvalid_1's auc: 0.755469\tvalid_1's gini: 0.510937\n",
      "Early stopping, best iteration is:\n",
      "[3011]\ttraining's auc: 0.856115\ttraining's gini: 0.71223\tvalid_1's auc: 0.756424\tvalid_1's gini: 0.512849\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.801071\ttraining's gini: 0.602142\tvalid_1's auc: 0.745613\tvalid_1's gini: 0.491226\n",
      "[2000]\ttraining's auc: 0.834676\ttraining's gini: 0.669351\tvalid_1's auc: 0.748834\tvalid_1's gini: 0.497668\n",
      "[3000]\ttraining's auc: 0.858351\ttraining's gini: 0.716701\tvalid_1's auc: 0.749253\tvalid_1's gini: 0.498506\n",
      "[4000]\ttraining's auc: 0.876797\ttraining's gini: 0.753595\tvalid_1's auc: 0.749339\tvalid_1's gini: 0.498677\n",
      "[5000]\ttraining's auc: 0.891794\ttraining's gini: 0.783587\tvalid_1's auc: 0.748922\tvalid_1's gini: 0.497844\n",
      "[6000]\ttraining's auc: 0.903691\ttraining's gini: 0.807382\tvalid_1's auc: 0.748259\tvalid_1's gini: 0.496518\n",
      "Early stopping, best iteration is:\n",
      "[3907]\ttraining's auc: 0.875313\ttraining's gini: 0.750627\tvalid_1's auc: 0.749448\tvalid_1's gini: 0.498896\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 2500 rounds.\n",
      "[1000]\ttraining's auc: 0.798398\ttraining's gini: 0.596797\tvalid_1's auc: 0.757695\tvalid_1's gini: 0.51539\n",
      "[2000]\ttraining's auc: 0.833368\ttraining's gini: 0.666736\tvalid_1's auc: 0.761551\tvalid_1's gini: 0.523102\n",
      "[3000]\ttraining's auc: 0.857736\ttraining's gini: 0.715472\tvalid_1's auc: 0.762378\tvalid_1's gini: 0.524755\n",
      "[4000]\ttraining's auc: 0.876643\ttraining's gini: 0.753287\tvalid_1's auc: 0.762377\tvalid_1's gini: 0.524753\n",
      "[5000]\ttraining's auc: 0.891762\ttraining's gini: 0.783525\tvalid_1's auc: 0.76203\tvalid_1's gini: 0.524059\n",
      "Early stopping, best iteration is:\n",
      "[3487]\ttraining's auc: 0.867431\ttraining's gini: 0.734862\tvalid_1's auc: 0.762523\tvalid_1's gini: 0.525046\n",
      "CV score: 0.50277 \n",
      "[0.22752983 0.36616858 0.41378513 ... 0.06696364 0.26285897 0.14071577]\n"
     ]
    }
   ],
   "source": [
    "def run_model(train_df, test_df):\n",
    "    features = [c for c in train_df.columns if c not in ['id', 'label']]\n",
    "    label = train_df['label']\n",
    "    num_round = 1000000\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=False, random_state=42)\n",
    "    oof = np.zeros(len(train_df))\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, label.values)):\n",
    "            print(\"Fold {}\".format(fold_))\n",
    "            trn_data = lgb.Dataset(\n",
    "                train_df.iloc[trn_idx][features], label=label.iloc[trn_idx])\n",
    "            val_data = lgb.Dataset(\n",
    "                train_df.iloc[val_idx][features], label=label.iloc[val_idx])\n",
    "            clf = lgb.train(params, trn_data, num_round, valid_sets=[trn_data, val_data],\n",
    "                            verbose_eval = 1000, feval = lgb_gini)\n",
    "            oof[val_idx] = clf.predict(\n",
    "                train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "            \n",
    "            predictions += clf.predict(test_df[features],\n",
    "                                       num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    print(\"CV score: {:<8.5f}\".format(gini(label, oof)))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',     \n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'early_stopping': 2500,\n",
    "    'lambda_l1': 9.573264707286953, \n",
    "    'lambda_l2': 0.26292036067115865, \n",
    "    'num_leaves': 31, \n",
    "    'feature_fraction': 0.5, \n",
    "    'bagging_fraction': 1.0, \n",
    "    'bagging_freq': 0, \n",
    "    'min_child_samples': 10,\n",
    "    'verbose': -1\n",
    "    }\n",
    "\n",
    "\n",
    "y_train = df_train[\"label\"]\n",
    "X_train = train_fe.drop(columns=[\"id\"], axis=1)\n",
    "X_test = test_fe.drop(columns=[\"id\"], axis=1)\n",
    "X_test_id = test_fe[\"id\"]\n",
    "\n",
    "feature_imp = get_feat_imp(X_train, y_train)\n",
    "imp = feature_imp[feature_imp['Value'] > 0]['Feature']\n",
    "imp = imp.append(pd.Series(['label'], index=[0]), ignore_index=True)\n",
    "print(\"No. training features:\", len(imp))\n",
    "\n",
    "train_fe['label'] = df_train['label']\n",
    "test_fe['label'] = np.array([-1 for i in range(len(df_test['id']))])\n",
    "\n",
    "predictions = run_model(train_fe[imp], test_fe[imp])\n",
    "print(predictions)\n",
    "\n",
    "result = pd.DataFrame({'id':X_test_id, 'label':predictions})\n",
    "result.to_csv(\"submission_31.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.074697,
     "end_time": "2020-09-27T03:35:03.047971",
     "exception": false,
     "start_time": "2020-09-27T03:35:02.973274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Taking average of results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T03:35:03.209225Z",
     "iopub.status.busy": "2020-09-27T03:35:03.206226Z",
     "iopub.status.idle": "2020-09-27T03:35:03.835843Z",
     "shell.execute_reply": "2020-09-27T03:35:03.835055Z"
    },
    "papermill": {
     "duration": 0.71263,
     "end_time": "2020-09-27T03:35:03.835985",
     "exception": false,
     "start_time": "2020-09-27T03:35:03.123355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_2 = result.copy()\n",
    "\n",
    "model_1 = df_test_c[[\"id\",\"label\"]]\n",
    "\n",
    "model_avg = pd.DataFrame({\"id\": model_1[\"id\"].values})\n",
    "\n",
    "model_avg[\"label\"] = [(model_1[\"label\"][i]+ model_2[\"label\"][i])/2 for i in range(len(model_1[\"id\"]))]\n",
    "model_avg.to_csv(\"submission_32.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2106.4699,
   "end_time": "2020-09-27T03:35:04.019135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-27T02:59:57.549235",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
