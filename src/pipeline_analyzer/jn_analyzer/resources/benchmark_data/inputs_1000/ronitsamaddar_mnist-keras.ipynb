{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.datasets import mnist#download mnist data and split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(50000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "###Seeing dimensions of the different sets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2c172dd410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Seeing example of random images\n",
    "image_no=5\n",
    "img=X_train[image_no]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_X(X):\n",
    "    X_norm=X/255\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_X(X):\n",
    "    X_reshaped=X.reshape(X.shape[0],28,28,1)\n",
    "    return X_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BUILDING THE MODEL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten#create model\n",
    "\n",
    "model = Sequential()#add model layers\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                184330    \n",
      "=================================================================\n",
      "Total params: 203,434\n",
      "Trainable params: 203,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre processing the data\n",
    "X_train=reshape_X(normalize_X(X_train))\n",
    "X_val=reshape_X(normalize_X(X_val))\n",
    "X_test=reshape_X(normalize_X(X_test))\n",
    "y_train=to_categorical(y_train)\n",
    "y_val=to_categorical(y_val)\n",
    "y_test=to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.1419 - accuracy: 0.9577 - val_loss: 0.0779 - val_accuracy: 0.9769\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 0.0526 - accuracy: 0.9844 - val_loss: 0.0473 - val_accuracy: 0.9853\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 0.0474 - val_accuracy: 0.9868\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0611 - val_accuracy: 0.9832\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0492 - val_accuracy: 0.9871\n",
      "Epoch 6/10\n",
      "22592/50000 [============>.................] - ETA: 42s - loss: 0.0071 - accuracy: 0.9978"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 17s 333us/step\n",
      "Training accuracy = 99.90599751472473\n",
      "10000/10000 [==============================] - 3s 345us/step\n",
      "Validation accuracy = 98.7500011920929\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_train,y_train)\n",
    "#print(result)\n",
    "print(\"Training accuracy = \"+str(result[1]*100))\n",
    "result = model.evaluate(X_val,y_val)\n",
    "#print(result)\n",
    "print(\"Validation accuracy = \"+str(result[1]*100))\n",
    "#result = model.evaluate(X_test,y_test)\n",
    "#print(result)\n",
    "#print(\"Test accuracy = \"+str(result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
