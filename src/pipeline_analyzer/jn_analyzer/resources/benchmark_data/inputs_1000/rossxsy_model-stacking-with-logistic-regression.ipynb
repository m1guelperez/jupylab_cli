{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd982c8a-5d29-067c-889c-fdae69b46e21"
   },
   "source": [
    "# Model Stacking with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "983af63c-f2cc-a135-2c2e-4de7f1eac86c"
   },
   "source": [
    "In this notebook, I tried to blend results of several models by a logistic regression, which generates improved logloss in comparison to the 1st level models. In this dataset, the blened result is not better than using logistic regression directly (LB: 0.040). However, this method definitely has more potential with a bigger and more complex dataset.\n",
    "\n",
    "1st level models - parameters have been tuned in one of my earlier published notebook.\n",
    "\n",
    "Ada Boosting best CV score: -2.27116019719\n",
    "Gradient Boosting best CV score: -2.12612708664\n",
    "Random Forest best CV score: -0.826567251939\n",
    "KNN best CV score: -0.173115044296\n",
    "SVC best CV score: -2.41476782204\n",
    "\n",
    "2nd leve Logistic Regression best LB score: 0.042\n",
    "\n",
    "My acknowledgement goes to Tilli's resply to my question in another competition, and also thanks to authors of the following codes:\n",
    "https://github.com/emanuele/kaggle_pbr/blob/master/blend.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "105dc18f-a7ed-6924-56b5-07579f5af57f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def warn(*args, **kwargs): pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "train = pd.read_csv('../input/train.csv').drop('id',axis=1)\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "test_ids = test['id']\n",
    "test.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6079b316-e3eb-a5af-4ac2-aa00d700b351"
   },
   "source": [
    "There is no null value in train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "74c2eeef-d821-2538-4bf1-6712f650ab13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().any().any())\n",
    "print(test.isnull().any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4d21cde6-f4a0-2a04-70a0-9042f0eaccc2"
   },
   "source": [
    "# Label Encoding the Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "7bd7e2bb-26ec-34a5-e69f-feb27e022992"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ffc4dd13-3163-adf1-81ec-908bd67eaad1"
   },
   "outputs": [],
   "source": [
    "species = train['species']\n",
    "train.drop('species',axis=1,inplace=True)\n",
    "y_train = le.fit_transform(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0b940fb-d0e7-5242-3e34-593781f9bfc4"
   },
   "source": [
    "# Normalize the Sparse Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "e5bcbae0-d109-c392-ca13-f7cb919c895a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8b533b01-139f-46df-6815-508f18682b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1584, 192)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.08888282,  0.11428711,  0.13953682, ...,  0.01298739,\n",
       "         0.        ,  0.16994177],\n",
       "       [ 0.06666212,  0.        ,  0.18604513, ...,  0.00259854,\n",
       "         0.44943277,  0.1503313 ],\n",
       "       [ 0.06666212,  0.04762044,  0.11627672, ...,  0.        ,\n",
       "         0.23595738,  0.01961047],\n",
       "       ..., \n",
       "       [ 0.19999772,  0.14285645,  0.09302256, ...,  0.        ,\n",
       "         0.49438525,  0.0457533 ],\n",
       "       [ 0.15555631,  0.04762044,  0.36046318, ...,  0.        ,\n",
       "         0.13483443,  0.12418847],\n",
       "       [ 0.        ,  0.57143554,  0.        , ...,  0.04155806,\n",
       "         0.        ,  0.11764942]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = np.vstack([train,test])\n",
    "mas = MaxAbsScaler()\n",
    "n_x_data = mas.fit_transform(x_data)\n",
    "print(n_x_data.shape)\n",
    "n_x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b96c3350-6f8c-3eb8-91b2-437e2fbe843b"
   },
   "source": [
    "# Split the dataset - raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "55fc716a-8c24-5956-9d3a-e99490a28f08"
   },
   "outputs": [],
   "source": [
    "x_test = n_x_data[len(species):,:]\n",
    "x_train = n_x_data[0:len(species),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d2f96381-cb13-5b35-4846-c246cf6d3d88"
   },
   "source": [
    "# Setting up models and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "3600a4ae-1c85-b58d-4344-88b4ce5199f6"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "17043611-06fd-8b53-e5ca-843b077ac83e"
   },
   "outputs": [],
   "source": [
    "seed=1\n",
    "models = [\n",
    "            'ADB',\n",
    "            'GBC',\n",
    "            'RFC',\n",
    "            'KNC',\n",
    "            'SVC'\n",
    "         ]\n",
    "clfs = [\n",
    "        AdaBoostClassifier(random_state=seed,n_estimators = 150, learning_rate = 0.01), # best score -2.27\n",
    "        GradientBoostingClassifier(random_state=seed,min_samples_split=2, n_estimators=100, learning_rate=0.01, \n",
    "                                   max_depth=3, min_samples_leaf=4), # best score -2.13\n",
    "        RandomForestClassifier(random_state=seed,n_jobs=-1,min_samples_split=2,n_estimators=100,\n",
    "                               criterion='gini',min_samples_leaf=1),\n",
    "        KNeighborsClassifier(n_jobs=-1,n_neighbors=5, weights='distance', leaf_size=15),\n",
    "        SVC(random_state=seed,probability=True,kernel='sigmoid',C=100, tol=0.005)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "828aa8e0-b3fe-c79b-977c-7d32f792d17b"
   },
   "outputs": [],
   "source": [
    "pred_train_models = []\n",
    "pred_test_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "4c7f9f50-f75c-3948-d7dd-aad04b28ca2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.01, n_estimators=150, random_state=1)\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "1 GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.01, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=4,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=1,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "2 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=-1, oob_score=False, random_state=1,\n",
      "            verbose=0, warm_start=False)\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "3 KNeighborsClassifier(algorithm='auto', leaf_size=15, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "           weights='distance')\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "4 SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=True, random_state=1, shrinking=True, tol=0.005,\n",
      "  verbose=False)\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = 3 # use a bigger number\n",
    "\n",
    "sss = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=seed)\n",
    "cvfolds = list(sss.split(x_train,y_train))\n",
    "\n",
    "for j,clf in enumerate(clfs):\n",
    "    print(j,clf)\n",
    "    dataset_test_j = 0 \n",
    "    dataset_train_j = np.zeros((x_train.shape[0],len(np.unique(y_train))))\n",
    "    for i,(train_index, test_index) in enumerate(cvfolds):\n",
    "        n_x_train, n_x_val = x_train[train_index], x_train[test_index]\n",
    "        n_y_train, n_y_val = y_train[train_index], y_train[test_index]\n",
    "        print('fold ' + str(i))        \n",
    "        clf.fit(n_x_train,n_y_train)\n",
    "        dataset_train_j[test_index,:] = clf.predict_proba(n_x_val)\n",
    "        dataset_test_j += clf.predict_proba(x_test)\n",
    "    pred_train_models.append(dataset_train_j)\n",
    "    pred_test_models.append(dataset_test_j/float(kfold))\n",
    "    \n",
    "pred_blend_train = np.hstack(pred_train_models)\n",
    "pred_blend_test = np.hstack(pred_test_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "108ceb6a-6ec1-868e-1815-c565057fbaa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Blending results with a Logistic Regression ... \n",
      "The Best parameters of the blending model\n",
      "{'C': 1000, 'tol': 0.01}\n",
      "The best score:-0.10498684701857776\n"
     ]
    }
   ],
   "source": [
    "print('\\Blending results with a Logistic Regression ... ')\n",
    "\n",
    "blendParams = {'C':[1000],'tol':[0.01]} # test more values in your local machine\n",
    "clf = GridSearchCV(LogisticRegression(solver='newton-cg', multi_class='multinomial'), blendParams, scoring='log_loss',\n",
    "                   refit='True', n_jobs=-1, cv=5)\n",
    "clf.fit(pred_blend_train,y_train)\n",
    "print('The Best parameters of the blending model\\n{}'.format(clf.best_params_))\n",
    "print('The best score:{}'.format(clf.best_score_))\n",
    "\n",
    "estimates = clf.predict_proba(pred_blend_test)\n",
    "submission = pd.DataFrame(estimates, index=test_ids, columns=le.classes_)\n",
    "submission.to_csv('./blendedEnsembles.csv')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 82,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
