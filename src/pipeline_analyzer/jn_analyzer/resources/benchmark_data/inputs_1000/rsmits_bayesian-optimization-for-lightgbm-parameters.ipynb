{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a091f3c59fffb72f2c0814f5c72402e84aa860f"
   },
   "source": [
    "In this competition feature selection and feature engineering are 2 very important steps in achieving a good model and hopefully high score. Another important task is choosing the parameters for your tool/model of choice wisely. There are many ways to choose or search those parameters.\n",
    "\n",
    "In this notebook I will setup a basic solution to use Bayesian optimization to search for an optimal set of parameters for LightGBM. It should be no problem to modify this code and use it for XGBoost for example.\n",
    "\n",
    "Some points to mention upfront. Because of the time needed I specified only 15 initialization rounds and 15 optimization rounds .. however the more rounds the better. I also limited the number of rows used and the maximum iterations for LightGBM. These could also be increased to get better results.\n",
    "\n",
    "For more background information visit the github site for Bayesian Optimization package used [https://github.com/fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c585cae279368a8b0b3451f328d2d957fb253eb9"
   },
   "source": [
    "Let's import the modules needed for Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Import modules specific for Bayesian Optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "984bc43e8456422509158fd77f09e2e0e706feaa"
   },
   "source": [
    "The script will run LightGBM 5 folds Cross Validation and will only load the first 1000000 rows of the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "1779678062ee59bab140612a3f7d13432f9e4e72"
   },
   "outputs": [],
   "source": [
    "# Specify some constants\n",
    "seed = 4249\n",
    "folds = 5\n",
    "number_of_rows = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90067538192355262f892b42d18e3b707648998b"
   },
   "source": [
    "For the features I just choose a couple of them. I'am still working on my own feature selection and engineering ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "48c06a7b7403d85bce0a4d532e515a2792eb205b"
   },
   "outputs": [],
   "source": [
    "# Select Features\n",
    "features = ['AVProductStatesIdentifier',\n",
    "            'AVProductsInstalled', \n",
    "            'Census_ProcessorModelIdentifier',\n",
    "            'Census_TotalPhysicalRAM',\n",
    "            'Census_PrimaryDiskTotalCapacity',\n",
    "            'EngineVersion',\n",
    "            'Census_SystemVolumeTotalCapacity',\n",
    "            'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "            'Census_OSBuildRevision',\n",
    "            'AppVersion',\n",
    "            'Census_OEMNameIdentifier',\n",
    "            'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "            'Census_ProcessorCoreCount',\n",
    "            'Census_OEMModelIdentifier',\n",
    "            'CountryIdentifier',\n",
    "            'LocaleEnglishNameIdentifier',\n",
    "            'GeoNameIdentifier',\n",
    "            'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "            'IeVerIdentifier',\n",
    "            'HasDetections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e7e7f0b1abe48e1c0f8b906cfccb8746ff1cf5c"
   },
   "source": [
    "Load the train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "46f773ea20f3dbd3aca08def67dbcffba155b2ef"
   },
   "outputs": [],
   "source": [
    "# Load Data with selected features\n",
    "X = pd.read_csv('../input/train.csv', usecols = features, nrows = number_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5decb045bbed572d6bf47055e5bb9d7f1e52006"
   },
   "source": [
    "Assign the labels to Y and drop the label column from the train dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a3592f017a594e997b1c5fd4f1cb0f7a1dc1e78e"
   },
   "outputs": [],
   "source": [
    "# Labels\n",
    "Y = X['HasDetections']\n",
    "\n",
    "# Remove Labels from Dataframe\n",
    "X.drop(['HasDetections'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05acd72d19694078fe0135f7b794480424b6c012"
   },
   "source": [
    "2 columns are factorized. The remainder of the columns are used as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c76cf910bb4ce7aa6b787821b472e66843df197c"
   },
   "outputs": [],
   "source": [
    "# Factorize Some Columns\n",
    "X['EngineVersion'] = pd.to_numeric(pd.factorize(X['EngineVersion'])[0])\n",
    "X['AppVersion'] = pd.to_numeric(pd.factorize(X['AppVersion'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "634631304db1e0f96d640396ee1d88077770e4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 19)\n",
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "# Final Data Shapes\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d3bb309038ac94b7137f2c5ba4000658991d1ff8"
   },
   "outputs": [],
   "source": [
    "# Create LightGBM Dataset\n",
    "lgbm_dataset = lgbm.Dataset(data = X, label = Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b19714a70e855abe7776d006812ce39fd7b3b67"
   },
   "source": [
    "I specify a function to run LightGBM Cross Validation with the specified parameters. After running for a maximum of 1250 iterations the function will return the achieved AUC.\n",
    "\n",
    "The specified parameters are:\n",
    "* learning_rate\n",
    "* num_leaves\n",
    "* feature_fraction\n",
    "* bagging_fraction\n",
    "* max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "0ca47df859702dbd4c374f57372cbede5015a27d"
   },
   "outputs": [],
   "source": [
    "# Specify LightGBM Cross Validation function\n",
    "def lgbm_cv_evaluator(learning_rate, num_leaves, feature_fraction, bagging_fraction, max_depth):\n",
    "    # Setup Parameters\n",
    "    params = {  'objective':            'binary',\n",
    "                'boosting':             'gbdt',\n",
    "                'num_iterations':       1250, \n",
    "                'early_stopping_round': 100, \n",
    "                'metric':               'auc',\n",
    "                'verbose':              -1\n",
    "            }\n",
    "    params['learning_rate'] =       learning_rate\n",
    "    params['num_leaves'] =          int(round(num_leaves))\n",
    "    params['feature_fraction'] =    feature_fraction\n",
    "    params['bagging_fraction'] =    bagging_fraction\n",
    "    params['max_depth'] =           int(round(max_depth))\n",
    "        \n",
    "    # Run LightGBM Cross Validation\n",
    "    result = lgbm.cv(params, lgbm_dataset, nfold = folds, seed = seed, \n",
    "                     stratified = True, verbose_eval = -1, metrics = ['auc']) \n",
    "    \n",
    "    # Return AUC\n",
    "    return max(result['auc-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70e1a59af022c607f2f2087dddda20070d4e1355"
   },
   "source": [
    "Next we create a function to display a custom progress status for each round of Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "ebb0c18550f42b3064897c8d1416cd2c62f9c10d"
   },
   "outputs": [],
   "source": [
    "def display_progress(event, instance):\n",
    "    iter = len(instance.res) - 1\n",
    "    print('Iteration: {} - AUC: {} - {}'.format(iter, instance.res[iter].get('target'), instance.res[iter].get('params')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b3cff5fc813e3b8a866c505683c96d733dfef6e"
   },
   "source": [
    "The following function initializes the BayesianOptimization package with the function to use and the different ranges for the parameters. For each parameter a lower and upper bound is specified.\n",
    "Also we subscribe to each Optimization Step a logger to log all results to json file and the function to show the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "de169aed3a23061fe4445868a68194621328652d"
   },
   "outputs": [],
   "source": [
    "def bayesian_parameter_optimization(init_rounds = 1, opt_rounds = 1):    \n",
    "    \n",
    "    # Initialize Bayesian Optimization\n",
    "    optimizer = BayesianOptimization(f = lgbm_cv_evaluator, \n",
    "                                    pbounds = { 'learning_rate':        (0.02, 0.06),\n",
    "                                                'num_leaves':           (20, 100),\n",
    "                                                'feature_fraction':     (0.25, 0.75),\n",
    "                                                'bagging_fraction':     (0.75, 0.95),\n",
    "                                                'max_depth':            (8, 15) },\n",
    "                                    random_state = seed, \n",
    "                                    verbose = 2)\n",
    "    \n",
    "    # Subscribe Logging to file for each Optimization Step\n",
    "    logger = JSONLogger(path = 'parameter_output.json')\n",
    "    optimizer.subscribe(Events.OPTMIZATION_STEP, logger)\n",
    "    \n",
    "    # Subscribe the custom display_progress function for each Optimization Step\n",
    "    optimizer.subscribe(Events.OPTMIZATION_STEP, \" \", display_progress)\n",
    "\n",
    "    # Perform Bayesian Optimization. \n",
    "    # Modify acq, kappa and xi to change the behaviour of Bayesian Optimization itself.\n",
    "    optimizer.maximize(init_points = init_rounds, n_iter = opt_rounds, acq = \"ei\", kappa = 2, xi = 0.1)\n",
    "    \n",
    "    # Return Found Best Parameter values and Target\n",
    "    return optimizer.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a90f80ec71daff9bdd12e8610510ad3e297d06b5"
   },
   "source": [
    "Finally we will trigger the optimization process and show the found optimal results. Note that the results from all rounds will be logged to the .json file in the output. In the Kaggle webpage it will show only 1 round..if you download the file you will see the information for all rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "042d822b1474530f6c7b4fea0d3ec7b6fa146f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 - AUC: 0.6805827770281999 - {'bagging_fraction': 0.8958573909164281, 'feature_fraction': 0.5461194901557971, 'learning_rate': 0.05959379197303104, 'max_depth': 11.861393331954002, 'num_leaves': 88.04406874840167}\n",
      "Iteration: 1 - AUC: 0.6809588556787933 - {'bagging_fraction': 0.7965312336845769, 'feature_fraction': 0.5316027243961312, 'learning_rate': 0.04652466867103855, 'max_depth': 11.901731116162148, 'num_leaves': 97.11938549548832}\n",
      "Iteration: 2 - AUC: 0.6779047398949763 - {'bagging_fraction': 0.7681713977815523, 'feature_fraction': 0.5477483476672664, 'learning_rate': 0.031363991609995555, 'max_depth': 8.697671306184727, 'num_leaves': 45.077617977405154}\n",
      "Iteration: 3 - AUC: 0.6801254199694775 - {'bagging_fraction': 0.8058095043692863, 'feature_fraction': 0.5879353478464306, 'learning_rate': 0.04878880420858015, 'max_depth': 9.6124527306123, 'num_leaves': 66.72461453193922}\n",
      "Iteration: 4 - AUC: 0.6802713597550933 - {'bagging_fraction': 0.8724102699259315, 'feature_fraction': 0.4665786174419668, 'learning_rate': 0.030179330411299415, 'max_depth': 14.360369900903518, 'num_leaves': 83.34689002563135}\n",
      "Iteration: 5 - AUC: 0.6814525576683508 - {'bagging_fraction': 0.9010894494159424, 'feature_fraction': 0.2624143966287678, 'learning_rate': 0.039293276623281345, 'max_depth': 12.587208368983609, 'num_leaves': 88.50181548090018}\n",
      "Iteration: 6 - AUC: 0.6801155962024537 - {'bagging_fraction': 0.7974044565033316, 'feature_fraction': 0.7267831625528121, 'learning_rate': 0.05696146445002111, 'max_depth': 9.798051795174523, 'num_leaves': 92.59519833656768}\n",
      "Iteration: 7 - AUC: 0.6789353625762253 - {'bagging_fraction': 0.9042507494159661, 'feature_fraction': 0.7145146548435449, 'learning_rate': 0.05702307483009482, 'max_depth': 12.514729032754074, 'num_leaves': 41.969658078407505}\n",
      "Iteration: 8 - AUC: 0.6793694957857411 - {'bagging_fraction': 0.7907369129115117, 'feature_fraction': 0.4242213967431454, 'learning_rate': 0.05600054004761791, 'max_depth': 11.341642126763785, 'num_leaves': 43.81364276310052}\n",
      "Iteration: 9 - AUC: 0.6793291411448303 - {'bagging_fraction': 0.7891063448471469, 'feature_fraction': 0.2782402851653586, 'learning_rate': 0.046264115600142874, 'max_depth': 9.98921694619526, 'num_leaves': 43.82100712709889}\n",
      "Iteration: 10 - AUC: 0.6802173716163955 - {'bagging_fraction': 0.7637055243537618, 'feature_fraction': 0.5644662523923635, 'learning_rate': 0.05743726665581696, 'max_depth': 13.30541979037866, 'num_leaves': 69.11761707632425}\n",
      "Iteration: 11 - AUC: 0.6796606009471878 - {'bagging_fraction': 0.9342076712056532, 'feature_fraction': 0.46109733506806505, 'learning_rate': 0.02620780866040917, 'max_depth': 8.653581002970473, 'num_leaves': 80.78465614048135}\n",
      "Iteration: 12 - AUC: 0.6802576179300038 - {'bagging_fraction': 0.7865905071133399, 'feature_fraction': 0.3900548690624679, 'learning_rate': 0.025710653880560992, 'max_depth': 8.843780205261872, 'num_leaves': 95.44713372555782}\n",
      "Iteration: 13 - AUC: 0.6789681380004102 - {'bagging_fraction': 0.8566613859882682, 'feature_fraction': 0.7324530180110709, 'learning_rate': 0.03341020780433361, 'max_depth': 9.527887001675925, 'num_leaves': 62.660063153691006}\n",
      "Iteration: 14 - AUC: 0.6811144661178039 - {'bagging_fraction': 0.9322200055985479, 'feature_fraction': 0.2632649668140535, 'learning_rate': 0.025400924379617405, 'max_depth': 12.54670384366479, 'num_leaves': 96.7348531803121}\n",
      "Iteration: 15 - AUC: 0.678623044486565 - {'bagging_fraction': 0.8909782703944403, 'feature_fraction': 0.25642592117615004, 'learning_rate': 0.04400411057106484, 'max_depth': 10.93507993570632, 'num_leaves': 38.92551392486533}\n",
      "Iteration: 16 - AUC: 0.6775295619476696 - {'bagging_fraction': 0.8267534312412996, 'feature_fraction': 0.4447578497832723, 'learning_rate': 0.04437529157491356, 'max_depth': 11.85608272173309, 'num_leaves': 30.27877169683128}\n",
      "Iteration: 17 - AUC: 0.6794685104368826 - {'bagging_fraction': 0.7547955468617669, 'feature_fraction': 0.7436458818488277, 'learning_rate': 0.030833871622025062, 'max_depth': 11.710072440723224, 'num_leaves': 84.01817945764321}\n",
      "Iteration: 18 - AUC: 0.6803015473747575 - {'bagging_fraction': 0.8115554336375601, 'feature_fraction': 0.6550898184041603, 'learning_rate': 0.05764232581194485, 'max_depth': 13.717988202775729, 'num_leaves': 92.34502339077396}\n",
      "Iteration: 19 - AUC: 0.6776156273521472 - {'bagging_fraction': 0.8538094565716612, 'feature_fraction': 0.2509496749213604, 'learning_rate': 0.036495417997105, 'max_depth': 11.540545226265655, 'num_leaves': 36.02433840261967}\n",
      "Iteration: 20 - AUC: 0.6766424561894706 - {'bagging_fraction': 0.7856606104688951, 'feature_fraction': 0.6148735906307045, 'learning_rate': 0.034991978729613585, 'max_depth': 12.803478366001181, 'num_leaves': 31.099747051146096}\n",
      "Iteration: 21 - AUC: 0.6799461394163415 - {'bagging_fraction': 0.9290437973445559, 'feature_fraction': 0.6185398812931817, 'learning_rate': 0.053047577114867434, 'max_depth': 10.828353443047092, 'num_leaves': 65.1049551312423}\n",
      "Iteration: 22 - AUC: 0.6800726744313894 - {'bagging_fraction': 0.8429045894169847, 'feature_fraction': 0.4492464463630168, 'learning_rate': 0.04495316706653883, 'max_depth': 11.0074872841273, 'num_leaves': 63.444347871472296}\n",
      "Iteration: 23 - AUC: 0.6786893909233901 - {'bagging_fraction': 0.8880656628329495, 'feature_fraction': 0.46568553061260337, 'learning_rate': 0.049922004380193855, 'max_depth': 11.223379664646018, 'num_leaves': 36.77914947601067}\n",
      "Iteration: 24 - AUC: 0.6810158917524802 - {'bagging_fraction': 0.8853952055460699, 'feature_fraction': 0.42833444009013805, 'learning_rate': 0.05157127213547609, 'max_depth': 11.702130356288611, 'num_leaves': 94.35850322055592}\n",
      "Iteration: 25 - AUC: 0.6795683842558995 - {'bagging_fraction': 0.8338198671460093, 'feature_fraction': 0.7305857517128551, 'learning_rate': 0.0386988719211, 'max_depth': 13.381379584969654, 'num_leaves': 70.8832411127417}\n",
      "Iteration: 26 - AUC: 0.6810982712820831 - {'bagging_fraction': 0.8926401102958366, 'feature_fraction': 0.25530372847090965, 'learning_rate': 0.026699939046168224, 'max_depth': 11.033756801298548, 'num_leaves': 95.7761589454377}\n",
      "Iteration: 27 - AUC: 0.6806586759925031 - {'bagging_fraction': 0.9408453030112307, 'feature_fraction': 0.5008591078521071, 'learning_rate': 0.05301415550407498, 'max_depth': 12.196468461480809, 'num_leaves': 85.13629404236023}\n",
      "Iteration: 28 - AUC: 0.6763336425515517 - {'bagging_fraction': 0.8999054057429583, 'feature_fraction': 0.5150122193045078, 'learning_rate': 0.020195226458281004, 'max_depth': 12.327576920746468, 'num_leaves': 44.465751069801804}\n",
      "Iteration: 29 - AUC: 0.6799139584838002 - {'bagging_fraction': 0.9059655262479324, 'feature_fraction': 0.6677799156947043, 'learning_rate': 0.05660894050471506, 'max_depth': 12.566008695336311, 'num_leaves': 79.17685019423013}\n",
      "================= Results\n",
      "Found Max AUC: 0.6814525576683508 with the following Parameters: \n",
      "{'bagging_fraction': 0.9010894494159424, 'feature_fraction': 0.2624143966287678, 'learning_rate': 0.039293276623281345, 'max_depth': 12.587208368983609, 'num_leaves': 88.50181548090018}\n"
     ]
    }
   ],
   "source": [
    "# Configure and Perform Bayesian Optimization \n",
    "max_params = bayesian_parameter_optimization(init_rounds = 15, opt_rounds = 15)\n",
    "\n",
    "print('================= Results')\n",
    "print('Found Max AUC: {} with the following Parameters: '.format(max_params.get('target')))\n",
    "print(max_params.get('params'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "922e1c7f86d58280c5d936bfccfe870638e1d56a"
   },
   "source": [
    "I hope you enjoyed this notebook and that you can use it for your own benefit.\n",
    "\n",
    "Please let me know if you have any questions/remarks/improvements. Those are allways welcome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
