{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# **This creates the lower scored of my submissions - Topics look better, but accuracy suffers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import scipy as sp;\n",
    "import sklearn;\n",
    "import sys;\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import nltk;\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import ldamodel\n",
    "from gensim.models.hdpmodel import HdpModel\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import matutils, models\n",
    "import gensim.corpora;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer;\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "import scipy.sparse\n",
    "import string\n",
    "import pickle;\n",
    "import re;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp = [i.lower() for i in stopwords.words('english')]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "mainData = pd.read_csv(\"../input/unstructured-l0-nlp-hackathon/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Function that takes in nltk POS tags and returns tags so that they can be used for\n",
    "    lemmatizaition\n",
    "    '''\n",
    "#     if treebank_tag.startswith('J'):\n",
    "#         return wordnet.ADJ\n",
    "#     elif treebank_tag.startswith('V'):\n",
    "#         return wordnet.VERB\n",
    "    if treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "#     elif treebank_tag.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_topics(model, num_topics):\n",
    "    word_dict = {}\n",
    "    topics = model.show_topics(num_topics,20)\n",
    "    word_dict = {'Topic '+str(i):[x.split('*') for x in words.split('+')] \\\n",
    "                 for i,words in model.show_topics(10,20)}\n",
    "    return pd.DataFrame.from_dict(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdp_topics(model, num_topics):\n",
    "    word_dict = {}\n",
    "    topics = model.show_topics(num_topics,20)\n",
    "    word_dict = {'Topic '+str(i):[x.split('*') for x in words.split('+')] \\\n",
    "                 for i,words in model.show_topics(10,20)}\n",
    "    return pd.DataFrame.from_dict(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_array(A):\n",
    "    tokens = nltk.word_tokenize(A)\n",
    "    postags = nltk.pos_tag(tokens)\n",
    "\n",
    "    resp_list = []\n",
    "\n",
    "    for elem,tag in postags:\n",
    "        if elem.lower().strip() not in stp and len(elem)>2:\n",
    "            try:\n",
    "                if get_wordnet_pos(tag) != None:\n",
    "                    resp_list.append(lemmatizer.lemmatize(elem.lower().strip(), get_wordnet_pos(tag)))\n",
    "            except:\n",
    "                print(elem, tag)\n",
    "\n",
    "    return(\" \".join(resp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData[\"clean\"] = mainData[\"text\"].apply(lambda x: cleaner_array(x))\n",
    "mainData[\"clean\"] = mainData[\"clean\"].str.lower().apply(lambda x: re.sub(r'(@[\\S]+)|(\\w+:\\/\\/\\S+)|(\\d+)','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'text', 'clean'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = mainData[\"clean\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Using TF-IDF values to find my BOW and running LDA\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer()\n",
    "tf_idf_model = tf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "DF_valid = pd.DataFrame(tf_idf_model.toarray(), columns=tf_vectorizer.get_feature_names())\n",
    "DF_valid.index = mainData.Id\n",
    "\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(DF_valid.transpose()))\n",
    "\n",
    "Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in tf_vectorizer.vocabulary_.items())\n",
    "\n",
    "lda = models.LdaModel(corpus=corpusna, num_topics=5, id2word=id2wordna, passes=50)\n",
    "\n",
    "get_lda_topics(lda,20)\n",
    "\n",
    "Topics arent as clear as would be liked - Let us try Counts instead (for similarity to how LDAmodel works)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Using Counts instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer(stop_words='english', max_features = 4000, max_df = 0.8)\n",
    "countvect_model = countvect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count = pd.DataFrame(countvect_model.toarray(), columns=countvect.get_feature_names())\n",
    "data_count.index = mainData.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_count = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_count.transpose()))\n",
    "\n",
    "\n",
    "id2word_count = dict((v, k) for k, v in countvect.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_mod = models.LdaModel(corpus=corpus_count,\n",
    "                          num_topics=5,\n",
    "                          id2word=id2word_count,\n",
    "                          random_state=1,\n",
    "                          passes=50,#50,\n",
    "                          alpha=0.001,\n",
    "                          eta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.011, \"season\" ]</td>\n",
       "      <td>[0.036, \"car\" ]</td>\n",
       "      <td>[0.008, \"company\" ]</td>\n",
       "      <td>[0.071, \"pro\" ]</td>\n",
       "      <td>[0.020, \"place\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ 0.010, \"league\" ]</td>\n",
       "      <td>[ 0.018, \"line\" ]</td>\n",
       "      <td>[ 0.008, \"today\" ]</td>\n",
       "      <td>[ 0.033, \"company\" ]</td>\n",
       "      <td>[ 0.020, \"home\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ 0.009, \"team\" ]</td>\n",
       "      <td>[ 0.017, \"organization\" ]</td>\n",
       "      <td>[ 0.007, \"designer\" ]</td>\n",
       "      <td>[ 0.027, \"work\" ]</td>\n",
       "      <td>[ 0.017, \"room\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ 0.007, \"city\" ]</td>\n",
       "      <td>[ 0.013, \"article\" ]</td>\n",
       "      <td>[ 0.006, \"game\" ]</td>\n",
       "      <td>[ 0.026, \"people\" ]</td>\n",
       "      <td>[ 0.015, \"bedroom\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ 0.007, \"player\" ]</td>\n",
       "      <td>[ 0.008, \"university\" ]</td>\n",
       "      <td>[ 0.005, \"year\" ]</td>\n",
       "      <td>[ 0.025, \"employee\" ]</td>\n",
       "      <td>[ 0.015, \"minute\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ 0.006, \"game\" ]</td>\n",
       "      <td>[ 0.008, \"cur\" ]</td>\n",
       "      <td>[ 0.005, \"request\" ]</td>\n",
       "      <td>[ 0.023, \"benefit\" ]</td>\n",
       "      <td>[ 0.012, \"house\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ 0.006, \"year\" ]</td>\n",
       "      <td>[ 0.007, \"time\" ]</td>\n",
       "      <td>[ 0.005, \"time\" ]</td>\n",
       "      <td>[ 0.020, \"management\" ]</td>\n",
       "      <td>[ 0.011, \"bed\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ 0.006, \"club\" ]</td>\n",
       "      <td>[ 0.006, \"engine\" ]</td>\n",
       "      <td>[ 0.004, \"service\" ]</td>\n",
       "      <td>[ 0.014, \"honeywell\" ]</td>\n",
       "      <td>[ 0.010, \"mile\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ 0.006, \"week\" ]</td>\n",
       "      <td>[ 0.006, \"distribution\" ]</td>\n",
       "      <td>[ 0.004, \"google\" ]</td>\n",
       "      <td>[ 0.014, \"year\" ]</td>\n",
       "      <td>[ 0.010, \"restaurant\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ 0.006, \"time\" ]</td>\n",
       "      <td>[ 0.006, \"year\" ]</td>\n",
       "      <td>[ 0.004, \"day\" ]</td>\n",
       "      <td>[ 0.014, \"job\" ]</td>\n",
       "      <td>[ 0.010, \"area\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[ 0.006, \"manchester\" ]</td>\n",
       "      <td>[ 0.005, \"thing\" ]</td>\n",
       "      <td>[ 0.004, \"startup\" ]</td>\n",
       "      <td>[ 0.013, \"pay\" ]</td>\n",
       "      <td>[ 0.010, \"family\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[ 0.005, \"manager\" ]</td>\n",
       "      <td>[ 0.005, \"problem\" ]</td>\n",
       "      <td>[ 0.004, \"apple\" ]</td>\n",
       "      <td>[ 0.012, \"lot\" ]</td>\n",
       "      <td>[ 0.009, \"kitchen\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[ 0.005, \"deal\" ]</td>\n",
       "      <td>[ 0.005, \"dealer\" ]</td>\n",
       "      <td>[ 0.004, \"world\" ]</td>\n",
       "      <td>[ 0.011, \"time\" ]</td>\n",
       "      <td>[ 0.008, \"bathroom\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[ 0.005, \"champion\" ]</td>\n",
       "      <td>[ 0.005, \"people\" ]</td>\n",
       "      <td>[ 0.004, \"video\" ]</td>\n",
       "      <td>[ 0.010, \"opportunity\" ]</td>\n",
       "      <td>[ 0.008, \"couple\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[ 0.005, \"premier\" ]</td>\n",
       "      <td>[ 0.005, \"oil\" ]</td>\n",
       "      <td>[ 0.004, \"list\" ]</td>\n",
       "      <td>[ 0.009, \"environment\" ]</td>\n",
       "      <td>[ 0.008, \"business\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[ 0.005, \"goal\" ]</td>\n",
       "      <td>[ 0.005, \"driver\" ]</td>\n",
       "      <td>[ 0.004, \"design\" ]</td>\n",
       "      <td>[ 0.008, \"manager\" ]</td>\n",
       "      <td>[ 0.008, \"access\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[ 0.004, \"cup\" ]</td>\n",
       "      <td>[ 0.004, \"price\" ]</td>\n",
       "      <td>[ 0.004, \"user\" ]</td>\n",
       "      <td>[ 0.007, \"team\" ]</td>\n",
       "      <td>[ 0.008, \"space\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[ 0.004, \"point\" ]</td>\n",
       "      <td>[ 0.004, \"speed\" ]</td>\n",
       "      <td>[ 0.003, \"information\" ]</td>\n",
       "      <td>[ 0.007, \"product\" ]</td>\n",
       "      <td>[ 0.007, \"neighborhood\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[ 0.004, \"contract\" ]</td>\n",
       "      <td>[ 0.004, \"model\" ]</td>\n",
       "      <td>[ 0.003, \"presentation\" ]</td>\n",
       "      <td>[ 0.007, \"place\" ]</td>\n",
       "      <td>[ 0.007, \"park\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[ 0.004, \"england\"]</td>\n",
       "      <td>[ 0.004, \"way\"]</td>\n",
       "      <td>[ 0.003, \"facebook\"]</td>\n",
       "      <td>[ 0.006, \"life\"]</td>\n",
       "      <td>[ 0.007, \"traveler\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Topic 0                    Topic 1  \\\n",
       "0        [0.011, \"season\" ]            [0.036, \"car\" ]   \n",
       "1       [ 0.010, \"league\" ]          [ 0.018, \"line\" ]   \n",
       "2         [ 0.009, \"team\" ]  [ 0.017, \"organization\" ]   \n",
       "3         [ 0.007, \"city\" ]       [ 0.013, \"article\" ]   \n",
       "4       [ 0.007, \"player\" ]    [ 0.008, \"university\" ]   \n",
       "5         [ 0.006, \"game\" ]           [ 0.008, \"cur\" ]   \n",
       "6         [ 0.006, \"year\" ]          [ 0.007, \"time\" ]   \n",
       "7         [ 0.006, \"club\" ]        [ 0.006, \"engine\" ]   \n",
       "8         [ 0.006, \"week\" ]  [ 0.006, \"distribution\" ]   \n",
       "9         [ 0.006, \"time\" ]          [ 0.006, \"year\" ]   \n",
       "10  [ 0.006, \"manchester\" ]         [ 0.005, \"thing\" ]   \n",
       "11     [ 0.005, \"manager\" ]       [ 0.005, \"problem\" ]   \n",
       "12        [ 0.005, \"deal\" ]        [ 0.005, \"dealer\" ]   \n",
       "13    [ 0.005, \"champion\" ]        [ 0.005, \"people\" ]   \n",
       "14     [ 0.005, \"premier\" ]           [ 0.005, \"oil\" ]   \n",
       "15        [ 0.005, \"goal\" ]        [ 0.005, \"driver\" ]   \n",
       "16         [ 0.004, \"cup\" ]         [ 0.004, \"price\" ]   \n",
       "17       [ 0.004, \"point\" ]         [ 0.004, \"speed\" ]   \n",
       "18    [ 0.004, \"contract\" ]         [ 0.004, \"model\" ]   \n",
       "19      [ 0.004, \"england\"]            [ 0.004, \"way\"]   \n",
       "\n",
       "                      Topic 2                   Topic 3  \\\n",
       "0         [0.008, \"company\" ]           [0.071, \"pro\" ]   \n",
       "1          [ 0.008, \"today\" ]      [ 0.033, \"company\" ]   \n",
       "2       [ 0.007, \"designer\" ]         [ 0.027, \"work\" ]   \n",
       "3           [ 0.006, \"game\" ]       [ 0.026, \"people\" ]   \n",
       "4           [ 0.005, \"year\" ]     [ 0.025, \"employee\" ]   \n",
       "5        [ 0.005, \"request\" ]      [ 0.023, \"benefit\" ]   \n",
       "6           [ 0.005, \"time\" ]   [ 0.020, \"management\" ]   \n",
       "7        [ 0.004, \"service\" ]    [ 0.014, \"honeywell\" ]   \n",
       "8         [ 0.004, \"google\" ]         [ 0.014, \"year\" ]   \n",
       "9            [ 0.004, \"day\" ]          [ 0.014, \"job\" ]   \n",
       "10       [ 0.004, \"startup\" ]          [ 0.013, \"pay\" ]   \n",
       "11         [ 0.004, \"apple\" ]          [ 0.012, \"lot\" ]   \n",
       "12         [ 0.004, \"world\" ]         [ 0.011, \"time\" ]   \n",
       "13         [ 0.004, \"video\" ]  [ 0.010, \"opportunity\" ]   \n",
       "14          [ 0.004, \"list\" ]  [ 0.009, \"environment\" ]   \n",
       "15        [ 0.004, \"design\" ]      [ 0.008, \"manager\" ]   \n",
       "16          [ 0.004, \"user\" ]         [ 0.007, \"team\" ]   \n",
       "17   [ 0.003, \"information\" ]      [ 0.007, \"product\" ]   \n",
       "18  [ 0.003, \"presentation\" ]        [ 0.007, \"place\" ]   \n",
       "19       [ 0.003, \"facebook\"]          [ 0.006, \"life\"]   \n",
       "\n",
       "                      Topic 4  \n",
       "0           [0.020, \"place\" ]  \n",
       "1           [ 0.020, \"home\" ]  \n",
       "2           [ 0.017, \"room\" ]  \n",
       "3        [ 0.015, \"bedroom\" ]  \n",
       "4         [ 0.015, \"minute\" ]  \n",
       "5          [ 0.012, \"house\" ]  \n",
       "6            [ 0.011, \"bed\" ]  \n",
       "7           [ 0.010, \"mile\" ]  \n",
       "8     [ 0.010, \"restaurant\" ]  \n",
       "9           [ 0.010, \"area\" ]  \n",
       "10        [ 0.010, \"family\" ]  \n",
       "11       [ 0.009, \"kitchen\" ]  \n",
       "12      [ 0.008, \"bathroom\" ]  \n",
       "13        [ 0.008, \"couple\" ]  \n",
       "14      [ 0.008, \"business\" ]  \n",
       "15        [ 0.008, \"access\" ]  \n",
       "16         [ 0.008, \"space\" ]  \n",
       "17  [ 0.007, \"neighborhood\" ]  \n",
       "18          [ 0.007, \"park\" ]  \n",
       "19       [ 0.007, \"traveler\"]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics(lda_mod,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Let us validate the results:\n",
    "* 2: \"glassdoor_reviews\",\n",
    "* 3: \"Automobiles\",\n",
    "* 4: \"sports_news\",\n",
    "* 1: \"tech_news\",\n",
    "* 0: \"room_rentals\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Seems moderately appropriate - let us consider lda_mod as final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_transformed = lda_mod[corpus_count]\n",
    "\n",
    "topics = []\n",
    "\n",
    "for i in range(len(corpus_transformed)):\n",
    "    v=dict(corpus_transformed[i])\n",
    "    for top, score in v.items():\n",
    "        if score == max(v.values()):\n",
    "            topics.append(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = pd.DataFrame(topics, index = mainData.Id, columns = [\"topic\"])\n",
    "\n",
    "final_output.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.replace({'topic': {2: \"glassdoor_reviews\",\n",
    "                                3: \"Automobiles\",\n",
    "                                4: \"sports_news\",\n",
    "                                1: \"tech_news\",\n",
    "                                0: \"room_rentals\"}},\n",
    "                     inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/output/submission_V9.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6f2037eb141f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/output/submission_V9.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/output/submission_V9.csv'"
     ]
    }
   ],
   "source": [
    "final_output.to_csv(\"../input/output/submission_V9.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
