{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7dfdfbdb-d389-4c21-ba76-89b15e6e4cbf",
    "_uuid": "e333703c4c31cf9e90d6db37457068198b2a6c1e"
   },
   "source": [
    "The idea of this Notebook is reorder the categorical variables to create a smaller decision tree, smaler ~= min(model.tree_.max_depth) ≃ getMetric()\n",
    "\n",
    "It execute a random permutation, or a sequential permutatition (from itertools). I have no idea if this can optimize the classifiers or not, just an start point to reorder categorical variables based on some metric\n",
    "https://github.com/rspadim/CategoricalReorders\n",
    "\n",
    "changed to multithread version ( 16 cores =] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c206b3ba-3b96-4ee8-8e1d-bac72cf59721",
    "_uuid": "c65a3b0cb7c02913453e9bab9f157a369664660c"
   },
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "182415be-a332-4363-81d0-aca3c5a92c7b",
    "_uuid": "a91a60132385d6bd2226f49744311d7c74e728dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading files...\n",
      "done :)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"reading files...\")\n",
    "train  =pd.read_csv(\"../input/train.csv\")\n",
    "predict=pd.read_csv(\"../input/test.csv\")\n",
    "cat_cols = [col for col in train.columns if '_cat' in col]\n",
    "print(\"done :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "58c2b487-9b67-469f-8b33-a7aebfb7948e",
    "_uuid": "e45257e9d015c96ce0d71d049ae91e2d363831b9"
   },
   "source": [
    "Reorder function - it return the series and a dictionary to replace the predict dataset, maybe we can do better with a class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "86452d0c-290e-4ef2-a9c0-d4025ad9ceea",
    "_uuid": "c5f62300c9cd996e3687e0218155e25e24ac9289",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from math import factorial\n",
    "from itertools import permutations\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score,log_loss,mean_absolute_error,mean_squared_error,r2_score\n",
    "from xgboost import XGBClassifier\n",
    "def getModel(classifier=True,tree_seed=19870425):\n",
    "    ## tests with xgb\n",
    "    #return XGBClassifier(max_depth=10000,\n",
    "    #                     learning_rate=0.1,\n",
    "    #                     n_estimators=10000, \n",
    "    #                     silent=True, \n",
    "    #                     objective='binary:logistic', \n",
    "    #                     booster='gbtree', \n",
    "    #                     n_jobs=1, \n",
    "    #                     nthread=None, \n",
    "    #                     gamma=0, \n",
    "    #                     min_child_weight=1, \n",
    "    #                     max_delta_step=0, \n",
    "    #                     subsample=1, \n",
    "    #                     colsample_bytree=1, \n",
    "    #                     colsample_bylevel=1, \n",
    "    #                     reg_alpha=0, \n",
    "    #                     reg_lambda=1, \n",
    "    #                     scale_pos_weight=1, \n",
    "    #                     base_score=0.5, \n",
    "    #                     random_state=tree_seed, \n",
    "    #                     seed=tree_seed, \n",
    "    #                     missing=None)\n",
    "    \n",
    "    \n",
    "    if(classifier):\n",
    "        return DecisionTreeClassifier(max_depth=None,presort=True,criterion='entropy',class_weight='balanced',random_state=tree_seed)\n",
    "    return DecisionTreeRegressor(max_depth=None,presort=True,random_state=tree_seed)\n",
    "\n",
    "def getMetric(model):\n",
    "    ## tests with xgb\n",
    "    #print(type(model))\n",
    "    #print(vars(model))\n",
    "    #print(model._Booster.get_dump())\n",
    "    #__die\n",
    "    #if(type(model)==DecisionTreeClassifier):\n",
    "    #    return model.tree_.max_depth\n",
    "    #return 0\n",
    "    return model.tree_.max_depth\n",
    "\n",
    "# small black magic\n",
    "def reorderCategorical(df,feature_col,target_col,classifier=True,\n",
    "                                 max_iterations=721,verbose=False,random_permutation=None,\n",
    "                                 tree_seed=19870425,random_seed=19870425):\n",
    "    #time it\n",
    "    start     = time.time()\n",
    "    values    =df[feature_col].sort_values().unique() #nd array, since df[col] is a series\n",
    "    len_values=len(values)\n",
    "\n",
    "    #min dictionary (l<=>l)\n",
    "    optimized=False\n",
    "    default_dict={l:l for l in values}\n",
    "    min_dict    ={l:l for l in values}\n",
    "    if(len_values<3):\n",
    "        if(verbose):\n",
    "            print(feature_col,': uniques=',len_values,', values=',values)\n",
    "            print('\\t\\tLESS THAN 3 UNIQUE VALUES, Time spent (seconds):',time.time() - start)\n",
    "        return df[feature_col],min_dict\n",
    "    \n",
    "    #Current Values\n",
    "    model=getModel(classifier,tree_seed)\n",
    "    model.fit(df[feature_col].values.reshape(-1,1),df[target_col])\n",
    "    min_depth_count=getMetric(model)\n",
    "    if(verbose):\n",
    "        print(feature_col,': uniques=',len_values,', depth=',min_depth_count,', values=',values)\n",
    "        if(classifier):\n",
    "            print('\\t\\tROC_AUC/LogLoss: ',\n",
    "                      roc_auc_score(df[target_col],model.predict_proba(df[feature_col].values.reshape(-1,1))[:,1] ),'/',\n",
    "                      log_loss(     df[target_col],model.predict_proba(df[feature_col].values.reshape(-1,1))[:,1]))\n",
    "        else:\n",
    "            print('\\t\\tMAE/MSE/R²: ',\n",
    "                      mean_absolute_error(df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1] ),'/',\n",
    "                      mean_squared_error( df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1]),'/',\n",
    "                      r2_score(           df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1]))\n",
    "    if(min_depth_count==1):\n",
    "        if(verbose):\n",
    "            print('\\t\\tDEPTH=1, Time spent (seconds):',time.time() - start)\n",
    "        return df[feature_col],min_dict\n",
    "    \n",
    "    #Naive order by count\n",
    "    if(classifier):\n",
    "        first_try=df[df[target_col]==0].groupby(feature_col)[feature_col].count().sort_values(ascending=True)\n",
    "    else:\n",
    "        #maybe a median/mean order? for example, target_col>mean(target) ?\n",
    "        first_try=df.groupby(feature_col)[feature_col].count().sort_values(ascending=True)\n",
    "    l,values_dict=0,{}\n",
    "    for i in first_try.index:\n",
    "        values_dict[values[l]]=i\n",
    "        l+=1\n",
    "    \n",
    "    model=getModel(classifier,tree_seed)\n",
    "    model.fit(df[feature_col].replace(values_dict).values.reshape(-1,1),df[target_col])\n",
    "    # better than l<=>l ?\n",
    "    if(min_depth_count>getMetric(model)):\n",
    "        optimized=True\n",
    "        if(verbose):\n",
    "            print('\\tNaive order by count: from ',min_depth_count,' to ',getMetric(model),', dict:',min_dict)\n",
    "            if(classifier):\n",
    "                print('\\t\\tROC_AUC/LogLoss: ',\n",
    "                          roc_auc_score(df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n",
    "                          log_loss(     df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n",
    "            else:\n",
    "                print('\\t\\tMAE/MSE/R²: ',\n",
    "                          mean_absolute_error(df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n",
    "                          mean_squared_error( df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]),'/',\n",
    "                          r2_score(           df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n",
    "        min_depth_count,min_dict=getMetric(model),values_dict\n",
    "        if(min_depth_count==1):\n",
    "            if(verbose):\n",
    "                print('\\t\\tDEPTH=1, Time spent (seconds):',time.time() - start)\n",
    "            return df[feature_col].replace(values_dict),values_dict\n",
    "    elif(verbose):\n",
    "        print('\\t\\t=[ No optimization using naive order by Count')\n",
    "    \n",
    "    # Search Space:\n",
    "    # maybe random_permutatition isn't the best method... \n",
    "    #     if len(permutations)~=factorial(len_values) < max_iterations, we can use permutatition (real brute force)\n",
    "    if(random_permutation==None):\n",
    "        random_permutation=False\n",
    "        if(factorial(len_values)>max_iterations):\n",
    "            random_permutation=True\n",
    "            if(verbose):\n",
    "                print('\\t\\tToo big search space, using RANDOM SAMPLING')\n",
    "        elif(verbose):\n",
    "            print('\\t\\tmax_iterations (',max_iterations,') >Factorial(length) (',factorial(len_values),'), USING PERMUTATION')\n",
    "    \n",
    "    # TODO: maybe we can do better with GA ?!\n",
    "    if(random_permutation):\n",
    "        # random permutation ( good lucky =] )\n",
    "        np.random.seed(random_seed)\n",
    "        space=range(max_iterations)\n",
    "    else:\n",
    "        # default itertools permutation\n",
    "        space=permutations(values)\n",
    "\n",
    "    count=0\n",
    "    for perm in space:\n",
    "        if(count>max_iterations):\n",
    "            break\n",
    "        # random permutation\n",
    "        if(random_permutation):\n",
    "            perm=np.random.permutation(values)\n",
    "        \n",
    "        values_dict={values[i]:perm[i] for i in range(0,len_values)}\n",
    "        model=getModel(classifier,tree_seed)\n",
    "        model.fit(df[feature_col].replace(values_dict).values.reshape(-1,1),df[target_col])\n",
    "        if(min_depth_count>getMetric(model)):\n",
    "            optimized=True\n",
    "            if(verbose):\n",
    "                print('\\t',count,'/',max_iterations,'NEW!!! from',min_depth_count,' to ',getMetric(model),' dict:',values_dict)\n",
    "                if(classifier):\n",
    "                    print('\\t\\tROC_AUC/LogLoss: ',\n",
    "                              roc_auc_score(df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n",
    "                              log_loss(     df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n",
    "                else:\n",
    "                    print('\\t\\tMAE/MSE/R²: ',\n",
    "                              mean_absolute_error(df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n",
    "                              mean_squared_error( df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]),'/',\n",
    "                              r2_score(           df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n",
    "            min_depth_count,min_dict=getMetric(model),values_dict\n",
    "            if(min_depth_count==1):\n",
    "                print('\\t\\tDEPTH=1')\n",
    "                break\n",
    "        count+=1\n",
    "    if(verbose):\n",
    "        print('\\t\\tTime spent (seconds):',time.time() - start)\n",
    "    if(not optimized):\n",
    "        return df[feature_col],default_dict\n",
    "    return df[feature_col].replace(values_dict),values_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f0f6e3ad-1cca-43ce-b00f-d372905688b2",
    "_uuid": "d89e3e7ccf4fb31e38eba56c4cd00380fbf967ed"
   },
   "source": [
    "Let's work! BRUTE FORCE IT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b150a41a-8151-4fca-a512-4ea1ac367d47",
    "_uuid": "0fad6268511318b6f2c1bfb36684a5422e3386a9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dream machine: :P, 128GB, 16cores\n",
      "cores:  16  threads: 16 freq:  None\n",
      "memory:  svmem(total=118283927552, available=69137915904, percent=41.5, used=48182636544, free=22524256256, active=69207314432, inactive=24377171968, buffers=30189408256, cached=17387626496, shared=347865088)\n",
      "swap:  sswap(total=0, used=0, free=0, percent=0, sin=0, sout=0)\n",
      "start/end:  16\n",
      "ps_ind_04_cat : uniques= 3 , depth= 2 , values= [-1  0  1]\n",
      "\t\tROC_AUC/LogLoss:  0.51405123471 / 0.6922691084\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tmax_iterations ( 721 ) >Factorial(length) ( 6 ), USING PERMUTATION\n",
      "\t\tTime spent (seconds): 2.284044027328491\n",
      "ps_ind_04_cat\n",
      "ps_ind_05_cat : uniques= 8 , depth= 5 , values= [-1  0  1  2  3  4  5  6]\n",
      "\t\tROC_AUC/LogLoss:  0.533673015183 / 0.687675456125\n",
      "\tNaive order by count: from  5  to  3 , dict: {-1: -1, 0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n",
      "\t\tROC_AUC/LogLoss:  0.533673015183 / 0.687675456125\n",
      "\t\tToo big search space, using RANDOM SAMPLING\n",
      "\t\tTime spent (seconds): 144.34480905532837\n",
      "ps_ind_05_cat\n",
      "ps_car_01_cat : uniques= 13 , depth= 6 , values= [-1  0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\t\tROC_AUC/LogLoss:  0.551759935886 / 0.688115346216\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tToo big search space, using RANDOM SAMPLING\n",
      "\t 7 / 721 NEW!!! from 6  to  5  dict: {-1: 8, 0: 11, 1: 7, 2: 6, 3: 0, 4: -1, 5: 3, 6: 10, 7: 5, 8: 4, 9: 9, 10: 1, 11: 2}\n",
      "\t\tROC_AUC/LogLoss:  0.551759935886 / 0.688115346216\n",
      "\t\tTime spent (seconds): 206.76657056808472\n",
      "ps_car_01_cat\n",
      "ps_car_02_cat : uniques= 3 , depth= 2 , values= [-1  0  1]\n",
      "\t\tROC_AUC/LogLoss:  0.531622548852 / 0.689886833817\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tmax_iterations ( 721 ) >Factorial(length) ( 6 ), USING PERMUTATION\n",
      "\t\tTime spent (seconds): 2.1568596363067627\n",
      "ps_car_02_cat\n",
      "ps_car_03_cat : uniques= 3 , depth= 2 , values= [-1  0  1]\n",
      "\t\tROC_AUC/LogLoss:  0.539652519522 / 0.689616495498\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tmax_iterations ( 721 ) >Factorial(length) ( 6 ), USING PERMUTATION\n",
      "\t\tTime spent (seconds): 2.2345902919769287\n",
      "ps_car_03_cat\n",
      "ps_car_04_cat : uniques= 10 , depth= 6 , values= [0 1 2 3 4 5 6 7 8 9]\n",
      "\t\tROC_AUC/LogLoss:  0.536776533342 / 0.688582518434\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tToo big search space, using RANDOM SAMPLING\n",
      "\t 0 / 721 NEW!!! from 6  to  5  dict: {0: 3, 1: 7, 2: 8, 3: 6, 4: 1, 5: 4, 6: 5, 7: 0, 8: 9, 9: 2}\n",
      "\t\tROC_AUC/LogLoss:  0.536776533342 / 0.688582518434\n",
      "\t 1 / 721 NEW!!! from 5  to  4  dict: {0: 6, 1: 2, 2: 9, 3: 5, 4: 8, 5: 7, 6: 0, 7: 3, 8: 1, 9: 4}\n",
      "\t\tROC_AUC/LogLoss:  0.536776533342 / 0.688582518434\n",
      "\t\tTime spent (seconds): 172.4797329902649\n",
      "ps_car_04_cat\n",
      "ps_car_05_cat : uniques= 3 , depth= 2 , values= [-1  0  1]\n",
      "\t\tROC_AUC/LogLoss:  0.530584809076 / 0.691282042403\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tmax_iterations ( 721 ) >Factorial(length) ( 6 ), USING PERMUTATION\n",
      "\t\tTime spent (seconds): 2.464533805847168\n",
      "ps_car_05_cat\n",
      "ps_car_06_cat : uniques= 18 , depth= 8 , values= [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
      "\t\tROC_AUC/LogLoss:  0.54271602056 / 0.688742824952\n",
      "\tNaive order by count: from  8  to  7 , dict: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17}\n",
      "\t\tROC_AUC/LogLoss:  0.54271602056 / 0.688742824952\n",
      "\t\tToo big search space, using RANDOM SAMPLING\n",
      "\t 8 / 721 NEW!!! from 7  to  6  dict: {0: 17, 1: 9, 2: 3, 3: 6, 4: 15, 5: 4, 6: 12, 7: 5, 8: 16, 9: 13, 10: 2, 11: 14, 12: 7, 13: 8, 14: 11, 15: 10, 16: 1, 17: 0}\n",
      "\t\tROC_AUC/LogLoss:  0.54271602056 / 0.688742824952\n",
      "\t 107 / 721 NEW!!! from 6  to  5  dict: {0: 8, 1: 6, 2: 0, 3: 1, 4: 10, 5: 17, 6: 5, 7: 13, 8: 4, 9: 7, 10: 11, 11: 9, 12: 3, 13: 14, 14: 16, 15: 15, 16: 12, 17: 2}\n",
      "\t\tROC_AUC/LogLoss:  0.54271602056 / 0.688742824952\n",
      "\t\tTime spent (seconds): 294.48338747024536\n",
      "ps_car_06_cat\n",
      "ps_car_07_cat : uniques= 3 , depth= 2 , values= [-1  0  1]\n",
      "\t\tROC_AUC/LogLoss:  0.522623024939 / 0.689348935665\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tmax_iterations ( 721 ) >Factorial(length) ( 6 ), USING PERMUTATION\n",
      "\t\tTime spent (seconds): 2.3140714168548584\n",
      "ps_car_07_cat\n",
      "ps_car_08_cat : uniques= 2 , values= [0 1]\n",
      "\t\tLESS THAN 3 UNIQUE VALUES, Time spent (seconds): 0.03331637382507324\n",
      "ps_car_08_cat\n",
      "ps_car_09_cat : uniques= 6 , depth= 4 , values= [-1  0  1  2  3  4]\n",
      "\t\tROC_AUC/LogLoss:  0.524724984653 / 0.690748392709\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tmax_iterations ( 721 ) >Factorial(length) ( 720 ), USING PERMUTATION\n",
      "\t 3 / 721 NEW!!! from 4  to  3  dict: {-1: -1, 0: 0, 1: 1, 2: 3, 3: 4, 4: 2}\n",
      "\t\tROC_AUC/LogLoss:  0.524724984653 / 0.690748392709\n",
      "\t\tTime spent (seconds): 170.10786700248718\n",
      "ps_car_09_cat\n",
      "ps_car_10_cat : uniques= 3 , depth= 2 , values= [0 1 2]\n",
      "\t\tROC_AUC/LogLoss:  0.500253622327 / 0.693143243704\n",
      "\t\t=[ No optimization using naive order by Count\n",
      "\t\tmax_iterations ( 721 ) >Factorial(length) ( 6 ), USING PERMUTATION\n",
      "\t\tTime spent (seconds): 3.026554584503174\n",
      "ps_car_10_cat\n",
      "ps_car_11_cat : uniques= 104 , depth= 17 , values= [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104]\n",
      "\t\tROC_AUC/LogLoss:  0.57375067626 / 0.684604217654\n",
      "\tNaive order by count: from  17  to  14 , dict: {1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45, 46: 46, 47: 47, 48: 48, 49: 49, 50: 50, 51: 51, 52: 52, 53: 53, 54: 54, 55: 55, 56: 56, 57: 57, 58: 58, 59: 59, 60: 60, 61: 61, 62: 62, 63: 63, 64: 64, 65: 65, 66: 66, 67: 67, 68: 68, 69: 69, 70: 70, 71: 71, 72: 72, 73: 73, 74: 74, 75: 75, 76: 76, 77: 77, 78: 78, 79: 79, 80: 80, 81: 81, 82: 82, 83: 83, 84: 84, 85: 85, 86: 86, 87: 87, 88: 88, 89: 89, 90: 90, 91: 91, 92: 92, 93: 93, 94: 94, 95: 95, 96: 96, 97: 97, 98: 98, 99: 99, 100: 100, 101: 101, 102: 102, 103: 103, 104: 104}\n",
      "\t\tROC_AUC/LogLoss:  0.57375067626 / 0.684604217654\n",
      "\t\tToo big search space, using RANDOM SAMPLING\n",
      "\t 5 / 721 NEW!!! from 14  to  13  dict: {1: 75, 2: 58, 3: 93, 4: 31, 5: 85, 6: 54, 7: 60, 8: 26, 9: 45, 10: 72, 11: 3, 12: 32, 13: 88, 14: 37, 15: 48, 16: 81, 17: 10, 18: 14, 19: 51, 20: 11, 21: 52, 22: 103, 23: 22, 24: 50, 25: 4, 26: 59, 27: 6, 28: 100, 29: 19, 30: 67, 31: 97, 32: 1, 33: 102, 34: 30, 35: 89, 36: 64, 37: 83, 38: 2, 39: 66, 40: 76, 41: 95, 42: 21, 43: 78, 44: 27, 45: 101, 46: 33, 47: 41, 48: 25, 49: 29, 50: 49, 51: 8, 52: 98, 53: 82, 54: 63, 55: 15, 56: 46, 57: 44, 58: 18, 59: 20, 60: 71, 61: 65, 62: 43, 63: 39, 64: 40, 65: 68, 66: 5, 67: 16, 68: 38, 69: 56, 70: 7, 71: 96, 72: 24, 73: 90, 74: 91, 75: 34, 76: 9, 77: 84, 78: 61, 79: 57, 80: 92, 81: 87, 82: 13, 83: 73, 84: 35, 85: 17, 86: 77, 87: 86, 88: 28, 89: 99, 90: 79, 91: 42, 92: 70, 93: 94, 94: 80, 95: 12, 96: 55, 97: 104, 98: 47, 99: 23, 100: 69, 101: 36, 102: 53, 103: 74, 104: 62}\n",
      "\t\tROC_AUC/LogLoss:  0.57375067626 / 0.684604217654\n",
      "\t 31 / 721 NEW!!! from 13  to  12  dict: {1: 87, 2: 48, 3: 88, 4: 76, 5: 85, 6: 92, 7: 94, 8: 36, 9: 26, 10: 6, 11: 66, 12: 71, 13: 74, 14: 14, 15: 38, 16: 65, 17: 20, 18: 68, 19: 59, 20: 75, 21: 42, 22: 54, 23: 64, 24: 55, 25: 41, 26: 7, 27: 67, 28: 70, 29: 99, 30: 43, 31: 63, 32: 28, 33: 30, 34: 77, 35: 37, 36: 35, 37: 39, 38: 91, 39: 97, 40: 102, 41: 45, 42: 5, 43: 104, 44: 95, 45: 103, 46: 11, 47: 19, 48: 44, 49: 23, 50: 49, 51: 33, 52: 13, 53: 89, 54: 51, 55: 15, 56: 78, 57: 93, 58: 58, 59: 81, 60: 17, 61: 24, 62: 16, 63: 47, 64: 3, 65: 101, 66: 12, 67: 61, 68: 53, 69: 32, 70: 52, 71: 72, 72: 100, 73: 9, 74: 50, 75: 8, 76: 69, 77: 22, 78: 27, 79: 80, 80: 10, 81: 2, 82: 29, 83: 4, 84: 83, 85: 21, 86: 73, 87: 62, 88: 86, 89: 31, 90: 1, 91: 96, 92: 25, 93: 40, 94: 60, 95: 34, 96: 90, 97: 98, 98: 18, 99: 56, 100: 57, 101: 84, 102: 79, 103: 82, 104: 46}\n",
      "\t\tROC_AUC/LogLoss:  0.57375067626 / 0.684604217654\n",
      "\t 183 / 721 NEW!!! from 12  to  11  dict: {1: 75, 2: 104, 3: 30, 4: 95, 5: 7, 6: 56, 7: 12, 8: 50, 9: 78, 10: 32, 11: 77, 12: 33, 13: 58, 14: 85, 15: 19, 16: 86, 17: 18, 18: 92, 19: 100, 20: 76, 21: 101, 22: 80, 23: 67, 24: 73, 25: 88, 26: 97, 27: 99, 28: 8, 29: 44, 30: 83, 31: 69, 32: 65, 33: 38, 34: 48, 35: 87, 36: 81, 37: 52, 38: 21, 39: 24, 40: 39, 41: 2, 42: 41, 43: 57, 44: 45, 45: 91, 46: 84, 47: 17, 48: 23, 49: 98, 50: 59, 51: 102, 52: 1, 53: 51, 54: 53, 55: 89, 56: 13, 57: 28, 58: 34, 59: 60, 60: 35, 61: 74, 62: 96, 63: 31, 64: 64, 65: 79, 66: 61, 67: 6, 68: 93, 69: 103, 70: 47, 71: 37, 72: 36, 73: 72, 74: 55, 75: 43, 76: 15, 77: 82, 78: 42, 79: 26, 80: 9, 81: 49, 82: 63, 83: 68, 84: 54, 85: 3, 86: 16, 87: 27, 88: 71, 89: 40, 90: 90, 91: 46, 92: 10, 93: 66, 94: 25, 95: 62, 96: 14, 97: 5, 98: 11, 99: 94, 100: 70, 101: 4, 102: 20, 103: 22, 104: 29}\n",
      "\t\tROC_AUC/LogLoss:  0.57375067626 / 0.684604217654\n",
      "\t\tTime spent (seconds): 1011.7050783634186\n",
      "ps_car_11_cat\n",
      "thread finished...exiting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#MULTI THREAD VERSION:\n",
    "import psutil \n",
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "def threaded_function(args):\n",
    "    global train,predict,lock\n",
    "    #print('cat_cols:',len(args))\n",
    "    for i in args:\n",
    "        reordered,values_dict=reorderCategorical(train,i,'target',verbose=True)\n",
    "        with lock:\n",
    "            train[  i+'_reordered']=reordered\n",
    "            predict[i+'_reordered']=predict[i].replace(values_dict)\n",
    "        print(i)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 4 threads\n",
    "    print(\"Dream machine: :P, 128GB, 16cores\")\n",
    "    print('cores: ',psutil.cpu_count(),' threads:',psutil.cpu_count(logical=False),\n",
    "         'freq: ',psutil.cpu_freq())\n",
    "    print('memory: ',psutil.virtual_memory())\n",
    "    print('swap: ',psutil.swap_memory())\n",
    "\n",
    "    cores=16\n",
    "    lencat =len(cat_cols)\n",
    "    lencatdiv=lencat//cores\n",
    "    start_end=[]\n",
    "    for i in range(0,cores):\n",
    "        if(i==cores-1):\n",
    "            start_end.append([i*lencatdiv+1,lencat]) # last one\n",
    "        else:\n",
    "            start_end.append([i*lencatdiv+1,lencatdiv*(i+1)])\n",
    "    print('start/end: ',len(start_end))\n",
    "    threads,l=[],0\n",
    "    \n",
    "    for i in start_end:\n",
    "        #print(\"cols: \",i[0],i[1],' - ',cat_cols[i[0] : i[1]])\n",
    "        #print(\"thread: \",l)\n",
    "        threads.append( threading.Thread(target = threaded_function, args = (cat_cols[i[0] : i[1]],) ) )\n",
    "        threads[l].start()\n",
    "        l+=1\n",
    "    l=0\n",
    "    for i in start_end:\n",
    "        threads[l].join()\n",
    "        l+=1\n",
    "    print(\"thread finished...exiting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "793f85fd-f38b-46c6-9537-8ae9ef9aa32b",
    "_uuid": "b1cffc8a187092f477de756616cc65297fd0e752",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SINGLE THREAD\n",
    "#for i in cat_cols:\n",
    "#    train[i+'_reordered'],values_dict=reorderCategorical(train,i,'target',verbose=True,max_iterations=5)\n",
    "#    predict[i+'_reordered']=predict[i].replace(values_dict)\n",
    "#print('Nice job! =]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dd1268bd-6a44-4707-b217-8285c18eb259",
    "_uuid": "18cbd2fed12c095c09272d9c2c1471a1e781c6e5"
   },
   "source": [
    "THANKS KAGGLE COMPUTERS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "a2f0fdfa-86b1-4261-99cb-9aa3cb1693d5",
    "_uuid": "08668c62c0a9bb0e60546e87e1d5263eb188f7a5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(  'Reordered-train.csv',index=False)\n",
    "predict.to_csv('Reordered-test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "21459b9e-d3cb-43cd-aa35-53810b9b0c57",
    "_uuid": "96d1f883bd352ad741467784212d3258373305e2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
