{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/covid19-with-population/update_train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The character ' will make later query function report an error,so it's replaced by a space\n",
    "train.Country.replace('Cote d\\'Ivoire','Cote d Ivoire',inplace=True)\n",
    "train.Province.replace('Cote d\\'Ivoire','Cote d Ivoire',inplace=True)\n",
    "\n",
    "# There are few infinite values in the weather data,it will cause the training loss become NAN.Since the amount of np.inf is very few,it's simply replace by 0.\n",
    "train.replace(np.inf,0,inplace=True)\n",
    "\n",
    "# Transform percentage data to float\n",
    "def get_percent(x):\n",
    "    x = str(x)\n",
    "    x = x.strip('%')\n",
    "    x = int(x)/100\n",
    "    return x\n",
    "\n",
    "train.UrbanPopRate = train.UrbanPopRate.apply(lambda x:get_percent(x))\n",
    "\n",
    "# Transform date type\n",
    "def get_dt(x):\n",
    "    return datetime.strptime(x,'%Y-%m-%d')\n",
    "\n",
    "train.Date = train.Date.apply(lambda x:get_dt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Province</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Days_After_1stJan</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Population</th>\n",
       "      <th>Density</th>\n",
       "      <th>Land_Area</th>\n",
       "      <th>Migrants</th>\n",
       "      <th>MedAge</th>\n",
       "      <th>UrbanPopRate</th>\n",
       "      <th>API_beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>38928346</td>\n",
       "      <td>60</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>-62920.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>38928346</td>\n",
       "      <td>60</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>-62920.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>38928346</td>\n",
       "      <td>60</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>-62920.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>38928346</td>\n",
       "      <td>60</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>-62920.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>38928346</td>\n",
       "      <td>60</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>-62920.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     Province      Country       Date  ConfirmedCases  Fatalities  \\\n",
       "0   1  Afghanistan  Afghanistan 2020-01-22             0.0         0.0   \n",
       "1   2  Afghanistan  Afghanistan 2020-01-23             0.0         0.0   \n",
       "2   3  Afghanistan  Afghanistan 2020-01-24             0.0         0.0   \n",
       "3   4  Afghanistan  Afghanistan 2020-01-25             0.0         0.0   \n",
       "4   5  Afghanistan  Afghanistan 2020-01-26             0.0         0.0   \n",
       "\n",
       "   Days_After_1stJan  Dayofweek  Month  Day  Population  Density  Land_Area  \\\n",
       "0                 21          2      1   22    38928346       60   652860.0   \n",
       "1                 22          3      1   23    38928346       60   652860.0   \n",
       "2                 23          4      1   24    38928346       60   652860.0   \n",
       "3                 24          5      1   25    38928346       60   652860.0   \n",
       "4                 25          6      1   26    38928346       60   652860.0   \n",
       "\n",
       "   Migrants  MedAge  UrbanPopRate  API_beds  \n",
       "0  -62920.0      18          0.25       0.5  \n",
       "1  -62920.0      18          0.25       0.5  \n",
       "2  -62920.0      18          0.25       0.5  \n",
       "3  -62920.0      18          0.25       0.5  \n",
       "4  -62920.0      18          0.25       0.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers handling\n",
    "#### The confirmedcases and fatalities are cumulative amount,but there are some values smaller than last dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in train.iterrows():\n",
    "    if train.iloc[index].Province == train.iloc[index - 1].Province and train.iloc[index].ConfirmedCases < train.iloc[index-1].ConfirmedCases:\n",
    "        train.iloc[index,4] = train.iloc[index-1,4]\n",
    "    if train.iloc[index].Province == train.iloc[index - 1].Province and train.iloc[index].Fatalities < train.iloc[index-1].Fatalities:\n",
    "        train.iloc[index,5] = train.iloc[index-1,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "train_exam = train[['Country','Province','Date','ConfirmedCases','Fatalities']]\n",
    "diff_df = pd.DataFrame(columns = ['Country','Province','Date','ConfirmedCases','Fatalities'])\n",
    "for country in train_exam.Country.unique():\n",
    "    for province in train_exam[train_exam.Country == country].Province.unique():\n",
    "        province_df = train_exam.query(f\"Country == '{country}' and Province == '{province}'\")\n",
    "        conf = province_df.ConfirmedCases\n",
    "        fata = province_df.Fatalities\n",
    "        diff_conf = conf.diff()\n",
    "        diff_fata = fata.diff()\n",
    "        province_df.ConfirmedCases = diff_conf\n",
    "        province_df.Fatalities = diff_fata\n",
    "        diff_df = pd.concat([diff_df,province_df],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(sum(diff_df.ConfirmedCases < 0),sum(diff_df.Fatalities<0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax normalization of confirmedcases and fatalities for each province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_train = pd.DataFrame(columns = ['Id_x', 'Province', 'Country', 'Date', 'ConfirmedCases', 'Fatalities',\n",
    "       'Days_After_1stJan', 'Dayofweek', 'Month', 'Day', 'Population',\n",
    "       'Density', 'Land_Area', 'Migrants', 'MedAge', 'UrbanPopRate', 'Id_y',\n",
    "       'Lat', 'Long', 'temp', 'min', 'max', 'stp', 'slp', 'dewp', 'rh', 'ah',\n",
    "       'wdsp', 'prcp', 'fog', 'API_beds'])\n",
    "for country in train.Country.unique():\n",
    "    for province in train.query(f\"Country=='{country}'\").Province.unique():\n",
    "        province_df = train.query(f\"Country=='{country}' and Province=='{province}'\")\n",
    "        province_confirm = province_df.ConfirmedCases\n",
    "        province_fatalities = province_df.Fatalities\n",
    "        province_confirm = np.array(province_confirm).reshape(-1,1)\n",
    "        province_fatalities = np.array(province_confirm).reshape(-1,1)\n",
    "        scaler1= preprocessing.MinMaxScaler()\n",
    "        scaled_confirm = scaler1.fit_transform(province_confirm)\n",
    "        scaler2 = preprocessing.MinMaxScaler()\n",
    "        scaled_fata = scaler2.fit_transform(province_fatalities)\n",
    "        province_df['ConfirmedCases'] = scaled_confirm\n",
    "        province_df['Fatalities'] = scaled_fata\n",
    "        scale_train = pd.concat((scale_train,province_df),axis = 0,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input data for LSTM\n",
    "\n",
    "#### This part referenced the code of the great notebook: https://www.kaggle.com/frlemarchand/covid-19-forecasting-with-an-rnn#5.-Generate-predictions-using-the-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [02:18<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "trend_df = pd.DataFrame(columns={\"infection_trend\",\"fatality_trend\",\"quarantine_trend\",\"school_trend\",\"total_population\",\"expected_cases\",\"expected_fatalities\"})\n",
    "\n",
    "train_df = scale_train\n",
    "days_in_sequence = 14\n",
    "\n",
    "trend_list = []\n",
    "\n",
    "with tqdm(total=len(list(train_df.Country.unique()))) as pbar:\n",
    "    for country in train_df.Country.unique():\n",
    "        for province in train_df.query(f\"Country=='{country}'\").Province.unique():\n",
    "            province_df = train_df.query(f\"Country=='{country}' and Province=='{province}'\")\n",
    "            \n",
    "\n",
    "            for i in range(0,len(province_df)):\n",
    "                if i+days_in_sequence<=len(province_df):\n",
    "                    #prepare all the trend inputs\n",
    "                    infection_trend = [float(x) for x in province_df[i:i+days_in_sequence-1].ConfirmedCases.values]\n",
    "                    fatality_trend = [float(x) for x in province_df[i:i+days_in_sequence-1].Fatalities.values]\n",
    "\n",
    "                    #preparing all the stable inputs\n",
    "                    days_after_1stJan = float(province_df.iloc[i].Days_After_1stJan)\n",
    "                    dayofweek = float(province_df.iloc[i].Dayofweek)\n",
    "                    month = float(province_df.iloc[i].Month)\n",
    "                    day= float(province_df.iloc[i].Day)\n",
    "                    population = float(province_df.iloc[i].Population)\n",
    "                    density = float(province_df.iloc[i].Density)\n",
    "                    land_area = float(province_df.iloc[i].Land_Area)\n",
    "                    migrants = float(province_df.iloc[i].Migrants)\n",
    "                    medage = float(province_df.iloc[i].MedAge)\n",
    "                    urbanpoprate = float(province_df.iloc[i].UrbanPopRate)\n",
    "                    beds = float(province_df.iloc[i].API_beds)\n",
    "\n",
    "                    #True cases in i+days_in_sequence-1 day\n",
    "                    expected_cases = float(province_df.iloc[i+days_in_sequence-1].ConfirmedCases)\n",
    "                    expected_fatalities = float(province_df.iloc[i+days_in_sequence-1].Fatalities)\n",
    "\n",
    "                    trend_list.append({\"infection_trend\":infection_trend,\n",
    "                                     \"fatality_trend\":fatality_trend,\n",
    "                                     \"stable_inputs\":[population,density,land_area,migrants,medage,urbanpoprate,beds],\n",
    "                                     \"expected_cases\":expected_cases,\n",
    "                                     \"expected_fatalities\":expected_fatalities})\n",
    "        pbar.update(1)\n",
    "trend_df = pd.DataFrame(trend_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_df[\"temporal_inputs\"] = [np.asarray([trends[\"infection_trend\"],trends[\"fatality_trend\"]]) for idx,trends in trend_df.iterrows()]\n",
    "trend_df = shuffle(trend_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infection_trend</th>\n",
       "      <th>fatality_trend</th>\n",
       "      <th>stable_inputs</th>\n",
       "      <th>expected_cases</th>\n",
       "      <th>expected_fatalities</th>\n",
       "      <th>temporal_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1439323776.0, 153.0, 9388211.0, -348399.0, 38...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>[0.9982014388489209, 0.9982014388489209, 0.998...</td>\n",
       "      <td>[0.9982014388489209, 0.9982014388489209, 0.998...</td>\n",
       "      <td>[1439323776.0, 153.0, 9388211.0, -348399.0, 38...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[0.9982014388489209, 0.9982014388489209, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>[0.4177215189873418, 0.4177215189873418, 0.430...</td>\n",
       "      <td>[0.4177215189873418, 0.4177215189873418, 0.430...</td>\n",
       "      <td>[287375.0, 668.0, 430.0, -79.0, 40.0, 0.31, 6.2]</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>[[0.4177215189873418, 0.4177215189873418, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18889</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[59734218.0, 67.0, 885800.0, -40076.0, 18.0, 0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[801.0, 2003.0, 0.0, -852.0, 19.0, 0.57, 2.9]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         infection_trend  \\\n",
       "6306   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6718   [0.9982014388489209, 0.9982014388489209, 0.998...   \n",
       "1789   [0.4177215189873418, 0.4177215189873418, 0.430...   \n",
       "18889  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "11177  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                          fatality_trend  \\\n",
       "6306   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6718   [0.9982014388489209, 0.9982014388489209, 0.998...   \n",
       "1789   [0.4177215189873418, 0.4177215189873418, 0.430...   \n",
       "18889  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "11177  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                           stable_inputs  expected_cases  \\\n",
       "6306   [1439323776.0, 153.0, 9388211.0, -348399.0, 38...        1.000000   \n",
       "6718   [1439323776.0, 153.0, 9388211.0, -348399.0, 38...        1.000000   \n",
       "1789    [287375.0, 668.0, 430.0, -79.0, 40.0, 0.31, 6.2]        0.860759   \n",
       "18889  [59734218.0, 67.0, 885800.0, -40076.0, 18.0, 0...        0.000000   \n",
       "11177      [801.0, 2003.0, 0.0, -852.0, 19.0, 0.57, 2.9]        0.000000   \n",
       "\n",
       "       expected_fatalities                                    temporal_inputs  \n",
       "6306              1.000000  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "6718              1.000000  [[0.9982014388489209, 0.9982014388489209, 0.99...  \n",
       "1789              0.860759  [[0.4177215189873418, 0.4177215189873418, 0.43...  \n",
       "18889             0.000000  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "11177             0.000000  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trend_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keeping 25 sequences where the number of cases stays at 0, as there were way too many of these samples in our dataset.\n",
    "i=0\n",
    "temp_df = pd.DataFrame()\n",
    "for idx,row in trend_df.iterrows():\n",
    "    if sum(row.infection_trend)>0:\n",
    "        temp_df = temp_df.append(row)\n",
    "    else:\n",
    "        if i<25:\n",
    "            temp_df = temp_df.append(row)\n",
    "            i+=1\n",
    "trend_df = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 13\n",
    "training_percentage = 0.9\n",
    "# The purpose of '-2'and'+2' is to make the number of samples in the training test set divisible by batchsize\n",
    "training_item_count = int(len(trend_df)*training_percentage)\n",
    "validation_item_count = len(trend_df)-int(len(trend_df)*training_percentage)\n",
    "training_df = trend_df[:training_item_count-2]\n",
    "validation_df = trend_df[training_item_count+2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temporal_train = np.asarray(np.transpose(np.reshape(np.asarray([np.asarray(x) for x in training_df[\"temporal_inputs\"].values]),(training_item_count-2,2,sequence_length)),(0,2,1) )).astype(np.float32)\n",
    "X_stable_train = np.asarray([np.asarray(x) for x in training_df[\"stable_inputs\"]]).astype(np.float32)\n",
    "Y_cases_train = np.asarray([np.asarray(x) for x in training_df[\"expected_cases\"]]).astype(np.float32)\n",
    "Y_fatalities_train = np.asarray([np.asarray(x) for x in training_df[\"expected_fatalities\"]]).astype(np.float32)\n",
    "\n",
    "X_temporal_test = np.asarray(np.transpose(np.reshape(np.asarray([np.asarray(x) for x in validation_df[\"temporal_inputs\"]]),(validation_item_count-2,2,sequence_length)),(0,2,1)) ).astype(np.float32)\n",
    "X_stable_test = np.asarray([np.asarray(x) for x in validation_df[\"stable_inputs\"]]).astype(np.float32)\n",
    "Y_cases_test = np.asarray([np.asarray(x) for x in validation_df[\"expected_cases\"]]).astype(np.float32)\n",
    "Y_fatalities_test = np.asarray([np.asarray(x) for x in validation_df[\"expected_fatalities\"]]).astype(np.float32)\n",
    "\n",
    "# Transform to tensor type\n",
    "X_temporal_train = torch.from_numpy(X_temporal_train)\n",
    "X_stable_train = torch.from_numpy(X_stable_train)\n",
    "Y_cases_train = torch.from_numpy(Y_cases_train)\n",
    "Y_fatalities_train = torch.from_numpy(Y_fatalities_train)\n",
    "\n",
    "X_temporal_test = torch.from_numpy(X_temporal_test)\n",
    "X_stable_test = torch.from_numpy(X_stable_test)\n",
    "Y_cases_test = torch.from_numpy(Y_cases_test)\n",
    "Y_fatalities_test = torch.from_numpy(Y_fatalities_test)\n",
    "\n",
    "# Merge two objective values\n",
    "Y_train = torch.cat((Y_cases_train.reshape(14770,1),Y_fatalities_train.reshape(14770,1)),1)\n",
    "Y_test = torch.cat((Y_cases_test.reshape(1640,1),Y_fatalities_test.reshape(1640,1)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14770 1640\n"
     ]
    }
   ],
   "source": [
    "print(len(X_temporal_train),len(X_temporal_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train,test loader for training\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data1,data2, labels):\n",
    "        self.trend= data1\n",
    "        self.stable= data2\n",
    "        self.labels = labels  \n",
    "\n",
    "    def __getitem__(self, index):    \n",
    "        trend,stable, labels = self.trend[index], self.stable[index], self.labels[index]\n",
    "        return trend,stable,labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trend) \n",
    "    \n",
    "train_ds = MyDataset(data1 = X_temporal_train,data2 = X_stable_train,labels = Y_train)\n",
    "test_ds =MyDataset(data1 = X_temporal_test,data2 = X_stable_test,labels = Y_test)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds,batch_size = 10,shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds,batch_size = 10,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.lstm = nn.LSTM(2,32,1,dropout = 0.5)\n",
    "            \n",
    "            self.stable_full = nn.Linear(7,16)\n",
    "            nn.init.kaiming_normal_(self.stable_full.weight)\n",
    "            self.BN1 = nn.BatchNorm1d(16)\n",
    "            self.stable_dropout = nn.Dropout(0.5)\n",
    "            \n",
    "            self.merge_full = nn.Linear(16+13*32,64)# stable:（5*16）  lstm:（13，5，32）\n",
    "            nn.init.kaiming_normal_(self.merge_full.weight)\n",
    "            self.BN2 = nn.BatchNorm1d(64)\n",
    "            self.merge_dropout = nn.Dropout(0.3)\n",
    "            self.merge_full2 = nn.Linear(64,2)\n",
    "            nn.init.kaiming_normal_(self.merge_full2.weight)\n",
    "\n",
    "    def reset_hidden(self):\n",
    "        self.hidden = (torch.zeros(self.hidden[0].shape), torch.zeros(self.hidden[1].shape))\n",
    "        \n",
    "    def forward(self, x_trend,x_stable):\n",
    "        batch_size = x_trend.reshape(13,-1,2).size(1)\n",
    "        x_trend = x_trend.reshape(13,batch_size,2)\n",
    "        x_trend, self.hidden = self.lstm(x_trend)\n",
    "        \n",
    "        x_stable = self.stable_dropout(F.relu(self.BN1(self.stable_full(x_stable))))\n",
    "        \n",
    "        s, b, h = x_trend.shape  #(seq, batch, hidden)\n",
    "        x_trend = x_trend.view(b, s*h)\n",
    "        x_merge = torch.cat((x_trend,x_stable),axis = 1)\n",
    "        x_merge = F.relu(self.merge_full2(self.merge_dropout(F.relu(self.BN2(self.merge_full(x_merge))))))\n",
    "        return x_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# Training Settings\n",
    "model = Net()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process\n",
    "def train_model(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (trend, stable, target) in enumerate(train_loader):\n",
    "        trend, stable, target = Variable(trend), Variable(stable),Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(trend,stable)\n",
    "        loss = criterion(output, target)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 300 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(trend), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "\n",
    "def test_model(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for trend, stable, target in test_loader:\n",
    "        trend,stable, target = Variable(trend),Variable(stable),Variable(target)\n",
    "        output = model(trend,stable)\n",
    "        test_loss += criterion(output, target).data\n",
    "        y_pred.append(output)\n",
    "        y_true.append(target)\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    MSE = mean_squared_error(y_true.detach().numpy(), y_pred.detach().numpy())\n",
    "    print('\\nTest set: Average loss: {:.4f}, MSE: {} \\n'.format(\n",
    "        test_loss, MSE \n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/14770 (0%)]\tLoss: 0.526345\n",
      "Train Epoch: 1 [3000/14770 (20%)]\tLoss: 0.317094\n",
      "Train Epoch: 1 [6000/14770 (41%)]\tLoss: 0.098466\n",
      "Train Epoch: 1 [9000/14770 (61%)]\tLoss: 0.070744\n",
      "Train Epoch: 1 [12000/14770 (81%)]\tLoss: 0.078822\n",
      "\n",
      "Test set: Average loss: 0.0148, MSE: 0.01481498870998621 \n",
      "\n",
      "Train Epoch: 2 [0/14770 (0%)]\tLoss: 0.009328\n",
      "Train Epoch: 2 [3000/14770 (20%)]\tLoss: 0.068321\n",
      "Train Epoch: 2 [6000/14770 (41%)]\tLoss: 0.021126\n",
      "Train Epoch: 2 [9000/14770 (61%)]\tLoss: 0.040517\n",
      "Train Epoch: 2 [12000/14770 (81%)]\tLoss: 0.019817\n",
      "\n",
      "Test set: Average loss: 0.0077, MSE: 0.007743104826658964 \n",
      "\n",
      "Train Epoch: 3 [0/14770 (0%)]\tLoss: 0.019969\n",
      "Train Epoch: 3 [3000/14770 (20%)]\tLoss: 0.014349\n",
      "Train Epoch: 3 [6000/14770 (41%)]\tLoss: 0.021481\n",
      "Train Epoch: 3 [9000/14770 (61%)]\tLoss: 0.018953\n",
      "Train Epoch: 3 [12000/14770 (81%)]\tLoss: 0.020888\n",
      "\n",
      "Test set: Average loss: 0.0075, MSE: 0.007543619722127914 \n",
      "\n",
      "Train Epoch: 4 [0/14770 (0%)]\tLoss: 0.032466\n",
      "Train Epoch: 4 [3000/14770 (20%)]\tLoss: 0.008282\n",
      "Train Epoch: 4 [6000/14770 (41%)]\tLoss: 0.012277\n",
      "Train Epoch: 4 [9000/14770 (61%)]\tLoss: 0.011843\n",
      "Train Epoch: 4 [12000/14770 (81%)]\tLoss: 0.009236\n",
      "\n",
      "Test set: Average loss: 0.0061, MSE: 0.006069365888834 \n",
      "\n",
      "Train Epoch: 5 [0/14770 (0%)]\tLoss: 0.005620\n",
      "Train Epoch: 5 [3000/14770 (20%)]\tLoss: 0.003428\n",
      "Train Epoch: 5 [6000/14770 (41%)]\tLoss: 0.008449\n",
      "Train Epoch: 5 [9000/14770 (61%)]\tLoss: 0.010600\n",
      "Train Epoch: 5 [12000/14770 (81%)]\tLoss: 0.013562\n",
      "\n",
      "Test set: Average loss: 0.0063, MSE: 0.006346110254526138 \n",
      "\n",
      "Train Epoch: 6 [0/14770 (0%)]\tLoss: 0.008808\n",
      "Train Epoch: 6 [3000/14770 (20%)]\tLoss: 0.005903\n",
      "Train Epoch: 6 [6000/14770 (41%)]\tLoss: 0.002819\n",
      "Train Epoch: 6 [9000/14770 (61%)]\tLoss: 0.011348\n",
      "Train Epoch: 6 [12000/14770 (81%)]\tLoss: 0.008386\n",
      "\n",
      "Test set: Average loss: 0.0049, MSE: 0.004917127080261707 \n",
      "\n",
      "Train Epoch: 7 [0/14770 (0%)]\tLoss: 0.007950\n",
      "Train Epoch: 7 [3000/14770 (20%)]\tLoss: 0.005673\n",
      "Train Epoch: 7 [6000/14770 (41%)]\tLoss: 0.007609\n",
      "Train Epoch: 7 [9000/14770 (61%)]\tLoss: 0.008490\n",
      "Train Epoch: 7 [12000/14770 (81%)]\tLoss: 0.006955\n",
      "\n",
      "Test set: Average loss: 0.0048, MSE: 0.004786072298884392 \n",
      "\n",
      "Train Epoch: 8 [0/14770 (0%)]\tLoss: 0.003791\n",
      "Train Epoch: 8 [3000/14770 (20%)]\tLoss: 0.005775\n",
      "Train Epoch: 8 [6000/14770 (41%)]\tLoss: 0.005957\n",
      "Train Epoch: 8 [9000/14770 (61%)]\tLoss: 0.002534\n",
      "Train Epoch: 8 [12000/14770 (81%)]\tLoss: 0.005076\n",
      "\n",
      "Test set: Average loss: 0.0039, MSE: 0.0038954662159085274 \n",
      "\n",
      "Train Epoch: 9 [0/14770 (0%)]\tLoss: 0.007343\n",
      "Train Epoch: 9 [3000/14770 (20%)]\tLoss: 0.003750\n",
      "Train Epoch: 9 [6000/14770 (41%)]\tLoss: 0.004057\n",
      "Train Epoch: 9 [9000/14770 (61%)]\tLoss: 0.002017\n",
      "Train Epoch: 9 [12000/14770 (81%)]\tLoss: 0.005316\n",
      "\n",
      "Test set: Average loss: 0.0036, MSE: 0.003648261073976755 \n",
      "\n",
      "Train Epoch: 10 [0/14770 (0%)]\tLoss: 0.003721\n",
      "Train Epoch: 10 [3000/14770 (20%)]\tLoss: 0.001955\n",
      "Train Epoch: 10 [6000/14770 (41%)]\tLoss: 0.003793\n",
      "Train Epoch: 10 [9000/14770 (61%)]\tLoss: 0.003853\n",
      "Train Epoch: 10 [12000/14770 (81%)]\tLoss: 0.006125\n",
      "\n",
      "Test set: Average loss: 0.0035, MSE: 0.0035081286914646626 \n",
      "\n",
      "Train Epoch: 11 [0/14770 (0%)]\tLoss: 0.011097\n",
      "Train Epoch: 11 [3000/14770 (20%)]\tLoss: 0.004394\n",
      "Train Epoch: 11 [6000/14770 (41%)]\tLoss: 0.006226\n",
      "Train Epoch: 11 [9000/14770 (61%)]\tLoss: 0.004197\n",
      "Train Epoch: 11 [12000/14770 (81%)]\tLoss: 0.004022\n",
      "\n",
      "Test set: Average loss: 0.0028, MSE: 0.002773139625787735 \n",
      "\n",
      "Train Epoch: 12 [0/14770 (0%)]\tLoss: 0.002344\n",
      "Train Epoch: 12 [3000/14770 (20%)]\tLoss: 0.004648\n",
      "Train Epoch: 12 [6000/14770 (41%)]\tLoss: 0.005568\n",
      "Train Epoch: 12 [9000/14770 (61%)]\tLoss: 0.003048\n",
      "Train Epoch: 12 [12000/14770 (81%)]\tLoss: 0.004096\n",
      "\n",
      "Test set: Average loss: 0.0028, MSE: 0.002753126434981823 \n",
      "\n",
      "Train Epoch: 13 [0/14770 (0%)]\tLoss: 0.003652\n",
      "Train Epoch: 13 [3000/14770 (20%)]\tLoss: 0.003383\n",
      "Train Epoch: 13 [6000/14770 (41%)]\tLoss: 0.006764\n",
      "Train Epoch: 13 [9000/14770 (61%)]\tLoss: 0.003088\n",
      "Train Epoch: 13 [12000/14770 (81%)]\tLoss: 0.004499\n",
      "\n",
      "Test set: Average loss: 0.0030, MSE: 0.003013298846781254 \n",
      "\n",
      "Train Epoch: 14 [0/14770 (0%)]\tLoss: 0.001374\n",
      "Train Epoch: 14 [3000/14770 (20%)]\tLoss: 0.004201\n",
      "Train Epoch: 14 [6000/14770 (41%)]\tLoss: 0.003800\n",
      "Train Epoch: 14 [9000/14770 (61%)]\tLoss: 0.004653\n",
      "Train Epoch: 14 [12000/14770 (81%)]\tLoss: 0.006073\n",
      "\n",
      "Test set: Average loss: 0.0026, MSE: 0.002588797826319933 \n",
      "\n",
      "Train Epoch: 15 [0/14770 (0%)]\tLoss: 0.002105\n",
      "Train Epoch: 15 [3000/14770 (20%)]\tLoss: 0.003896\n",
      "Train Epoch: 15 [6000/14770 (41%)]\tLoss: 0.008314\n",
      "Train Epoch: 15 [9000/14770 (61%)]\tLoss: 0.004533\n",
      "Train Epoch: 15 [12000/14770 (81%)]\tLoss: 0.004350\n",
      "\n",
      "Test set: Average loss: 0.0031, MSE: 0.0030947457998991013 \n",
      "\n",
      "Train Epoch: 16 [0/14770 (0%)]\tLoss: 0.004467\n",
      "Train Epoch: 16 [3000/14770 (20%)]\tLoss: 0.001043\n",
      "Train Epoch: 16 [6000/14770 (41%)]\tLoss: 0.005377\n",
      "Train Epoch: 16 [9000/14770 (61%)]\tLoss: 0.002909\n",
      "Train Epoch: 16 [12000/14770 (81%)]\tLoss: 0.007334\n",
      "\n",
      "Test set: Average loss: 0.0025, MSE: 0.0024911474902182817 \n",
      "\n",
      "Train Epoch: 17 [0/14770 (0%)]\tLoss: 0.000770\n",
      "Train Epoch: 17 [3000/14770 (20%)]\tLoss: 0.001797\n",
      "Train Epoch: 17 [6000/14770 (41%)]\tLoss: 0.004160\n",
      "Train Epoch: 17 [9000/14770 (61%)]\tLoss: 0.002276\n",
      "Train Epoch: 17 [12000/14770 (81%)]\tLoss: 0.005989\n",
      "\n",
      "Test set: Average loss: 0.0023, MSE: 0.0023132641799747944 \n",
      "\n",
      "Train Epoch: 18 [0/14770 (0%)]\tLoss: 0.002973\n",
      "Train Epoch: 18 [3000/14770 (20%)]\tLoss: 0.001474\n",
      "Train Epoch: 18 [6000/14770 (41%)]\tLoss: 0.007965\n",
      "Train Epoch: 18 [9000/14770 (61%)]\tLoss: 0.002047\n",
      "Train Epoch: 18 [12000/14770 (81%)]\tLoss: 0.004561\n",
      "\n",
      "Test set: Average loss: 0.0023, MSE: 0.0022509698756039143 \n",
      "\n",
      "Train Epoch: 19 [0/14770 (0%)]\tLoss: 0.000757\n",
      "Train Epoch: 19 [3000/14770 (20%)]\tLoss: 0.003722\n",
      "Train Epoch: 19 [6000/14770 (41%)]\tLoss: 0.008021\n",
      "Train Epoch: 19 [9000/14770 (61%)]\tLoss: 0.004245\n",
      "Train Epoch: 19 [12000/14770 (81%)]\tLoss: 0.004498\n",
      "\n",
      "Test set: Average loss: 0.0024, MSE: 0.002380437683314085 \n",
      "\n",
      "Train Epoch: 20 [0/14770 (0%)]\tLoss: 0.001390\n",
      "Train Epoch: 20 [3000/14770 (20%)]\tLoss: 0.005260\n",
      "Train Epoch: 20 [6000/14770 (41%)]\tLoss: 0.005364\n",
      "Train Epoch: 20 [9000/14770 (61%)]\tLoss: 0.001415\n",
      "Train Epoch: 20 [12000/14770 (81%)]\tLoss: 0.004399\n",
      "\n",
      "Test set: Average loss: 0.0025, MSE: 0.0024824757128953934 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 21):\n",
    "    train_model(epoch)\n",
    "    test_model(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction base on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use query function,transform datetime to string\n",
    "def get_str_date(x):\n",
    "    x = str(x)[0:10]\n",
    "    return x\n",
    "\n",
    "scale_train.Date = scale_train.Date.apply(lambda x: get_str_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del scale_train['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test_df and a new train_df\n",
    "test_df = pd.read_csv('/kaggle/input/covid-with-weather-and-population/test_processed.csv')\n",
    "train_df2 =  pd.read_csv('/kaggle/input/covid19-with-population/update_train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.query(\"Date > '2020-04-25'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same preprocess as before\n",
    "train_df2.Country.replace('Cote d\\'Ivoire','Cote d Ivoire',inplace=True)\n",
    "train_df2.Province.replace('Cote d\\'Ivoire','Cote d Ivoire',inplace=True)\n",
    "train_df2.replace(np.inf,0,inplace=True)\n",
    "train_df2.UrbanPopRate = train_df2.UrbanPopRate.apply(lambda x:get_percent(x))\n",
    "\n",
    "test_df.Country.replace('Cote d\\'Ivoire','Cote d Ivoire',inplace=True)\n",
    "test_df.Province.replace('Cote d\\'Ivoire','Cote d Ivoire',inplace=True)\n",
    "test_df.replace(np.inf,0,inplace=True)\n",
    "test_df.UrbanPopRate = test_df.UrbanPopRate.apply(lambda x:get_percent(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train dataframe and test dataframe have same columns\n",
    "test_df['ConfirmedCases'] = np.NAN\n",
    "test_df['Fatalities'] = np.NAN\n",
    "test_df['Id_x'] = 0\n",
    "test_df['Id_y'] = 0\n",
    "test_df = test_df[list(scale_train.columns)]\n",
    "# merge scale_train and test\n",
    "total_df = pd.concat((scale_train,test_df),axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare prediction input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_scaler(country,province):\n",
    "    train_df2_province = train_df2.query(f\"Country == '{country}' and Province =='{province}'\")\n",
    "    train_df2_province_conf = train_df2_province['ConfirmedCases']\n",
    "    train_df2_province_fata = train_df2_province['Fatalities']\n",
    "    province_conf_scaler = preprocessing.MinMaxScaler()\n",
    "    province_fata_scaler = preprocessing.MinMaxScaler()\n",
    "    province_conf_scaler.fit(np.array(train_df2_province_conf).reshape(-1,1))\n",
    "    province_fata_scaler.fit(np.array(train_df2_province_fata).reshape(-1,1))\n",
    "    return province_conf_scaler,province_fata_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_input(country,province,start,end):\n",
    "    input_province = total_df.query(f\"Country =='{country}' and Province == '{province}' and Date>='{start}' and Date<='{end}'\")\n",
    "    input_list_province = []\n",
    "    #prepare all the trend inputs\n",
    "    infection_trend = [float(x) for x in input_province[:-1].ConfirmedCases.values]\n",
    "    fatality_trend = [float(x) for x in input_province[:-1].Fatalities.values]\n",
    "\n",
    "    #preparing all the stable inputs\n",
    "    ##date inputs\n",
    "    days_after_1stJan = float(input_province.iloc[-1].Days_After_1stJan)\n",
    "    dayofweek = float(input_province.iloc[-1].Dayofweek)\n",
    "    month = float(input_province.iloc[-1].Month)\n",
    "    day= float(input_province.iloc[-1].Day)\n",
    "    ##population inputs\n",
    "    'Population','Density', 'Land_Area', 'Migrants', 'MedAge', 'UrbanPopRate'\n",
    "    population = float(input_province.iloc[-1].Population)\n",
    "    density = float(input_province.iloc[-1].Density)\n",
    "    land_area = float(input_province.iloc[-1].Land_Area)\n",
    "    migrants = float(input_province.iloc[-1].Migrants)\n",
    "    medage = float(input_province.iloc[-1].MedAge)\n",
    "    urbanpoprate = float(input_province.iloc[-1].UrbanPopRate)\n",
    "    beds = float(input_province.iloc[-1].API_beds)\n",
    "\n",
    "    input_list_province.append({\"infection_trend\":infection_trend,\n",
    "                     \"fatality_trend\":fatality_trend,\n",
    "                     \"stable_inputs\":[population,density,land_area,migrants,medage,urbanpoprate,beds],})\n",
    "    input_df_province = pd.DataFrame(input_list_province)\n",
    "    input_df_province[\"temporal_inputs\"] = [np.asarray([input_df_province[\"infection_trend\"],input_df_province[\"fatality_trend\"]])]\n",
    "    \n",
    "    province_temporal_train = np.asarray(np.transpose(np.reshape(np.asarray([np.asarray(x) for x in input_df_province[\"temporal_inputs\"].values]),(1,2,sequence_length)),(2,0,1) )).astype(np.float32)\n",
    "    province_stable_train = np.asarray([np.asarray(x) for x in input_df_province[\"stable_inputs\"]]).astype(np.float32)\n",
    "    province_temporal_train = torch.from_numpy(province_temporal_train)\n",
    "    province_stable_train = torch.from_numpy(province_stable_train)\n",
    "    return province_temporal_train,province_stable_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(country,province,trend,stable):\n",
    "    conf_scaler,fata_scaler = get_conf_scaler(country,province)\n",
    "    output = model(trend,stable)\n",
    "    conf_output = conf_scaler.inverse_transform(output[0][0].detach().numpy().reshape(-1,1))\n",
    "    fata_output = fata_scaler.inverse_transform(output[0][1].detach().numpy().reshape(-1,1))\n",
    "    original_output = [conf_output,fata_output]\n",
    "    return output,original_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_for_province(country,province):\n",
    "    start_date = datetime.strptime('2020-04-13','%Y-%m-%d')\n",
    "    end_date = datetime.strptime('2020-04-26','%Y-%m-%d')\n",
    "    pred = []\n",
    "    trend_input,stable_input = get_initial_input(country,province,str(start_date)[0:10],str(end_date)[0:10])\n",
    "    for i in range(0,19):\n",
    "        start = str(start_date+timedelta(days = i))[0:10]\n",
    "        end = str(end_date+timedelta(days = i))[0:10]\n",
    "        output,original_output = get_pred(country,province,trend_input,stable_input)\n",
    "        pred.append([end,original_output[0],original_output[1]])\n",
    "        trend_input = trend_input[1:]\n",
    "        output_tensor = torch.as_tensor(output)\n",
    "        new = torch.as_tensor(output_tensor.reshape(1,1,2))\n",
    "        trend_input = torch.cat((trend_input,new),0)\n",
    "    pred_for_province = pd.DataFrame(pred,columns=['Date','confirmed_pred','fata_pred'])\n",
    "    pred_for_province['Province'] = province\n",
    "    pred_for_province['Country'] = country\n",
    "    pred_for_province = pred_for_province[['Country','Province','Date','confirmed_pred','fata_pred']]\n",
    "    return pred_for_province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_table = pd.DataFrame(columns = ['Country','Province','Date','confirmed_pred','fata_pred'])\n",
    "for country in test_df.Country.unique():\n",
    "    for province in test_df.query(f\"Country == '{country}'\")['Province'].unique():\n",
    "        province_pred = get_pred_for_province(country,province)\n",
    "        pred_table = pd.concat((pred_table,province_pred),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Province</th>\n",
       "      <th>Date</th>\n",
       "      <th>confirmed_pred</th>\n",
       "      <th>fata_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>[[1479.3992]]</td>\n",
       "      <td>[[47.529827]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>[[1513.97]]</td>\n",
       "      <td>[[48.640118]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>[[1538.581]]</td>\n",
       "      <td>[[49.430218]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>[[1554.7622]]</td>\n",
       "      <td>[[49.949574]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>[[1562.9114]]</td>\n",
       "      <td>[[50.210766]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>[[31.748672]]</td>\n",
       "      <td>[[4.096348]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>[[31.688362]]</td>\n",
       "      <td>[[4.0885606]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>[[31.639093]]</td>\n",
       "      <td>[[4.0821996]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>[[31.599237]]</td>\n",
       "      <td>[[4.077055]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>[[31.568861]]</td>\n",
       "      <td>[[4.0731335]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5947 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country     Province        Date confirmed_pred      fata_pred\n",
       "0   Afghanistan  Afghanistan  2020-04-26  [[1479.3992]]  [[47.529827]]\n",
       "1   Afghanistan  Afghanistan  2020-04-27    [[1513.97]]  [[48.640118]]\n",
       "2   Afghanistan  Afghanistan  2020-04-28   [[1538.581]]  [[49.430218]]\n",
       "3   Afghanistan  Afghanistan  2020-04-29  [[1554.7622]]  [[49.949574]]\n",
       "4   Afghanistan  Afghanistan  2020-04-30  [[1562.9114]]  [[50.210766]]\n",
       "..          ...          ...         ...            ...            ...\n",
       "14     Zimbabwe     Zimbabwe  2020-05-10  [[31.748672]]   [[4.096348]]\n",
       "15     Zimbabwe     Zimbabwe  2020-05-11  [[31.688362]]  [[4.0885606]]\n",
       "16     Zimbabwe     Zimbabwe  2020-05-12  [[31.639093]]  [[4.0821996]]\n",
       "17     Zimbabwe     Zimbabwe  2020-05-13  [[31.599237]]   [[4.077055]]\n",
       "18     Zimbabwe     Zimbabwe  2020-05-14  [[31.568861]]  [[4.0731335]]\n",
       "\n",
       "[5947 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge result for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt(x):\n",
    "    x = datetime.strptime(x,'%Y-%m-%d')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train.Date = original_train.Date.apply(lambda x:get_dt(x))\n",
    "original_train.rename(columns = {'Province_State':'Province','Country_Region':'Country'},inplace = True)\n",
    "for i in range(len(original_train)):\n",
    "    if original_train.Province[i] is np.NaN:\n",
    "        original_train.Province[i] = original_train.Country[i]\n",
    "        \n",
    "for i in range(len(original_train)):\n",
    "    if original_train.Date[i]<datetime.strptime('2020-04-02','%Y-%m-%d') or original_train.Date[i]>datetime.strptime('2020-04-25','%Y-%m-%d'):\n",
    "        original_train.drop(i,inplace=True)\n",
    "        \n",
    "del original_train['Id']\n",
    "#del original_train['Country']\n",
    "\n",
    "original_train.Province.replace('Cote d\\'Ivoire','Cote d Ivoire',inplace=True)\n",
    "#del pred_table['Country']\n",
    "original_train.Date = original_train.Date.apply(lambda x:get_str_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number(x):\n",
    "    return x[0][0]\n",
    "pred_table.confirmed_pred = pred_table.confirmed_pred.apply(lambda x:get_number(x))\n",
    "pred_table.fata_pred = pred_table.fata_pred.apply(lambda x:get_number(x))\n",
    "\n",
    "pred_table.rename(columns = {'confirmed_pred':'ConfirmedCases','fata_pred':'Fatalities'},inplace = True)\n",
    "pred_table.Country.replace('Cote d Ivoire','Cote d\\'Ivoire',inplace = True)\n",
    "pred_table.Province.replace('Cote d Ivoire','Cote d\\'Ivoire',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\n",
    "for i in range(len(original_test)):\n",
    "    if original_test.iloc[i]['Province_State'] is np.NaN:\n",
    "        original_test.iloc[i,1] = original_test.iloc[i,2]\n",
    "        \n",
    "original_test.rename(columns = {'Country_Region':'Country','Province_State':'Province'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([pred_table,original_train],axis = 0,sort = True)\n",
    "final_submit = pd.merge(original_test,final,on = ['Country','Province','Date'],how = 'left')\n",
    "submission = final_submit[['ForecastId','ConfirmedCases','Fatalities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13454</th>\n",
       "      <td>13455</td>\n",
       "      <td>31.748672</td>\n",
       "      <td>4.096348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13455</th>\n",
       "      <td>13456</td>\n",
       "      <td>31.688362</td>\n",
       "      <td>4.088561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13456</th>\n",
       "      <td>13457</td>\n",
       "      <td>31.639093</td>\n",
       "      <td>4.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13457</th>\n",
       "      <td>13458</td>\n",
       "      <td>31.599237</td>\n",
       "      <td>4.077055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13458</th>\n",
       "      <td>13459</td>\n",
       "      <td>31.568861</td>\n",
       "      <td>4.073133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13459 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ForecastId  ConfirmedCases  Fatalities\n",
       "0               1      273.000000    6.000000\n",
       "1               2      281.000000    6.000000\n",
       "2               3      299.000000    7.000000\n",
       "3               4      349.000000    7.000000\n",
       "4               5      367.000000   11.000000\n",
       "...           ...             ...         ...\n",
       "13454       13455       31.748672    4.096348\n",
       "13455       13456       31.688362    4.088561\n",
       "13456       13457       31.639093    4.082200\n",
       "13457       13458       31.599237    4.077055\n",
       "13458       13459       31.568861    4.073133\n",
       "\n",
       "[13459 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
