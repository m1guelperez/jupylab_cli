{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "06e2fc8513afb8499f7323cf375a23d080fe90d5",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I prefer to approach the problem in stages starting with a \"quick and dirty\" (but complete) model and then improving gradually from there. I like to see the bigger picture before focusing on details of the analysis. The dataset is described by the author (Dean De Cock) in https://ww2.amstat.org/publications/jse/v19n3/decock.pdf and it has 34 numeric variables (20 continuous and 14 discrete) and 46 categorical variables (23 nominal and 23 ordinal). It is is small enough to examine in a spreadsheet at first. After reading the data to pandas we split the qualitative variables and replace them with numeric ones (using sklean LabelEncoder) and fill the missing values. We tranform all numeric variables using ln(x+1). Then we apply lasso regression using the Lars method from sklearn. Such model can be done using less than 20 lines of code and it produces prediction which ranks better than average (730 out of 1800 submissions with the test error 0.128 and about the same train error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "92d6131a-dc8f-487b-be14-e9962b497afc",
    "_execution_state": "idle",
    "_uuid": "581114a0baf1a19a450e0a121582f47fe7318a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12953649785\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train=pd.read_csv(\"../input/train.csv\")\n",
    "test=pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "y_train = train['SalePrice']\n",
    "train = pd.concat((train,test)).reset_index(drop=True)\n",
    "train.drop(['Id','SalePrice'], axis = 1, inplace = True)\n",
    "\n",
    "qualitative = [f for f in train.columns if train.dtypes[f] == 'object']\n",
    "train[qualitative] = train[qualitative].fillna('Missing')\n",
    "for c in qualitative:  \n",
    "    le = LabelEncoder().fit(list(train[c].values)) \n",
    "    train[c] = le.transform(list(train[c].values))\n",
    "    \n",
    "quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\n",
    "for item in quantitative:\n",
    "    train[item] = np.log1p(train[item].values)\n",
    "\n",
    "X_train = train[:len(y_train)].fillna(0)\n",
    "X_test = train[len(y_train):].fillna(0)\n",
    "                        \n",
    "model = linear_model.LassoLarsCV()\n",
    "model.fit(X_train, np.log(y_train))\n",
    "\n",
    "prediction = pd.DataFrame({\"Id\": test[\"Id\"], \"SalePrice\": np.exp(model.predict(X_test))})\n",
    "prediction.to_csv('house_submission1.csv', index=False)   \n",
    "\n",
    "print(np.sqrt(np.sum(np.square(np.log(y_train)-model.predict(X_train)))/len(y_train)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
