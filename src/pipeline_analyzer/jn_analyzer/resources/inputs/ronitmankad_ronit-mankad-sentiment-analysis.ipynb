{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "1. Model Used: Simple Dense Neural Network trained on TFIDF Vectors\n",
    "2. Learning Rate: 0.001\n",
    "3. Criterion: BCELoss\n",
    "4. Optimizer: Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'train.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "print(os.listdir('../input/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Importing the Train CSV and splitting into train and val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I have done a lot of international travel, bot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>One of the most frightening game experiences e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I was amazingly impressed by this movie. It co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This film is stale, and misses the mark. It is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>At last!! Sandra Bullock is indeed a beautiful...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             review  sentiment\n",
       "0   0  I have done a lot of international travel, bot...          1\n",
       "1   1  One of the most frightening game experiences e...          1\n",
       "2   2  I was amazingly impressed by this movie. It co...          1\n",
       "3   3  This film is stale, and misses the mark. It is...          0\n",
       "4   4  At last!! Sandra Bullock is indeed a beautiful...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF = pd.read_csv('../input/train.csv')\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(trainDF['review'], trainDF['sentiment'], test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: *Most Important*, Creating the TFIDF Vectors for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=25000)\n",
    "tfidf_vect.fit(trainDF['review'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xval_tfidf = tfidf_vect.transform(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Sparse matrix into a numpy array\n",
    "xtrain_tfidf = xtrain_tfidf.toarray()\n",
    "xval_tfidf = xval_tfidf.toarray()\n",
    "# Converting pandas Series into numpy array\n",
    "train_y = np.array(train_y)\n",
    "val_y = np.array(val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Converting the Numpy arrays into Pytorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(xtrain_tfidf).double(), torch.from_numpy(train_y).double())\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(xval_tfidf).double(), torch.from_numpy(val_y).double())\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=64)\n",
    "\n",
    "dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "epochs = 30\n",
    "input_dim = 25000\n",
    "output_dim = 1\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Defining a Simple Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(input_dim, 2048),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(2048, 256),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, output_dim),\n",
    "                      nn.Sigmoid()).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Defining the Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    model = model.cuda()\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(int(epochs)):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        model.train()\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        else:\n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            for inputs, labels in val_dataloader:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                outputs = model(inputs)\n",
    "                predictions = torch.round(outputs.squeeze())\n",
    "                loss = criterion(predictions, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                equals = (predictions == labels.data)\n",
    "    \n",
    "                num_correct += torch.sum(equals.data).item()\n",
    "            \n",
    "            val_acc = num_correct / len(val_dataset)\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print('---------Epoch {} -----------'.format(epoch))\n",
    "        print('Train Loss: {:.6f} Val Loss: {:.6f} Val Accuracy: {:.6f}'.format(\n",
    "                 train_loss/len(train_dataset), val_loss/len(val_dataset), val_acc))\n",
    "        \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Epoch 0 -----------\n",
      "Train Loss: 0.009009 Val Loss: 0.008801 Val Accuracy: 0.873429\n",
      "---------Epoch 1 -----------\n",
      "Train Loss: 0.008401 Val Loss: 0.008789 Val Accuracy: 0.891714\n",
      "---------Epoch 2 -----------\n",
      "Train Loss: 0.008283 Val Loss: 0.008736 Val Accuracy: 0.899429\n",
      "---------Epoch 3 -----------\n",
      "Train Loss: 0.008223 Val Loss: 0.008849 Val Accuracy: 0.891143\n",
      "---------Epoch 4 -----------\n",
      "Train Loss: 0.008188 Val Loss: 0.008824 Val Accuracy: 0.892857\n",
      "---------Epoch 5 -----------\n",
      "Train Loss: 0.008162 Val Loss: 0.008844 Val Accuracy: 0.891143\n",
      "---------Epoch 6 -----------\n",
      "Train Loss: 0.008142 Val Loss: 0.008811 Val Accuracy: 0.892286\n",
      "---------Epoch 7 -----------\n",
      "Train Loss: 0.008133 Val Loss: 0.008794 Val Accuracy: 0.890000\n",
      "---------Epoch 8 -----------\n",
      "Train Loss: 0.008136 Val Loss: 0.009025 Val Accuracy: 0.878571\n",
      "---------Epoch 9 -----------\n",
      "Train Loss: 0.008122 Val Loss: 0.008831 Val Accuracy: 0.893429\n",
      "---------Epoch 10 -----------\n",
      "Train Loss: 0.008124 Val Loss: 0.008792 Val Accuracy: 0.892000\n",
      "---------Epoch 11 -----------\n",
      "Train Loss: 0.008111 Val Loss: 0.008853 Val Accuracy: 0.890571\n",
      "---------Epoch 12 -----------\n",
      "Train Loss: 0.008111 Val Loss: 0.008834 Val Accuracy: 0.889429\n",
      "---------Epoch 13 -----------\n",
      "Train Loss: 0.008112 Val Loss: 0.008759 Val Accuracy: 0.895429\n",
      "---------Epoch 14 -----------\n",
      "Train Loss: 0.008094 Val Loss: 0.008928 Val Accuracy: 0.886286\n",
      "---------Epoch 15 -----------\n",
      "Train Loss: 0.008097 Val Loss: 0.008830 Val Accuracy: 0.887429\n",
      "---------Epoch 16 -----------\n",
      "Train Loss: 0.008090 Val Loss: 0.008853 Val Accuracy: 0.886000\n",
      "---------Epoch 17 -----------\n",
      "Train Loss: 0.008085 Val Loss: 0.008815 Val Accuracy: 0.891143\n",
      "---------Epoch 18 -----------\n",
      "Train Loss: 0.008077 Val Loss: 0.008768 Val Accuracy: 0.894000\n",
      "---------Epoch 19 -----------\n",
      "Train Loss: 0.008079 Val Loss: 0.008901 Val Accuracy: 0.889143\n",
      "---------Epoch 20 -----------\n",
      "Train Loss: 0.008074 Val Loss: 0.008774 Val Accuracy: 0.892857\n",
      "---------Epoch 21 -----------\n",
      "Train Loss: 0.008078 Val Loss: 0.008775 Val Accuracy: 0.894571\n",
      "---------Epoch 22 -----------\n",
      "Train Loss: 0.008067 Val Loss: 0.008774 Val Accuracy: 0.883429\n",
      "---------Epoch 23 -----------\n",
      "Train Loss: 0.008079 Val Loss: 0.008845 Val Accuracy: 0.893143\n",
      "---------Epoch 24 -----------\n",
      "Train Loss: 0.008068 Val Loss: 0.008759 Val Accuracy: 0.892857\n",
      "---------Epoch 25 -----------\n",
      "Train Loss: 0.008060 Val Loss: 0.008799 Val Accuracy: 0.894857\n",
      "---------Epoch 26 -----------\n",
      "Train Loss: 0.008051 Val Loss: 0.008752 Val Accuracy: 0.897714\n",
      "---------Epoch 27 -----------\n",
      "Train Loss: 0.008058 Val Loss: 0.008784 Val Accuracy: 0.897429\n",
      "---------Epoch 28 -----------\n",
      "Train Loss: 0.008050 Val Loss: 0.008774 Val Accuracy: 0.890000\n",
      "---------Epoch 29 -----------\n",
      "Train Loss: 0.008056 Val Loss: 0.008807 Val Accuracy: 0.890571\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Load the test csv and create the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')\n",
    "xtest_tfidf =  tfidf_vect.transform(test_df['review'])\n",
    "xtest_tfidf = xtest_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.zeros(xtest_tfidf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = classifier.predict(xtest_tfidf)\n",
    "test_dataset = TensorDataset(torch.from_numpy(xtest_tfidf), torch.from_numpy(test_y))\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Predicting on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for inputs, _ in test_dataloader:\n",
    "        inputs = inputs.cuda()\n",
    "        output = model(inputs)\n",
    "        preds = torch.round(output)\n",
    "        predictions.extend([p.item() for p in preds])\n",
    "    return predictions\n",
    "\n",
    "predictions = predict(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame()\n",
    "sub_df['Id'] = test_df['Id']\n",
    "sub_df['sentiment'] = [int(p) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  sentiment\n",
       "0  35000          1\n",
       "1  35001          0\n",
       "2  35002          0\n",
       "3  35003          0\n",
       "4  35004          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('my_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
