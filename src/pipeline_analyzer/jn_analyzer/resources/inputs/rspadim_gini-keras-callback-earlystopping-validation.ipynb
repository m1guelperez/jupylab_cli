{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ac228e73-0ffa-4dee-97bd-6249e361bde3",
    "_uuid": "17f6bcd35060823c600f9f9a27f8134a47003845"
   },
   "source": [
    "Motivation: auc/gini with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2cb538a0-e640-4362-a736-cb26f64dbae1",
    "_uuid": "da301e76f462e3594e18add4aee3b5449b80a9b6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "8fb03ab7-4c63-4668-9c4e-be07b8b91fd6",
    "_uuid": "c0cde987ee904bffe6d8e601b99c396c92fb73d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "print('Reading files')\n",
    "train  =pd.read_csv(\"../input/train.csv\")\n",
    "test   =pd.read_csv(\"../input/test.csv\")\n",
    "col_x= train.columns.drop(['target'])\n",
    "col  = train.columns.drop(['id','target'])\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fa54554a-4b3d-489e-b593-6df810587ccd",
    "_uuid": "5e41fb3d1157e0df879613ccd2ba3148237ebcbe"
   },
   "source": [
    "Blablah keras toys you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0b82e77f-cbef-41a3-9a74-05fb54c7cfb7",
    "_uuid": "7eb208ddeec475acb30cd27b8774236eb69dd1f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4188a5de-c98b-4940-92a4-08e69c6c2d34",
    "_uuid": "7145ac7f914a5d891dcb8f21b802cf5c57e46ede"
   },
   "source": [
    "Kaggle discussion/kernels metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "54947964-db5f-468e-a0fd-81316b4b99c9",
    "_uuid": "aac1908563fd37d5be03a4911e89df189c773c6d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score\n",
    "\n",
    "# FROM https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41108\n",
    "def jacek_auc(y_true, y_pred):\n",
    "   score, up_opt = tf.metrics.auc(y_true, y_pred)\n",
    "   #score, up_opt = tf.contrib.metrics.streaming_auc(y_pred, y_true)    \n",
    "   K.get_session().run(tf.local_variables_initializer())\n",
    "   with tf.control_dependencies([up_opt]):\n",
    "       score = tf.identity(score)\n",
    "   return score\n",
    "\n",
    "# FROM https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41015\n",
    "# AUC for a binary classifier\n",
    "def discussion41015_auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "\n",
    "#---------------------\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "\n",
    "#----------------\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "baa50a2f-3306-43c5-936c-1d021e12587b",
    "_uuid": "88154d25124b0b82c936139a5550e44dc6a0a074"
   },
   "source": [
    "Any model, just an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "94410713-e1c6-4de6-a012-e8e4ccf1f358",
    "_uuid": "63f5c1587a1265e66912d41d32ed07f4758b1254",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_relu1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=57, activation='relu', name='in'))\n",
    "    model.add(Dense(   1, activation='sigmoid', name='out'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[jacek_auc,discussion41015_auc])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e8131ec9-865b-4c1a-afdb-8a7c18155f40",
    "_uuid": "43290a586cc0dffe8a82952eebc5baad35b86f40"
   },
   "source": [
    "# Option 1 - magic , create an callback and handle everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8cb8e3ef-6445-4266-89f0-2ddcb9d2ea99",
    "_uuid": "45ae4b3b93e90780d0959938a072e233c139202b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#go here, it's easier to understand callbacks reading keras source code:\n",
    "#   https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L838\n",
    "#   https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L1040\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class GiniWithEarlyStopping(keras.callbacks.Callback):\n",
    "    def __init__(self, min_delta=0, patience=0, verbose=0, predict_batch_size=1024):\n",
    "        #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n",
    "        \n",
    "        # FROM EARLY STOP\n",
    "        super(GiniWithEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.min_delta = min_delta\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.monitor_op = np.greater\n",
    "        self.predict_batch_size=predict_batch_size\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        if(self.verbose > 1):\n",
    "            if(batch!=0):\n",
    "                print(\"\")\n",
    "            print(\"Hi! on_batch_begin() , batch=\",batch,\",logs:\",logs)\n",
    "            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if(self.verbose > 1):\n",
    "            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n",
    "            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        if(self.verbose > 1):\n",
    "            print(\"Hi! on_train_begin() ,logs:\",logs)\n",
    "            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n",
    "\n",
    "        # FROM EARLY STOP\n",
    "        # Allow instances to be re-used\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = -np.Inf\n",
    "    \n",
    "    def on_train_end(self, logs={}):\n",
    "        if(self.verbose > 1):\n",
    "            print(\"Hi! on_train_end() ,logs:\",logs)\n",
    "            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n",
    "\n",
    "        # FROM EARLY STOP\n",
    "        if self.stopped_epoch > 0 and self.verbose > 0:\n",
    "            print('Epoch ',self.stopped_epoch,': GiniEarlyStopping')\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        if(self.verbose > 1):\n",
    "            print(\"Hi! on_epoch_begin() , epoch=\",epoch,\",logs:\",logs)\n",
    "            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(self.validation_data):\n",
    "            y_hat_val=self.model.predict(self.validation_data[0],batch_size=self.predict_batch_size)\n",
    "            \n",
    "        if(self.verbose > 1):\n",
    "            print(\"Hi! on_epoch_end() , epoch=\",epoch,\",logs:\",logs)\n",
    "            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n",
    "        \n",
    "        #i didn't found train data to check gini on train set (@TODO HERE)\n",
    "        # from source code of Keras: https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L1127\n",
    "        # for cbk in callbacks:\n",
    "        #     cbk.validation_data = val_ins\n",
    "        # Probably we will need to change keras... \n",
    "        # \n",
    "        \n",
    "            print(\"    GINI Callback:\")\n",
    "            if(self.validation_data):\n",
    "                print('        validation_data.inputs       : ',np.shape(self.validation_data[0]))\n",
    "                print('        validation_data.targets      : ',np.shape(self.validation_data[1]))\n",
    "                print(\"        roc_auc_score(y_real,y_hat)  : \",roc_auc_score(self.validation_data[1], y_hat_val ))\n",
    "                print(\"        gini_normalized(y_real,y_hat): \",gini_normalized(self.validation_data[1], y_hat_val))\n",
    "                print(\"        roc_auc_scores*2-1           : \",roc_auc_score(self.validation_data[1], y_hat_val)*2-1)\n",
    "        \n",
    "            print('    Logs (others metrics):',logs)\n",
    "        # FROM EARLY STOP\n",
    "        if(self.validation_data):\n",
    "            if (self.verbose == 1):\n",
    "                print(\"\\n GINI Callback:\",gini_normalized(self.validation_data[1], y_hat_val))\n",
    "            current = gini_normalized(self.validation_data[1], y_hat_val)\n",
    "            \n",
    "            # we can include an \"gambiarra\" (very usefull brazilian portuguese word)\n",
    "            # to logs (scores) and use others callbacks too....\n",
    "            # logs['gini_val']=current\n",
    "            \n",
    "            if self.monitor_op(current - self.min_delta, self.best):\n",
    "                self.best = current\n",
    "                self.wait = 0\n",
    "            else:\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    self.stopped_epoch = epoch\n",
    "                    self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "e851e72e-9531-4574-abab-83fcceda67f5",
    "_uuid": "7eb7e7fa25e9e8ca36da9878c9030df574830f33",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Hi! on_train_begin() ,logs: {}\n",
      "Hi! on_epoch_begin() , epoch= 0 ,logs: {}\n",
      "Epoch 1/100\n",
      "Hi! on_batch_begin() , batch= 0 ,logs: {'batch': 0, 'size': 500}\n",
      "Hi! on_batch_end() , batch= 0 ,logs: {'batch': 0, 'size': 500, 'loss': 0.46887365, 'jacek_auc': 0.0, 'discussion41015_auc': 0.4920834}\n",
      "500/800 [=================>............] - ETA: 1s - loss: 0.4689 - jacek_auc: 0.0000e+00 - discussion41015_auc: 0.4921\n",
      "Hi! on_batch_begin() , batch= 1 ,logs: {'batch': 1, 'size': 300}\n",
      "Hi! on_batch_end() , batch= 1 ,logs: {'batch': 1, 'size': 300, 'loss': 0.21426727, 'jacek_auc': 0.4925521, 'discussion41015_auc': 0.45023149}\n",
      "Hi! on_epoch_end() , epoch= 0 ,logs: {'val_loss': 0.14205174148082733, 'val_jacek_auc': 0.48828127980232239, 'val_discussion41015_auc': 0.36224490404129028, 'loss': 0.3733962569385767, 'jacek_auc': 0.18470703810453415, 'discussion41015_auc': 0.47638893499970436}\n",
      "    GINI Callback:\n",
      "        validation_data.inputs       :  (200, 57)\n",
      "        validation_data.targets      :  (200, 1)\n",
      "        roc_auc_score(y_real,y_hat)  :  0.484693877551\n",
      "        gini_normalized(y_real,y_hat):  -0.030612244898\n",
      "        roc_auc_scores*2-1           :  -0.030612244898\n",
      "    Logs (others metrics): {'val_loss': 0.14205174148082733, 'val_jacek_auc': 0.48828127980232239, 'val_discussion41015_auc': 0.36224490404129028, 'loss': 0.3733962569385767, 'jacek_auc': 0.18470703810453415, 'discussion41015_auc': 0.47638893499970436}\n",
      "800/800 [==============================] - 4s - loss: 0.3734 - jacek_auc: 0.1847 - discussion41015_auc: 0.4764 - val_loss: 0.1421 - val_jacek_auc: 0.4883 - val_discussion41015_auc: 0.3622\n",
      "Hi! on_epoch_begin() , epoch= 1 ,logs: {}\n",
      "Epoch 2/100\n",
      "Hi! on_batch_begin() , batch= 0 ,logs: {'batch': 0, 'size': 500}\n",
      "Hi! on_batch_end() , batch= 0 ,logs: {'batch': 0, 'size': 500, 'loss': 0.29410082, 'jacek_auc': 0.52651012, 'discussion41015_auc': 0.42202362}\n",
      "500/800 [=================>............] - ETA: 0s - loss: 0.2941 - jacek_auc: 0.5265 - discussion41015_auc: 0.4220\n",
      "Hi! on_batch_begin() , batch= 1 ,logs: {'batch': 1, 'size': 300}\n",
      "Hi! on_batch_end() , batch= 1 ,logs: {'batch': 1, 'size': 300, 'loss': 0.30443293, 'jacek_auc': 0.50697064, 'discussion41015_auc': 0.15034483}\n",
      "Hi! on_epoch_end() , epoch= 1 ,logs: {'val_loss': 0.18659481406211853, 'val_jacek_auc': 0.51007848978042603, 'val_discussion41015_auc': 0.23341836035251617, 'loss': 0.29797536134719849, 'jacek_auc': 0.51918281614780426, 'discussion41015_auc': 0.32014407776296139}\n",
      "    GINI Callback:\n",
      "        validation_data.inputs       :  (200, 57)\n",
      "        validation_data.targets      :  (200, 1)\n",
      "        roc_auc_score(y_real,y_hat)  :  0.496173469388\n",
      "        gini_normalized(y_real,y_hat):  -0.00765306122449\n",
      "        roc_auc_scores*2-1           :  -0.00765306122449\n",
      "    Logs (others metrics): {'val_loss': 0.18659481406211853, 'val_jacek_auc': 0.51007848978042603, 'val_discussion41015_auc': 0.23341836035251617, 'loss': 0.29797536134719849, 'jacek_auc': 0.51918281614780426, 'discussion41015_auc': 0.32014407776296139}\n",
      "800/800 [==============================] - 0s - loss: 0.2980 - jacek_auc: 0.5192 - discussion41015_auc: 0.3201 - val_loss: 0.1866 - val_jacek_auc: 0.5101 - val_discussion41015_auc: 0.2334\n",
      "Hi! on_epoch_begin() , epoch= 2 ,logs: {}\n",
      "Epoch 3/100\n",
      "Hi! on_batch_begin() , batch= 0 ,logs: {'batch': 0, 'size': 500}\n",
      "Hi! on_batch_end() , batch= 0 ,logs: {'batch': 0, 'size': 500, 'loss': 0.32033917, 'jacek_auc': 0.5238409, 'discussion41015_auc': 0.19279015}\n",
      "500/800 [=================>............] - ETA: 0s - loss: 0.3203 - jacek_auc: 0.5238 - discussion41015_auc: 0.1928\n",
      "Hi! on_batch_begin() , batch= 1 ,logs: {'batch': 1, 'size': 300}\n",
      "Hi! on_batch_end() , batch= 1 ,logs: {'batch': 1, 'size': 300, 'loss': 0.49257466, 'jacek_auc': 0.52223176, 'discussion41015_auc': 0.11321638}\n",
      "Hi! on_epoch_end() , epoch= 2 ,logs: {'val_loss': 0.19684718549251556, 'val_jacek_auc': 0.51045536994934082, 'val_discussion41015_auc': 0.23214283585548401, 'loss': 0.38492748141288757, 'jacek_auc': 0.52323747426271439, 'discussion41015_auc': 0.16294998582452536}\n",
      "    GINI Callback:\n",
      "        validation_data.inputs       :  (200, 57)\n",
      "        validation_data.targets      :  (200, 1)\n",
      "        roc_auc_score(y_real,y_hat)  :  0.49362244898\n",
      "        gini_normalized(y_real,y_hat):  -0.0127551020408\n",
      "        roc_auc_scores*2-1           :  -0.0127551020408\n",
      "    Logs (others metrics): {'val_loss': 0.19684718549251556, 'val_jacek_auc': 0.51045536994934082, 'val_discussion41015_auc': 0.23214283585548401, 'loss': 0.38492748141288757, 'jacek_auc': 0.52323747426271439, 'discussion41015_auc': 0.16294998582452536}\n",
      "800/800 [==============================] - 0s - loss: 0.3849 - jacek_auc: 0.5232 - discussion41015_auc: 0.1629 - val_loss: 0.1968 - val_jacek_auc: 0.5105 - val_discussion41015_auc: 0.2321\n",
      "Hi! on_train_end() ,logs: {}\n",
      "Epoch  2 : GiniEarlyStopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6e2bc75f8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# reduce train size, just to this kernel example\n",
    "t=train[0:1000]\n",
    "# batch_size=500 ~= 2 batchs\n",
    "estimator = KerasClassifier(build_fn=model_relu1, nb_epoch=3, batch_size=500, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "cb = [\n",
    "    # verbose =2 make many prints (nice to learn keras callback)\n",
    "    GiniWithEarlyStopping(patience=1, verbose=2) \n",
    "]\n",
    "\n",
    "estimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2beedcc0-c093-4a4c-8ba9-e00148ab5857",
    "_uuid": "a06a5922d2b239def68e5cb3dfe3f4613a808a81",
    "collapsed": true
   },
   "source": [
    "I don't know why the last line \" < keras.callbacks.History at 0x..... > \" anyone please check it and comment to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "fa405dab-ef65-4528-a722-5dfbfa320d8d",
    "_uuid": "21d50cd93e1c8a66bda0dff4f323ad7924a1bd81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "500/800 [=================>............] - ETA: 1s - loss: 0.2019 - jacek_auc: 0.0000e+00 - discussion41015_auc: 0.5649\n",
      " GINI Callback: 0.0892857142857\n",
      "800/800 [==============================] - 5s - loss: 0.2309 - jacek_auc: 0.2132 - discussion41015_auc: 0.4864 - val_loss: 0.1062 - val_jacek_auc: 0.5061 - val_discussion41015_auc: 0.5255\n",
      "Epoch 2/100\n",
      "500/800 [=================>............] - ETA: 0s - loss: 0.1959 - jacek_auc: 0.5178 - discussion41015_auc: 0.4669\n",
      " GINI Callback: 0.0612244897959\n",
      "800/800 [==============================] - 0s - loss: 0.1883 - jacek_auc: 0.5106 - discussion41015_auc: 0.5392 - val_loss: 0.1664 - val_jacek_auc: 0.5234 - val_discussion41015_auc: 0.5281\n",
      "Epoch  1 : GiniEarlyStopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6c8fe3048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = [\n",
    "    # verbose =1 print gini per epoch\n",
    "    GiniWithEarlyStopping(patience=1, verbose=1) \n",
    "]\n",
    "\n",
    "estimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f32ff083-d86d-496e-a2f8-1cf104de4ae8",
    "_uuid": "9b6ba6e17bd863a9637d435ac53d930274c591ab"
   },
   "source": [
    "I don't know why the last line \" < keras.callbacks.History at 0x..... > \" anyone please check it and comment to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "d28cca82-a771-4325-8d3f-bd4fcc9cbc77",
    "_uuid": "3cb9173ecf43c6a4a48491d99a97b1ac4e949d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 5s - loss: 0.2735 - jacek_auc: 0.1710 - discussion41015_auc: 0.4796 - val_loss: 0.1443 - val_jacek_auc: 0.5124 - val_discussion41015_auc: 0.4885\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s - loss: 0.2955 - jacek_auc: 0.5374 - discussion41015_auc: 0.3256 - val_loss: 0.1301 - val_jacek_auc: 0.5104 - val_discussion41015_auc: 0.4936\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s - loss: 0.2370 - jacek_auc: 0.5146 - discussion41015_auc: 0.4312 - val_loss: 0.1250 - val_jacek_auc: 0.5144 - val_discussion41015_auc: 0.5153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6b17ed128>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = [\n",
    "    # verbose =0 don't print\n",
    "    GiniWithEarlyStopping(patience=1, verbose=0) \n",
    "]\n",
    "\n",
    "estimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0ea5f1d3-eb85-4325-853b-f131d434c0ac",
    "_uuid": "adde2a46b4a9f00b272dfd7abb092b39384885de",
    "collapsed": true
   },
   "source": [
    "# Option 2 - magic, Include metric in logs dictionary\n",
    "\n",
    "example with Roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "484b7bcd-a9e9-4db0-88e5-194805ec3056",
    "_uuid": "33426449d0f23ca963d5ca2edd9cf65991257e65",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class RocAucMetricCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, predict_batch_size=1024, include_on_batch=False):\n",
    "        super(RocAucMetricCallback, self).__init__()\n",
    "        self.predict_batch_size=predict_batch_size\n",
    "        self.include_on_batch=include_on_batch\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if(self.include_on_batch):\n",
    "            logs['roc_auc_val']=float('-inf')\n",
    "            if(self.validation_data):\n",
    "                logs['roc_auc_val']=roc_auc_score(self.validation_data[1], \n",
    "                                                  self.model.predict(self.validation_data[0],\n",
    "                                                                     batch_size=self.predict_batch_size))\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('roc_auc_val' in self.params['metrics']):\n",
    "            self.params['metrics'].append('roc_auc_val')\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['roc_auc_val']=float('-inf')\n",
    "        if(self.validation_data):\n",
    "            logs['roc_auc_val']=roc_auc_score(self.validation_data[1], \n",
    "                                              self.model.predict(self.validation_data[0],\n",
    "                                                                 batch_size=self.predict_batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "78a70077-f712-4307-a82c-cc21c4a3b971",
    "_uuid": "8cef5db284ac94619eec45b96b8d92d57420bb4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 7s - loss: 0.3734 - jacek_auc: 0.1847 - discussion41015_auc: 0.4764 - val_loss: 0.1420 - val_jacek_auc: 0.4883 - val_discussion41015_auc: 0.3622 - roc_auc_val: 0.4834\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s - loss: 0.2979 - jacek_auc: 0.5192 - discussion41015_auc: 0.3201 - val_loss: 0.1865 - val_jacek_auc: 0.5101 - val_discussion41015_auc: 0.2334 - roc_auc_val: 0.4962\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s - loss: 0.3850 - jacek_auc: 0.5232 - discussion41015_auc: 0.1627 - val_loss: 0.1970 - val_jacek_auc: 0.5104 - val_discussion41015_auc: 0.2321 - roc_auc_val: 0.4936\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6619e9668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# reduce train size, just to this kernel example\n",
    "t=train[0:1000]\n",
    "# batch_size=500 ~= 2 batchs\n",
    "estimator = KerasClassifier(build_fn=model_relu1, nb_epoch=3, batch_size=500, verbose=1)\n",
    "\n",
    "cb = [\n",
    "    RocAucMetricCallback(), # include it before EarlyStopping!\n",
    "    EarlyStopping(monitor='roc_auc_val',patience=1, verbose=2) \n",
    "]\n",
    "\n",
    "estimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f5b6e9d0-aa07-4e76-aa69-6c1290b70c58",
    "_uuid": "9e8e2f60afdcf429419b29bd2d4781ddd4d51346"
   },
   "source": [
    "\"Epoch 00002: early stopping\" - Nice =D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "4bfda9f3-304a-4714-9d1a-9221174351d1",
    "_uuid": "8a6c4524d709cdba04b493ba9d62e25bfcff3de1",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "500/800 [=================>............] - ETA: 2s - loss: 0.2019 - jacek_auc: 0.0000e+00 - discussion41015_auc: 0.5649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.0.6-py3.6.egg/keras/callbacks.py:496: RuntimeWarning: Early stopping conditioned on metric `roc_auc_val` which is not available. Available metrics are: val_loss,val_jacek_auc,val_discussion41015_auc,loss,jacek_auc,discussion41015_auc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-08a018644acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mRocAucMetricCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# include it before EarlyStopping! i told you...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.0.6-py3.6.egg/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.0.6-py3.6.egg/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.0.6-py3.6.egg/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.0.6-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.0.6-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.0.6-py3.6.egg/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.0.6-py3.6.egg/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    497\u001b[0m             )\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "cb = [\n",
    "    EarlyStopping(monitor='roc_auc_val',patience=1, verbose=2), \n",
    "    RocAucMetricCallback(), # include it before EarlyStopping! i told you...\n",
    "]\n",
    "estimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "e798580a-6f2c-41d1-9845-5ca73972f4a3",
    "_uuid": "8cf4c2e069954e280660958ff47a5db300dc7a49",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
