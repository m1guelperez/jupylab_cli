{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic NLP for ecosustem mapping\n",
    "In this short tutorial you'll learn some basic (high-level) NLP Functionally that may come handy when analysing industries or other topics of interest. We will be using Named Entity Recognition, which is an advanced technique – however, as we will be relying on the Spacy library, we don't have to worry about developing the functionality from scratch. This has solved for us and the performance is okay for our demands...\n",
    "\n",
    "In Python (as in many other languages) you can comment things by adding a \"#\". Everything after a # in a line will be ignored by the compiler. Leaving clear comments is good practice, allowing others and yourself – it's so easy to forget code – to understand what you've actually done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 12.6MB/s \r\n",
      "\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 7.4MB 5.5MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.6/site-packages (from newspaper3k) (2.6.0)\r\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\r\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\r\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 42.5MB/s \r\n",
      "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/90/18ac0e5340b6228c25cc8e79835c3811e7553b2b9ae87296dfeb62b7866d/tldextract-2.2.1-py2.py3-none-any.whl (48kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 25.6MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: lxml>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from newspaper3k) (4.2.1)\r\n",
      "Requirement already satisfied: requests>=2.10.0 in /opt/conda/lib/python3.6/site-packages (from newspaper3k) (2.21.0)\r\n",
      "Requirement already satisfied: PyYAML>=3.11 in /opt/conda/lib/python3.6/site-packages (from newspaper3k) (3.12)\r\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /opt/conda/lib/python3.6/site-packages (from newspaper3k) (5.1.0)\r\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: nltk>=3.2.1 in /opt/conda/lib/python3.6/site-packages (from newspaper3k) (3.2.4)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.6/site-packages (from newspaper3k) (4.6.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.3->newspaper3k) (1.12.0)\r\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.6/site-packages (from tldextract>=2.0.1->newspaper3k) (2.6)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from tldextract>=2.0.1->newspaper3k) (39.1.0)\r\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k) (1.22)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k) (2019.3.9)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\r\n",
      "Building wheels for collected packages: jieba3k, feedfinder2, tinysegmenter, feedparser\r\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\r\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\r\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\r\n",
      "  Building wheel for feedparser (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\r\n",
      "Successfully built jieba3k feedfinder2 tinysegmenter feedparser\r\n",
      "Installing collected packages: jieba3k, feedfinder2, tinysegmenter, feedparser, requests-file, tldextract, cssselect, newspaper3k\r\n",
      "Successfully installed cssselect-1.0.3 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.4.3 tinysegmenter-0.3 tldextract-2.2.1\r\n",
      "Collecting newsapi-python\r\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/44/1bcbf1a73fb9fd17047869f1569f4a0d0650b0bc234ba783e497e8984bf3/newsapi-python-0.2.3.tar.gz\r\n",
      "Collecting requests==2.17.1 (from newsapi-python)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/41/f6fdaf24a80c726a72f76b15869a20734b7a527081129a380ddce99ffae0/requests-2.17.1-py2.py3-none-any.whl (87kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 6.1MB/s \r\n",
      "\u001b[?25hCollecting idna<2.6,>=2.5 (from requests==2.17.1->newsapi-python)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/7d/9bbbd7bb35f34b0169542487d2a8859e44306bb2e6a4455d491800a5621f/idna-2.5-py2.py3-none-any.whl (55kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 29.5MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests==2.17.1->newsapi-python) (2019.3.9)\r\n",
      "Collecting urllib3<1.22,>=1.21.1 (from requests==2.17.1->newsapi-python)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/53/f397db567de0aa0e81b211d81c13c41a779f14893e42189cf5bdb97611b2/urllib3-1.21.1-py2.py3-none-any.whl (131kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 14.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests==2.17.1->newsapi-python) (3.0.4)\r\n",
      "Building wheels for collected packages: newsapi-python\r\n",
      "  Building wheel for newsapi-python (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/a0/58/f4/627d98e817f4c1819fc524ec3b3187534f8078e36c0d4048a1\r\n",
      "Successfully built newsapi-python\r\n",
      "\u001b[31mtrackml 0.1.12 has requirement requests>=2.18.4, but you'll have requests 2.17.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mmxnet 1.4.0.post0 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mmxnet 1.4.0.post0 has requirement requests>=2.20.0, but you'll have requests 2.17.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mgoogle-api-core 1.9.0 has requirement requests<3.0.0dev,>=2.18.0, but you'll have requests 2.17.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31manaconda-client 1.6.14 has requirement python-dateutil>=2.6.1, but you'll have python-dateutil 2.6.0 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: idna, urllib3, requests, newsapi-python\r\n",
      "  Found existing installation: idna 2.6\r\n",
      "    Uninstalling idna-2.6:\r\n",
      "      Successfully uninstalled idna-2.6\r\n",
      "  Found existing installation: urllib3 1.22\r\n",
      "    Uninstalling urllib3-1.22:\r\n",
      "      Successfully uninstalled urllib3-1.22\r\n",
      "  Found existing installation: requests 2.21.0\r\n",
      "    Uninstalling requests-2.21.0:\r\n",
      "      Successfully uninstalled requests-2.21.0\r\n",
      "Successfully installed idna-2.5 newsapi-python-0.2.3 requests-2.17.1 urllib3-1.21.1\r\n"
     ]
    }
   ],
   "source": [
    "# Install the libraries needed for getting a list of URLs and for extracting text from articles\n",
    "!pip install newspaper3k\n",
    "!pip install newsapi-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an ! in front of a commant will execute it not in Python but in the undelying system (here Linux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the article-extractor package\n",
    "from newspaper import Article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Loop example\n",
    "numbers = [1,2,3,4,5]\n",
    "for some_happy_number in numbers:\n",
    "    print(some_happy_number * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loops** are a fundamental concept in programming, which allow us to let the computer perform some repetitive task over and over again.\n",
    "Above, you see a loop that takes the numbers 1-5 out of their list \"number\" one by one and displays the product of the respective number multiplied by 2\n",
    "\n",
    "Make sure that you follow the indentation structure in python. Everything that has to happen \"in the loop\" – over and over – has to be on a lower level of indentation than the other code. Usually once you use \":\" which starts a loop, python will indent automatically.\n",
    "\n",
    "Now, let's fetch some article texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list [] called \"urls\" with 2 urls leading to some news articles\n",
    "urls = ['https://techcrunch.com/2019/04/08/iphone-spyware-certificate/', \n",
    " \"https://techcrunch.com/2019/04/07/rise-of-the-snapchat-empire/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the article text\n",
    "article_container = [] #create an empy list\n",
    "\n",
    "for happy_url in urls: #take one url at a time\n",
    "    our_happy_test_article = Article(happy_url) #instantiate it as an \"Article\"\n",
    "    our_happy_test_article.download() #download it\n",
    "    our_happy_test_article.parse() #read it (and try to guess what the title, author etc. are)\n",
    "    article_container.append(our_happy_test_article.text) #extract its text and put it (append) into the empty list created earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a more realistic case, you would like to fetch more than two articles. You probably would also not like to compile the list of urls manually. Well, one way to automatize the process is using the NewsApiClient. It's a programmatic news search engine built for app developers that want to include news-streams in their applications.\n",
    "To use it, please register with them and get a free API-key https://newsapi.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient #import news-api\n",
    "from collections import Counter #import the counter module, which allows to count stuff (useful)\n",
    "import itertools #iterator library that helps performing complex iteration routines (e.g. combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example: give me all possible combinations of 2 elements from 1,2,3\n",
    "\n",
    "list(itertools.combinations([1,2,3], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify with the server...\n",
    "\n",
    "# GET your free API key at https://newsapi.org/\n",
    "\n",
    "newsapi = NewsApiClient(api_key='XXXXXXX12345')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NewsAPIException",
     "evalue": "{'status': 'error', 'code': 'apiKeyInvalid', 'message': 'Your API key is invalid or incorrect. Check your key, or go to https://newsapi.org to create a free API key.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNewsAPIException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-997bccefa077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                         \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                         \u001b[0msort_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relevancy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                         \u001b[0mpage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                                         \u001b[0;31m#from_param = start_date,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                         \u001b[0;31m#to = end_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/newsapi/newsapi_client.py\u001b[0m in \u001b[0;36mget_everything\u001b[0;34m(self, q, sources, domains, from_param, to, language, sort_by, page, page_size)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# Check Status of Request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNewsAPIException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewsAPIException\u001b[0m: {'status': 'error', 'code': 'apiKeyInvalid', 'message': 'Your API key is invalid or incorrect. Check your key, or go to https://newsapi.org to create a free API key.'}"
     ]
    }
   ],
   "source": [
    "# Let's fetch urls for 100 most relevant articles for the query: \"China Artificial Intelligence\"\n",
    "# As you can see, you have many other options inlcuding language and dates\n",
    "all_articles = newsapi.get_everything(q='China Artificial Intelligence',\n",
    "                                        #domains = \"techcrunch.com\",\n",
    "                                        language='en',\n",
    "                                        sort_by='relevancy',\n",
    "                                        page_size = 100,\n",
    "                                        #from_param = start_date,\n",
    "                                        #to = end_date\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2e46d81ef8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This will display the url of the first article that has been found - Python indices start with 0, R starts with 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'articles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_articles' is not defined"
     ]
    }
   ],
   "source": [
    "# This will display the url of the first article that has been found - Python indices start with 0, R starts with 1\n",
    "\n",
    "all_articles['articles'][0]['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the \"all_articles\" object created above is a dictionary – a list of key-value pairs.\n",
    "More on dictionaries here: https://www.geeksforgeeks.org/python-dictionary/\n",
    "\n",
    "Calling ['articles'] opens up a list with the 100 found articles. Each of these elements are again dictionaries.\n",
    "The structure is thus dict - lists - dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-29b2241e1fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# each element in all_articles['articles']*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0murls_big\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'articles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_articles' is not defined"
     ]
    }
   ],
   "source": [
    "# here we collect all urls into one list.\n",
    "# the below is a list comprehension - a short option in Python to write a loop.\n",
    "# it can be translated into: *Create a list in which you pyt the url that you strip from\n",
    "# each element in all_articles['articles']*\n",
    "\n",
    "urls_big = [x['url'] for x in all_articles['articles']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more on that here: https://www.pythonforbeginners.com/basics/list-comprehensions-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urls_big' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0dc79f1ccca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls_big\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'urls_big' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's fetch all the 100 articles\n",
    "\n",
    "texts = []\n",
    "\n",
    "for url in urls_big:\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    try:\n",
    "      article.parse()\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      continue\n",
    "    texts.append(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is just as before where we only had 2 urls. However, we add some exception handling here. We do that because some news outlets e.g. forbes don't like what we are doing here and will try to block us. When this happens ususually our function would break. For this not to happen, we add the try-except statement, which will attempt to do what we want but skip to the next url in case an error occurs.\n",
    "\n",
    "More on that here: https://www.datacamp.com/community/tutorials/exception-handling-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts seems to be a list of objects that are not purely text but als contain other meta-information\n",
    "# let's make sure that only the text is left\n",
    "texts = [x.text for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick check of how long they are\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downlaod the medium size-model if you work on your computer or google colab (or elsewhere) for now we comment that out \n",
    "# because Kaggle has us covered with the large model\n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing spacy\n",
    "\n",
    "import spacy #load the library\n",
    "nlp = spacy.load('en_core_web_lg') #load the (larg english) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info on Spacy: https://spacy.io/\n",
    "and https://nlpforhackers.io/complete-guide-to-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try out some stuff\n",
    "\n",
    "# product 3 sentences\n",
    "sen1 = \"The weather today is cold and Donald Trump is fun.\"\n",
    "sen2 = \"It's sunny and im HAPPY\"\n",
    "sen3 = \"Everyone is bored and cold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let spacy read and annotate them\n",
    "\n",
    "AI_sen1 = nlp(sen1)\n",
    "AI_sen2 = nlp(sen2)\n",
    "AI_sen3 = nlp(sen3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PERSON'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the 2nd entity type of the first sentence\n",
    "AI_sen1.ents[1].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6b502d45ecf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# let's have it read one of our articles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mAI_texts_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# let's have it read one of our articles\n",
    "\n",
    "AI_texts_0 = nlp(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AI_texts_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5a5d0b4068d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Make a list of entity-texts from all entities in text 0 if the entity is a person\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAI_texts_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PERSON'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'AI_texts_0' is not defined"
     ]
    }
   ],
   "source": [
    "#Make a list of entity-texts from all entities in text 0 if the entity is a person\n",
    "\n",
    "[ent.text for ent in AI_texts_0.ents if ent.label_ == 'PERSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets extract all (location, person, orga : GPE, PERSON, ORG) entities into an empty container\n",
    "\n",
    "container = []\n",
    "\n",
    "for article in texts: # take an article\n",
    "    article_nlp = nlp(article) #read it\n",
    "    entities = [ent.text for ent in article_nlp.ents if ent.label_ == 'GPE'] # extract entities for the single articles\n",
    "    container.extend(entities) # drop them into the \"container\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = Counter(container) #count up stuff in the container\n",
    "people.most_common(100) #show most common 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org = Counter(container)\n",
    "org.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpe = Counter(container)\n",
    "gpe.most_common(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
