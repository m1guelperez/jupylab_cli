{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['covertype_forest.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from torch import nn\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0612e-09, 4.1223e-09, 6.1835e-09])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def grad_example(x,w): #variant 3 \n",
    "    w.requires_grad_(True)\n",
    "    ex = torch.exp(-x.matmul(w))\n",
    "    res = 1/(1+ex)\n",
    "    res.backward()\n",
    "    print(w.grad)\n",
    "x = torch.tensor([1.,2.,3.])\n",
    "w = torch.tensor([2.,3.,4.])\n",
    "grad_example(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_df = pd.read_csv(\"../input/covertype_forest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6 6 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder().fit(cover_df[\"class\"])\n",
    "cover_target = label_encoder.transform(cover_df[\"class\"])\n",
    "print(cover_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "cover_df = cover_df.drop(\"class\",axis=1)\n",
    "df_train, df_test, y_train, y_test = train_test_split(cover_df, cover_target, test_size=0.15, stratify=cover_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elevation', 'aspect', 'slope', 'horizontal_distance_to_hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "to_normalize = [(i, col) for i, col in enumerate(cover_df.columns)\n",
    "                        if not col.startswith('wilderness_area') and not col.startswith('soil_type')]\n",
    "idx_to_normalize = [i for i,col in to_normalize] #номера столбцов\n",
    "columns_to_normalize = [col for i, col in to_normalize] #названия\n",
    "\n",
    "print(columns_to_normalize)\n",
    "print(idx_to_normalize)\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "tensor_train = torch.from_numpy(df_train.values).type(torch.FloatTensor)\n",
    "tensor_test = torch.from_numpy(df_test.values).type(torch.FloatTensor)\n",
    "train_mean = torch.mean(tensor_train[:,idx_to_normalize], dim=0)\n",
    "train_std = torch.std(tensor_train[:,idx_to_normalize], dim=0)\n",
    "\n",
    "tensor_train[:,idx_to_normalize] -= train_mean\n",
    "tensor_train[:,idx_to_normalize] /= train_std\n",
    "tensor_test[:,idx_to_normalize] -= train_mean\n",
    "tensor_test[:,idx_to_normalize] /= train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "y_test_tensor = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "train_ds = TensorDataset(tensor_train, y_train_tensor)\n",
    "test_ds = TensorDataset(tensor_test, y_test_tensor)\n",
    "train_loader = DataLoader(train_ds,batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5311,  1.5348,  0.2564,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6428,  0.3364, -0.8154,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.2841,  1.5616,  1.1942,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 1.1317,  1.7494,  0.6583,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.6812, -0.2181, -0.0116,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6214, -1.1661, -0.8154,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([4, 4, 4, 6, 2, 4, 5, 4, 6, 4, 2, 4, 5, 6, 4, 6, 6, 4, 6, 4, 6, 4, 6, 4,\n",
      "        4, 4, 4, 4, 6, 2, 6, 4, 4, 4, 6, 4, 6, 4, 6, 3, 4, 4, 6, 5, 4, 2, 4, 4,\n",
      "        4, 4, 4, 6, 5, 4, 6, 4, 4, 6, 6, 4, 6, 0, 4, 4, 4, 1, 4, 6, 1, 4, 4, 4,\n",
      "        4, 6, 4, 4, 3, 6, 5, 4, 4, 4, 6, 4, 4, 6, 6, 4, 4, 4, 6, 4, 2, 6, 6, 4,\n",
      "        6, 4, 4, 6, 6, 4, 4, 2, 0, 4, 5, 4, 4, 6, 4, 3, 4, 4, 6, 5, 6, 4, 4, 3,\n",
      "        4, 5, 6, 4, 4, 4, 4, 6, 4, 4, 4, 6, 4, 4, 4, 4, 6, 0, 4, 4, 5, 6, 6, 4,\n",
      "        6, 4, 4, 3, 4, 6, 6, 6, 4, 6, 4, 4, 3, 6, 4, 0, 2, 6, 6, 6, 4, 6, 6, 4,\n",
      "        6, 6, 4, 6, 6, 4, 4, 5, 6, 6, 5, 6, 6, 0, 0, 4, 4, 0, 4, 6, 4, 6, 4, 6,\n",
      "        6, 6, 4, 6, 3, 6, 6, 5, 3, 5, 6, 4, 6, 4, 4, 6, 0, 5, 4, 4, 4, 6, 6, 5,\n",
      "        4, 6, 6, 6, 4, 6, 4, 4, 6, 5, 2, 4, 5, 4, 3, 6, 4, 3, 6, 4, 0, 6, 0, 4,\n",
      "        4, 6, 6, 6, 6, 0, 6, 4, 4, 4, 6, 6, 6, 4, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    print(xx)\n",
    "    print(yy)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_net:\n",
    "    def __init__(self):\n",
    "        self.w_inp = torch.randn(54,200).type(torch.FloatTensor).requires_grad_(True)\n",
    "        self.b_inp = torch.randn(200).type(torch.FloatTensor).requires_grad_(True)\n",
    "        self.w_out = torch.randn(200,7).type(torch.FloatTensor).requires_grad_(True)\n",
    "        self.b_out = torch.randn(7).type(torch.FloatTensor).requires_grad_(True)\n",
    "    def train(self, loader,lr,epoch):\n",
    "        for i in range(epoch):\n",
    "            for xx,yy in loader:\n",
    "                if self.w_inp.grad is not None:\n",
    "                    self.w_inp.grad.zero_()\n",
    "                    self.b_inp.grad.zero_()\n",
    "                    self.w_out.grad.zero_()\n",
    "                    self.b_out.grad.zero_()\n",
    "                h = xx.matmul(self.w_inp) + self.b_inp\n",
    "                h = h.relu()\n",
    "                out = h.matmul(self.w_out) + self.b_out\n",
    "                out = out.log_softmax(dim = 1)\n",
    "                loss = -(1/len(xx))*out[torch.arange(len(xx)),yy].sum()\n",
    "                loss.backward()\n",
    "                with torch.no_grad():\n",
    "                    self.w_inp -= self.w_inp.grad*lr\n",
    "                    self.b_inp -= self.b_inp.grad*lr\n",
    "                    self.w_out -= self.w_out.grad*lr\n",
    "                    self.b_out -= self.b_out.grad*lr\n",
    "            print(i,\"loss: \", loss)\n",
    "    def pred(self,loader):\n",
    "        res = []\n",
    "        for xx,yy in loader:\n",
    "                h = xx.matmul(self.w_inp) + self.b_inp\n",
    "                h = h.relu()\n",
    "                out = h.matmul(self.w_out) + self.b_out\n",
    "                out = out.log_softmax(dim = 1)\n",
    "                res.append(out.argmax(dim=1).numpy())\n",
    "        return res\n",
    "    def predict(self,xx):\n",
    "        h = xx.matmul(self.w_inp) + self.b_inp\n",
    "        h = h.relu()\n",
    "        out = h.matmul(self.w_out) + self.b_out\n",
    "        out = out.log_softmax(dim = 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = my_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  tensor(1.1926, grad_fn=<MulBackward0>)\n",
      "1 loss:  tensor(1.2346, grad_fn=<MulBackward0>)\n",
      "2 loss:  tensor(0.8325, grad_fn=<MulBackward0>)\n",
      "3 loss:  tensor(0.8479, grad_fn=<MulBackward0>)\n",
      "4 loss:  tensor(0.7526, grad_fn=<MulBackward0>)\n",
      "5 loss:  tensor(0.6585, grad_fn=<MulBackward0>)\n",
      "6 loss:  tensor(0.8211, grad_fn=<MulBackward0>)\n",
      "7 loss:  tensor(0.7453, grad_fn=<MulBackward0>)\n",
      "8 loss:  tensor(0.8047, grad_fn=<MulBackward0>)\n",
      "9 loss:  tensor(0.8232, grad_fn=<MulBackward0>)\n",
      "10 loss:  tensor(0.7527, grad_fn=<MulBackward0>)\n",
      "11 loss:  tensor(0.7177, grad_fn=<MulBackward0>)\n",
      "12 loss:  tensor(0.6192, grad_fn=<MulBackward0>)\n",
      "13 loss:  tensor(0.6642, grad_fn=<MulBackward0>)\n",
      "14 loss:  tensor(0.6661, grad_fn=<MulBackward0>)\n",
      "15 loss:  tensor(0.8088, grad_fn=<MulBackward0>)\n",
      "16 loss:  tensor(0.6200, grad_fn=<MulBackward0>)\n",
      "17 loss:  tensor(0.6211, grad_fn=<MulBackward0>)\n",
      "18 loss:  tensor(0.5974, grad_fn=<MulBackward0>)\n",
      "19 loss:  tensor(0.7813, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net.train(train_loader,0.5,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.58      0.31       144\n",
      "           1       0.10      0.72      0.18        29\n",
      "           2       0.28      0.61      0.39       279\n",
      "           3       0.61      0.81      0.70       509\n",
      "           4       0.85      0.78      0.81      8392\n",
      "           5       0.79      0.68      0.73      1294\n",
      "           6       0.78      0.77      0.77      5912\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     16559\n",
      "   macro avg       0.52      0.71      0.56     16559\n",
      "weighted avg       0.80      0.77      0.78     16559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for xx,yy in test_loader:\n",
    "    out = net.predict(xx)\n",
    "    for i in out:\n",
    "        y_pred.append(int(i.argmax()))\n",
    "    for i in yy:\n",
    "        y_true.append(int(i))\n",
    "print(classification_report(y_pred,y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
